
https://solodit.xyz/issues/c-01-users-cant-bridge-funds-back-from-the-app-chain-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        (uint256 tokenFees, uint256 nativeFees) =\n            getFees(withdrawToken, socketController, socketConnector, socketMsgGasLimit, socketPayloadSize);\n        if (tokenAmount > tokenFees) {\n            uint256 tokensToWithdraw = tokenAmount - tokenFees;\n@>          socketController.bridge{ value: nativeFees }({\n                receiver_: receiver,\n                amount_: tokensToWithdraw,\n                msgGasLimit_: socketMsgGasLimit,\n                connector_: socketConnector,\n                execPayload_: abi.encode(),\n                options_: abi.encode()\n            });\n",
        "contract PeripheryRouter is\n    ConfigurationModule,\n    DepositsModule,\n    DepositsFallbackModule,\n    OrderModule,\n    TransfersModule,\n    WithdrawalsModule,\n    OwnerUpgradeModule,\n    ERC721ReceiverModule,\n    FeatureFlagModule\n{ }\n\ncontract PeripheryProxy is UUPSProxyWithOwner, PeripheryRouter {\n    constructor(\n        address firstImplementation,\n        address initialOwner\n    )\n        UUPSProxyWithOwner(firstImplementation, initialOwner)\n    { }\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "The protocol must pay a fee in native coin to bridge funds back from the app chain:",
        "Periphery is the module that interacts with the bridge. The problem is that none of these contracts has payable function to receive ETH"
    ],
    "Recommendations": [
        "",
        "Make sure that PeripheryRouter.sol inherits the module with the function receive() payable"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-attacker-can-drain-periphery-by-specifying-big-socketpayloadsize-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function getFees(...)\n        internal\n        view\n        returns (uint256 feeInToken, uint256 nativeFees)\n    {\n@>      nativeFees = controller.getMinFees(connector, gasLimit, payloadSize);\n        feeInToken = Configuration.getStaticWithdrawFee(token, connector);\n    }\n",
        "    function executeBridging(...)\n        internal\n    {\n        ISocketControllerWithPayload socketController =\n            ISocketControllerWithPayload(Configuration.getController(withdrawToken));\n\n        (uint256 tokenFees, uint256 nativeFees) =\n            getFees(withdrawToken, socketController, socketConnector, socketMsgGasLimit, socketPayloadSize);\n        if (tokenAmount > tokenFees) {\n            uint256 tokensToWithdraw = tokenAmount - tokenFees;\n@>          socketController.bridge{ value: nativeFees }({\n                receiver_: receiver,\n                amount_: tokensToWithdraw,\n                msgGasLimit_: socketMsgGasLimit,\n                connector_: socketConnector,\n                execPayload_: abi.encode(),\n                options_: abi.encode()\n            });\n            withdrawToken.safeTransfer(OwnableStorage.getOwner(), tokenFees);\n        } else {\n            revert Errors.NotEnoughFees(tokenAmount, tokenFees);\n        }\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "When a user withdraws funds from protocol, tokens are bridged to another chain to address receiver. The fee to pay for bridging is based on gasLimit and payloadSize:",
        "User can just set very high payloadSize and protocol will pay high fee:",
        "Note that Socket which is used for bridging doesn't send back excessive msg.value. It treats excessive msg.value as executionFee:\nLink",
        "Another note is that currently payloadSize is not used in fee calculation, but will be in a future version\nlink"
    ],
    "Recommendations": [
        "",
        "Remove argument socketPayloadSize and use 0 instead"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-03-decimals-are-incorrectly-handled-in-divreducernode-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function process(NodeOutput.Data[] memory parentNodeOutputs) internal pure returns (NodeOutput.Data memory) {\n        if (parentNodeOutputs[1].price == 0) {\n            revert InvalidPrice();\n        }\n\n@>      uint256 price = divUintUint(parentNodeOutputs[0].price, parentNodeOutputs[1].price).unwrap();\n        uint256 timestamp = (parentNodeOutputs[0].timestamp + parentNodeOutputs[1].timestamp) / 2;\n\n        return NodeOutput.Data({ price: price, timestamp: timestamp });\n    }\n\n\nfunction divUintUint(uint256 a, uint256 b) pure returns (UD60x18) {\n    return UD60x18.wrap(a).div(UD60x18.wrap(b));\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "Node DivReducer is supposed to have 2 parents which are Redstone oracles and combine 2 prices. For example, to price ETH/USDC it will fetch 2 prices and divide (ETH/USD) / (USDC/USD).",
        "The problem is that Redstone oracles have 8 decimals by default, but the code uses 1e18 arithmetic:",
        "Here you can see the default decimals is 8:\nlink"
    ],
    "Recommendations": [
        "",
        "Normalize the price from RedstoneOracle by decimals of that oracle. Only after using it in internal calculations"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-user-can-lose-tokens-during-deposit-fallback-bridging-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        try DepositsModule(address(this)).depositPassivePool(inputs) { }\n        catch {\n            BridgingUtils.executeBridging({\n                withdrawToken: usdc,\n                socketConnector: fallbackData.socketConnector,\n                socketMsgGasLimit: fallbackData.socketMsgGasLimit,\n                tokenAmount: inputs.amount,\n@>              receiver: inputs.owner,\n                socketPayloadSize: fallbackData.socketPayloadSize\n            });\n        }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "DepositsFallbackModule handles situations where a deposit reverts and initiates bridging back of users' funds. Note that it uses the address receiver of the deposit on the Reya chain to bridge back funds on the source chain:",
        "It incorrectly assumes that the address inputs.owner on the source chain is owned by the same person on Reya chain. There are 2 cases when the assumption is not guaranteed:"
    ],
    "Recommendations": [
        "",
        "Add argument receiver to FallbackData struct and use it instead of inputs.accountOwner in DepositsFallbackModule.sol"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-inadequate-verification-of-tokenamount-leads-to-potential-dust-theft-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "The Periphery's functionality allows bridging of funds between the source chain and the protocol, encompassing integration with the deposit, withdrawal, and transfer functionalities of the Core and Passive Pool. An issue arises when the deposit action fails on the destination chain; the DepositsFallbackModule is designed to catch this failure and refund the user on the source chain via the Socket bridge. The problem occurs when the tokenAmount is lower than the tokenFees (a static fee), leading to a transaction revert due to insufficient fees, consequently trapping the tokenAmount in the periphery. This scenario becomes exploitable due to the absence of verification between the user-input tokenAmount and the bridgeAmount in the BridgingUtils::executeBridging function. Attackers can exploit this by calling DepositsFallbackModule::depositPassivePool with a tokenAmount equating to the Periphery's balance (accumulated from previous users' dust) and a different bridgeAmount, causing a revert in the DepositsModule::depositPassivePool that triggers the BridgingUtils::executeBridging function, thereby bridging the Periphery's balance back to the attacker in the other chain. This issue allows attackers to siphon accumulated dust amounts from the Periphery."
    ],
    "Recommendations": [
        "",
        "To mitigate this vulnerability and safeguard against potential dust theft, it is recommended to:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-stale-price-data-in-divreducer-due-to-average-timestamp-calculation-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "The DivReducer function within the system is designed to calculate the quotient of the prices from two input nodes, typically used for deriving asset prices in alternative currency terms when direct feeds are not available. A critical part of this functionality is the calculation of the updated_at timestamp for the output, which currently averages the timestamps of the two input nodes. This approach introduces a significant risk; if one input node provides a very recent timestamp and the other is significantly stale, the averaged timestamp could misleadingly pass staleness checks, thus presenting the output as more current than it actually is. This can lead to the use of outdated price data in critical financial calculations, potentially affecting all dependent systems relying on the accuracy of this feed for timely decision-making."
    ],
    "Recommendations": [
        "",
        "To mitigate the risk of using stale data and enhance the reliability of the DivReducer node's output, amend the logic for determining the updated_at timestamp of the DivReducerNode output. Instead of averaging the timestamps of the input nodes, use the minimum of the two timestamps. This approach ensures that the output timestamp accurately reflects the freshness of the data, prioritizing the most conservative estimate of data recency."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-lack-of-price-freshness-verification-in-oracle-price-data-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "The getOraclePrice and getCollateralExchangeInfo functions retrieve NodeOutput.Data containing price information and a timestamp indicating the freshness of this price. An issue has been identified wherein these functions use the price data directly without verifying the freshness of the data based on the timestamp. This oversight could lead to scenarios where stale or outdated price data is used in significant financial calculations or decision-making processes."
    ],
    "Recommendations": [
        "",
        "To address this vulnerability and ensure the reliability of price data used throughout the system by introducing logic in both getOraclePrice and getCollateralExchangeInfo functions to check the timestamp of the NodeOutput.Data against a predefined freshness threshold."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-invalid-nodes-can-be-registered-due-to-an-incorrect-check-pashov-none-reyanetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _isValidNodeDefinition(NodeDefinition.Data memory nodeDefinition) internal view returns (bool valid) {\n        if (nodeDefinition.nodeType == NodeDefinition.NodeType.DIV_REDUCER) {\n            //check if parents are processable\n@>          _hasValidParentNodeDefinitions(nodeDefinition);\n        }\n\n        ...\n    }\n\n    function _hasValidParentNodeDefinitions(NodeDefinition.Data memory nodeDefinition)\n        internal\n        view\n        returns (bool valid)\n    {\n        for (uint256 i = 0; i < nodeDefinition.parents.length; i++) {\n            NodeDefinition.Data memory nodeDef = _getNode(nodeDefinition.parents[i]);\n            if (!_isValidNodeDefinition(nodeDef)) {\n                return false;\n            }\n        }\n        return true;\n    }\n",
        "    function _isValidNodeDefinition(NodeDefinition.Data memory nodeDefinition) internal view returns (bool valid) {\n        if (nodeDefinition.nodeType == NodeDefinition.NodeType.DIV_REDUCER) {\n            //check if parents are processable\n-           _hasValidParentNodeDefinitions(nodeDefinition);\n+          if( !_hasValidParentNodeDefinitions(nodeDefinition)) return false;\n        }\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "DivReducer node is supposed to have 2 parent nodes. During registration node is checked to be valid, however it does nothing if parents are invalid:"
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-uniswap-oracle-manipulation-to-buy-for-a-lower-price-pashov-none-forgottenplayland-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "uniswapV2Router.getAmountsIn() is used to calculate the amount of paymentToken required for the amount in referenceToken.\nThis feed is easily manipulated by a large swap in Uniswap pairs.\nSo the attacker can in one transaction:"
    ],
    "Recommendations": [
        "",
        "TWAP is the recommended way of reading the price from Uniswap V2 pairs. But it is also can be manipulated for low liquidity pairs.\nConsider using centralized oracles like Chainlink. E.g. Chainlink feeds can be provided when allowing a token as paymentToken."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-mistake-using-primary-price-for-customsalewithpermit-pashov-none-forgottenplayland-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function customSaleWithPermit(uint256 _amount, PermitSignature calldata _permitSignature, bytes32[] calldata _proof)\n        external\n        nonReentrant\n        customSaleChecks(_permitSignature.owner, _permitSignature.token, _amount, _proof)\n    {\n        ...\n        _collectWithPermit(\n            _amount, getFullCustomPrice(price, _permitSignature.token), saleStruct.referenceToken, _permitSignature\n        );\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "ToyBox uses customSale() and customSaleWithPermit() for non-primary sales, and these functions should not use data from the primary sales.\nBut customSaleWithPermit() uses the price for the primary sale, which likely is not the intended behavior.",
        "As a result, users signing approvals via permit will receive a different price."
    ],
    "Recommendations": [
        "",
        "Replace price with saleStruct.price, as in customSale()."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-bypassing-saleusercap-and-whitelist-pashov-none-forgottenplayland-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    modifier customSaleChecks(address _receiver, address _paymentToken, uint256 _amount, bytes32[] calldata _proof) {\n        ...\n        // If the merkleRoot is set, check if the user is in the list\n        if (saleStruct.merkleRoot != bytes32(0)) {\n            bytes32 leaf = keccak256(abi.encode(msg.sender));\n            if (!MerkleProof.verify(_proof, saleStruct.merkleRoot, leaf)) {\n                revert InvalidProof();\n            }\n        }\n        ...\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "ToyBox.customSaleChecks() does many checks, but this check for a user is very likely wrong:",
        "The problem is that msg.sender is checked, when the \"user\" here is _receiver. It works correctly when they are the same, but it will be wrong in all other cases.\nLater in the code, _receiver is the target for checking saleUserCap, not msg.sender. It allows minting to different receivers bypassing saleUserCap.\nMoreover, msg.sender is checked when calling customSaleWithPermit() which is also probably wrong.\nIn addition, these receivers are not checked for being whitelisted."
    ],
    "Recommendations": [
        "",
        "Replace msg.sender with _receiver in customSaleChecks()."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-force-buy-toybox-for-anyone-who-sets-approval-for-contract-pashov-none-forgottenplayland-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "In ToyBox contract and primarySaleWithPermit() and customSaleWithPermit() code doesn't check that msg.sender is equal to the permitSignature.owner. Also valid permission signature is not enforced in trustlessPermit() so If someone has set approval for the ToyBox contract, it would be possible to call those functions with spoofed permission signature and buy ToyBox token for them without their permission. Attacker can spend all the users' tokens that gave spending allowance and also buy ToyBox when price is not fair."
    ],
    "Recommendations": [
        "",
        "Code should verify msg.sender to be equal to the permitSignature.owner."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-wrong-usage-of-blocks-timestamp-instead-of-blocks-number-pashov-none-forgottenplayland-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        bytes32 pseudoRandomness =\n            keccak256(abi.encode(blockhash(block.timestamp - 1), msg.sender, nonces[msg.sender])) >> 3;\n",
        "blockhash(uint blockNumber) returns (bytes32): hash of the given block - only works for 256 most recent blocks\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "When code wants to get last block hash it uses blockhash(block.timestamp - 1).",
        "But according to Solidity docs:",
        "As a result blockhash(block.timestamp - 1) would be calculated for a nonexisting block and would always result in 0 so the pesudoRandomness would be more predictable and not according to the docs."
    ],
    "Recommendations": [
        "",
        "Change code to blockhash(block.number - 1)."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-toyboxsol-contract-lacks-discounttokens-setter-pashov-none-forgottenplayland-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function getFullPrice(uint256 _price, address _paymentToken) internal view returns (uint256) {\n>>      uint256 _discount = discountTokens[_paymentToken];\n        if (_discount > 0) {\n            _price = _price - (_price * _discount / 10000);\n        }\n        return _price;\n    }\n\n    function getFullCustomPrice(uint256 _price, address _paymentToken) internal view returns (uint256) {\n>>      uint256 _discount = saleTokenDiscounts[customSaleActive][_paymentToken];\n        if (_discount > 0) {\n            _price = _price - (_price * _discount / 10000);\n        }\n        return _price;\n    }\n"
    ],
    "Impact": [
        " Low"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "When user buys a ToyBox token from the sale, a discount is applied to the price",
        "The discountTokens and saleTokenDiscounts mappings store the discount percentages for primary and custom sales, respectively. However, the sale manager is unable to customize discounts for primary sales using discountTokens due to the absence of a setter function, unlike for custom sale discounts managed through setSaleTokenDiscounts/setSaleTokenDiscount functions."
    ],
    "Recommendations": [
        "",
        "Consider either adding functions to set discountTokens[_paymentToken] or remove the step of calculating a discount for primary sales in primarySale() and primarySaleWithPermit()."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-rounding-issue-in-price-formula-pashov-none-sofamon-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        return (\n            (totalSupply * curveFactor) / (totalSupply - x) - (totalSupply * curveFactor) / totalSupply\n                - initialPriceFactor / 1000 * x\n        ) * 1 ether;\n",
        "        return (totalSupply * curveFactor * 1 ether) / (totalSupply - x) - (curveFactor * 1 ether) - initialPriceFactor * x / 1000;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "Here is current formula:",
        "There are several issues:"
    ],
    "Recommendations": [
        "",
        "Here are 1st and 2nd param precision increased to 1e18, and changed order of operations in 3rd param:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-using-the-same-signature-multiple-times-pashov-none-sofamon-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, createSigner signs for the exact amount for a given sale, but in fact, it can be any amount in the end"
    ],
    "Likelihood": [
        " Medium, easily available, requires receiving a signature only once for a private sale"
    ],
    "Description": [
        "",
        "Private sales require a signature from createSigner for a given wearablesSubject+amount, with different signatures for buy and sell.\nBut once signed the signature can be used many times. As a result, in fact, createSigner has no power to control amount for buy and sell operations. It is even possible to arrange a secondary market, where only one signature is used to access anyone to a sale, so the private market will be not so private."
    ],
    "Recommendations": [
        "",
        "Consider having a separate mapping for used signatures or applying an incrementing nonce logic in the signature."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-excessive-msgvalue-lost-when-buying-pashov-none-sofamon-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "msg.value < price + protocolFee + creatorFee\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, funds lost forever"
    ],
    "Likelihood": [
        " Low, requires a mistake from a user"
    ],
    "Description": [
        "",
        "msg.value is considered incorrect only in this equation:",
        "As a result, msg.value above price+fees will pass, but never return and thus lost.",
        "It can happen in case of a mistake from users if they provide the wrong msg.value.",
        "This mistake can be either from fee calculations, or it can be some sell operations before the user, so the total price is less than expected."
    ],
    "Recommendations": [
        "",
        "Consider either having a strict requirement to have msg.value the exact price+fees (better), or return excessive funds back to the user (more risky)."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-balance-going-below-base_wearable_unit-pashov-none-sofamon-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function sellPrivateWearables(bytes32 wearablesSubject, uint256 amount, bytes calldata signature)\n        external\n        payable\n    {\n            // Check if amount is greater than base unit\n            if (amount < BASE_WEARABLE_UNIT) revert InsufficientBaseUnit();\n            ...\n    }\n\n    function transferWearables(bytes32 wearablesSubject, address from, address to, uint256 amount) external {\n        ...\n\n        // Check if amount is greater than base unit\n        if (amount < BASE_WEARABLE_UNIT) revert InsufficientBaseUnit();\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, some balance cannot be sold and transferred, it is small but potentially valuable enough in case of low curveAdjustmentFactor or high supply"
    ],
    "Likelihood": [
        " Medium, just required sending any number not strictly devisable by 0.001 ETH"
    ],
    "Description": [
        "",
        "transferWearables() only requires sending amount above BASE_WEARABLE_UNIT=0.001 ether.\nBut allows sending e.g. 0.0015 ether when the user has 0.002 ether.\n0.0005 ether will remain in this case, below BASE_WEARABLE_UNIT.",
        "The same thing for selling wearables.",
        "This new amount will not pass the minimum requirements in transferWearables() and sell operations. The only option for the user is to buy more wearables to pass the limit."
    ],
    "Recommendations": [
        "",
        "Consider checking that after transfer and a sell operation a user has the balance above BASE_WEARABLE_UNIT"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-last-user-cant-sell-all-his-wearables-pashov-none-sofamon-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function test_custom1() public {\n\n// Setup wearable\n// ------------------------------------------------------------\n        bytes32 wearablesSubject = keccak256(abi.encode(\"test hoodie\", \"hoodie image url\"));\n\n        vm.startPrank(signer1);\n        bytes32 digest = keccak256(\n            abi.encodePacked(creator1, \"test hoodie\", \"hoodie\", \"this is a test hoodie\", \"hoodie image url\")\n        ).toEthSignedMessageHash();\n        (uint8 v, bytes32 r, bytes32 s) = vm.sign(signer1Privatekey, digest);\n        bytes memory signature = abi.encodePacked(r, s, v);\n        vm.stopPrank();\n\n        vm.startPrank(creator1);\n        sofa.createWearable(\n            SofamonWearables.CreateWearableParams({\n                name: \"test hoodie\",\n                category: \"hoodie\",\n                description: \"this is a test hoodie\",\n                imageURI: \"hoodie image url\",\n                isPublic: true,\n                curveAdjustmentFactor: 50_000,\n                signature: signature\n            })\n        );\n        vm.stopPrank();\n// ------------------------------------------------------------\n\n        vm.startPrank(creator1);\n        vm.deal(creator1, 1_000_000 ether);\n\n        uint256 total = 0;\n        // buy 10 batches of wearables\n        for (uint256 i; i < 10; i++) {\n            uint256 amount = 1e18 + 49_999;\n            total += amount;\n            uint256 buyPrice = sofa.getBuyPriceAfterFee(wearablesSubject, amount);\n            sofa.buyWearables{value: buyPrice}(wearablesSubject, amount);\n        }\n\n        console.log(\"sellPrice                \", sofa.getSellPrice(wearablesSubject, total));\n        console.log(\"SofamonWearables balance:\", address(sofa).balance);\n\n        // Sell all wearables\n        //@note However it reverts with `error SendFundsFailed`, because not enough balance in contract\n        sofa.sellWearables(wearablesSubject, total);\n\n        console.log(creator1.balance);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, user can be unable to sell if has only 1 share of Wearable"
    ],
    "Likelihood": [
        " Medium, the last user to sell will get the error."
    ],
    "Description": [
        "",
        "Price calculation rounds down in both situations: buy and sell. Therefore buy price can be lower than the sell price if dividing one purchase into several batches, that's because of rounding down.",
        "There is a possible situation when a lower price is paid on buy compared to the sell.\nAs a result, the contract can calculate the sell price to be greater than the buy price, as shown in this test:",
        "The issue can be avoided if dividing sell on multiple batches, however, it is not possible if the user owns a minimal allowed amount of BASE_WEARABLE_UNIT = 0.001 ether"
    ],
    "Recommendations": [
        "",
        "Round up when calculating the buy price."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-attacker-can-manipulate-the-protocols-aum-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "In the new design, the AUM value will be set and updated by off-chain bot. The issue is that the bot defines the absolute value of the AUM and the Fyde contract changes the current AUM based on the bot-provided value so the attacker can change the current AUM by front-running and causing the wrong AUM value when the bot's transaction executes. This is POC:",
        "In fact, each user would have an incentive to withdraw before the AUM update transaction because AUM is getting decreased. So the protocol would be in an unstable situation and the difference between real AUM and the protocol's AUM would increase."
    ],
    "Recommendations": [
        "",
        "The code should allow for AUM differential updates. For example, the off-chain bot should set the amount that AUM should be decreased or increased, in this way the AUM value always changes in the correct direction."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-user-can-divide-big-depositwithdraw-into-small-parts-to-reduce-tax-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function _computeDepositTaxableAmount(\n    ProcessParam memory processParam,\n    uint256 protocolAUM,\n    uint256 totalUsdDeposit\n  ) internal pure returns (ProcessParam memory) {\n    int256 deltaConc = protocolAUM.toInt()\n      * (processParam.currentConc.toInt() - processParam.targetConc.toInt()) / 1e20;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "Tax to pay depends on how much deposit/withdraw makes current asset concentration deviate from the target value, therefore big amounts will pay bigger tax.\nHowever, users can supply a request array with the same assets, which can significantly reduce the tax to pay. For example, when asset concentration is too low, the tax to pay on deposit for this asset can equal to 0 to incentivize deposits.\nPart of fee calculation that uses delta concentration of deposit works incorrectly when an array with the same assets is supplied. Because initial concentration is used, it's not updated upon iteration:",
        "As a result, delta concentration is undervalued which results in lower tax than intended.",
        "You can see the difference in amounts in these tests."
    ],
    "Recommendations": [
        "",
        "Add duplicate check in deposit() and withdraw()."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-attacker-can-inflate-share-price-and-cause-loss-for-users-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function _convertToShares(uint256 _usdValue, uint256 _usdAUM, uint256 totalTrsySupply)  {\n    return totalTrsySupply == 0 ? _usdValue : (_usdValue * totalTrsySupply) / _usdAUM;\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "When the share amount is calculated and totalSupply is zero, the code uses the deposit amount and doesn't add extra precision, this will give the attacker the ability to inflate the share price up to 1000 * 1e18 and cause a loss for depositors because of rounding error.",
        "This is one example that this could happen:"
    ],
    "Recommendations": [
        "",
        "Add more precision to the share\nfunction _convertToShares(uint256 _usdValue, uint256 _usdAUM, uint256 totalTrsySupply) {\nreturn totalTrsySupply == 0 ? 10^18 _ _usdValue : (_usdValue _ totalTrsySupply) / _usdAUM;\n}"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-user-may-lose-funds-if-there-are-duplicate-tokens-in-the-deposit-list-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "RelayerV2 doesn't check that token lists don't have duplicate items and doesn't support duplicate items in the list. If token lists have duplicate items then users may lose funds because some logics won't work as designed. For example when users set _keepGovRights as True, code loops through the tokens list and unstake all the RelayerV2 remaining balance, and it will cause the user to not receive the duplicate amounts. This is POC:"
    ],
    "Recommendations": [
        "",
        "Make code to support duplicate items or have some checks to ensure the list has no duplicate items or warn users about this risk."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-slippage-check-may-be-inefficient-in-deposit-when-_keepgovrightstrue-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "In deposit() function code checks that slippageChecker with the sum of the minted shares sharesToMint, the issue is that when _keepGovRights = True then the code sends users different sTrsy tokens and there is no slippage check for their values. So even so some of the tokens may be higher than slippageChecker but the user may receive unfavorable sTrsy tokens. This is an issue because the token prices in the Fyde can be higher/lower than real token prices and the code would mint more/less sTrsy tokens for those tokens.",
        "Also, because the code use mint(contract balance, sharesAfterTax) to calculate sTrsy transfer amount, so the total transferred amount can be lower than sharesToMint and the code should check real transferred amounts with slippageChecker."
    ],
    "Recommendations": [
        "",
        "Users should be able to add a slippage amount for each individual sTrsy they receive."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-aum-value-update-can-be-sandwiched-to-extract-value-from-the-protocol-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "Protocol requires the off-chain bot to update AUM value so it can compute the share amount in deposited/withdrawal function and the attacker can use this to his advantage and perform the sandwich attack to extract value from the protocol. This is the POC:"
    ],
    "Recommendations": [
        "",
        "Don't allow withdraw and deposit in the same block for each user to make the attack harder.\nUse the same AUM value for the whole block.\nAdd delay for withdrawal or deposit."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-guardian-cant-unpause-the-relayerv2-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  ///@notice Unpause the protocol\n  function unpauseProtocol() external onlyOwner {\n    paused = false;\n    emit Unpause(block.timestamp);\n  }\n\n  ///@notice Unpause the swaps\n  function unpauseSwap() external onlyOwner {\n    swapPaused = false;\n    emit Unpause(block.timestamp);\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "According to the docs, Guardian should be able to pause/unpause the protocol.",
        "The issue is that the unpause functions access controls don't allow Guardian to unpause the protocol."
    ],
    "Recommendations": [
        "",
        "Allow Guardian to unpause the protocol."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-centralization-risk-that-causes-fund-loss-or-lock-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "There are multiple roles that are crucial for the protocol to work properly like the off-chain bot that updates AUM and the price setter role. If these roles comprised or work expectedly then contract crucial features would not work and users may lose funds. For example:"
    ],
    "Recommendations": [
        "",
        "Add max/min limit for what off-chain operator can set and also update them frequently. Also add longer period price change detection, for example, don't let AUM be changed more than 10% in 5 min."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-oraclemodule-assumes-that-all-chainlink-feeds-have-a-heartbeat-of-24-hours-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function setStalePeriod(uint32 _stalePeriod) public onlyOwner {\n    stalePeriod = _stalePeriod;\n  }\n",
        "  function _isStale(uint256 timestamp) internal view returns (bool) {\n    return block.timestamp - timestamp <= stalePeriod ? false : true;\n  }\n",
        "  ///@notice Period for checking if chainlink data is stale\n  ///@dev At init set at 25 hours, most of the chainlink feed have an heartbeat of 24h\n  uint32 public stalePeriod;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "In OracleModule.sol, there is a function to set the stale period of the chainlink feed.",
        "This stale period will check whether the updatedAt variable returned from the latestRoundData() call is up to date.",
        "The stalePeriod is set at 90000 seconds (25 hours). OracleModule.sol is hardcoded to 25 hours, assuming most of the Chainlink data feeds have 24 hours deviation threshold:",
        "However, some assets have 1-hour heartbeat, the most significant is ETH/USD: according to DefiLlama 43% of Fyde TVL is WETH.",
        "The issue is that some Chainlink feeds which are used by the protocol, like ETH-USD and BTC-USD have a heartbeat of (1 hour). In those cases, if the prices derived from Chainlink are stale, the protocol will still assume that the prices are healthy because it sets the stalePeriod as 25 hours, which will lead to incorrect accounting when depositing assets for TRSY or burning TRSY for assets."
    ],
    "Recommendations": [
        "",
        "The protocol has the ability to choose the assets that interact with the protocol and will potentially be using many Chainlink feeds. Consider saving all the Chainlink AggregatorV3Interface into a mapping and using different stalePeriod for different heartbeats instead of interacting directly with the AccessControlledOffchainAggregator."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-08-users-cannot-burn-their-trsy-in-exchange-for-assets-when-relayerv2withdraw-is-paused-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function pauseProtocol() public onlyGuard {\n    paused = true;\n    emit Pause(block.timestamp);\n  }\n",
        "  function withdraw(UserRequest[] calldata _userRequest, uint256 _maxTRSYToPay)\n    external\n    payable\n>   whenNotPaused\n    onlyUser\n  {\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "In RelayerV2.sol, the guard, which is appointed by the keeper, can pause the protocol through pauseProtocol().",
        "When the protocol is paused, functions with the whenNotPaused modifier, such as withdraw() and governanceWithdraw() cannot be used.",
        "Most of the time, users should always be able to withdraw their funds even if the protocol is paused. They should not depend on the owner/guard to be able to withdraw their funds."
    ],
    "Recommendations": [
        "",
        "Recommend removing the whenNotPaused modifier in the withdraw() functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-09-assets-with-more-than-18-decimals-are-incorrectly-handled-in-uniswapadaptor-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function _getUniswapPrice(address asset, AssetInfo calldata assetInfo, uint32 twapPeriod)\n    internal\n    view\n    returns (uint256)\n  {\n    uint256 baseAmount = 10 ** assetInfo.assetDecimals;\n@>  uint256 factor = (18 - assetInfo.quoteTokenDecimals); // 18 decimals\n    uint256 finalPrice;\n\n    uint32[] memory secondsAgos = new uint32[](2);\n    secondsAgos[0] = twapPeriod;\n    secondsAgos[1] = 0;\n\n    try IUniswapV3Pool(assetInfo.uniswapPool).observe(secondsAgos) returns (\n      int56[] memory tickCumulatives, uint160[] memory\n    ) {\n      int24 tick = _computeTick(tickCumulatives, twapPeriod);\n\n      int256 price = OracleLibrary.getQuoteAtTick(\n        tick, baseAmount.to128(), asset, assetInfo.uniswapQuoteToken\n      ).toInt();\n\n      finalPrice = factor > 0\n        ? price.upscale(factor).toUint()\n@>      : price.downscale((-factor.toInt()).toUint()).toUint();\n      return finalPrice;\n    } catch {\n      return finalPrice;\n    }\n  }\n",
        "    uint256 baseAmount = 10 ** assetInfo.assetDecimals;\n-   uint256 factor = (18 - assetInfo.quoteTokenDecimals); // 18 decimals\n+   int256 factor = 18 - int256(int8(assetInfo.quoteTokenDecimals)); // 18 decimals\n    uint256 finalPrice;\n\n    uint32[] memory secondsAgos = new uint32[](2);\n    secondsAgos[0] = twapPeriod;\n    secondsAgos[1] = 0;\n\n    try IUniswapV3Pool(assetInfo.uniswapPool).observe(secondsAgos) returns (\n      int56[] memory tickCumulatives, uint160[] memory\n    ) {\n      int24 tick = _computeTick(tickCumulatives, twapPeriod);\n\n      int256 price = OracleLibrary.getQuoteAtTick(\n        tick, baseAmount.to128(), asset, assetInfo.uniswapQuoteToken\n      ).toInt();\n\n      finalPrice = factor > 0\n-       ? price.upscale(factor).toUint()\n-       : price.downscale((-factor.toInt()).toUint()).toUint();\n+       ? price.upscale(factor.toUint()).toUint()\n+       : price.downscale((-factor).toUint()).toUint();\n      return finalPrice;\n    } catch {\n      return finalPrice;\n    }\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "Function _getUniswapPrice() is supposed to handle cases when the quote token has more than 18 decimals by downscaling the price. However, it will just revert on the first line because factor is uint:"
    ],
    "Recommendations": [
        "",
        "Refactor to:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-10-attacker-can-reenter-relayerv2-with-erc777-tokens-and-steal-funds-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "There's no reentrancy guard in the RelayerV2 contract and if one of the deposit or withdraw tokens had a hook (ERC777 or ...) then it would be possible to reenter the RelayerV2 contract again and steal the funds while the state is wrong. There are multiple ways that attackers can exploit this, one way is to set previous caching prices for tokens for the current operation. This is the POC:",
        "There could be other methods to exploit this too."
    ],
    "Recommendations": [
        "",
        "Add reentrancy guard for RelayerV2 contract"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-11-code-doesnt-validate-stale-aum-values-pashov-none-fyde-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "In the new design of the system, the value of the AUM should be updated by the off-chain bot. The issue is that there is no validation time for the AUM value and the code assumes that AUM is valid, this would cause issues when the off-chain bot can't update the AUM value for any reason. There are multiple reasons for AUM to not be updated, for example when the Ethereum network is busy when there is a bug in the off-chain bot, or when it's compromised. This is the POC for this issue:"
    ],
    "Recommendations": [
        "",
        "Like the manual price in the Oracle which is set by the off-chain operator and has an expiration time the AUM set by the off-chain bot should have a valid period(expiration time) too and the code should check it when using the AUM value. If the AUM value is stale then the code shouldn't allow interactions."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-excessive-msgvalue-lost-when-creating-an-offer-pashov-none-frontrunmarket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function newOfferETH(\n    uint8 offerType,\n    bytes32 tokenId,\n    uint256 amount,\n    uint256 value,\n    uint256 minAmount\n  ) external payable nonReentrant {\n    ...\n\n    // collateral\n    uint256 collateral = (value * $.config.pledgeRate) / WEI6;\n\n    uint256 _ethAmount = offerType == OFFER_BUY ? value : collateral;\n@>  require(_ethAmount <= msg.value, 'Insufficient Funds');\n    ...\n  }\n",
        "-   require(_ethAmount <= msg.value, 'Insufficient Funds');\n+   require(_ethAmount == msg.value, 'Insufficient Funds');\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, funds lost forever"
    ],
    "Likelihood": [
        " Low, requires a mistake from a user"
    ],
    "Description": [
        "",
        "msg.value is considered valid if it is greater or equal than needed:",
        "But the amount to pay is static and only depends on submitted offer params, so excessive msg.value means a mistake on the user's side. For example, software performing trading contains an error."
    ],
    "Recommendations": [
        "",
        "Don't accept excessive msg.value:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-eth-transfer-griefing-pashov-none-frontrunmarket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    if (offer.exToken == address(0)) {\n      // refund ETH\n      if (buyerRefundValue > 0 && buyer != address(0)) {\n        (bool success,) = buyer.call{value: buyerRefundValue}('');\n        require(success, 'Transfer Funds to Seller Fail');\n      }\n      if (sellerRefundValue > 0 && seller != address(0)) {\n        (bool success,) = seller.call{value: sellerRefundValue}('');\n        require(success, 'Transfer Funds to Seller Fail');\n      }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Low"
    ],
    "Description": [
        "",
        "forceCancelOrder() uses a direct address call to send ETH to buyer and seller on refund in ETH.",
        "Both buyer and seller can grief each other reverting on these calls, blocking refund execution for both parties and managing the suitable time/conditions to finalize the refund. In the worst cases, it can be used as a means of blackmailing.\nIn addition, it can be not intentional reverts, e.g. when the receiver is a smart-contract that hasn't designed refund logic (and cannot receive ETH)."
    ],
    "Recommendations": [
        "",
        "Consider implementing a claiming logic when users do not receive calls and transfers, and the contract stores their pending withdrawals. Users have to use a separate function to claim these funds.\nThis logic is worth implementing for all ETH transfers - including settleFilled(), settle2Steps() and cancelOffer()."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-transfer_from_with_permit-command-is-vulnerable-to-dos-via-frontrunning-pashov-none-spectra-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    // File: test/Router/RouterTest.t.sol:ContractRouterTest\n    function testPermitFrontRun() public {\n        uint256 amount = 10e18;\n        uint256 privateKey = 0xABCD;\n        address owner = vm.addr(privateKey);\n        underlying.mint(owner, amount);\n        //\n        // 1. Owner signs to router\n        vm.startPrank(owner);\n        underlying.approve(address(principalToken), amount);\n        uint256 shares = principalToken.deposit(amount, owner);\n\n        bytes32 PERMIT_TYPEHASH = keccak256(\n            \"Permit(address owner,address spender,uint256 value,uint256 nonce,uint256 deadline)\"\n        );\n        uint256 deadline = block.timestamp + 10000;\n        (uint8 v, bytes32 r, bytes32 s) = vm.sign(\n            privateKey,\n            keccak256(\n                abi.encodePacked(\n                    \"\\x19\\x01\",\n                    principalToken.DOMAIN_SEPARATOR(),\n                    keccak256(\n                        abi.encode(PERMIT_TYPEHASH, owner, address(router), shares, 0, deadline)\n                    )\n                )\n            )\n        );\n        vm.stopPrank();\n        //\n        // 2. Attacker frontrun the caller, the nounce is incremented.\n        vm.prank(address(1337));\n        principalToken.permit(owner, address(router), shares, deadline, v, r, s);\n        //\n        // 3. Router executes the permit and it will be reverted\n        vm.startPrank(owner);\n        bytes memory commands = abi.encodePacked(bytes1(uint8(Commands.TRANSFER_FROM_WITH_PERMIT)));\n        bytes[] memory inputs = new bytes[](1);\n        inputs[0] = abi.encode(address(principalToken), shares, deadline, v, r, s);\n        vm.expectRevert();\n        router.execute(commands, inputs);\n        vm.stopPrank();\n    }\n",
        "try IERC20Permit(token).permit(msgSender, address(this), value, deadline, v, r, s) {\n    // Permit executed successfully, proceed\n} catch {\n    // Check allowance to see if permit was already executed\n    uint256 currentAllowance = IERC20(token).allowance(msgSender, address(this));\n    if(currentAllowance < value) {\n        revert(\"Permit failed and allowance insufficient\");\n    }\n    // Otherwise, proceed as if permit was successful\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, because it allows for denial of service (DOS) attacks which can prevent the execution of legitimate transactions."
    ],
    "Likelihood": [
        " Medium, given that the exploit requires specific conditions to be met, such as observing and front-running transactions in the mempool."
    ],
    "Description": [
        "",
        "The TRANSFER_FROM_WITH_PERMIT command is intended to allow off-chain signed approvals to be used on-chain, saving gas and improving user experience.",
        "However, including this command in a call to execute() will make the transaction susceptible to DOS via frontrunning. An attacker can observe the transaction in the mempool, extract the permit signature and values from the calldata and execute the permit before the original transaction is processed. This would consume the nonce associated with the user's permit and cause the original transaction to fail due to the now-invalid nonce.",
        "This attack vector has been previously described in Permission Denied - The Story of an EIP that Sinned .",
        "The following test demonstrates how the attacker=address(1337) front-runs the owner transaction and calls permit, resulting in the command execution being reverted:",
        "The user's execution will be reverted, but the user can re-call the router, forcing it to re-call the router and formulate the commands, thus spending in another transaction."
    ],
    "Recommendations": [
        "",
        "Consider implementing a mechanism to check if an allowance for the desired amount exists in case the call to permit() fails. A potential code adjustment could be:",
        "This approach ensures that the transaction can proceed if the end state is as expected, even if the permit call itself fails due to front-running or other issues."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-code-doesnt-work-with-fee-on-transfer-tokens-pashov-none-spectra-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, core functionality would be broken."
    ],
    "Likelihood": [
        " Low, having fee-on-transfer token is a probable scenario."
    ],
    "Description": [
        "",
        "There are some places in the code that assume the ERC20 transfer function will transfer a specified amount and this is not true for tokens with fee. This will cause wrong calculation results in those cases. Some of the places where this issue happens:"
    ],
    "Recommendations": [
        "",
        "Consider significant code modifications (managing actual balances) or prevent fee-on-transfer from appearing during code execution or acknowledge that these tokens will always have wrong calculation"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-attack-surface-in-the-middle-of-the-execute-pashov-none-spectra-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "   User1 -> Router.execute() -> .... -> malicious address -> Router.execute() -> USDT.transferFrom(User1, malicious address, )\n",
        "   User1 -> Router.execute() -> .... -> malicious address -> Router.onFlashLoan() -> Router.execute() -> USDT.transferFrom(User1, malicious address, )\n",
        "A.  Malicious_address -> Router.execute() -> USDT.approve(malicious address, uint256.max)\nB.  User1 -> Router.execute() -> .... -> Malicious_address -> USDT.transferFrom(Router, malicious address, )\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, user would lose approved tokens."
    ],
    "Likelihood": [
        " Low, execution flow should reach a malicious address which is hard to reach"
    ],
    "Description": [
        "",
        "Users can execute multiple commands through Router contract's execute() function. These commands allow to transfer funds from msg.sender which is set as msgSender in the first execute() call. The issue is that if during the execute() execution, the execution reaches a malicious address, the attacker can perform a variety of actions leading to funds stolen.",
        "The condition \"execution flow reaches a malicious address\" can happen in various ways, for example with hook functionality that some ERC20 tokens have(ERC777, ERC677 and ...), the execution will reach the recipient address that is defined in the commands."
    ],
    "Recommendations": [
        "",
        "Each attack requires a separate defense:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-betexpress-is-broken-when-a-bet-has-a-condition-with-more-than-one-outcome-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    if (outcomeOrdinal == 0) {\n        condition.payouts.push(subBetPayout);\n",
        "    if (condition.winningOutcomesCount == 0)\n        condition.winningOutcomesCount = winningOutcomesCounts[\n            i\n        ];\n",
        "    function _calcReserve(\n        Condition storage condition\n    ) internal view returns (uint128) {\n        return\n            uint128(\n                Math.diffOrZero(\n                    Math.maxSum(\n                        condition.payouts,\n                        condition.winningOutcomesCount\n                    ),\n                    condition.fund\n                )\n            );\n    }\n",
        "    /**\n    * @notice Get the sum of `n` max items of `a`.\n    */\n    function maxSum(\n        uint128[] memory a,\n        uint256 n\n    ) internal pure returns (uint256 sum_) {\n        if (n < 2) return max(a);\n\n        uint256 length = a.length;\n\n        uint128[] memory sorted = new uint128[](length);\n        for (uint256 i = 0; i < length; ++i) {\n            sorted[i] = a[i];\n        }\n        sort(sorted, 0, length - 1);\n\n        for (uint256 i = 0; i < n; ++i) {\n            sum_ += sorted[length - 1 - i];\n        }\n    }\n",
        "        for (uint256 i = 0; i < n; ++i) {\n            sum_ += sorted[length - 1 - i];\n        }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, having a condition with two or more winning outcomes, the functionality of BetExpress doesn't work."
    ],
    "Likelihood": [
        " Medium, it happens when a condition has two or more winning outcomes."
    ],
    "Description": [
        "",
        "In the scenario where a deposit is made for a condition supporting two or more outcomes, BetExpress's construction logic improperly handles the condition.payouts array by pushing only one subBetPayout, despite multiple outcomes being possible.",
        "The variable winningOutcomesCount is designated to count the winning outcomes for a condition. If a condition is configured with two or more outcomes, this count exceeds 2, indicating multiple winning outcomes.",
        "During liquidity reservation calculation, the Math.maxSum function is invoked with condition.payouts and condition.winningOutcomesCount as arguments, aiming to ensure sufficient liquidity is reserved.",
        "However, this logic fails for conditions with multiple outcomes as the payouts array contains only a single element, while n >= 2.",
        "This operation leads to a revert due to underflow in the summing loop, where length - 1 - i becomes negative when length = 1 and i = 1 (since n = 2)."
    ],
    "Recommendations": [
        "",
        "Handling the case there is more than one winning outcome."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-payout-not-resolved-for-losing-bet-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _calcPayout(Bet storage bet) internal view returns (uint128) {\n        ...\n        for (uint256 i = 0; i < length; ++i) {\n            ICoreBase.CoreBetData storage subBet = subBets[i];\n            ICondition.Condition memory condition = core.getCondition(\n                subBet.conditionId\n            );\n\n            if (condition.state == IConditionState.ConditionState.RESOLVED) {\n                if (core.isOutcomeWinning(subBet.conditionId, subBet.outcomeId))\n                    winningOdds = winningOdds.mul(bet.conditionOdds[i]);\n                else return 0;\n            } else if (\n                !(condition.state == IConditionState.ConditionState.CANCELED ||\n                    lp.isGameCanceled(condition.gameId))\n            ) {\n                revert ConditionNotFinished(subBet.conditionId);\n            }\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, affects core function resolvePayout, leading to delays in resolving bets, which in turn affects the efficient use of funds."
    ],
    "Likelihood": [
        " Medium, there's a common scenario where a sub-bet, not necessarily the first in the sequence, is resolved first, without it being the winning outcome."
    ],
    "Description": [
        "",
        "When an express bet has any of its sub-bets lost, the entire bet is considered lost and should be resolved accordingly. We can see that if condition.state = RESOVLED then the payout returns 0.",
        "The problem occurs because subBets are checked in order, starting from the first element. If there's a non-resolved sub-bet before a losing sub-bet, the entire express bet remains unresolved. For instance, consider an express bet consisting of three sub-bets with the following conditions:",
        "This scenario prevents the express bet from being resolved, leading to funds being unnecessarily locked and delaying payouts to the DAO and oracles. In extreme cases, resolution awaits the final sub-bet's outcome. Each prediction engine has a locked liquidity limit level, unresolved bets can lead to other betters cannot use the engine if it is in high demand."
    ],
    "Recommendations": [
        "",
        "Iterate through all sub-bets to identify any losing bet promptly and return 0, allowing for the express bet to be resolved without waiting for all sub-bets to finish."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-a-carefully-timed-express-bet-can-lock-up-the-whole-liquidity-pool-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addCore(address core) external override onlyFactory {\n        CoreData storage coreData = _getCore(core);\n        coreData.minBet = 1;\n        coreData.reinforcementAbility = uint64(FixedMath.ONE);\n        coreData.state = CoreState.ACTIVE;\n\n        emit CoreSettingsUpdated(\n            core,\n            CoreState.ACTIVE,\n            uint64(FixedMath.ONE),\n            1\n        );\n    }\n",
        "function changeLockedLiquidity(\n        uint256 gameId,\n        int128 deltaReserve\n    ) external override isActive(msg.sender) {\n        if (deltaReserve > 0) {\n            uint128 _deltaReserve = uint128(deltaReserve);\n            if (gameId > 0) {\n                games[gameId].lockedLiquidity += _deltaReserve;\n            }\n\n            CoreData storage coreData = _getCore(msg.sender);\n            coreData.lockedLiquidity += _deltaReserve;\n\n            vault.lockLiquidity(_deltaReserve);\n\n            if (coreData.lockedLiquidity > getLockedLiquidityLimit(msg.sender))\n                revert LockedLiquidityLimitReached();\n        } else\n            _reduceLockedLiquidity(msg.sender, gameId, uint128(-deltaReserve));\n    }\n",
        "function getLockedLiquidityLimit(\n        address core\n    ) public view returns (uint128) {\n        return\n            uint128(\n                _getCore(core).reinforcementAbility.mul(vault.getReserve())\n            );\n    }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, since no other bets can be made by any other users, and if the express bet is successful the whole liquidity pool will be drained"
    ],
    "Likelihood": [
        " Low, since the attack can only be performed during a short timeframe and it requires significant upfront capital with a significant risk of losing that capital"
    ],
    "Description": [
        "",
        "As detailed in the documentation and implemented in the code, there are limits on the max express bets at various levels:",
        "The first two protections are adequate, however, the cap on the reinforcementAbility for the BetExpress contract isn't sufficiently strict. When a new BetExpress contract is plugged into a core via the Factory contract, the addCore method is called which sets the reinforcementAbility of the core to 1 by default:",
        "This by default allows the core to lock all the liquidity from the LP. This can be seen in the changeLockedLiquidity method:",
        "This method is called from BetExpress when new express bets are made to reserve liquidity from the LP for potential successful bet payouts, and it calls getLockedLiquidityLimit under the hood:",
        "So, by default, a core can lock 100% of the liquidity pool until the LP owner explicitly updates the settings of a core by calling updateCoreSettings.",
        "This is particularly important for express bets because the odds can be compounded up to 1000 by default. So, a malicious user could wait for a BetExpress contract to be plugged into an existing core, at which point they could immediately place an express bet with a selection of sub bets that maximize the odds at close to 1000 without hitting the reinforcement limit for the conditions in the sub bets. An attacker that wanted to cause the maximum grief would pick these conditions to be ones that resolve as far in the future as possible to maximize the amount of time that the liquidity is locked up and the contracts are unusable for other bettors.",
        "At this point, the admin could either:",
        "Although the attacker does have to risk their capital, a sufficiently financed attacker may be willing to take that risk since there is the potential to capture the whole pool and it's likely that the LP owner would choose option 2 above to reduce downtime for other customers (which would mean the attacker gets their funds back)."
    ],
    "Recommendations": [
        "",
        "When a new BetExpress contract is plugged into a liquidity pool, the factory plugExpress method should allow the LP owner to specify the reinforcementAbility of the contract. By specifying this during registration, there isn't a window after registration and before a call to updateCoreSettings where the BetExpress contract can lock up the liquidity pool."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-incorrect-token-order-passed-for-weth-rdnt-swaps-pashov-none-radiant-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "_swap(RDNT_ADDRESS, REAL_WETH_ADDR, _wethAmount, _minAmountOut, WETH_RDNT_POOL_ID, msg.sender);\n",
        "- _swap(RDNT_ADDRESS, REAL_WETH_ADDR, _wethAmount, _minAmountOut, WETH_RDNT_POOL_ID, msg.sender);\n+ _swap(wethAddr, RDNT_ADDRESS, _wethAmount, _minAmountOut, WETH_RDNT_POOL_ID, msg.sender);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "The BalancerPoolHelper.swapWethToRdnt() is intended to swap WETH for RDNT. However, the input and output tokens are in reverse:",
        "resulting in an attempted RDNT -> WETH swap instead."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-_wethtordnt-will-certainly-revert-as-rdntout-is-always-zero-pashov-none-radiant-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "- IVault(vaultAddr).swap(singleSwap, funds, _minAmountOut, block.timestamp);\n+ return IVault(vaultAddr).swap(singleSwap, funds, _minAmountOut, block.timestamp);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " High"
    ],
    "Description": [
        "",
        "BalancerPoolHelper._swap() always returns 0 because it lacks a return statement or return parameter assignment. Hence, rdntOut = poolHelper_.swapWethToRdnt(_wethIn, 0); will always be 0, causing the slippage check to fail."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-incorrect-quoteweth-implementation-out-of-scope-pashov-none-radiant-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 weth = lpToken.token0() != address(rdntAddr) ? reserve0 : reserve1;\nuint256 rdnt = lpToken.token0() == address(rdntAddr) ? reserve0 : reserve1;\nuint256 lpTokenSupply = lpToken.totalSupply();\n\nuint256 neededWeth = (rdnt * lpAmount) / lpTokenSupply;\n",
        "uint256 neededRdnt = (lpAmount * rdnt) / (lpAmount + lpTokenSupply);\nuint256 neededRdntInWeth = router.getAmountIn(neededRdnt, weth, rdnt);\nuint256 neededWeth = (weth - neededRdntInWeth) * lpAmount / lpTokenSupply;\nreturn neededWeth + neededRdntInWeth;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High"
    ],
    "Likelihood": [
        " Medium"
    ],
    "Description": [
        "",
        "UniswapPoolHelper.quoteWETH() is used to calculate the WBNB (denoted as WETH) required for LP-ing into the WBNB-RDNT pool on BSC. There are 2 issues with its implementation:",
        "neededWeth is derived from the wrong reserve",
        "The neededWeth should be using weth instead of rdnt.",
        "Required amounts are derived from pool amounts before swap, not after",
        "Doing 1-sided liquidity is akin to swapping half of the amount for the other token, then adding liquidity with the remaining half and swapped amounts.",
        "The implementation uses the pool reserves before the swap to calculate the amounts needed, but it should use the altered reserves from the swap where weth increases and rdnt decreases."
    ],
    "Recommendations": [
        "",
        "The suggested implementation is below."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-redeem-period-is-less-than-intended-down-to-0-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _redeem(address from, address to, uint256 amount) internal {\n        ...\n\n        // Users can redeem without waiting for the cooldown period in a post-slashing state\n        if (!isInPostSlashingState) {\n            // Make sure the user's cooldown period is over and the unstake window didn't pass\n            uint256 cooldownStartTimestamp = _stakersCooldowns[from];\n            if (block.timestamp < cooldownStartTimestamp + COOLDOWN_SECONDS) {\n                revert StakedToken_InsufficientCooldown(cooldownStartTimestamp + COOLDOWN_SECONDS);\n            }\n@>          if (block.timestamp - cooldownStartTimestamp + COOLDOWN_SECONDS > UNSTAKE_WINDOW) {\n                revert StakedToken_UnstakeWindowFinished(cooldownStartTimestamp + COOLDOWN_SECONDS + UNSTAKE_WINDOW);\n            }\n        }\n\n        // ... redeem logic\n    }\n",
        "-          if (block.timestamp - cooldownStartTimestamp + COOLDOWN_SECONDS > UNSTAKE_WINDOW) {\n+          if (block.timestamp - cooldownStartTimestamp - COOLDOWN_SECONDS > UNSTAKE_WINDOW) {\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, StakedTokens are not redeemable in case the cooldown period is 2 times greater than unstake window, therefore underlying tokens are stuck forever"
    ],
    "Likelihood": [
        " High, calculation mistake on redeem"
    ],
    "Description": [
        "",
        "To redeem StakedToken, the user needs to submit a request to cooldown() and wait time of COOLDOWN_SECONDS.\nThen he should be able to redeem for a period of UNSTAKE_WINDOW after cooldown.",
        "However, this check underestimates the open window by 2 * COOLDOWN_SECONDS:",
        "Here you can see PoC"
    ],
    "Recommendations": [
        "",
        "Refactor check to:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-stakedtoken-is-vulnerable-to-share-inflation-attack-via-donation-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function returnFunds(address from, uint256 amount) external onlySafetyModule {\n\n        if (amount == 0) revert StakedToken_InvalidZeroAmount();\n        if (from == address(0)) revert StakedToken_InvalidZeroAddress();\n\n        // Update the exchange rate\n        //@audit the exchange rate can be manipulated via direct donation due to the use of balanceOf()\n        _updateExchangeRate(UNDERLYING_TOKEN.balanceOf(address(this)) + amount, totalSupply());\n\n        // Transfer the underlying tokens back to this contract\n        UNDERLYING_TOKEN.safeTransferFrom(from, address(this), amount);\n        emit FundsReturned(from, amount);\n    }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, as the targeted staker will lose fund"
    ],
    "Likelihood": [
        " Medium, possible when all stakers redeemed their stake"
    ],
    "Description": [
        "",
        "StakedToken allows staking of underlying tokens (assets) for staked tokens (shares). It uses an explicit exchangeRate for share price calculation that is updated on slashing/returning of funds.",
        "As the exchangeRate is updated using the UNDERLYING_TOKEN.balanceOf(address(this)) in StakedToken, it is vulnerable to manipulation via donation by sending underlying tokens directly to StakedToken contract.",
        "An attacker can exploit the issue in the following scenario,"
    ],
    "Recommendations": [
        "",
        "Implement an internal balance tracking for the underlying token in StakedToken.",
        "This mitigation also requires an invariant total underlying token balance <= total shares to be implemented for functions that increase underlying token balance without increasing shares like returnFunds(). Otherwise, it will enable an attacker to perform stealth donation by staking. For example when the exchange rate is 2:1 (asset to shares), staking 1 wei underlying token will mint zero shares, which then have the effect of donating 1 wei and inflating share price as the share count remains the same.",
        "Also, it will not work with rebasing tokens and might need a rescue fund function for unintended donations via direct underlying token transfer (not through StakedToken)."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-stakers-could-lose-extra-rewards-due-to-accrual-on-behalf-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function updatePosition(address market, address user) external virtual override {\n        ...\n\n        // Accrue rewards to the user for each reward token\n        uint256 rewardMultiplier = computeRewardMultiplier(user, market);\n        uint256 numTokens = rewardTokens.length;\n        for (uint256 i; i < numTokens;) {\n            address token = rewardTokens[i];\n            ...\n\n            //@audit When staker receives new staked tokens, this will trigger the reward accrual\n            //      and apply the current reward multiplier.\n            uint256 newRewards = prevPosition.mul(\n                _cumulativeRewardPerLpToken[token][market] - _cumulativeRewardPerLpTokenPerUser[user][token][market]\n            ).mul(rewardMultiplier);\n\n            // Update the user's stored accumulator value\n            _cumulativeRewardPerLpTokenPerUser[user][token][market] = _cumulativeRewardPerLpToken[token][market];\n        }\n            ...\n\n            //@audit a transfer by someone else will also delay the multiplier start time\n            _multiplierStartTimeByUser[user][market] += (block.timestamp - _multiplierStartTimeByUser[user][market]).mul(\n                (newPosition - prevPosition).div(newPosition)\n            );\n            ...\n    }\n\n    function claimRewardsFor(address _user, address[] memory _rewardTokens)\n        public\n        override\n        nonReentrant\n        whenNotPaused\n    {\n        uint256 numMarkets = _getNumMarkets();\n        for (uint256 i; i < numMarkets;) {\n\n            //@audit When someone claims reward on behalf of staker, it will trigger\n            //      the reward accrual and apply the current reward multiplier.\n            _accrueRewards(_getMarketAddress(_getMarketIdx(i)), _user);\n\n            ...\n        }\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, loss of extra rewards for users who want to accumulate unaccrued rewards and claim at max rewards multiplier"
    ],
    "Likelihood": [
        " High, always occurs as anyone can claim rewards on behalf"
    ],
    "Description": [
        "",
        "Stakers are allocated a rewards multiplier that incentivizes them to keep/increase their stakes for a long period of time. The reward multiplier increases over time, and is applied to the unaccrued rewards when the staker claims the reward or changes their stake position.",
        "The design is such that a staker can maximize their rewards by staking once and only claiming when the reward multiplier reaches the max value. This means the max reward multiplier will be applied to the unaccrued rewards when the staker proceeds to claim it.",
        "However, the accumulation of unaccrued rewards can be disrupted when the staker receives 1 wei dust staked token from someone else, as it will call SMRewardDistributor.updatePosition(). The same disruption will also occur when someone triggers claimRewardsFor() on behalf of the staker. Both actions will trigger the accrual of the rewards and apply the reward multiplier at that point in time, preventing the staker from maximizing the rewards with the max reward multiplier.",
        "Also, receiving staked tokens from someone else will delay the _multiplierStartTimeByUser, though the impact will be low for dust transfer due to the token-weighted computation.",
        "Suppose the scenario,",
        "Note: Bob could also repeat the same transfer more frequently to further diminish the rewards for Alice. The same disruption can be achieved using claimRewardsFor() too."
    ],
    "Recommendations": [
        "",
        "First, prevent claiming rewards on behalf and only allow claiming by the staker himself.\nSecond, impose a minimum transfer amount such that the receiver would benefit more from the transfer than the lost reward."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-users-cant-claim-all-rewards-after-reward-token-removal-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function removeRewardToken(address _rewardToken) external onlyRole(GOVERNANCE) {\n        ...\n        // Determine how much of the removed token should be sent back to governance\n        uint256 balance = _rewardTokenBalance(_rewardToken);\n        uint256 unclaimedAccruals = _totalUnclaimedRewards[_rewardToken];\n        uint256 unaccruedBalance;\n        if (balance >= unclaimedAccruals) {\n            unaccruedBalance = balance - unclaimedAccruals;\n            // Transfer remaining tokens to governance (which is the sender)\n            IERC20Metadata(_rewardToken).safeTransferFrom(ecosystemReserve, msg.sender, unaccruedBalance);\n        }\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, there are always users who can't claim reward"
    ],
    "Likelihood": [
        " Medium, token removal is not a usual operation but is possible"
    ],
    "Description": [
        "",
        "There is a method removeRewardToken() which leaves only accrued but not yet claimed rewards in reserve, transferring the other part to governance. The issue is that the method doesn't take into consideration pending but not yet accrued rewards.",
        "Relevant code block:",
        "Variable _totalUnclaimedRewards is updated only on reward claim and position updates, therefore doesn't contain pending rewards"
    ],
    "Recommendations": [
        "",
        "Leave enough tokens in reserve after token removal to cover current rewards to users. However fix is not obvious due to earlyWithdrawalPenalty and rewardMultiplier which depend on the user and can't be calculated in advance."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-04-griefer-can-reset-users-multiplier-to-1-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        if (prevPosition == 0 || newPosition <= prevPosition) {\n            // Removed stake, started cooldown or staked for the first time - need to reset reward multiplier\n            if (newPosition != 0) {\n                /**\n                 * Partial removal, cooldown or first stake - reset multiplier to 1\n                 * Rationale:\n                 * - If prevPosition == 0, it's the first time the user has staked, naturally they start at 1\n                 * - If newPosition < prevPosition, the user has removed some or all of their stake, and the multiplier\n                 *   is meant to encourage stakers to keep their tokens staked, so we reset the multiplier to 1\n@>               * - If newPosition == prevPosition, the user has started their cooldown period, and to avoid gaming\n                 *   the system by always remaining in either the cooldown or unstake period, we reset the multiplier\n                 */\n                _multiplierStartTimeByUser[user][market] = block.timestamp;\n            } else {\n                // Full removal - set multiplier to 0 until the user stakes again\n                delete _multiplierStartTimeByUser[user][market];\n            }\n",
        "-   function updatePosition(address market, address user) external virtual override {\n+   function updatePosition(address market, address user, bytes calldata data) external virtual override {\n+   bool isStartCooldown = abi.decode(data, (bool));\n        ...\n-       if (prevPosition == 0 || newPosition <= prevPosition) {\n+       if (prevPosition == 0 || newPosition < prevPosition) {\n            // Removed stake, started cooldown or staked for the first time - need to reset reward multiplier\n            if (newPosition != 0) {\n                /**\n                 * Partial removal, cooldown or first stake - reset multiplier to 1\n                 * Rationale:\n                 * - If prevPosition == 0, it's the first time the user has staked, naturally they start at 1\n                 * - If newPosition < prevPosition, the user has removed some or all of their stake, and the multiplier\n                 *   is meant to encourage stakers to keep their tokens staked, so we reset the multiplier to 1\n                 * - If newPosition == prevPosition, the user has started their cooldown period, and to avoid gaming\n                 *   the system by always remaining in either the cooldown or unstake period, we reset the multiplier\n                 */\n                _multiplierStartTimeByUser[user][market] = block.timestamp;\n            } else {\n                // Full removal - set multiplier to 0 until the user stakes again\n                delete _multiplierStartTimeByUser[user][market];\n            }\n+       } else if (isStartCooldown) {\n+           _multiplierStartTimeByUser[user][market] = block.timestamp;\n        } else {\n            /**\n             * User added to their existing stake - need to update multiplier start time\n             * Rationale:\n             * - To prevent users from gaming the system by staked a small amount early to start the multiplier and\n             *   then staked a large amount once their multiplier is very high in order to claim a large reward.\n             * - We shift the start time of the multiplier forward by an amount proportional to the ratio of the\n             *   increase in stake, i.e., `newPosition - prevPosition`, to the new position. By shifting the start\n             *   time forward we reduce the multiplier proportionally in a way that strongly disincentivizes this\n             *   bad behavior while limiting the impact on users who are genuinely increasing their stake.\n             */\n            _multiplierStartTimeByUser[user][market] += (block.timestamp - _multiplierStartTimeByUser[user][market]).mul(\n                (newPosition - prevPosition).div(newPosition)\n            );\n        }\n...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, multiplier of a certain user can be permanently kept at 1 at the will of an attacker, which lowers the user's reward multiple times"
    ],
    "Likelihood": [
        " Medium, there is no direct benefit for the attacker to perform it, however, there are no preconditions"
    ],
    "Description": [
        "",
        "Multiplier must be reset in several situations in SMRewardDistributor.sol:",
        "However condition newPosition == prevPosition can be triggered not only on cooldown, but in 2 additional situations:"
    ],
    "Recommendations": [
        "",
        "Remove = from condition, instead use flag isStartCooldown() and set it to true in function cooldown()"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-05-trapped-underlying-tokens-in-the-auction-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: StakedToken.sol\n235:     function returnFunds(address from, uint256 amount) external onlySafetyModule {\n236:         if (amount == 0) revert StakedToken_InvalidZeroAmount();\n237:         if (from == address(0)) revert StakedToken_InvalidZeroAddress();\n238:\n239:         // Update the exchange rate\n240:         _updateExchangeRate(UNDERLYING_TOKEN.balanceOf(address(this)) + amount, totalSupply());\n241:\n242:         // Transfer the underlying tokens back to this contract\n243:         UNDERLYING_TOKEN.safeTransferFrom(from, address(this), amount);\n244:         emit FundsReturned(from, amount);\n245:     }\n",
        "    // Filename: test/unit/SafetyModuleTest.sol:SafetyModuleTest\n    // $ forge test --match-test \"testFuzz_TerminateAuctionErrorZero\" -vvv\n    function testFuzz_TerminateAuctionErrorZero(\n        uint8 numLots,\n        uint128 lotPrice,\n        uint128 initialLotSize,\n        uint64 slashPercent,\n        uint16 lotIncreasePeriod,\n        uint32 timeLimit\n    ) public {\n        /* bounds */\n        numLots = uint8(bound(numLots, 2, 10));\n        lotPrice = uint128(bound(lotPrice, 1e8, 1e12)); // denominated in USDC w/ 6 decimals\n        slashPercent = uint64(bound(slashPercent, 1e16, 1e18));\n        // lotSize x numLots should not exceed auctionable balance\n        uint256 auctionableBalance = stakedToken1.totalSupply().wadMul(slashPercent);\n        initialLotSize = uint128(bound(initialLotSize, 1e18, auctionableBalance / numLots));\n        uint96 lotIncreaseIncrement = uint96(bound(initialLotSize / 50, 2e16, type(uint96).max));\n        lotIncreasePeriod = uint16(bound(lotIncreasePeriod, 1 hours, 18 hours));\n        timeLimit = uint32(bound(timeLimit, 5 days, 30 days));\n        //\n        // 1. Start an auction and check that it was created correctly\n        uint256 auctionId = _startAndCheckAuction(\n            stakedToken1,\n            numLots,\n            lotPrice,\n            initialLotSize,\n            slashPercent,\n            lotIncreaseIncrement,\n            lotIncreasePeriod,\n            timeLimit\n        );\n        //\n        // 2. `liquidityProviderOne` redeems all tokens\n        vm.startPrank(liquidityProviderOne);\n        uint256 stakedBalance = stakedToken1.balanceOf(liquidityProviderOne);\n        stakedToken1.redeem(stakedBalance);\n        vm.stopPrank();\n        //\n        // 3. `SafetyModule` terminates auction, the transaction will be reverted by \"panic: division or modulo by zero\"\n        vm.expectRevert();\n        safetyModule.terminateAuction(auctionId);\n        //\n        // 4. underlying token trapped in `AuctionModule` contract\n        assertGt(stakedToken1.getUnderlyingToken().balanceOf(address(auctionModule)), 0); // AuctionModule.underlyingBalance > 0\n    }\n",
        "    function _updateExchangeRate(uint256 totalAssets, uint256 totalShares) internal {\n++      if (totalShares == 0)\n++          exchangeRate = 1e18;\n++      else\n++          exchangeRate = totalAssets.wadDiv(totalShares);\n        emit ExchangeRateUpdated(exchangeRate);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because there will be underlying tokens that cannot be returned to the staked token contract, trapping those underlying tokens within the AuctionModule contract. Additionally, the auction cannot be closed, preventing the entire lot from being bought. The staked token would become unusable as there is no way to stake due to isInPostSlashingState being true."
    ],
    "Likelihood": [
        " Medium, because there are no restrictions for users to redeem all their tokens. If users decide to redeem all their tokens, the staked token will be left with zero supply."
    ],
    "Description": [
        "",
        "During an insolvency event, the governance can take underlying tokens from the StakedToken contract and auction them using the function SafetyModule::slashAndStartAuction. This action sends the underlying tokens to the AuctionModule.sol contract, initiating the auction.",
        "Subsequently, the auction can be closed using the AuctionModule::_completeAuction function. This function can be called when all underlying tokens are auctioned in AuctionModule::buyLots, when the auction expires and someone decides to end the auction with the function AuctionModule::completeAuction, or when governance decides to terminate the auction early with the function SafetyModule::terminateAuction.",
        "The issue arises when there are no restrictions on redeeming staked tokens during the auction process. Users can completely exit and redeem all their tokens. Later, when attempting to close the auction, it will fail due to a division by zero error. This happens because when AuctionModule::_completeAuction is called, it invokes StakedToken::returnFunds and then updates the exchange rate using the function StakedToken::_updateExchangeRate. This function performs a division by totalSupply(), which is zero (code line StakedToken#L240):",
        "Consider the following scenario:",
        "I conducted the following test, which demonstrates that ending an auction will be reversed when liquidityProviderOne redeems all the staked tokens, leaving the remaining underlying tokens trapped in AuctionModule.sol:"
    ],
    "Recommendations": [
        "",
        "It is suggested that when stakedToken.totalSupply=0, the exchangeRate should be set to 1e18."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-returnfunds-can-be-frontrun-to-profit-from-an-increase-in-share-price-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, an attacker can profit from the share price increase"
    ],
    "Likelihood": [
        " Low, only profitable if a large amount of funds are returned"
    ],
    "Description": [
        "",
        "SafetyModule.returnFunds() is used by governance to inject funds back into StakedToken, in the form of underlying tokens. For example, when there are excess funds raised from the auction, they can be returned back to compensate the stakers.",
        "The issue is that anyone can frontrun returnFunds() with a stake() to profit from the share price increase and then redeem shortly once it has reached the unstake window. This will be profitable if a large amount of funds are returned within a transaction.",
        "Furthermore, a return of funds likely indicates there will be no slash event in the near term, which makes it a risk-free transaction to capitalize on it and wait for the unstake window to redeem."
    ],
    "Recommendations": [
        "",
        "If returning excess funds raised is the only scenario when returnFunds() is used, then a solution would be to set a target fund amount to raise, and end the auction early when it is reached. This ensures minimal/zero excess funds will be raised if the auction has reached the target, and only requires a small/no amount of funds to be returned to StakedToken.",
        "Otherwise, the alternative solution is to pause the contract without indicating the reason (to deter anticipation) and then call returnFunds() after a few blocks to prevent frontrunning. Finally un-pause the contract when it is completed. This has the same effect as the post-slashing state check to disable stake(), except that it is used after the auction ends.",
        "Another possible solution is to return the funds via rewards token. It would be a better incentive to keep users staked for a longer period as opposed to increasing the share price, which users can reap the profit and withdraw after the cooldown period. This will then not require the use of returnFunds() and can be removed if not necessary."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-addstakedtoken-can-be-griefed-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function initMarketStartTime(address _market) external onlySafetyModule {\n        //@audit When this function is called by addStakedToken(), this check will revert\n       //        if start time has already been initialized\n        if (_timeOfLastCumRewardUpdate[_market] != 0) {\n            revert RewardDistributor_AlreadyInitializedStartTime(_market);\n        }\n        _timeOfLastCumRewardUpdate[_market] = block.timestamp;\n    }\n",
        "    function _updateMarketRewards(address market) internal override {\n        uint256 numTokens = rewardTokens.length;\n        uint256 deltaTime = block.timestamp - _timeOfLastCumRewardUpdate[market];\n        if (deltaTime == 0 || numTokens == 0) return;\n        if (deltaTime == block.timestamp || _totalLiquidityPerMarket[market] == 0) {\n            // Either the market has never been updated or it has no liquidity,\n            // so just initialize the timeOfLastCumRewardUpdate and return\n\n            //@audit This can be triggered by attacker via stake() and registerPositions(),\n            //       before the StakedToken (market) is added to SafetyModule\n            //       to cause addStakedToken() to revert.\n            _timeOfLastCumRewardUpdate[market] = block.timestamp;\n            return;\n        }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, prevent adding of StakedToken"
    ],
    "Likelihood": [
        " Medium, can be conducted by staking 1 wei"
    ],
    "Description": [
        "",
        "When a StakedToken is added to the SafetyModule via addStakedToken(), it will call initMarketStartTime(StakedToken) to set _timeOfLastCumRewardUpdate[StakedToken] = block.timestamp. If _timeOfLastCumRewardUpdate was already set for that StakedToken, a check will cause a revert to ensure that the start time has not been initialized.",
        "However, an attacker can exploit this check to cause addStakedToken() to fail by performing a StakedToken.stake() with just 1 wei followed by a registerPositions([StakedToken]). This will indirectly call _updateMarketRewards(StakedToken), which will then set _timeOfLastCumRewardUpdate[StakedToken] = block.timestamp, as it has not been initialized yet.",
        "Now that _timeOfLastCumRewardUpdate is initialized for the StakedToken, it will cause subsequent addStakedToken() for that particular StakedToken to revert and fail."
    ],
    "Recommendations": [
        "",
        "Remove registerPositions() for SMRewardDistributor since it is not required.",
        "Alternatively, in SMRewardDistributor._registerPosition(), verify that the StakedToken has been added to SafetyModule using the check safetyModule.getStakedTokenIdx(market)."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-stakers-can-activate-cooldown-during-the-pause-and-try-to-evade-slashing-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    //@audit missing whenNotPaused could allow\n    function cooldown() external override {\n        if (balanceOf(msg.sender) == 0) {\n            revert StakedToken_ZeroBalanceAtCooldown();\n        }\n        if (isInPostSlashingState) {\n            revert StakedToken_CooldownDisabledInPostSlashingState();\n        }\n        //solium-disable-next-line\n        _stakersCooldowns[msg.sender] = block.timestamp;\n\n        // Accrue rewards before resetting user's multiplier to 1\n        smRewardDistributor.updatePosition(address(this), msg.sender);\n\n        emit Cooldown(msg.sender);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, as staker can possibly evade the slash event and cause remaining stakers to pay more for the slashing"
    ],
    "Likelihood": [
        " Low, when the protocol is paused, followed by slash event"
    ],
    "Description": [
        "",
        "StakedToken.cooldown() is missing the whenNotPaused modifier. That means stakers can activate cooldown when the protocol is paused.",
        "Stakers could be aware of or anticipate an upcoming slash event due to the pause and attempt to stay within unstake window by activating cooldown when the protocol is paused. As a pause event is an emergency action to mitigate certain risks, there are reasons to believe that a protocol deficit could occur after that, requiring a slash of staked tokens.",
        "By activating cooldown during protocol pause, stakers could try to frontrun the slash event with redemption if it occurs within the unstake window. Those who succeeded in evading the slash event will cause the remaining stakers to pay more for the slashing.",
        "Note that the stakers will be penalized with a reset of the reward multiplier for activating the cooldown, but the benefit of evading slash event will likely outweigh the additional rewards at an emergency pause event."
    ],
    "Recommendations": [
        "",
        "Add the whenNotPaused modifier to cooldown()."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-disabling-of-cooldown-during-post-slash-can-be-bypassed-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function getNextCooldownTimestamp(\n        uint256 fromCooldownTimestamp,\n        uint256 amountToReceive,\n        address toAddress,\n        uint256 toBalance\n    ) public view returns (uint256) {\n        uint256 toCooldownTimestamp = _stakersCooldowns[toAddress];\n        if (toCooldownTimestamp == 0) return 0;\n\n        uint256 minimalValidCooldownTimestamp = block.timestamp - COOLDOWN_SECONDS - UNSTAKE_WINDOW;\n\n        //@audit when `toCooldownTimestamp` is still valid, this will continue to next line\n        if (minimalValidCooldownTimestamp > toCooldownTimestamp) return 0;\n\n        //@audit when `fromCooldownTimestamp` has expired/not set, it will be set to current time\n        if (minimalValidCooldownTimestamp > fromCooldownTimestamp) {\n            fromCooldownTimestamp = block.timestamp;\n        }\n        //@audit weighted-average will be set for recieving account, when `toCooldownTimestamp` is still valid\n        //       and this will activate cooldown for the sent amount\n        if (fromCooldownTimestamp >= toCooldownTimestamp) {\n            toCooldownTimestamp = (amountToReceive * fromCooldownTimestamp + (toBalance * toCooldownTimestamp))\n                / (amountToReceive + toBalance);\n        }\n\n        return toCooldownTimestamp;\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as staker can bypass disabling of cooldown"
    ],
    "Likelihood": [
        " Medium, during the post slash period"
    ],
    "Description": [
        "",
        "When StakedToken is in the post-slashing state, the cooldown function is disabled, preventing the staker from activating it by setting _stakersCooldowns[msg.sender] = block.timestamp.",
        "However, the staker can possibly bypass the disabling of the cooldown function by transferring to another account that has a valid cooldown timestamp.",
        "That is because when fromCooldownTimestamp is expired/not-set and toCooldownTimestamp is valid, the weighted average will be set for the receiving account's cooldown timestamp.",
        "That will allow the staker to activate the cooldown for the staked token sent from the sending account."
    ],
    "Recommendations": [
        "",
        "Disable transfer of StakedToken during post-slashing state to prevent bypassing of the disabling of cooldown."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-final-slashed-amount-could-be-much-lower-than-expected-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function slashAndStartAuction(\n        address _stakedToken,\n        uint8 _numLots,\n        uint128 _lotPrice,\n        uint128 _initialLotSize,\n        uint64 _slashPercent,\n        uint96 _lotIncreaseIncrement,\n        uint16 _lotIncreasePeriod,\n        uint32 _timeLimit\n    ) external onlyRole(GOVERNANCE) returns (uint256) {\n        if (_slashPercent > 1e18) {\n            revert SafetyModule_InvalidSlashPercentTooHigh();\n        }\n\n        IStakedToken stakedToken = stakedTokens[getStakedTokenIdx(_stakedToken)];\n\n        // Slash the staked tokens and transfer the underlying tokens to the auction module\n       //@audit slashAmount could end up lesser than expected if multiple redemption occurred before this\n        uint256 slashAmount = stakedToken.totalSupply().mul(_slashPercent);\n        uint256 underlyingAmount = stakedToken.slash(address(auctionModule), slashAmount);\n        ...\n   }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, lower final slash amount could require further slashing, causing remaining stakers to lose more"
    ],
    "Likelihood": [
        " Medium, happens when slashed"
    ],
    "Description": [
        "",
        "slashAndStartAuction() allows governance to slash a percentage of the StakedToken to settle protocol deficits. A slash percentage is provided as a parameter and derived from the absolute value required to cover the deficits.",
        "However, as the slash transaction is executed based on the relative percentage value, it could cause the final slashed value to end up less than expected, when there are multiple redeem() occurring before it.",
        "It could happen when stakers try to frontrun the slash when they see the public proposal of the slashing or just simply due to race conditions.",
        "When that occurs, this issue will cause the final slash amount to be lower than the initial expected amount and be insufficient to cover the deficits. That means another slash event is likely to be required and the issue could reoccur."
    ],
    "Recommendations": [
        "",
        "It is also not feasible to predict the amount of redemption before the slash and use that to set a higher slash percentage. Thus, it is better to use an absolute slash amount.",
        "Note that slashAndStartAuction() should also prevent a revert by using the maximum possible amount to slash when the absolute slash amount is greater than what is available to slash or the percentage cap."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-extra-rewards-due-to-a-malfunction-with-the-_cumulativerewardperlptoken-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: RewardDistributor.sol\n281:     function _updateMarketRewards(address market) internal override {\n...\n315:             uint256 newRewards = getInflationRate(token).mulDiv(_marketWeightsByToken[token][market], MAX_BASIS_POINTS)\n316:                 .mulDiv(deltaTime, 365 days).div(_totalLiquidityPerMarket[market]);\n317:             if (newRewards != 0) {\n318:                 _cumulativeRewardPerLpToken[token][market] += newRewards;\n319:                 emit RewardAccruedToMarket(market, token, newRewards);\n320:             }\n...\n327:     }\n",
        "File: SMRewardDistributor.sol\n328:     function _accrueRewards(address market, address user) internal virtual override {\n...\n...\n357:             uint256 newRewards = userPosition.mul(\n358:                 _cumulativeRewardPerLpToken[token][market] - _cumulativeRewardPerLpTokenPerUser[user][token][market]\n359:             ).mul(rewardMultiplier);\n360:             // Update the user's stored accumulator value\n361:             _cumulativeRewardPerLpTokenPerUser[user][token][market] = _cumulativeRewardPerLpToken[token][market];\n...\n382:     }\n",
        "uint256 newRewards = lpPosition.mul(_cumulativeRewardPerLpToken[token][market] - _cumulativeRewardPerLpTokenPerUser[user][token][market]);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because users may receive more rewards than allocated."
    ],
    "Likelihood": [
        " Low, because it requires the removal and re-addition of a rewardToken."
    ],
    "Description": [
        "",
        "When the rewards for a market are updated using the function RewardDistributor::_updateMarketRewards, the _cumulativeRewardPerLpToken variable is increased to later be used in the _accrueRewards function for each user.",
        "The issue is that this _cumulativeRewardPerLpToken variable is not reset to zero when a token is re-added using the RewardDistributor::addRewardToken function, causing incorrect counting. Consider the following scenario:",
        "Therefore, if a user has, for example, a position of 10e18 tokens, then their rewards will be calculated as newRewards = 10e18 * (100 - 0) = 1000e18, which is incorrect since those rewards (_cumulativeRewardPerLpToken) were allocated before the execution of step 1. The correct calculation should be newRewards = 10e18 * (0 - 0) = 0 as for the point where the rewardToken is re-added, it starts generating new rewards."
    ],
    "Recommendations": [
        "",
        "It is recommended to reset _cumulativeRewardPerLpToken to zero in the RewardDistributor::addRewardToken function. This way, if for any reason governance decides to re-add the same rewardToken, the rewards counting will be correctly assigned.",
        "Additionally, caution must be exercised in the implementation as rewards will be lost for users who have not claimed their tokens within the period when the reward token was removed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-unauthorized-rewardtokens-in-_marketweightsbytoken-pashov-none-increment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: RewardDistributor.sol\n281:     function _updateMarketRewards(address market) internal override {\n...\n315:             uint256 newRewards = getInflationRate(token).mulDiv(_marketWeightsByToken[token][market], MAX_BASIS_POINTS)\n316:                 .mulDiv(deltaTime, 365 days).div(_totalLiquidityPerMarket[market]);\n317:             if (newRewards != 0) {\n318:                 _cumulativeRewardPerLpToken[token][market] += newRewards;\n319:                 emit RewardAccruedToMarket(market, token, newRewards);\n320:             }\n...\n327:     }\n",
        "    function removeRewardToken(address _rewardToken) external onlyRole(GOVERNANCE) {\n        ...\n        ...\n        // Update rewards for all markets before removal\n        uint256 numMarkets = _rewardInfoByToken[_rewardToken].marketAddresses.length;\n        for (uint256 i; i < numMarkets;) {\n            _updateMarketRewards(_rewardInfoByToken[_rewardToken].marketAddresses[i]);\n            unchecked {\n                ++i; // saves 63 gas per iteration\n            }\n++          delete _marketWeightsByToken[_rewardToken][_rewardInfoByToken[_rewardToken].marketAddresses[i]];\n        }\n        ...\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because a market can receive unauthorized rewardTokens."
    ],
    "Likelihood": [
        " Low, as it requires a rewardToken to be re-added after governance removes it."
    ],
    "Description": [
        "",
        "The _marketWeightsByToken variable is used in the RewardDistributor::_updateMarketRewards function to assign rewards to a market based on the weight assigned to that market:",
        "The issue arises when the rewardToken is removed using the RewardDistributor::removeRewardToken function and later re-added using the RewardDistributor::addRewardToken function. Consider the following scenario:",
        "The market stakedToken1 will receive unauthorized rewards even when rewardTokenA distributes 100% to the stakedToken2 market in step3, not to the stakedToken1 market."
    ],
    "Recommendations": [
        "",
        "When removing a rewardToken, ensure that the associated _marketWeightsByToken is also cleared."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-attack-to-force-the-project-into-the-exodusmode-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, disabled core project functions forever"
    ],
    "Likelihood": [
        " High, easy to execute by anyone"
    ],
    "Description": [
        "",
        "The attack flow:",
        "As a result, the check enforceExodusMode will not pass in core Nume functions - enabling a Mass exit scenario for the project, which means no new deposits and force withdrawals enabled (with no withdrawal requests on Nume).\nAlso, there is no way to set isInExodusMode back to false.\n(Actually, it exists - urgently develop a new facet with the new code, deploy, and run the fix)\nThe same issue can happen with ERC20 tokens with blacklists, for example USDC.",
        "Another attacker vector with the same principle - avoid the deposit being invalidated.\nIf an ETH deposit by a user is tagged as invalid (during notarizeSettlement), Nume pays back the deposit.\nIf such a malicious deposit is among valid deposits - there will be no way to remove it, thus it will be a problem to process valid deposits.\nSo the owner will have to treat such a deposit as valid."
    ],
    "Recommendations": [
        "",
        "It is better to let users withdraw their ETH by themselves, in a separate function.\nInstead of transferring funds directly, the function can increment a mapping like user=>token=>amount. Then, users have to call the function to withdraw this \"balance\".\nAlso, consider introducing some instruments to disable exoduceMode."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-attacker-can-turn-on-exodus-mode-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "            for (uint256 i; i < numContractWithdrawals; ) {\n                ...\n                delete ns.withdrawalRequests[\n                    _args.contractWithdrawalAddresses[i]\n                ][_args.contractWithdrawalTokenAddresses[i]];\n                delete ns.withdrawalRequestTimestamps[\n@>                  ns.lastFinalizedWithdrawalsQueueIndex + i + 1\n                ];\n                if (_args.contractWithdrawalAmounts[i] > 0) {\n                    PaymentUtils.pay(\n                        _args.contractWithdrawalAddresses[i],\n                        _args.contractWithdrawalTokenAddresses[i],\n                        _args.contractWithdrawalAmounts[i]\n                    );\n                    PaymentUtils.pay(\n                        _args.contractWithdrawalAddresses[i],\n                        0x1111111111111111111111111111111111111111,\n                        ns.WITHDRAWAL_STAKE\n                    );\n                }\n                ...\n            }\n            ...\n@>          ns.lastFinalizedWithdrawalsQueueIndex = _args\n                .handledWithdrawalsQueueIndex;\n",
        "    function challengeUserWithdrawal(\n        uint256 _queueIndex,\n        bool _isNft\n    ) external {\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n\n        if (_isNft) {\n            ... // Skipped because scenario describes ERC20 withdrawal\n        } else {\n            require(\n                _queueIndex <= ns.currWithdrawalsQueueIndex &&\n@>                  _queueIndex > ns.lastFinalizedWithdrawalsQueueIndex,\n                \"WithdrawalsFacet: Invalid queue index\"\n            );\n            require(\n                block.timestamp >\n@>                  ns.withdrawalRequestTimestamps[_queueIndex] +\n                        ns.WITHDRAWAL_REQUEST_TIMEOUT,\n                \"WithdrawalsFacet: Withdrawal request has not expired yet\"\n            );\n        }\n\n        ns.isInExodusMode = true;\n        emit ExodusModeEntered(_queueIndex, _isNft);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High. Protocol stops operating."
    ],
    "Likelihood": [
        " High. Nothing stops from performing this attack."
    ],
    "Description": [
        "",
        "Attacker can reenter Nume when Witdrawal_Stake is returned on settlement notarization, and in fallback() call challengeUserWithdrawal() to activate Exodus Mode.",
        "notarizeSettlement() processes withdrawals submitted on-chain, such on-chain submissions require Withdrawal_stake which is returned on successful withdrawal. Note that it firstly deletes timestamp of that withdrawalRequest, but updates ns.lastFinalizedWithdrawalsQueueIndex in the very end after all withdrawals:",
        "It introduces attack vector:",
        "Now let's have a look on challengeUserWithdrawal(). 1) As you remember, ns.lastFinalizedWithdrawalsQueueIndex is updated in the very end, therefore current queueIndex is not finalized. 2) Timestamp was cleared before transferring assets. As a result, all requires are passed and protocol enters Exodus Mode"
    ],
    "Recommendations": [
        "",
        "Add nonReentrant modifier on all external functions of Nume."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-user-can-repeat-calling-withdrawexodus-to-steal-all-tokens-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function withdrawExodus(\n        WithdrawalRequestArgs calldata _args\n    ) external nonReentrant {\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n        if (!ns.isInExodusMode) {\n            revert AppStorage.NotInExodusMode();\n        }\n        require(\n            ECDSAUtils.recoverSigner(\n                abi.encodePacked(_args.user, ns.currBlockNumber),\n                _args.signature\n            ) == _args.user,\n            \"WithdrawExodus: Invalid user signature\"\n        );\n\n        VerifyUserUtils.verifyUser(...);\n\n        if (_args.isNft) {\n            PaymentUtils.payNft(\n                _args.user,\n                _args.tokenAddress,\n                _args.balanceOrTokenId,\n                _args.mintedNft\n            );\n        } else {\n            require(\n                _args.balanceOrTokenId > 0,\n                \"WithdrawalsFacet: Invalid balance\"\n            );\n            PaymentUtils.pay(\n                _args.user,\n                _args.tokenAddress,\n                _args.balanceOrTokenId\n            );\n        }\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High. Any user can steal all funds."
    ],
    "Likelihood": [
        " Medium. Exodus Mode must be enabled."
    ],
    "Description": [
        "",
        "Function withdrawExodus() is used to withdraw funds deposited to Nume when protocol enters Exodus Mode, i.e. when operator doesn't perform bridging from Nume to Polygon.",
        "This function only verifies that user had token balance prior to the last settlement. If yes - transfers requested tokens to user. However nothing stops user from replaying call to withdrawExodus().",
        "Suppose following scenario:"
    ],
    "Recommendations": [
        "",
        "Keep track of withdrawn amounts in withdrawExodus(). For example introduce internal mapping (address token => uint256 withdrawnAmount)"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-nft-withdrawal-request-is-not-deleted-after-successful-withdrawal-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function withdrawNFT(\n        address _user,\n        address _nftContractAddress,\n        uint256 _tokenId,\n        bool _mintedNft,\n        uint256 _queueIndex,\n        bool _isContractWithdrawal\n    ) external nonReentrant {\n        AppStorage.enforceExodusMode();\n\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n\n        bytes32 queueItem = keccak256(\n            abi.encodePacked(_user, _nftContractAddress, _tokenId, _mintedNft)\n        );\n\n        if (_isContractWithdrawal) {\n            ...\n        } else {\n@>          bytes[] memory userBackendNftWithdrawalRequests = ns\n                .userBackendNftWithdrawalRequests[_user];\n            require(\n                _queueIndex <= userBackendNftWithdrawalRequests.length,\n                \"NFTWithdrawalsFacet: Invalid queue index\"\n            );\n            (\n                address user,\n                address nftContractAddress,\n                uint256 tokenId,\n                bool mintedNft\n            ) = abi.decode(\n                    userBackendNftWithdrawalRequests[_queueIndex - 1],\n                    (address, address, uint256, bool)\n                );\n            PaymentUtils.payNft(user, nftContractAddress, tokenId, mintedNft);\n@>          delete userBackendNftWithdrawalRequests[_queueIndex - 1];\n        }\n\n        emit NFTWithdrawn(_user, _nftContractAddress, _tokenId, _mintedNft);\n    }\n",
        "    function withdrawNFT(\n        address _user,\n        address _nftContractAddress,\n        uint256 _tokenId,\n        bool _mintedNft,\n        uint256 _queueIndex,\n        bool _isContractWithdrawal\n    ) external nonReentrant {\n        ...\n\n        if (_isContractWithdrawal) {\n            ...\n        } else {\n            bytes[] memory userBackendNftWithdrawalRequests = ns\n                .userBackendNftWithdrawalRequests[_user];\n            require(\n                _queueIndex <= userBackendNftWithdrawalRequests.length,\n                \"NFTWithdrawalsFacet: Invalid queue index\"\n            );\n            ...\n            PaymentUtils.payNft(user, nftContractAddress, tokenId, mintedNft);\n-           delete userBackendNftWithdrawalRequests[_queueIndex - 1];\n+           delete ns.userBackendNftWithdrawalRequests[_user][_queueIndex - 1];\n        }\n\n        emit NFTWithdrawn(_user, _nftContractAddress, _tokenId, _mintedNft);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High. Attacker can steal user's nfts."
    ],
    "Likelihood": [
        " Medium. It requires re-deposit of NFT"
    ],
    "Description": [
        "",
        "Withdrawal backend nft request is incorrectly deleted after performing withdrawal.",
        "Here you can see that delete is performed on memory array instead of storage:",
        "It means actually user's withdrawal request is not deleted after withdrawal. It allows user to withdraw the same nft multiple times.\nSuppose following scenario:"
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-breaking-the-deposit-limit-with-different-msgvalue-and-_user-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "...\nuint256 currentTime = block.timestamp;\nif (currentTime - ns.userDepositTimestamp[_user] >= 1 days) {\n            delete ns.userDepositCount[_user];\n            ns.userDepositTimestamp[_user] = currentTime;\n        }\nrequire ( ns.userDepositCount[msg.sender] < ns.depositsLimit )\n...\nns.userDepositCount[msg.sender]++;\n_deposit(_user, 0x1111111111111111111111111111111111111111, msg.value);\n",
        "delete ns.userDepositCount[_user];\n",
        "require ( ns.userDepositCount[msg.sender] < ns.depositsLimit )\n...\nns.userDepositCount[msg.sender]++;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, a daily limit bypassed (invariant broken)"
    ],
    "Likelihood": [
        " High, easily available behavior"
    ],
    "Description": [
        "",
        "Nume tries to limit the number of deposits per day for a user in two contracts - NFTDepositsFacet and DepositsFacet.\nDuring the deposit, we have this code (slightly rewritten for simplicity):",
        "As you can see, the function deletes the counter for the _user daily:",
        "But later, the function checks the counter for the msg.sender and does ++ for msg.sender:",
        "userDepositCount[_user] is never checked to be below ns.depositsLimit, and is never incremented.\nAs a result, ns.depositsLimit can easily be bypassed by changing msg.senders.",
        "Moreover, ns.userDepositCount[msg.sender] is always incremented, and never deleted/nullified, even daily."
    ],
    "Recommendations": [
        ""
    ],
    "OR": [
        "Replace ns.userDepositCount[msg.sender] with ns.userDepositCount[_user] in both deposit functions - depositERC20() and deposit().\nMake sure that msg.sender is only used as a token sender.\nThis problem exists in both deposit contracts - NFTDepositsFacet and DepositsFacet.\n\nMaybe it was the intention to limit exactly msg.sender. To prevent spamming.\nIf yes, delete ns.userDepositCount[_user]; should be replaced with delete ns.userDepositCount[msg.sender];, because the counter for msg.sender is never nullified."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-04-stuck-tokens-during-the-exodus-mode-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "AppStorage.enforceExodusMode();\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, tokens stuck"
    ],
    "Likelihood": [
        " Medium, it must be pending withdrawals, and the Exodus Mode enabled"
    ],
    "Description": [
        "",
        "During the Exodus Mode users can prove their Nume balance and call withdrawExodus() to withdraw NFTs not yet withdrawn and that have not received approval in notarizeSettlement() yet.\nAlso, users can have some funds already approved. In this case, they have to call withdrawNFT() manually, which is the final step to finalize the approved withdrawals.\nBut this function has the following line:",
        "It means that these approved withdrawals will not be finalized during the exodus mode:"
    ],
    "Recommendations": [
        "",
        "Remove AppStorage.enforceExodusMode(); from withdrawNFT()"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-withdrawal_request_timeout-cannot-be-too-short-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, the protocol will stop"
    ],
    "Likelihood": [
        " Low, the variable has a default value and unlikely to be revised"
    ],
    "Description": [
        "",
        "OwnershipFacet has setWithdrawalRequestTimeout() which sets WITHDRAWAL_REQUEST_TIMEOUT.",
        "WITHDRAWAL_REQUEST_TIMEOUT is a highly risky parameter. If it is too low, there will be more likely to fall into exodusMode - which means the protocol is disabled (no functions to get back from the exodusMode, the protocol will require deploying a new Diamond or adding new facets)."
    ],
    "Recommendations": [
        "",
        "We recommend setting a minimum allowed value for WITHDRAWAL_REQUEST_TIMEOUT or disabling revisions from the default 14 days."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-the-same-signature-is-used-for-both-withdrawal-request-and-subscription-cancelling-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function submitWithdrawalRequest(\n        WithdrawalRequestArgs calldata _args\n    ) external payable nonReentrant {\n        AppStorage.enforceExodusMode();\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n        ...\n        require(\n            ECDSAUtils.recoverSigner(\n@>              abi.encodePacked(_args.user, ns.currBlockNumber),\n                _args.signature\n            ) == _args.user,\n            \"SubmitWithdrawalRequest: Invalid user signature\"\n        );\n       ...\n    }\n\n    function cancelSubscriptionRequest(\n        CancelSubscriptionRequestArgs calldata _args\n    ) external {\n        AppStorage.enforceExodusMode();\n\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n\n        require(\n            ECDSAUtils.recoverSigner(\n@>              abi.encodePacked(_args.user, ns.currBlockNumber),\n                _args.signature\n            ) == _args.user,\n            \"SettlementsFacet: Invalid user signature\"\n        );\n        ...\n    }\n",
        "    function submitWithdrawalRequest(\n        WithdrawalRequestArgs calldata _args\n    ) external payable nonReentrant {\n        AppStorage.enforceExodusMode();\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n        ...\n        require(\n            ECDSAUtils.recoverSigner(\n-               abi.encodePacked(_args.user, ns.currBlockNumber),\n+               abi.encodePacked(_args.user, ns.currBlockNumber, \"submitWithdrawalRequest\"),\n                _args.signature\n            ) == _args.user,\n            \"SubmitWithdrawalRequest: Invalid user signature\"\n        );\n       ...\n    }\n\n    function cancelSubscriptionRequest(\n        CancelSubscriptionRequestArgs calldata _args\n    ) external {\n        AppStorage.enforceExodusMode();\n\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n\n        require(\n            ECDSAUtils.recoverSigner(\n-               abi.encodePacked(_args.user, ns.currBlockNumber),\n+               abi.encodePacked(_args.user, ns.currBlockNumber, \"cancelSubscriptionRequest\"),\n                _args.signature\n            ) == _args.user,\n            \"SettlementsFacet: Invalid user signature\"\n        );\n        ...\n    }\n\n    function withdrawExodus(\n        WithdrawalRequestArgs calldata _args\n    ) external nonReentrant {\n        AppStorage.NumeStorage storage ns = AppStorage.numeStorage();\n        if (!ns.isInExodusMode) {\n            revert AppStorage.NotInExodusMode();\n        }\n        require(\n            ECDSAUtils.recoverSigner(\n-               abi.encodePacked(_args.user, ns.currBlockNumber),\n+               abi.encodePacked(_args.user, ns.currBlockNumber, \"withdrawExodus\"),\n                _args.signature\n            ) == _args.user,\n            \"WithdrawExodus: Invalid user signature\"\n        );\n        ...\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium. User can't specify what action to perform when gives signature. As a result, user can't use signatures in trustless manner because tx sender can perform different action on behalf of user."
    ],
    "Likelihood": [
        " Medium. Usage of signature is impacted, however user can send transaction on his own to avoid problems."
    ],
    "Description": [
        "",
        "Here you can see that signature in both methods contains the same parameters:",
        "It means that transmitter who sends transaction, can withdraw user's funds though user signed to perform subscription cancelling and vice versa. Possibility of altering data breaks possibility of trustless use of signatures."
    ],
    "Recommendations": [
        "",
        "Add unique salt to signature arguments, for example method name:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-setting-deposit-limit-to-zero-stops-all-new-deposits-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, new deposit will be stopped (DoS)"
    ],
    "Likelihood": [
        " Low, zero input by mistake or with the intention to cancel/disable deposit limit"
    ],
    "Description": [
        "",
        "Deposit limits are managed with functions setDepositsLimit() and setNftDepositsLimit().\nThey set depositsLimit and nftDepositsLimit without zero input checks.\nZero can be inputted either by mistake, or with the intention to disable limits."
    ],
    "Recommendations": [
        "",
        "We recommend requiring that the new value is not zero."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-withdrawal_stake-and-pending-deposits-are-returned-to-wrong-address-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function notarizeSettlement(\n        NotarizeSettlementArgs calldata _args\n    ) external nonReentrant {\n            ...\n            for (uint256 i; i < numContractWithdrawals; ) {\n                ...\n                if (_args.contractWithdrawalAmounts[i] > 0) {\n                    PaymentUtils.pay(\n                        _args.contractWithdrawalAddresses[i],\n                        _args.contractWithdrawalTokenAddresses[i],\n                        _args.contractWithdrawalAmounts[i]\n                    );\n@>                  PaymentUtils.pay(\n                        _args.contractWithdrawalAddresses[i],\n                        0x1111111111111111111111111111111111111111,\n                        ns.WITHDRAWAL_STAKE\n                    );\n                }\n                ...\n            }\n            for (uint256 i; i < numContractWithdrawals; ) {\n                ...\n                if (_args.isContractNftWithdrawalValid[i]) {\n@>                  PaymentUtils.pay(\n                        _args.contractNftWithdrawalAddresses[i],\n                        0x1111111111111111111111111111111111111111,\n                        ns.WITHDRAWAL_STAKE\n                    );\n                } else {\n                    ...\n                }\n                ...\n            }\n        ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low. Withdrawal initiator loses 0.01 ETH per withdrawal"
    ],
    "Likelihood": [
        " High. The only prerequisite is to perform withdrawal on behalf of another user, which is expected behavior"
    ],
    "Description": [
        "",
        "Currently Withdrawal_Stake is returned to user whose withdrawal is processed, instead of actual sender who submitted withdrawal request and staked it.",
        "Here you can see that Withdrawal_Stake is returned to withdrawal receiver, instead of withdrawal initiator:"
    ],
    "Recommendations": [
        "",
        "Introduce parameter sender in withdrawals requests. Return Withdrawal_Stake to sender of request instead of withdrawal receiver."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-staked-withdrawal_stake-cannot-be-withdrawn-during-the-exodusmode-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, a portion of user funds lost"
    ],
    "Likelihood": [
        " Medium, exodusMode is a scenario, but not so likely"
    ],
    "Description": [
        "",
        "submitWithdrawalRequest() requires provided msg.value=WITHDRAWAL_STAKE in order to have a pending withdrawal. It is designed to be returned when a withdrawal request is approved via notarizeSettlement().\nBut during the mass exit scenario, there is no way to return staked WITHDRAWAL_STAKE. Only pending deposits and verified Nume balance can be withdrawn, but not WITHDRAWAL_STAKE if any."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-unexpected-gainslosses-for-pending-withdrawals-if-withdrawal_stake-is-changed-pashov-none-nume-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, potential funds stolen from other users and DoS"
    ],
    "Likelihood": [
        " Low, as Withdrawal_Stake is not so likely to be changed, must be increased, and must have pending withdrawals"
    ],
    "Description": [
        "",
        "submitWithdrawalRequest() receives msg.value as WITHDRAWAL_STAKE. However, it does not store the exact value received per request.\nWhen withdrawal requests are proceeded in notarizeSettlement(), the current WITHDRAWAL_STAKE is returned.\nThus if WITHDRAWAL_STAKE was updated between \"submit\" and \"notarize\" (via setWithdrawStake()), the new updated value will be sent back, which is different from initially staked. As a result, pending withdrawals will experience either a loss or a gain.\nIf WITHDRAWAL_STAKE decreases - users will receive less than staked (loss)\nIf WITHDRAWAL_STAKE increases - users will receive more than staked (gain)",
        "Gains for such users mean a loss for the whole contract - lack of funds to finalize all withdrawals in case of a mass exit scenario (DoS).",
        "Some extravagant scenarios include the frontrun attack:"
    ],
    "Recommendations": [
        "",
        "There are a few options:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-mint-price-will-be-inaccurate-for-quantities-that-jumped-more-than-one-price-tier-pashov-none-hytopia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function getPriceForQuantity(uint256 _startingId, uint256 _qty) public pure returns (uint256) {\n      if (_qty == 1) {\n          return getCurrentPrice(_startingId);\n      }\n      uint256 _startingPrice = getCurrentPrice(_startingId);\n      uint256 _endingPrice = getCurrentPrice(_startingId + _qty - 1);\n      if (_endingPrice == _startingPrice) {\n          return _startingPrice * _qty;\n      }\n      // find the quantity in starting price and ending price (ex qty = 5, starting at id #3182 means 2 are at starting price, 3 are at ending price\n      uint256 _lastTierId = getLastIdForTier(_startingId);\n      // @audit - this will not work properly if jump more than 1 tier\n      uint256 _startingPriceQty = _lastTierId - _startingId + 1;\n      return (_startingPrice * _startingPriceQty) + (_endingPrice * (_qty - _startingPriceQty));\n  }\n",
        "  function test_mint_three_tiers() public {\n        _warpPublicMint();\n\n        uint256 _lastIdForTier1 = _getLastIdForTier();\n\n        vm.deal(leet, 10000 ether);\n\n        vm.prank(leet);\n        hychainNodeKey.mint{ value: 1000 ether }(address(this), _lastIdForTier1 - 1);\n\n        // second tier\n        uint256 _lastIdForTier2 = hychainNodeKey.getLastIdForTier(_lastIdForTier1 + 1);\n\n        uint256 _qty3 = _lastIdForTier2 + 1 - (hychainNodeKey.totalSupply() + 1) + 1;\n\n        // price if we mint in 1 call (one call with jump from 1 -> 3)\n        uint256 price_ = hychainNodeKey.getPriceForQuantity(hychainNodeKey.totalSupply() + 1, _qty3);\n\n        console.log(\"total price in 1 call : \");\n        console.log(price_);\n        console.log(\"quantity : \");\n        console.log(_qty3);\n\n        // now, we compare with price with multiple calls (one with jump from 1 -> 2, one call with jump from 2 -> 3)\n\n        uint256 stepQty1 = _lastIdForTier2 - (hychainNodeKey.totalSupply() + 1) + 1;\n        uint256 stepQty2 = _qty3 - stepQty1;\n\n        uint256 price_1 =  hychainNodeKey.getPriceForQuantity(hychainNodeKey.totalSupply() + 1, stepQty1);\n        uint256 price_2 =  hychainNodeKey.getPriceForQuantity(hychainNodeKey.totalSupply() + 1 + stepQty1, stepQty2);\n\n        uint256 totalPrice = price_1 + price_2;\n        console.log(\"total price in 2 calls : \");\n        console.log(totalPrice);\n        console.log(\"step qty 1 : \");\n        console.log(stepQty1);\n        console.log(\"step qty 2 : \");\n        console.log(stepQty2);\n    }\n",
        "Logs:\n  total price in 1 call :\n  400156250000000000000\n  quantity :\n  3026\n\n  total price in 2 calls :\n  347992250000000000000\n  step qty 1 :\n  3025\n  step qty 2 :\n  1\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, prices can be significantly different and not considering the in-between price tier."
    ],
    "Likelihood": [
        " Medium, it is possible for users that buy the token in high quantity or when the current token id is near the end of the current price tier."
    ],
    "Description": [
        "",
        "When users mint the HychainNodeKey, it will eventually calculate the price that needs to be paid by the users, given the current token id and the quantity of tokens that the user wants to mint by calling getPriceForQuantity.",
        "However, as can be observed, it will only consider _startingPrice and _endingPrice from the provided starting token id and quantity. If the provided quantity passes through multiple price tiers, it will only consider the first and last price tier, ignoring the information from the in-between price tiers.",
        "PoC scenario :",
        "Coded PoC :",
        "Log output :"
    ],
    "Recommendations": [
        "",
        "Consider modifying the pricing to account for multiple price tier changes, or restrict the quantity to ensure that no more than one price tier change occurs."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-incorrect-excessfeerefundaddress-and-callvaluerefundaddress-are-provided-when-bridging-tokens-to-the-l2-pashov-none-hytopia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _mintAndBridge(address _to, uint256 _qty) internal {\n        uint256 _startingTokenId = _nextTokenId();\n        _mint(_to, _qty);\n        HychainNodeKeyStorage.Layout storage $ = HychainNodeKeyStorage.layout();\n        // require enough nativeToken to bridge\n        if ($._topia != address(0)) {\n            // TODO: figure out the exact amount\n            require(IERC20($._topia).balanceOf(address(this)) >= $._transferCost, \"Not enough $TOPIA to mint\");\n        }\n        // approve inbox to transfer token\n        IERC20($._topia).approve($._inbox, $._transferCost);\n        // register ownership via retryable ticket\n        uint256 ticketID = IERC20Inbox($._inbox).createRetryableTicket(\n            $._l2NodeKeyAddress, // to\n            0, // l2CallValue\n            $._maxSubmissionCost, // maxSubmissionCost\n>>>         address(this), // excessFeeRefundAddress\n>>>         address(this), // callValueRefundAddress\n            $._l2GasLimit, // gasLimit\n            $._l2GasPrice, // maxGasPrice\n            4e15, // tokenTotalFeeAmount\n            abi.encodeWithSignature(\"mint(address,uint256,uint256)\", msg.sender, _startingTokenId, _qty)\n        );\n\n        emit InboxTicketCreated(msg.sender, ticketID, _startingTokenId, _qty);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, address(this) is provided for the excessFeeRefundAddress and callValueRefundAddress parameters when calling createRetryableTicket, which could lead to a loss of excess fee and the ability to cancel the L1 -> L2 ticket."
    ],
    "Likelihood": [
        " Medium, The ability to cancel a ticket might needed when there is potentially malicious behavior that needs to be prevented when _mintAndBridge is triggered."
    ],
    "Description": [
        "",
        "HYCHAIN's blockchain uses the same technology that powers Arbitrum Nova (L2). One of the capabilities that is available and used is L1 -> L2 bridging for the minted node key token. According to the docs, excessFeeRefundAddress is L2 address to which the excess fee is credited and callValueRefundAddress is address that has the capability to cancel the bridging ticket if needed.",
        "However, address(this) is provided for those two parameters, which could become an issue when the excess fee is non-zero or when the cancel action is required to prevent unexpected behavior."
    ],
    "Recommendations": [
        "",
        "Consider putting a configurable L2 address for excessFeeRefundAddress and callValueRefundAddress"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-incorrect-address-provided-as-the-receiver-when-bridging-and-minting-the-node-key-token-on-the-l2-pashov-none-hytopia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _mintAndBridge(address _to, uint256 _qty) internal {\n        uint256 _startingTokenId = _nextTokenId();\n        _mint(_to, _qty);\n        HychainNodeKeyStorage.Layout storage $ = HychainNodeKeyStorage.layout();\n        // require enough nativeToken to bridge\n        if ($._topia != address(0)) {\n            // TODO: figure out the exact amount\n            require(IERC20($._topia).balanceOf(address(this)) >= $._transferCost, \"Not enough $TOPIA to mint\");\n        }\n        // approve inbox to transfer token\n        IERC20($._topia).approve($._inbox, $._transferCost);\n        // register ownership via retryable ticket\n        uint256 ticketID = IERC20Inbox($._inbox).createRetryableTicket(\n            $._l2NodeKeyAddress, // to\n            0, // l2CallValue\n            $._maxSubmissionCost, // maxSubmissionCost\n            address(this), // excessFeeRefundAddress\n            address(this), // callValueRefundAddress\n            $._l2GasLimit, // gasLimit\n            $._l2GasPrice, // maxGasPrice\n            4e15, // tokenTotalFeeAmount\n>>>         abi.encodeWithSignature(\"mint(address,uint256,uint256)\", msg.sender, _startingTokenId, _qty)\n        );\n\n        emit InboxTicketCreated(msg.sender, ticketID, _startingTokenId, _qty);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, The user may not expect the msg.sender to receive the token on L2 instead of the _to address provided."
    ],
    "Likelihood": [
        " Medium, as this will happen all the time when users mint Node Key token and _mintAndBridge is triggered and msg.sender is not the same with _to address provided."
    ],
    "Description": [
        "",
        "When users mint Node Key token, it will eventually trigger _mintAndBridge, which mints the token to the _to address provided and bridges the mint information to the L2. However, inside the calldata provided to L2, it provides msg.sender instead of _to parameter provided by users.",
        "Users might expect the _to parameter provided to also be the receiver in the L2. This could lead to unexpected behavior if the msg.sender is a contract that may not be available on L2 or cannot handle the minted token."
    ],
    "Recommendations": [
        "",
        "Provide _to instead of msg.sender to the calldata passed to L2."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-mints-can-be-bricked-from-nft-redemptions-pashov-none-pupniks-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 currentAmount = amountMinted;\n\nfor (uint256 i = 1; i <= quantity;) {\n  _mint(msg.sender, currentAmount + i);\n  ++i;\n}\n",
        "function test_dos_sale(uint256 amount) public {\n  // setup: mint 2-5 NFTs (exclude 1 because we need to redeem NFT id < lastMinted)\n  amount = bound(amount, 2, 5);\n  _deploy();\n\n  changePrank(owner);\n  pupniks.setSignerAddress(signer);\n  pupniks.toggleSaleStatus();\n  changePrank(user);\n\n  uint256 nonce = 0;\n\n  (bytes32 hash, uint8 v, bytes32 r, bytes32 s) = getSignature(user, nonce, amount, signerPkey);\n\n  pupniks.mintPupnik{value: 0.5 ether * amount}(hash, abi.encodePacked(r, s, v), nonce, amount);\n\n  // redeem 1 NFT\n  pupniks.redeemPupnik(1);\n\n  // then try to mint more, but it reverts with TokenAlreadyExists()\n  nonce = 1;\n  (hash, v, r, s) = getSignature(user, nonce, amount, signerPkey);\n  vm.expectRevert(ERC721.TokenAlreadyExists.selector);\n  pupniks.mintPupnik{value: 0.5 ether * amount}(hash, abi.encodePacked(r, s, v), nonce, amount);\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, prevents subsequent Pupnik sales"
    ],
    "Likelihood": [
        " Medium, can be easily performed by malicious parties"
    ],
    "Description": [
        "",
        "Pupnik NFTs can be redeemed at any point in time after it has been minted. Redeeming a Pupnik whose ID is strictly less than amountMinted while the sale is ongoing will cause subsequent sales to revert, because the redemption decrements amountMinted, which the sale relies on.",
        "The decrement will attempt to mint the existing ID of amountMinted before it is decremented."
    ],
    "POC": [
        ""
    ],
    "Recommendations": [
        "",
        "Either have a separate variable that only keeps track of minted Pupniks and never decrements, or delay Pupnik redemptions for a fixed period till the sale is deemed complete."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-attacker-can-drain-all-eth-from-ipseed-due-to-re-configuring-tokenid-pashov-none-catalyst-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function spawn(\n    uint256 tokenId,\n    string calldata name,\n    string calldata symbol,\n    string calldata projectId,\n    IIPSeedCurve curve,\n    bytes32 curveParameters,\n    address sourcer\n  ) public {\n    if (tokenId != computeTokenId(_msgSender(), projectId)) {\n      revert InvalidTokenId();\n    }\n\n    // ERC1155's `exists` function checks for totalSupply > 0, which is not what we want here\n    if (bytes(tokenMeta[tokenId].projectId).length > 0) {\n      revert TokenAlreadyExists();\n    }\n\n    Metadata memory newMetadata =\n      Metadata(sourcer, sourcer, name, symbol, projectId, curve, curveParameters);\n    tokenMeta[tokenId] = newMetadata;\n\n    emit Spawned(tokenId, sourcer, newMetadata);\n  }\n"
    ],
    "Severity": [
        "",
        "Impact: High. Attacker can drain all ETH from IPSeed.",
        "Likelihood: High. Nothing prevents from exploiting."
    ],
    "Description": [
        "",
        "Metadata of tokenId can be partially configured. While projectId is empty string, the creator can change the token parameters anytime:",
        "This behavior introduces following attack:",
        "Here is link to PoC: https://gist.github.com/T1MOH593/4c28ede6cdc6d183927bb7e14352ea73"
    ],
    "Recommendations": [
        "",
        "Disallow re-configuring of tokenId, for example require to pass non-empty string projectId"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-attacker-can-drain-all-eth-from-ipseed-due-to-malicious-iipseedcurve-implementation-pashov-none-catalyst-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function spawn(\n    uint256 tokenId,\n    string calldata name,\n    string calldata symbol,\n    string calldata projectId,\n    IIPSeedCurve curve,\n    bytes32 curveParameters,\n    address sourcer\n  ) public {\n    ...\n\n    Metadata memory newMetadata =\n@>    Metadata(sourcer, sourcer, name, symbol, projectId, curve, curveParameters);\n    tokenMeta[tokenId] = newMetadata;\n\n    emit Spawned(tokenId, sourcer, newMetadata);\n  }\n",
        "  function getBuyPrice(uint256 tokenId, uint256 want)\n    public\n    view\n    returns (uint256 gross, uint256 net, uint256 protocolFee, uint256 sourcerFee)\n  {\n    net = tokenMeta[tokenId].priceCurve.getBuyPrice(\n      totalSupply(tokenId), want, tokenMeta[tokenId].curveParameters\n    );\n    (protocolFee, sourcerFee) = computeFees(net);\n    gross = net + protocolFee + sourcerFee;\n  }\n\n  function getSellPrice(uint256 tokenId, uint256 sell)\n    public\n    view\n    returns (uint256 gross, uint256 net, uint256 protocolFee, uint256 sourcerFee)\n  {\n    gross = tokenMeta[tokenId].priceCurve.getSellPrice(\n      totalSupply(tokenId), sell, tokenMeta[tokenId].curveParameters\n    );\n    (protocolFee, sourcerFee) = computeFees(gross);\n    net = gross - protocolFee - sourcerFee;\n  }\n"
    ],
    "Severity": [
        "",
        "Impact: High. Attacker can drain all ETH.",
        "Likelihood: High. Nothing prevents from exploiting."
    ],
    "Description": [
        "",
        "Currently user can specify arbitrary implementation of IIPSeedCurve:",
        "However Curve implementation can be malicious: for example return 0 price on buy and arbitrary price on sell. On burning and minting IPSeed quotes it from Curve implementation:",
        "Malicious Curve implementation can incorrectly price tokens and therefore drain ETH on selling."
    ],
    "Recommendations": [
        "",
        "Allow using only whitelisted implementation of IIPSeedCurve"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-burn-function-doesnt-have-slippage-control-pashov-none-catalyst-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "- function burn(address account, uint256 tokenId, uint256 amount)\n+ function burn(address account, uint256 tokenId, uint256 amount, uint256 minOutputAmount)\n    public\n    virtual\n    override\n    nonReentrant\n  {\n    ...\n\n    //when selling, gross < net\n    (uint256 gross, uint256 net, uint256 protocolFee, uint256 sourcerFee) =\n      getSellPrice(tokenId, amount);\n+   require(net >= minOutputAmount);\n    ...\n  }\n"
    ],
    "Severity": [
        "",
        "Impact: Medium. User receives less collateral than expects.",
        "Likelihood: Medium. Price must go down after submitting transaction to mempool."
    ],
    "Description": [
        "",
        "Currently there is no mechanism for user to specify accepted price on selling tokens.",
        "Therefore following scenario is possible:"
    ],
    "Recommendations": [
        "",
        "Introduce argument like minOutputAmount:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-maxtotaldeposits-is-not-checked-properly-inside-_beforedeposit-pashov-none-ebisu-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function deposit(uint256 assets, address receiver) public virtual override returns (uint256) {\n        // require(assets <= maxDeposit(receiver), \"ERC4626: deposit more than max\");\n>>      _beforeDeposit(assets);\n\n        uint256 shares = previewDeposit(assets);\n        _deposit(_msgSender(), receiver, assets, shares);\n\n        return shares;\n    }\n",
        "    function _beforeDeposit(uint256 assets) internal virtual {\n        require(assets <= maxPerDeposit, \"Vault: deposit amount exceeds per-deposit cap\");\n>>      require(_tokenBalance() <= maxTotalDeposits, \"Vault: deposit amount exceeds total cap\");\n    }\n",
        "    function _beforeDeposit(uint256 assets) internal virtual {\n        require(assets <= maxPerDeposit, \"Vault: deposit amount exceeds per-deposit cap\");\n-        require(_tokenBalance() <= maxTotalDeposits, \"Vault: deposit amount exceeds total cap\");\n+        require(_tokenBalance() + assets <= maxTotalDeposits, \"Vault: deposit amount exceeds total cap\");\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, Because it will allow user to deposit more than maxTotalDeposits."
    ],
    "Likelihood": [
        " Medium, Because it doesn't require a specific scenario, the deposit/mint action at some point can deposit more than maxTotalDeposits."
    ],
    "Description": [
        "",
        "Ebisu vault implements a _beforeDeposit check before users deposit/mint to ensure it does not exceed the configured maxPerDeposit and maxTotalDeposits.",
        "However, in the current _beforeDeposit implementation, the check against maxTotalDeposits only verifies the token balance inside the vault and does not consider the assets that will be deposited by users.",
        "This will allow users to deposit assets that could surpass the maxTotalDeposits value."
    ],
    "Recommendations": [
        "",
        "Consider assets that will be deposited by users when checking against maxTotalDeposits."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-settvllimits-incorrectly-assigns-_newmaxtotaldeposits-to-maxperdeposit-instead-of-maxtotaldeposits-pashov-none-ebisu-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function setTVLLimits(uint256 _newMaxPerDeposit, uint256 _newMaxTotalDeposits) external onlyCapRaiser() {\n        require(_newMaxPerDeposit<=_newMaxTotalDeposits, \"newMaxPerDeposit exceeds newMaxTotalDeposits\");\n\n        maxPerDeposit = _newMaxPerDeposit;\n>>      maxPerDeposit = _newMaxTotalDeposits;\n\n        emit MaxPerDepositUpdated(maxPerDeposit, _newMaxPerDeposit);\n        emit MaxTotalDepositsUpdated(maxTotalDeposits, _newMaxTotalDeposits);\n    }\n",
        "    function setTVLLimits(uint256 _newMaxPerDeposit, uint256 _newMaxTotalDeposits) external onlyCapRaiser() {\n        require(_newMaxPerDeposit<=_newMaxTotalDeposits, \"newMaxPerDeposit exceeds newMaxTotalDeposits\");\n\n        maxPerDeposit = _newMaxPerDeposit;\n-       maxPerDeposit = _newMaxTotalDeposits;\n+       maxTotalDeposits = _newMaxTotalDeposits;\n\n        emit MaxPerDepositUpdated(maxPerDeposit, _newMaxPerDeposit);\n        emit MaxTotalDepositsUpdated(maxTotalDeposits, _newMaxTotalDeposits);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, Because the cap raiser cannot update maxTotalDeposits and will wrongly update maxPerDeposit with _newMaxTotalDeposits."
    ],
    "Likelihood": [
        " Medium, Because it will happened every time cap raiser want to update TVL limits."
    ],
    "Description": [
        "",
        "Current implementation of setTVLLimits is incorrectly assigns _newMaxTotalDeposits to maxPerDeposit instead of maxTotalDeposits."
    ],
    "Recommendations": [
        "",
        "Assign _newMaxTotalDeposits to maxTotalDeposits instead of maxPerDeposit."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-initial-griefing-attack-possible-pashov-none-ebisu-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    Vault vault;\n    MockERC20 asset;\n\n    address bob = makeAddr('bob');\n\n    function setUp() public {\n        asset = new MockERC20();\n        vault = new Vault(100e18,100e18,asset);\n\n        asset.mint(address(this), 10e18 + 9);\n        asset.mint(bob,1e18);\n    }\n\n    function test_initialSupplyManipulation() public {\n        // mint a small number of shares\n        // (9 + 1 = 10) makes math simpler\n        asset.approve(address(vault),9);\n        vault.deposit(9, address(this));\n\n        // do a large donation\n        asset.transfer(address(vault), 10e18);\n\n        // shares per assets is now manipulated\n        assertEq(1e18+1,vault.convertToAssets(1));\n\n        // victim stakes in vault\n        vm.startPrank(bob);\n        asset.approve(address(vault), 1e18);\n        vault.deposit(1e18, bob);\n        vm.stopPrank();\n\n        // due to manipulation they receive 0 shares\n        assertEq(0,vault.balanceOf(bob));\n\n        // attacker redeems their shares\n        vault.redeem(vault.balanceOf(address(this)), address(this), address(this));\n\n        // even though the attacker loses 0.1 tokens\n        assertEq(9.9e18 + 9,asset.balanceOf(address(this)));\n        // the vicims tokens are lost and locked in the contract\n        assertEq(1.1e18,asset.balanceOf(address(vault)));\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, as the victim loses their funds"
    ],
    "Likelihood": [
        " Low, as it comes at a cost for the attacker"
    ],
    "Description": [
        "",
        "The famous initial deposit attack is largely mitigated by the +1 done in the asset/shares conversion. However, doing this attack can cause some strange behavior that could grief users (at high cost of the attacker) and leave the vault in a weird state:",
        "Here's a PoC showing the impacts, can be added to Deposit.t.sol:",
        "As you can see the attacker needs to pay 0.1e18 of assets for the attack. But they have effectively locked the victims 1e18 tokens in the contract.",
        "Even though this is not profitable for the attacker it will leave the vault in a weird state and the victim will still have lost their tokens."
    ],
    "Recommendations": [
        "",
        "Consider mitigating this with an initial deposit of a small amount. This is the most common and easy way to make sure this is not possible, as long as it is an substantial amount it will make this attack too costly."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-inflating-redemption-request-and-dos-in-the-vault-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function requestRedeem(\n        uint256 shares,\n        address operator,\n        address owner\n    ) public nonReentrant {\n        if (owner != msg.sender || shares == 0 || balanceOf(owner) < shares)\n            revert Unauthorized();\n",
        "    uint256 pendingRedemption = totalPendingRedemptionRequest();\n\n    req.totalClaimableRedemption += pendingRedemption;\n",
        "    function sharePrice() public view virtual returns (uint256) {\n        uint256 supply = totalAccountedSupply();\n        return\n            supply == 0\n                ? weiPerShare\n                : totalAccountedAssets().mulDiv( // eg. e6\n                    weiPerShare ** 2, // 1e8*2\n                    supply * weiPerAsset\n                ); // eg. (1e6+1e8+1e8)-(1e8+1e6)\n    }\n",
        "    function totalAccountedAssets() public view returns (uint256) {\n        return\n            totalAssets() -\n            req.totalClaimableRedemption.mulDiv(\n                last.sharePrice * weiPerAsset,\n                weiPerShare ** 2\n            ); // eg. (1e8+1e8+1e6)-(1e8+1e8) = 1e6\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because this can disrupt all primary functionalities of the vaults, leading to a denial of service"
    ],
    "Likelihood": [
        " High, because any vault share owner can exploit this easily"
    ],
    "Description": [
        "",
        "In requestRedeem, the function ensures that the shares requested for redemption are not greater than the owner's share balance. However, the operator parameter is not validated. This allows users to inflate the req.totalRedemption value by repeatedly submitting redemption requests with different operator addresses. The req.totalRedemption can be inflated to be larger than totalAssets.",
        "This inflation of totalRedemption subsequently leads to an increase in pendingRedemption during the liquidate function call by the keeper, which in turn inflates req.totalClaimableRedemption",
        "The inflated req.totalClaimableRedemption disrupts the sharePrice() function, causing it to consistently revert. This is problematic as critical operations like deposit, mint, withdraw, and redeem rely on the sharePrice function.",
        "The sharePrice function reverts because the totalAccountedAssets calculation returns a negative value due to totalAssets being smaller than the inflated req.totalClaimableRedemption. This calculation error results in a DoS for the entire protocol."
    ],
    "Recommendations": [
        "",
        "To validate the operator in the requestRedeem function and ensure that an owner can only request redemption once, using their own shares."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-wrong-usage-of-mapping-target-in-cancelredeemrequest-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function cancelRedeemRequest(\n        address operator,\n        address owner\n    ) external nonReentrant {\n\n        if (owner != msg.sender && operator != msg.sender)\n            revert Unauthorized();\n\n        Erc7540Request storage request = req.byOperator[operator];\n        uint256 shares = request.shares;\n\n        if (shares == 0) revert AmountTooLow(0);\n\n        last.sharePrice = sharePrice();\n\n        if (last.sharePrice > request.sharePrice) {\n            // burn the excess shares from the loss incurred while not farming\n            // with the idle funds (opportunity cost)\n            uint256 opportunityCost = shares.mulDiv(\n                last.sharePrice - request.sharePrice,\n                weiPerShare\n            ); // eg. 1e8+1e8-1e8 = 1e8\n            _burn(owner, opportunityCost);\n        }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, one can burn others' tokens"
    ],
    "Likelihood": [
        " High, it can be done permissionless"
    ],
    "Description": [
        "",
        "Users can call cancelRedeemRequest() can cancel their redeem requests and code would burn the excess shares from the loss incurred while not farming with the idle funds (opportunity cost). The issue is that code doesn't check that operator have allowance over owner's funds and one can call this function and burn others tokens.",
        "also the second mistake is that code uses req.byOperator[operator] instead of the req.byOperator[owner].",
        "This is the POC:",
        "There is similar bug in the requestRedeem() and _withdraw() that require attention too."
    ],
    "Recommendations": [
        "",
        "In cancelRedeemRequest() use req.byOperator[owner] and also make sure operator have allowance over owner tokens.\nIn requestRedeem() code should save information in req.byOperator[owner] and also confirms that operator have allowance over owner funds.\nUse req.byOperator[_owner] in _withdraw()."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-accounts-not-properly-removed-from-roles-upon-revoking-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _revokeRole(bytes32 role, address account) internal virtual {\n        if (hasRole(role, account)) {\n            _roles[role].members.remove(account.toBytes32());\n            emit RoleRevoked(role, account, msg.sender);\n        }\n    }\n",
        "    struct Set {\n        bytes32[] data;\n        mapping(bytes32 => uint32) index;\n    }\n",
        "    function remove(Set storage q, bytes32 o) internal {\n        uint32 i = q.index[o];\n        require(i > 0, \"Element not found\");\n        removeAt(q, i - 1);\n    }\n\n    function removeAt(Set storage q, uint256 i) internal {\n        require(i < q.data.length, \"Index out of bounds\");\n        if (i < q.data.length - 1) {\n            delete q.data[i];\n            q.data[i] = q.data[q.data.length - 1];\n        }\n        q.data.pop();\n    }\n",
        "    function hasRole(bytes32 role, address account) public view virtual returns (bool) {\n        return _roles[role].members.has(account.toBytes32());\n    }\n",
        "    function has(Set storage q, bytes32 o) internal view returns (bool) {\n        return q.index[o] > 0 && q.index[o] <= q.data.length;\n    }\n",
        "    function remove(Set storage q, bytes32 o) internal {\n        uint32 i = q.index[o];\n+       q.index[o] = 0;\n        require(i > 0, \"Element not found\");\n        removeAt(q, i - 1);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High - Accounts that are removed from a role, particularly critical roles like the default admin, retain access to the role's privileges. This poses significant security risks."
    ],
    "Likelihood": [
        " Medium - The issue occurs consistently every time the revokeRole function is called."
    ],
    "Description": [
        "",
        "When an account is revoked from a role, _revokeRole function removes account from the members set.",
        "In the AsSequentialSet.sol library, roles are stored in the Set struct, which contains an array data and a mapping index from bytes32 to uint32.",
        "The remove function in the library is supposed to handle the removal of elements but calls removeAt which only removes the account from the Set.data array and does not reset the Set.index.",
        "Therefore, when the hasRole function checks if a user has a role by using the has function.",
        "And the has function only checks the index of that account, and the index still exists. It means after the user is removed from the role, it still has the role."
    ],
    "POC": [
        "",
        "Put the file in test/POC.t.sol",
        "https://gist.github.com/thangtranth/685dd8fa7faae141cdd2b1d0061b16f5"
    ],
    "Recommendations": [
        "",
        "The remove function in AsSequentialSet.sol should be modified to reset the index of the removed account"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-flash-loan-wrong-balance-check-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: src\\abstract\\As4626.sol\n696:     function flashLoanSimple() external nonReentrant {\n\n705:         uint256 fee = exemptionList[msg.sender] ? 0 : amount.bp(fees.flash);\n706:         uint256 toRepay = amount + fee;\n707:\n708:         uint256 balanceBefore = asset.balanceOf(address(this));\n709:         totalLent += amount;\n710:\n711:         asset.safeTransferFrom(address(this), address(receiver), amount);\n712:         receiver.executeOperation(address(asset), amount, fee, msg.sender, params);\n713:\n714:         if ((asset.balanceOf(address(this)) - balanceBefore) < toRepay)\n715:             revert FlashLoanDefault(msg.sender, amount);\n\n718:     }\n",
        "File: src\\abstract\\As4626.sol\n696:     function flashLoanSimple() external nonReentrant {\n\n705:         uint256 fee = exemptionList[msg.sender] ? 0 : amount.bp(fees.flash);\n- 706:         uint256 toRepay = amount + fee;\n707:\n708:         uint256 balanceBefore = asset.balanceOf(address(this));\n709:         totalLent += amount;\n710:\n711:         asset.safeTransferFrom(address(this), address(receiver), amount);\n712:         receiver.executeOperation(address(asset), amount, fee, msg.sender, params);\n713:\n- 714:         if ((asset.balanceOf(address(this)) - balanceBefore) < toRepay)\n+ 714:         if ((asset.balanceOf(address(this)) - balanceBefore) < fee)\n715:             revert FlashLoanDefault(msg.sender, amount);\n\n718:     }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, because the flash loan functionality is affected"
    ],
    "Likelihood": [
        " High, because it will revert every time \u0430 flash loan is used"
    ],
    "Description": [
        "",
        "balanceBefore is recorded before the flash loan amount being transferred. As a result, in line 714, balanceAfter need to be more than needed. Users have to pay extra with the same amount to use a flash loan."
    ],
    "Recommendations": [
        "",
        "The toRepay variable could be dropped, or record the balanceBefore after safeTransferFrom:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-flash-loan-not-working-due-to-transferfrom-issue-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        function flashLoanSimple(\n            IFlashLoanReceiver receiver,\n            uint256 amount,\n            bytes calldata params\n        ) external nonReentrant {\n\n            uint256 available = availableBorrowable();\n            if (amount > available || amount > maxLoan) revert AmountTooHigh(amount);\n\n            uint256 fee = exemptionList[msg.sender] ? 0 : amount.bp(fees.flash);\n            uint256 toRepay = amount + fee;\n\n            uint256 balanceBefore = asset.balanceOf(address(this));\n            totalLent += amount;\n\n@>          asset.safeTransferFrom(address(this), address(receiver), amount);\n            receiver.executeOperation(address(asset), amount, fee, msg.sender, params);\n\n            if ((asset.balanceOf(address(this)) - balanceBefore) < toRepay)\n                revert FlashLoanDefault(msg.sender, amount);\n\n            emit FlashLoan(msg.sender, amount, fee);\n        }\n",
        "    function transferFrom(\n        address from,\n        address to,\n        uint256 value\n    )\n        external\n        override\n        whenNotPaused\n        notBlacklisted(msg.sender)\n        notBlacklisted(from)\n        notBlacklisted(to)\n        returns (bool)\n    {\n        require(\n            value <= allowed[from][msg.sender],\n            \"ERC20: transfer amount exceeds allowance\"\n        );\n        _transfer(from, to, value);\n        allowed[from][msg.sender] = allowed[from][msg.sender].sub(value);\n        return true;\n    }\n",
        "        function flashLoanSimple(\n            IFlashLoanReceiver receiver,\n            uint256 amount,\n            bytes calldata params\n        ) external nonReentrant {\n\n            uint256 available = availableBorrowable();\n            if (amount > available || amount > maxLoan) revert AmountTooHigh(amount);\n\n            uint256 fee = exemptionList[msg.sender] ? 0 : amount.bp(fees.flash);\n            uint256 toRepay = amount + fee;\n\n            uint256 balanceBefore = asset.balanceOf(address(this));\n            totalLent += amount;\n\n-           asset.safeTransferFrom(address(this), address(receiver), amount);\n+           asset.safeTransfer(address(receiver), amount);\n            receiver.executeOperation(address(asset), amount, fee, msg.sender, params);\n\n            if ((asset.balanceOf(address(this)) - balanceBefore) < toRepay)\n                revert FlashLoanDefault(msg.sender, amount);\n\n            emit FlashLoan(msg.sender, amount, fee);\n        }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium - The flash loan functionality is non-operational, but there's no risk of fund loss."
    ],
    "Likelihood": [
        " High - The flash loan function consistently fails to execute as intended."
    ],
    "Description": [
        "",
        "The issue arises when users attempt to use the flashLoanSimple function:",
        "To transfer the fund to users, it uses asset.safeTransferFrom(address(this), address(receiver), amount);",
        "This line intends to transfer funds to the user. However, it fails because safeTransferFrom requires the contract to have a sufficient allowance to \"spend\" on behalf of itself. In the context of ERC20 tokens like USDC, the transferFrom function includes a crucial check: value <= allowed[from][msg.sender]",
        "However, because the contract has not yet approved itself, leading to a situation where the allowance remains at zero, and hence the transferFrom call reverts.",
        "USDC - FiatTokenV1.sol: https://arbiscan.io/address/0xaf88d065e77c8cc2239327c5edb3a432268e5831",
        "Using transfer does not require additional approval."
    ],
    "Recommendations": [
        "",
        "Replacing the safeTransferFrom function with safeTransfer:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-04-withdraw-worst-price-will-distort-shareprice-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: src\\abstract\\As4626.sol\n149:     function _withdraw() internal nonReentrant returns (uint256) {\n159:         last.sharePrice = sharePrice();\n\n161:         uint256 price = (claimable >= _shares)\n162:             ? AsMaths.min(last.sharePrice, request.sharePrice) // worst of if pre-existing request\n163:             : last.sharePrice; // current price\n",
        "File: src\\abstract\\As4626.sol\n84:     function _deposit() internal nonReentrant returns (uint256) {\n93:         last.sharePrice = sharePrice();\n\n149:     function _withdraw() internal nonReentrant returns (uint256) {\n159:         last.sharePrice = sharePrice();\n\n512:     function requestRedeem() public nonReentrant {\n523:         last.sharePrice = sharePrice();\n\n577:     function cancelRedeemRequest() external nonReentrant {\n590:         last.sharePrice = sharePrice();\n",
        "File: src\\abstract\\As4626Abstract.sol\n175:     function sharePrice() public view virtual returns (uint256) {\n176:         uint256 supply = totalAccountedSupply();\n177:         return\n178:             supply == 0\n179:                 ? weiPerShare\n180:  @>>>>          : totalAccountedAssets().mulDiv( // eg. e6\n181:                     weiPerShare ** 2, // 1e8*2\n182:                     supply * weiPerAsset\n183:                 ); // eg. (1e6+1e8+1e8)-(1e8+1e6)\n184:     }\n\n154:     function totalAccountedAssets() public view returns (uint256) {\n155:         return\n156:             totalAssets() -\n157:             req.totalClaimableRedemption.mulDiv(\n158:  @>>>>          last.sharePrice * weiPerAsset,\n159:                 weiPerShare ** 2\n160:             ); // eg. (1e8+1e8+1e6)-(1e8+1e8) = 1e6\n161:     }\n",
        "File: src\\abstract\\As4626Abstract.sol\n154:     function totalAccountedAssets() public view returns (uint256) {\n155:         return\n156:             totalAssets() -\n157:             req.totalClaimableRedemption.mulDiv(\n158:                 last.sharePrice * weiPerAsset,\n159:                 weiPerShare ** 2\n160:             ); // eg. (1e8+1e8+1e6)-(1e8+1e8) = 1e6\n161:     }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because inaccurate price will cause long term value leaking, and can not be fixed"
    ],
    "Likelihood": [
        " Medium, because every time withdraw() with existing request will bring in error into the system"
    ],
    "Description": [
        "",
        "The worst price is used in _withdraw(), which means the actual withdraw price is different from last.sharePrice.",
        "last.sharePrice is only updated in the following cases, none of them take the real withdraw price into consideration.``",
        "Let's look at how sharePrice() is calculated:\nFirst it calls totalAccountedAssets(), and in totalAccountedAssets() the last.sharePrice is directly used, seems the assumption is: last.sharePrice remain constant with each deposit()/withdraw(). However it does not hold since the worst price usage.",
        "To summarize, when request.sharePrice < sharePrice(), the withdrawal will processed at a lower price than current, in which case the discrepancy would incur an effective sharePrice increase that would not be factored-in last.sharePrice.",
        "Let's see some number example:",
        "Now total asset is 1000 - 20 * 5 = 900. But last.sharePrice remains 10, due to As4626.sol#159 (last.sharePrice = sharePrice()). The actual price should be 900 / 80 = 11.25.",
        "The next time totalAccountedAssets() will return 900 - 20 * 10 = 700, sharePrice() will return 700 / 60 = 11.67, around 3.7% difference (11.67~11.25).",
        "So if some user tries to deposit a bit amount, 3.7% slippage will be the loss.",
        "I believe in normal situations, if the last.sharePrice and request.sharePrice are relatively close, the sharePrice will only diff slightly."
    ],
    "Recommendations": [
        "",
        "One possible mitigation is to update the last.sharePrice after deposit()/withdraw()."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-05-fee-calculation-mismatch-in-mint-deposit-redeem-and-withdraw-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, fee will be a little higher/lower"
    ],
    "Likelihood": [
        " High, because it happens in every call to mint and deposit functions"
    ],
    "Description": [
        "",
        "When users calls mint(shares) code calls _deposit(previewMint(_shares), _shares and previewMint(shares) = convertToAssets(shares).addBp().\nWhen users calls deposit(amount) code calls _deposit(_amount, previewDeposit(_amount) and previewDeposit(amount) = convertToShares(amount).subBp.",
        "Let's assume that price is 1:1 and fee is 10% and check the both case:",
        "As you can see the deposit() call overcharge the user. The reason is that code calculates fee based on user-specified amount by using subBp() but user-specified amount is supposed to be amount + fee so the calculation for fee should be .... * base / (base +fee).",
        "When users call redeem(shares) code calls _withdraw(previewRedeem(_shares), _shares) and previewRdeem(shares) = convertToAssets(_shares).subBp().",
        "When users call withdraw() code calls _withdraw(_amount, previewWithdraw(_amount)) and previewWithdraw(_amount) = convertToShares(_assets).addBp()",
        "Let's assume that asset to share price is 1:1 and fee is 10% and check both case:",
        "So as you can see redeem() overcharges users. The reason is that code calculates fee based on user provided share with subBp() but the provided amount is total amount (burnAmount + fee) and calculation should be ..... * base / (base + fee)"
    ],
    "Recommendations": [
        "",
        "Calculate the fee for deposit() with convertToShare(amount) * base / (base +fee).\nCalculate the fee for previewRedeem() with convertToAssets(shares) * base / (base + fee)"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-06-fee-target-mismatch-in-deposit-mint-withdraw-redeem-and-preview-methods-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function previewDeposit(\n        uint256 _amount\n    ) public view returns (uint256 shares) {\n        return convertToShares(_amount).subBp(exemptionList[msg.sender] ? 0 : fees.entry);\n    }\n\n    function previewMint(uint256 _shares) public view returns (uint256) {\n        return convertToAssets(_shares).addBp(exemptionList[msg.sender] ? 0 : fees.entry);\n    }\n",
        "        if (!exemptionList[_receiver])\n            claimableAssetFees += _amount.revBp(fees.entry);\n",
        "    function previewWithdraw(uint256 _assets) public view returns (uint256) {\n        return convertToShares(_assets).addBp(exemptionList[msg.sender] ? 0 : fees.exit);\n    }\n\n    function previewRedeem(uint256 _shares) public view returns (uint256) {\n        return convertToAssets(_shares).subBp(exemptionList[msg.sender] ? 0 : fees.exit);\n    }\n",
        "        if (!exemptionList[_owner])\n            claimableAssetFees += _amount.revBp(fees.exit);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because it can cause double spending and disturb the pool calculations"
    ],
    "Likelihood": [
        " Medium, because exception recipients are set by admin for common addresses"
    ],
    "Description": [
        "",
        "When users want to deposit their tokens, code calculates fee in previewDeposit() and previewMint() and add/subtract it from the amount/share. As you can see code checks entry fee based on msg.sender:",
        "In _deposit(), code wants to account the fee and keep track of it, it perform this action:",
        "As you can see it uses _receiver variable which is controllable by caller.",
        "So attacker with two addresses: RECV1 address and has set as exemptionList[] can ADDERSS1 which doesn't set as exemptionList[] can call mint and deposit with ADDRESS1 and set recipient as RECV1 . In preview functions code doesn't add the fee for user deposit(or subtract it from shares) and code would assume user didn't pay any fee, but in the _deposit() function code would check RECV1 address and would add calculated fee to accumulated fee. So in the end user didn't paid the fee but code added fee and double spending would happen.",
        "Attacker can use another scenarios to perform this issue too. (code calculates fee and caller pays it but code doesn't add it to claimableAssetFees )",
        "When users want to withdraw their tokens, Code charges fee and it's done in preview functions by adding/subtracting fee from amount/share. As you can see code checks exit fee based on exemptionList[] and uses msg.sender as target:",
        "But in _withdraw() function when code wants to calculates fee and accumulated it, it uses _owner:",
        "owner can be different that caller(msg.sender) and code checks that caller have approval over the owner's funds.\nSo attacker can exploit this with two of his address: OWNER1 which has set as exemptionList[] and OPERATOR1 which doesn't set as exemptionList[]. If attacker give approval of OWNER1 tokens to OPERATOR1 and calls withdraw(OWNER1) with OPERATOR1 address then double spend would happen. While code returns funds fully with no charged fee it would also add fee to claimableAssetFees.",
        "This can be exploited in other scenarios too. In general this inconsistency would cause accountant errors."
    ],
    "Recommendations": [
        "",
        "Calculate the fee based on msg.sender in the _deposit() function.\nIn _withdraw() function calculate fee based on msg.sender and finally fix the preview functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-07-accounting-issues-after-underlying-asset-change-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because the accounting would go wrong for multiple scenarios"
    ],
    "Likelihood": [
        " Medium, because it would happen when admin calls changeAsset()"
    ],
    "Description": [
        "",
        "In general updating underlying asset is very risky move in a pool.\nAll the cached prices will be wrong.",
        "In the current code we have two cached prices(that I know of):\nIn requestRedeem() code caches pool prices for requests. Code use it later in the withdraw and cancel request. (the price impact withdraw price and also burning tokens in cancel requests)",
        "In calculating fee, code caches pool price and use it to calculate fee later.",
        "(there may be other places the pool price is cached)",
        "\u2014\u2014\u2014\nAnother place that is asset amount is cached is claimableAssetFees. updateAsset() calls the _collectFees() to handle the claimableAssetFees and set it to zero but because of this line in the _collectFees()\nIf (profit == 0) return;\nclaimableAssetFees (which shows amount in old asset) could remain non-zero after asset update."
    ],
    "Recommendations": [
        "",
        "Reset the cached prices after the asset change."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-redeem-function-active-when-vault-is-paused-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function deposit(\n        uint256 _amount,\n        address _receiver\n    ) public whenNotPaused returns (uint256 shares) {\n\n    function safeDeposit(\n        uint256 _amount,\n        uint256 _minShareAmount,\n        address _receiver\n    ) public whenNotPaused returns (uint256 shares) {\n\n    function withdraw(\n        uint256 _amount,\n        address _receiver,\n        address _owner\n    ) external whenNotPaused returns (uint256) {\n\n    function safeWithdraw(\n        uint256 _amount,\n        uint256 _minAmount,\n        address _receiver,\n        address _owner\n    ) public whenNotPaused returns (uint256 amount) {\n",
        "    function redeem(\n        uint256 _shares,\n        address _receiver,\n        address _owner\n    ) external returns (uint256 assets) {\n\n    function safeRedeem(\n        uint256 _shares,\n        uint256 _minAmountOut,\n        address _receiver,\n        address _owner\n    ) external returns (uint256 assets) {\n",
        "    function redeem(\n        uint256 _shares,\n        address _receiver,\n        address _owner\n-   ) external returns (uint256 assets) {\n+   ) external whenNotPaused returns (uint256 assets) {\n        return _withdraw(previewRedeem(_shares), _shares, _receiver, _owner);\n    }\n\n    function safeRedeem(\n        uint256 _shares,\n        uint256 _minAmountOut,\n        address _receiver,\n        address _owner\n-    ) external returns (uint256 assets) {\n+    ) external whenNotPaused returns (uint256 assets) {\n        assets = _withdraw(\n            previewRedeem(_shares),\n            _shares, // _shares\n            _receiver, // _receiver\n            _owner // _owner\n        );\n        if (assets < _minAmountOut) revert AmountTooLow(assets);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High - Allows unauthorized withdrawal of assets during critical situations when the vault is paused."
    ],
    "Likelihood": [
        " Low - This issue occurs only when the vault is in a paused state."
    ],
    "Description": [
        "",
        "The vault's deposit, mint, and withdraw functionalities are halted when it is paused. This is implemented through the whenNotPaused modifier in the following functions:",
        "However, the redeem function is not pausable because the whenNotPaused modifier is not applied . This absence allows users to withdraw assets from the vaul when they should not."
    ],
    "Recommendations": [
        "",
        "Adding the whenNotPaused modifier to both the redeem and safeRedeem functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-wrong-rounding-direction-in-previewwithdraw-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        // amount/shares cannot be higher than the share price (dictated by the inline convertToAssets below)\n        if (_amount >= _shares.mulDiv(price * weiPerAsset, weiPerShare ** 2))\n            revert AmountTooHigh(_amount);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low, because revert in mint() and violates EIP4626"
    ],
    "Likelihood": [
        " High, because division happens in each tx"
    ],
    "Description": [
        "",
        "According to the EIP4626  previewWithdraw should round up when performing division:",
        "But in current implementation code rounds down and favors the caller instead of the contract.",
        "Function withdraw() uses previewWithdraw() to calculate shares and calls _withdraw(), as there is a check for price in _withdraw() to make sure user received price isn't better than current price, so that check will fail and cause revert when rounding errors happens. (calculated _shares will be smaller and the right side of the condition will be smaller)"
    ],
    "Recommendations": [
        "",
        "Change previewWithdraw so that it rounds up when calculating shares."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-wrong-rounding-direction-in-previewmint-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        if (_shares > _amount.mulDiv(weiPerShare ** 2, last.sharePrice * weiPerAsset))\n            revert AmountTooHigh(_amount);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low, because it violates EIP and also cause revert in mint()"
    ],
    "Likelihood": [
        " High, because division happens in every mint() call"
    ],
    "Description": [
        "",
        "According to the EIP4626 function previewMint() should round up when calculating assets:",
        "in current implementation code rounds down. this will cause calculations to be in favor of the caller instead of the contract.",
        "in function mint() code uses previewMint() and calls _deposit(), as previewMint() would calculate smaller amount for _amount so the check inside the _deposit() that makes sure user don't receive better price than current price would fail and call would revert: (_amount would be lower a little and cause right side of the condition to be smaller)"
    ],
    "Recommendations": [
        "",
        "Change previewMint so that it rounds up when calculating shares."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-wrong-usage-of-revbp-in-deposit-in-fee-calculation-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        // slice the fee from the amount (gas optimized)\n        if (!exemptionList[_receiver])\n            claimableAssetFees += _amount.revBp(fees.entry);\n",
        "    function revBp(\n        uint256 amount,\n        uint256 basisPoints\n    ) internal pure returns (uint256) {\n        return mulDiv(amount, basisPoints, BP_BASIS - basisPoints);\n    }\n",
        "             claimableAssetFees  += _amount * fees.entry / (BP_BASIS  + fees.entry)\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low, because wrong accounting of fee"
    ],
    "Likelihood": [
        " High, because it will happen in each call to deposit/mint"
    ],
    "Description": [
        "",
        "In _deposit() function code calculates fee like this:",
        "And the revBp() logic is:",
        "As the amount in the deposit is not sliced and it is deposit + fee so the calculation for fee is wrong."
    ],
    "Recommendations": [
        "",
        "Fee calculation should be:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-using-deprecated-function-in-chainlink-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _usdToInput(uint256 _amount, uint8 _index) internal view returns (uint256) {\n    return _amount.mulDiv(10**uint256(inputFeedDecimals[_index]) * inputDecimals[_index],\n        uint256(inputPriceFeeds[_index].latestAnswer()) * 1e6); // eg. (1e6+1e8+1e6)-(1e8+1e6) = 1e6\n}\n",
        "uint256 private constant GRACE_PERIOD_TIME = 3600; // how long till we consider the price as stale\n\nfunction getChainlinkPrice (AggregatorV2V3Interface feed) internal {\n    (uint80 roundId, int256 price, uint startedAt, uint updatedAt, uint80 answeredInRound) = feed.latestRoundData();\n    require(price > 0, \"invalid price\");\n    require(block.timestamp <= updatedAt + GRACE_PERIOD_TIME, \"Stale price\");\n    return price;\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High - Using stale prices leads to inaccurate calculations of total asset values and share prices."
    ],
    "Likelihood": [
        " Low - The return price can be wrong or stale without validating"
    ],
    "Description": [
        "",
        "To convert from USD to input token amount, StrategyV5Chainlink uses IChainlinkAggregatorV3.latestAnswer. However the function latestAnswer is deprecated by Chainlink. This deprecated function usage is also observed in other libraries, such as ChainlinkUtils.",
        "For reference: https://docs.chain.link/data-feeds/api-reference#latestanswer",
        "IChainlinkAggregatorV3.latestRoundData should be used instead."
    ],
    "Recommendations": [
        "",
        "Update the function to use latestRoundData from Chainlink. This method provides comprehensive data about the latest price round, including the timestamp, ensuring the price's freshness and relevance.",
        "Example implementation:",
        "When deploying on Arbitrum, include a check to verify the status of the Arbitrum Sequencer, as this can impact the reliability of the price feeds.",
        "Example: https://docs.chain.link/data-feeds/l2-sequencer-feeds#example-code"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-fee-on-transfer-token-will-break-accounting-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: src\\abstract\\As4626.sol\n69:     function mint(\n70:         uint256 _shares,\n71:         address _receiver\n72:     ) public returns (uint256 assets) {\n73:         return _deposit(previewMint(_shares), _shares, _receiver);\n74:     }\n\n117:     function deposit(\n118:         uint256 _amount,\n119:         address _receiver\n120:     ) public whenNotPaused returns (uint256 shares) {\n121:         return _deposit(_amount, previewDeposit(_amount), _receiver);\n122:     }\n\n84:     function _deposit(\n85:         uint256 _amount,\n86:         uint256 _shares,\n87:         address _receiver\n88:     ) internal nonReentrant returns (uint256) {\n\n98:         asset.safeTransferFrom(msg.sender, address(this), _amount);\n\n105:         _mint(_receiver, _shares);\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because the accounting will be incorrect, and the sharePrice will be affected"
    ],
    "Likelihood": [
        " Low, because fee on transfer token is not commonly used"
    ],
    "Description": [
        "",
        "mint()/deposit() is using amount for transfering and accounting. But fee on transfer token could break the accounting, since the actual token received will be less than amount. As a result, sharePrice will have some small error each time.",
        "USDT potentially could turn on fee on transfer feature, but not yet."
    ],
    "Recommendations": [
        "",
        "Use before and after balance to accurately reflect the true amount received, and update share price accordingly."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-using-stale-price-in-pyth-network-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function assetExchangeRate(uint8 inputId) public view returns (uint256) {\n        if (inputPythIds[inputId] == assetPythId)\n            return weiPerShare; // == weiPerUnit of asset == 1:1\n        PythStructs.Price memory inputPrice = pyth.getPriceUnsafe(inputPythIds[inputId]);\n        PythStructs.Price memory assetPrice = pyth.getPriceUnsafe(assetPythId);\n        ...\n    }\n",
        "    /// @notice Returns the price of a price feed without any sanity checks.\n    /// @dev This function returns the most recent price update in this contract without any recency checks.\n    /// This function is unsafe as the returned price update may be arbitrarily far in the past.\n    ///\n    /// Users of this function should check the `publishTime` in the price to ensure that the returned price is\n    /// sufficiently recent for their application. If you are considering using this function, it may be\n    /// safer / easier to use either `getPrice` or `getPriceNoOlderThan`.\n    /// @return price - please read the documentation of PythStructs.Price to understand how to use this safely.\n    function getPriceUnsafe(\n        bytes32 id\n    ) external view returns (PythStructs.Price memory price);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High - Using stale prices leads to inaccurate calculations of total asset values and share prices."
    ],
    "Likelihood": [
        " Low - Price can be stale frequently if there is no update"
    ],
    "Description": [
        "",
        "The StrategyV5Pyth uses pyth.getPriceUnsafe for obtaining Pyth oracle price feeds to calculate the asset/input exchange rate.",
        "However, from the Pyth documents, using the getPriceUnsafe can return stale price if the price is not updated.",
        "The assetExchangeRate function doesn't verify Price.publishTime, potentially leading to outdated exchange rates, incorrect investment calculations, and distorted total asset values."
    ],
    "Recommendations": [
        "",
        "Using pyth.updatePriceFeeds for updating prices, followed by pyth.getPrice for retrieval.\nFollowing the example in: https://github.com/pyth-network/pyth-sdk-solidity/blob/main/README.md#example-usage"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-08-erc20approve-will-revert-for-some-non-standard-tokens-like-usdt-pashov-none-astrolab-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function setSwapperAllowance(uint256 _amount) public onlyAdmin {\n        address swapperAddress = address(swapper);\n\n        for (uint256 i = 0; i < rewardLength; i++) {\n            if (rewardTokens[i] == address(0)) break;\n            IERC20Metadata(rewardTokens[i]).approve(swapperAddress, _amount);\n        }\n        for (uint256 i = 0; i < inputLength; i++) {\n            if (address(inputs[i]) == address(0)) break;\n            inputs[i].approve(swapperAddress, _amount);\n        }\n        asset.approve(swapperAddress, _amount);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, because functionality won't work"
    ],
    "Likelihood": [
        ": Medium, because USDT is a common token"
    ],
    "Description": [
        "",
        "Code uses the approve method to set allowance for ERC20 tokens in setSwapperAllowance. This will cause revert if the target ERC20 was a non-standard token that has different function signature for approve() function. Tokens like USDT will cause revert for this function, so they can't be used as reward token, input token and underlying asset."
    ],
    "Recommendations": [
        "",
        "Use SafeERC20's forceApprove method instead to support all the ERC20 tokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-gateway-creator-can-steal-all-tokens-from-the-gatewayregistry-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function register(bytes calldata peerId, string memory metadata, address gatewayAddress) public whenNotPaused {\n    require(peerId.length > 0, \"Cannot set empty peerId\");\n    bytes32 peerIdHash = keccak256(peerId);\n    require(gateways[peerIdHash].operator == address(0), \"PeerId already registered\");\n\n    gateways[peerIdHash] = Gateway({\n      operator: msg.sender,\n      peerId: peerId,\n      strategy: defaultStrategy,\n      ownAddress: gatewayAddress,\n      metadata: metadata,\n      totalStaked: 0,\n>>    totalUnstaked: 0\n    });\n",
        "  function _stakeWithoutTransfer(bytes calldata peerId, uint256 amount, uint128 durationBlocks) internal {\n    (Gateway storage gateway, bytes32 peerIdHash) = _getGateway(peerId);\n    _requireOperator(gateway);\n\n    uint256 _computationUnits = computationUnitsAmount(amount, durationBlocks);\n    uint128 lockStart = router.networkController().nextEpoch();\n    uint128 lockEnd = lockStart + durationBlocks;\n>>  stakes[peerIdHash].push(Stake(amount, _computationUnits, lockStart, lockEnd));\n",
        "  function _unstakeable(Gateway storage gateway) internal view returns (uint256) {\n    Stake[] memory _stakes = stakes[keccak256(gateway.peerId)];\n    uint256 blockNumber = block.number;\n    uint256 total = 0;\n    for (uint256 i = 0; i < _stakes.length; i++) {\n      Stake memory _stake = _stakes[i];\n      if (_stake.lockEnd <= blockNumber) {\n        total += _stake.amount;\n      }\n    }\n    return total - gateway.totalUnstaked;\n  }\n",
        "  function test_StealStakes() public {\n    uint256 amount = 100;\n    address alice = address(0xA11cE);\n    token.transfer(alice, amount);\n\n    // stakers stake into their gateways\n    gatewayRegistry.stake(peerId, amount, 200);\n    vm.startPrank(alice);\n    token.approve(address(gatewayRegistry), type(uint256).max);\n    gatewayRegistry.register(bytes(\"alice\"), \"\", address(0x6a7e));\n    gatewayRegistry.stake(bytes(\"alice\"), amount, 200);\n\n    assertEq(token.balanceOf(address(gatewayRegistry)), 200);\n    // exploit\n    vm.roll(block.number + 300);\n    gatewayRegistry.unstake(bytes(\"alice\"), amount);\n    gatewayRegistry.unregister(bytes(\"alice\"));\n    gatewayRegistry.register(bytes(\"alice\"), \"\", address(0x6a7e));\n    // unstake again\n    gatewayRegistry.unstake(bytes(\"alice\"), amount);\n    assertEq(token.balanceOf(address(gatewayRegistry)), 0);\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, user's funds will be stolen"
    ],
    "Likelihood": [
        " High, can be exploited by anyone and easy to implement"
    ],
    "Description": [
        "",
        "GatewayRegistry contract allows users to register and stake tokens into gateways to receive computation units CUs. First, the user registers a gateway,",
        "note totalUnstaked is set to 0. After this we can stake tokens",
        "stakes mapping is used to track all user stakes. The problem arises when we unregister the gateway, we do not delete the stakes, it can be exploited in the following steps:",
        "Here is the coded POC for GatewayRegistry.unstake.t.sol "
    ],
    "Recommendations": [
        "",
        "Delete stakes mapping when gateway is being unregistered."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-missing-check-on-toblock-allows-distributors-to-change-past-rewards-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\n    recipients.length == workerRewards.length,\n    \"Recipients and worker amounts length mismatch\"\n);\nrequire(\n    recipients.length == _stakerRewards.length,\n    \"Recipients and staker amounts length mismatch\"\n);\n\nrequire(currentDistributor() == msg.sender, \"Not a distributor\");\n//@audit missing check on block span\nrequire(toBlock < block.number, \"Future block\");\n",
        "require(\n    lastBlockRewarded == 0 || fromBlock == lastBlockRewarded + 1,\n    \"Not all blocks covered\"\n);\n",
        "lastBlockRewarded = toBlock;\n",
        "function test_RunsDistributionAfter3Approves() public {\n    (\n        uint256[] memory recipients,\n        uint256[] memory workerAmounts,\n        uint256[] memory stakerAmounts\n    ) = prepareRewards(1);\n    rewardsDistribution.addDistributor(address(1));\n    rewardsDistribution.addDistributor(address(2));\n    rewardsDistribution.setApprovesRequired(3);\n    vm.roll(10);\n    rewardsDistribution.commit(\n        1,\n        0,\n        recipients,\n        workerAmounts,\n        stakerAmounts\n    );\n    hoax(address(1));\n    rewardsDistribution.approve(\n        1,\n        0,\n        recipients,\n        workerAmounts,\n        stakerAmounts\n    );\n    hoax(address(2));\n    rewardsDistribution.approve(\n        1,\n        0,\n        recipients,\n        workerAmounts,\n        stakerAmounts\n    );\n}\n",
        "require(toBlock > fromBlock, \"Invalid block span\");\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, Breaks sequential rewards, can reward same epoch multiple times"
    ],
    "Likelihood": [
        ": Medium, Requires malicious distributor/s"
    ],
    "Description": [
        "",
        "The function commit in DistributedRewardDistribution.sol is used to save a reward commit. However this function does not check if the toBlock is larger than the fromBlock. Thus distributors can set toBlock to 0 even.",
        "This creates further problems in the distribute function itself. There is a check there which tries to force distributions to be sequential.",
        "However, an user can set the toBlock to be lower than the fromBlock and this will break the sequence. In fact, if a user sets toBlock to 0, they can even set lastBlockRewarded to 0 since the assignment takes place in the next line.",
        "POC:",
        "The test test_RunsDistributionAfter3Approves can be modified with the blockspan running from 1 to 0 to demonstrate the issue.",
        "Test passes with no issues."
    ],
    "Recommendations": [
        "",
        "Enforce the check",
        "Either in the commit function or in the distribute function."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-computationunitsavailable-can-overestimate-number-of-available-units-if-staking-duration-is-too-small-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < _stakes.length; i++) {\n    Stake memory _stake = _stakes[i];\n    if (\n        _stake.lockStart <= blockNumber && _stake.lockEnd > blockNumber\n    ) {\n        total +=\n            (_stake.computationUnits * epochLength) /\n            (uint256(_stake.lockEnd - _stake.lockStart));\n    }\n}\nreturn total;\n",
        "function test_AttackStake() public {\n    gatewayRegistry.stake(peerId, 10 ether, 1);\n    GatewayRegistry.Stake[] memory stakes = gatewayRegistry.getStakes(\n        peerId\n    );\n    goToNextEpoch();\n    emit log_named_uint(\"Stake compute units\", stakes[0].computationUnits);\n    emit log_named_uint(\n        \"Available compute units\",\n        gatewayRegistry.computationUnitsAvailable(peerId)\n    );\n}\n",
        "[PASS] test_AttackStake() (gas: 212925)\nLogs:\n  Stake compute units: 10\n  Available compute units: 50\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, can lead to inflated compute unit allocation"
    ],
    "Likelihood": [
        ": Medium, can be easily exploited by a malicious user at no cost"
    ],
    "Description": [
        "",
        "The computationUnitsAvailable function computes the amount of computation units available to a peerId. This is defined in the GatewayRegistry.sol contract as shown below.",
        "If _stake.lockEnd - _stake.lockStart is less than epochLength, the computation units available per epoch will be higher than the total amount of computation units available to the peerId.",
        "The _stake.computationUnits is calculated during staking, and is the total amount of computation units available to the peerId during the entire staking duration. The objective of the computationUnitsAvailable function is to compute the amount of computation units available per block. However, if the staking duration is lower than the epoch length, the computation units available per block will be calculated to be higher than the total amount of computation units available to the peerId.",
        "During staking, there is no restriction on the staking duration, so users can set it to be arbitrarily small. Thus epochLength/duration gives a large number, instead of calculating the inverse of the number of epochs passed.",
        "A short POC demonstrates the issue:",
        "The output:",
        "This shows that while the total number of units assigned was 10, the per-epoch units available is 50.",
        "Since computationUnitsAvailable is used off-chain to calculate the amount of computation units to allocate to workers, this can be used to assign extra computational units than intended.",
        "Thus malicious users can repeatedly stake small amounts and pump up the amount of available computation units, and then unstake to get back their stake. They can increase their computational units allocation by a factor of epochLength by setting the duration to 1."
    ],
    "Recommendations": [
        "",
        "Set a minimum staking duration of 1 epoch."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-workers-could-withdraw-without-deregister-and-waiting-for-the-lock-period-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  /**\n   * @dev Withdraws the bond of a worker.\n   * @param peerId The unique peer ID of the worker.\n   * @notice Worker must be inactive\n   * @notice Worker must be registered by the caller\n   * @notice Worker must be deregistered for at least lockPeriod // @audit - prerequisite for withdraw\n   */\n  function withdraw(bytes calldata peerId) external whenNotPaused {\n    uint256 workerId = workerIds[peerId];\n    require(workerId != 0, \"Worker not registered\");\n    Worker storage worker = workers[workerId];\n    require(!isWorkerActive(worker), \"Worker is active\");\n    require(worker.creator == msg.sender, \"Not worker creator\");\n    require(block.number >= worker.deregisteredAt + lockPeriod(), \"Worker is locked\");\n\n    uint256 bond = worker.bond;\n    delete workers[workerId];\n\n    tSQD.transfer(msg.sender, bond);\n\n    emit WorkerWithdrawn(workerId, msg.sender);\n  }\n",
        "  function testImmediatelyWithdraw() public {\n    vm.roll(176329477);\n    workerRegistration.register(workerId);\n    workerRegistration.withdraw(workerId);\n  }\n",
        "  function withdraw(bytes calldata peerId) external whenNotPaused {\n    uint256 workerId = workerIds[peerId];\n    require(workerId != 0, \"Worker not registered\");\n    Worker storage worker = workers[workerId];\n    require(!isWorkerActive(worker), \"Worker is active\");\n    require(worker.creator == msg.sender, \"Not worker creator\");\n-    require(block.number >= worker.deregisteredAt + lockPeriod(), \"Worker is locked\");\n+    require(block.number >= worker.deregisteredAt + lockPeriod() && worker.deregisteredAt != 0, \"Worker is locked\");\n\n    uint256 bond = worker.bond;\n    delete workers[workerId];\n\n    tSQD.transfer(msg.sender, bond);\n\n    emit WorkerWithdrawn(workerId, msg.sender);\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, this bypass the designed deregister flow and doesn't delete worker from active workers list."
    ],
    "Likelihood": [
        " Medium, as long as not currently active, worker can directly withdraw without deregister as a worker."
    ],
    "Description": [
        "",
        "The designed flow and expected worker's behavior for withdrawing their bond is to first deregister the registered peerId. After that, they have to wait for the lock period before they can trigger the withdraw, as it can be seen from withdraw functions expected flow.",
        "However, as long as the worker is not yet active (the current block has not yet reached the registeredAt), it can directly withdraw without calling deregister and waiting for the lock period. While this does not impact the TVL calculation, it violates the designed withdrawal flow and does not remove the worker from the activeWorkerIds array which will enable the unbounded loop attack vector.",
        "Added POC to WorkerRegistration.withdraw.t.sol."
    ],
    "Recommendations": [
        "",
        "Consider to add extra check when withdraw is performed :"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-04-lack-of-access-control-on-tsqds-registertokenonl2-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function registerTokenOnL2(\n    address l2CustomTokenAddress,\n    uint256 maxSubmissionCostForCustomGateway,\n    uint256 maxSubmissionCostForRouter,\n    uint256 maxGasForCustomGateway,\n    uint256 maxGasForRouter,\n    uint256 gasPriceBid,\n    uint256 valueForGateway,\n    uint256 valueForRouter,\n    address creditBackAddress\n  ) public payable {\n    require(!shouldRegisterGateway, \"ALREADY_REGISTERED\");\n    shouldRegisterGateway = true;\n\n    gateway.registerTokenToL2{value: valueForGateway}(\n      l2CustomTokenAddress, maxGasForCustomGateway, gasPriceBid, maxSubmissionCostForCustomGateway, creditBackAddress\n    );\n\n    router.setGateway{value: valueForRouter}(\n      address(gateway), maxGasForRouter, gasPriceBid, maxSubmissionCostForRouter, creditBackAddress\n    );\n\n    shouldRegisterGateway = false;\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, malicious attacker can set L2 custom address to different address to break the bridge token."
    ],
    "Likelihood": [
        ": Medium, attacker can front-ran the registerTokenOnL2 to break the bridge token."
    ],
    "Description": [
        "",
        "tSQD is designed so that it can be bridged from Ethereum (L1) to Arbitrum (L2) via Arbitrum\u2019s generic-custom gateway.\nHowever, the registerTokenOnL2 function, which sets the L2 token address via gateway.registerTokenToL2, is not currently restricted.",
        "An attacker can front-run the registerTokenOnL2 and put an incorrect address for l2CustomTokenAddress to break the bridge token. Once it is called, the L2 token cannot be changed inside the gateway."
    ],
    "Recommendations": [
        "",
        "Use the Ownable functionality inside tSQD and restrict registerTokenOnL2 so that it can only be called by the owner/admin, as suggested by the Arbitrum bridge token design."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-setgatewayaddress-incorrectly-updates-address-of-the-gateway-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function setGatewayAddress(bytes calldata peerId, address newAddress) public {\n    (Gateway storage gateway, bytes32 peerIdHash) = _getGateway(peerId);\n    _requireOperator(gateway);\n\n    if (gateway.ownAddress != address(0)) {\n>>    delete gatewayByAddress[gateway.ownAddress];\n    }\n\n    if (address(newAddress) != address(0)) {\n      require(gatewayByAddress[newAddress] == bytes32(0), \"Gateway address already registered\");\n>>     gatewayByAddress[newAddress] = peerIdHash;\n    }\n",
        "  function allocateComputationUnits(bytes calldata peerId, uint256[] calldata workerId, uint256[] calldata cus)\n    external\n    whenNotPaused\n  {\n    require(workerId.length == cus.length, \"Length mismatch\");\n    (Gateway storage gateway,) = _getGateway(peerId);\n>>  require(gateway.ownAddress == msg.sender, \"Only gateway can allocate CUs\");\n",
        "  function test_SetAddress() public {\n    GatewayRegistry.Gateway memory gt = gatewayRegistry.getGateway(bytes(\"peerId\"));\n    bytes32 peerIdHash = gatewayRegistry.gatewayByAddress(address(this));\n    // check previous gateway address\n    assertEq(gt.ownAddress, address(this));\n    assertEq(peerIdHash, keccak256(\"peerId\"));\n    // try set a new one\n    address newAddy = address(0x6a7e);\n    gatewayRegistry.setGatewayAddress(bytes(\"peerId\"), newAddy);\n    gt = gatewayRegistry.getGateway(bytes(\"peerId\"));\n    peerIdHash = gatewayRegistry.gatewayByAddress(newAddy);\n    assertEq(peerIdHash, keccak256(\"peerId\"));\n    // this will fail, since address is not updated\n    assertEq(gt.ownAddress, newAddy);\n  }\n",
        "    ...\n    if (address(newAddress) != address(0)) {\n      require(gatewayByAddress[newAddress] == bytes32(0), \"Gateway address already registered\");\n      gatewayByAddress[newAddress] = peerIdHash;\n>>    gateway.ownAddress = newAddress;\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, gateway will still has it's old address"
    ],
    "Likelihood": [
        " Medium, only occurs if the user decides to set a new address for his gateway"
    ],
    "Description": [
        "",
        "The gateway owner can set a new address for it using setGatewayAddress function. Unfortunately, this function only updates gatewayByAddress mapping, leaving Gateway struct intact",
        "If the user tries to call allocateComputationUnits, the contract will expect the old gateway address in msg.sender",
        "Coded POC for GatewayRegistry.unstake.t.sol"
    ],
    "Recommendations": [
        "",
        "Update ownAddress variable as well"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-activeworkerids-have-no-size-limit-can-grow-unbounded-and-gas-grief-cause-oog-errors-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function deregister(bytes calldata peerId) external whenNotPaused {\n    for (uint256 i = 0; i < activeWorkerIds.length; i++) {\n        if (activeWorkerIds[i] == workerId) {\n            activeWorkerIds[i] = activeWorkerIds[\n                activeWorkerIds.length - 1\n            ];\n            activeWorkerIds.pop();\n            break;\n        }\n    }\n",
        "function getActiveWorkers() public view returns (Worker[] memory) {\n    for (uint256 i = 0; i < activeWorkerIds.length; i++) {\n        uint256 workerId = activeWorkerIds[i];\n        Worker storage worker = workers[workerId];\n        if (isWorkerActive(worker)) {\n            activeWorkers[activeIndex] = worker;\n            activeIndex++;\n        }\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, Denial of service and high gas costs to users"
    ],
    "Likelihood": [
        ": Low, unprofitable due to bond submitted"
    ],
    "Description": [
        "",
        "The function register in WorkerRegistration.sol contract adds a new element to the activeWorkerIds array whenever a new worker is registered. There are no checks for registered peerIds, so anyone can register any peerId as a worker. The only restriction is that the user has to submit a bond amount of tokens in order to do so, which will get unlocked later.",
        "The issue is that if this array grows too large, it will cause excessive gas costs for other users, since plenty functions loop over this array. An extreme scenario is when the gas cost to loop over the array exceeds the block gas limit, DOSing operations.",
        "An example of such loops over activeWorkerIds is shown below.",
        "This is also valid for the functions getActiveWorkerIds and getActiveWorkerCount.",
        "Since a user can increase the gas costs of other users at no cost to themselves, this is an issue. The malicious user can always come back after the lock period and deregister and withdraw their bond amount. However, users who interacted with the protocol in between pays inflated gas amounts due to this manipulation.",
        "An unlikely scenario is when the inflated array is too large to traverse in a single block due to the block gas limit and DOSes the entire protocol. However this will not be profitable by the attacker."
    ],
    "Recommendations": [
        "",
        "Use a whitelist of peerIds, and limit the size of the activeWorkerIds array to a reasonable amount."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-user-can-lock-tokens-from-the-temporaryholding-for-an-infinite-amount-of-time-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function execute(address to, bytes calldata data, uint256 requiredApprove) public returns (bytes memory) {\n    require(_canExecute(msg.sender), \"Not allowed to execute\");\n    require(router.networkController().isAllowedVestedTarget(to), \"Target is not allowed\");\n\n    // It's not likely that following addresses will be allowed by network controller, but just in case\n    require(to != address(this), \"Cannot call self\");\n    require(to != address(tSQD), \"Cannot call tSQD\");\n\n    if (requiredApprove > 0) {\n      tSQD.approve(to, requiredApprove);\n    }\n    return to.functionCall(data);\n  }\n",
        "  function _canExecute(address executor) internal view override returns (bool) {\n    if (block.timestamp < lockedUntil) {\n      return executor == beneficiary;\n    }\n    return executor == admin;\n  }\n",
        "  function _stakeWithoutTransfer(bytes calldata peerId, uint256 amount, uint128 durationBlocks) internal {\n    (Gateway storage gateway, bytes32 peerIdHash) = _getGateway(peerId);\n    _requireOperator(gateway);\n\n    uint256 _computationUnits = computationUnitsAmount(amount, durationBlocks);\n    uint128 lockStart = router.networkController().nextEpoch();\n>>  uint128 lockEnd = lockStart + durationBlocks;\n    ...\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, admin won't be able to retrieve tokens after lock time has passed"
    ],
    "Likelihood": [
        " Medium, attacker needs to be a temporary holding beneficiary"
    ],
    "Description": [
        "",
        "TemporaryHoldings.sol allows the beneficiary address to use tSQD in the whitelisted protocol contracts for a limited amount of time",
        "after lockedUntil amount of time has passed admin regains control over the funds inside",
        "One of the whitelisted targets is the GatewayRegistry. A savvy beneficiary can stake tokens from TemporaryHolding for a time far in the future and enjoy boosted CU, while admin cannot unstake these tokens even after lockedUntil"
    ],
    "Recommendations": [
        "",
        "The easiest solution would be to disallow using gateway registry through TemporaryHolding.sol. If it's necessary for us to keep it as a valid target, consider decoding the payload in theexecute function, and if it is the stake or extend functions, validate the duration."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-protocol-uses-manipulatable-randomness-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function distributorIndex() public view returns (uint256) {\n    uint256 slotStart = (block.number / 256) * 256;\n    return uint256(blockhash(slotStart)) % distributors.length();\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, distributors are generally trusted actors, but this could be a vector for manipulation."
    ],
    "Likelihood": [
        ": Medium, randomness can be manipulated via multiple vectors"
    ],
    "Description": [
        "",
        "The protocol generates a random number to choose which distributor will be able to commit rewards for a span of blocks. The issue is in the way the protocol generates this randomness.",
        "After this distributionIndex is calculated, it is used to select a distributor from the array.",
        "There are two issues with this design:",
        "In Arbitrum, transactions are ordered in first-come-first-serve ordering, and the sequencer responsible for ordering the transactions is centralized. However, the Arbitrum DAO plans to decentralize the sequencer in the future, meaning that malicious sequencers can keep including and broadcasting transactions until they can get a favourable hash for the block. Due to the nature of Arbitrum this is more difficult to pull of than in Ethereum mainnet, but is still possible once sequencer decentralization is achieved.",
        "slotStart is calculated as (block.number / 256) * 256. Now every time the block.number is a multiple of 256, slotStart will be calculated as the block.number itself.",
        "According to the ethereum yellow paper, blockhash of the current block always returns 0. This is because the block hash of the current block hasnt been calculated yet. So every time the block.number is a multiple of 256, the uint256(blockhash(slotStart)) will be calculated as 0. This allows the 0th distributor to make a commit everytime the block.number is a multiple of 256.",
        "Since the randomness of the system is broken in these two ways, this is an issue"
    ],
    "Recommendations": [
        "",
        "Firstly, blockhash should never be called on the current block, which is what happens in scenario 2 above. So using the bloackhash of slotStart-1 will give the same effect without the 0th index being able to manipulate the randomness.",
        "Secondly, in the future the blockhash on arbitrum might be more manipulatable. considering using chainlink VRF to generate randomness in a more robust manner."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-vesting-contract-can-lead-to-frequent-reverts-pashov-none-subsquid-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function releasable() public view virtual returns (uint256) {\n    return vestedAmount(uint64(block.timestamp)) - released();\n}\n",
        "function test_AttackVesting() public {\n    token.transfer(address(vesting), 8 ether);\n\n    // Half (4 eth) is vested out\n    vm.warp(vesting.start() + vesting.duration() / 2);\n    vesting.release();\n    assert(vesting.released(address(token)) == 4 ether);\n\n    // Stake half of rest (2 ETH)\n    bytes memory call = abi.encodeWithSelector(\n        Staking.deposit.selector,\n        0,\n        2 ether\n    );\n    vesting.execute(address(router.staking()), call, 2 ether);\n\n    // pass some time\n    vm.warp(vesting.start() + (vesting.duration() * 60) / 100);\n    // check rewards\n    vm.expectRevert();\n    vesting.release();\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, temporary DOS of funds"
    ],
    "Likelihood": [
        ": Medium, occurs when funds are staked / used in the protocol"
    ],
    "Description": [
        "",
        "The Vesting is used to lock funds on behalf of a user while giving them the ability to participate in the protocol. The idea behind the contract is that the amount of funds in the contract will gradually be unlocked over time, while giving the owner the ability to use those tokens to stake or register workers and gateways with. This allows the users to use the tokens in the ecosystem, without having the option to withdraw them all at once.",
        "The VestingWallet OpenZeppelin contract tracks a _erc20Released variable which keeps track of the tokens already paid out. When trigerring a new payout, the amount of tokens available is calculated as shown below.",
        "The issue is that since the contract uses the erc20.balanceOf function to track the vesting amounts, this above expression can underflow and revert. This is because the balance in the contract can decrease if the user wishes to allocate some of the vested amount to staking or registering workers and gateways.",
        "This is best demonstrated in the POC below.",
        "The issue is recreated in the following steps",
        "So even though the contract has funds and can afford to pay out some vested rewards, this function reverts.",
        "This causes a temporary DOS, and users are unable to release vested tokens until their stake or registration is paid out.",
        "Since users lose access to part of the funds they deserve, this is a medium severity issue."
    ],
    "Recommendations": [
        "",
        "Consider adding a depositForVesting(unit amount) function, and tracking the amount with a storage variable baseAmount updated in this function. This way, the vesting rewards will calculate rewards based on this and not the erc20.balanceOf value. The result is that we need not decrease the baseAmount when tokens are sent out for staking, and then the vested amounts will be correctly calculated based on the value of the contract, instead of just the balances. This will prevent scenarios where claiming can revert even if funds are available."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-incorrect-withdrawal-amount-computation-for-variable-participants-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function vaultEndedWithdraw(uint256 side) internal {\n      ...\n      //@audit totalEarnings will not be reduced correctly as withdrawnStakingEarnings is not reduced\n      uint256 totalEarnings = withdrawnStakingEarnings + vaultEndedStakingEarnings;\n\n      if (totalEarnings > 0) {\n        //@audit stakingEarningsShare will be wrong as totalEarnings will be incorrect\n        (uint256 currentState, uint256 stakingEarningsShare) = calculateVariableWithdrawState(\n          totalEarnings,\n          variableToWithdrawnStakingEarnings[msg.sender]\n        );\n        stakingShareAmount = stakingEarningsShare;\n        variableToWithdrawnStakingEarnings[msg.sender] = currentState;\n      }\n\n      uint256 feeShareAmount = 0;\n      //@audit totalFees will not be reduced correctly as withdrawnFeeEarnings is not reduced\n      uint256 totalFees = withdrawnFeeEarnings + feeEarnings;\n\n      if (totalFees > 0) {\n        //@audit feesShare will be wrong as totalFees will be incorrect\n        (uint256 currentState, uint256 feesShare) = calculateVariableWithdrawState(\n          totalFees,\n          variableToWithdrawnFees[msg.sender]\n        );\n        feeShareAmount = feesShare;\n        variableToWithdrawnFees[msg.sender] = currentState;\n      }\n\n      //@audit only vaultEndedStakingEarnings and feeEarnings are reduced\n      vaultEndedStakingEarnings -= stakingShareAmount;\n      feeEarnings -= feeShareAmount;\n\n      variableBearerToken.burn(msg.sender, bearerBalance);\n\n      uint256 sendAmount = stakingShareAmount + feeShareAmount;\n      sendFunds(sendAmount);\n\n      emit VariableFundsWithdrawn(sendAmount, msg.sender, isStarted(), isEnded());\n      return;\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, wrong withdrawal amount can cause vault from servicing all withdrawals"
    ],
    "Likelihood": [
        " High, always occur as variable participants will withdraw earnings"
    ],
    "Description": [
        "",
        "When vaultEndedWithdraw() is called by variable participants, it determines the sendAmount to be withdrawn based on the participant's share of totalEarnings and feeEarnings using calculateVariableWithdrawState().",
        "Both totalEarnings and feeEarnings have a withdrawn component, withdrawnStakingEarnings and withdrawnFeeEarnings. These are used to keep track of staking/fee earnings withdrawn by variable participants when vault is on-going.",
        "The issue is that both withdrawnStakingEarnings and withdrawnFeeEarnings are not reduced in vaultEndedWithdraw(), while vaultEndedStakingEarnings and feeEarnings are reduced. As they are used to determine totalEarnings and feeEarnings, the inconsistent behaviour will cause the share calculation to be incorrect.",
        "As variableBearerToken is burned in vaultEndedWithdraw(), both totalEarnings and feeEarnings are supposed to be reduced accordingly. However, as withdrawnStakingEarnings and withdrawnFeeEarnings are not reduced, subsequent vaultEndedWithdraw() will end up with a sendAmount that is higher than expected. That will lead to insufficient funds in the vault to service all withdrawals."
    ],
    "Recommendations": [
        "",
        "Ideally, we should have a consistent share calculation for simplicity, so it is recommended to use the same share amount computation as vault-on-going withdrawal.",
        "That means for vault-end withdrawals, the totalEarnings and totalFees should not be reduced on withdrawals. And variableSideCapacity can be used instead of variableBearerToken.totalSupply() for the share amount computation, as variableBearerToken is still required to be burned."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-fixed-participants-can-claim-more-premium-than-expected-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function claimFixedPremium() external nonReentrant {\n    require(isStarted(), \"CBS\");\n\n    // Check and cache balance for gas savings\n    uint256 claimBal = fixedClaimToken.balanceOf(msg.sender);\n    require(claimBal > 0, \"NCT\");\n\n    //@audit fixedLidoSharesTotalSupply() will reduces upon withdrawal, but variableSideCapacity is not.\n    //       this will cause sendAmount to be higher for subsequent claims\n    // Send a proportional share of the total variable side deposits (premium) to the fixed side depositor\n    uint256 sendAmount = claimBal.mulDiv(1e18, fixedLidoSharesTotalSupply()).mulDiv(variableSideCapacity, 1e18);\n\n    // Track premiums\n    userToFixedUpfrontPremium[msg.sender] = sendAmount;\n\n    (bool sent, ) = msg.sender.call{value: sendAmount}(\"\");\n    require(sent, \"ETF\");\n\n    // Mint bearer token\n    fixedBearerToken.mint(msg.sender, claimBal);\n\n    // Burn claim tokens\n    fixedClaimToken.burn(msg.sender, claimBal);\n\n    emit FixedPremiumClaimed(sendAmount, claimBal, msg.sender);\n  }\n",
        "uint256 sendAmount = fixedETHDepositToken.balanceOf(msg.sender).mulDiv(variableSideCapacity, fixedSideCapacity);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, wrong premium amount will allow some participants to withdraw more than others"
    ],
    "Likelihood": [
        " High, always occur as fixed participants will claim premiums"
    ],
    "Description": [
        "",
        "claimFixedPremium() is called to allow fixed participants to claim their fixed premium when vault is started. And sendAmount, the premium amount to be claimed, is determined by the participant's share of variableSideCapacity, using their balance of fixedClaimTokens over fixedLidoSharesTotalSupply().",
        "As fixedLidoSharesTotalSupply() is the sum of fixedBearerToken.totalSupply() and fixedClaimTokens.totalSupply(), it will be reduced when fixed participants performs on-going vault withdrawals due to the fact that the participant's balance of fixedBearerToken will be burned.",
        "This will cause an issue with the sendAmount calculation within claimFixedPremium(), giving a higher than expected share of the variableSideCapacity after vault withdrawal by fixed participants. This allows fixed participants to claim more premium than allowed by doing it after certain amount of withdrawals."
    ],
    "Recommendations": [
        "",
        "In claimFixedPremium(), use fixedSideCapacity instead of fixedLidoSharesTotalSupply() for L439 as follows:"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-03-premium-could-be-stolen-by-fixed-side-participant-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n746:   function vaultEndedWithdraw(uint256 side) internal {\n747:     if (vaultEndedWithdrawalRequestIds.length == 0 && !vaultEndedWithdrawalsFinalized) {\n748:       emit VaultEnded(block.timestamp, msg.sender);\n749:\n750:       if (lidoAdapter.stakingBalance() < lidoAdapter.minStETHWithdrawalAmount()) {\n751:         // not enough staking ETH to withdraw just override vault ended state and continue the withdraw\n752:         vaultEndedWithdrawalsFinalized = true;\n753:       } else {\n754:         vaultEndedWithdrawalRequestIds = lidoAdapter.requestEntireBalanceWithdraw(msg.sender);\n755:\n756:         emit LidoWithdrawalRequested(msg.sender, vaultEndedWithdrawalRequestIds, side, isStarted(), isEnded());\n757:         // need to call finalizeVaultEndedWithdrawals once request is processed\n758:         return;\n759:       }\n760:     }\n...\n",
        "File: LidoVault.sol\n665:   function finalizeVaultEndedWithdrawals(uint256 side) external nonReentrant {\n666:     require(side == FIXED || side == VARIABLE, \"IS\");\n667:     require(vaultEndedWithdrawalRequestIds.length != 0 && !vaultEndedWithdrawalsFinalized, \"WNR\");\n668:\n669:     vaultEndedWithdrawalsFinalized = true;\n670:\n671:     // claim any ongoing fixed withdrawals too\n672:     uint256 arrayLength = fixedOngoingWithdrawalUsers.length;\n673:     for (uint i = 0; i < arrayLength; i++) {\n674:       address fixedUser = fixedOngoingWithdrawalUsers[i];\n675:       fixedToPendingWithdrawalAmount[fixedUser] = claimFixedVaultOngoingWithdrawal(fixedUser);\n676:     }\n...\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, since variable side participants could lose their deposits"
    ],
    "Likelihood": [
        " High, since vector could be easily done"
    ],
    "Description": [
        "",
        "The vaultEndedWithdraw function allows users to request withdrawal of all staking balance after the vault duration is ended (L754). In case if vault balance is less than Lido's minimum withdrawal amount - the function just puts the vault into the state of vaultEndedWithdrawalsFinalized (L752) since there is no need to create a new withdrawal request and now users are allowed to withdraw their earnings if there are any:",
        "However, in the last case function failed to claim all requests that were created during an ongoing stage in the same way as finalizeVaultEndedWithdrawals do at L673-L676:",
        "This could lead to the next scenario:"
    ],
    "Recommendations": [
        "",
        "Even if the lidoAdapter.stakingBalance() is less than the lidoAdapter.minStETHWithdrawalAmount() vault still should claim all fixed ongoing withdrawal requests in the vaultEndedWithdraw function."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-finalizevaultendedwithdrawals-will-fail-when-last-withdrawal-request-is-less-than-100-wei-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  /// @notice Request a withdrawal on Lido to exchange stETH for ETH\n  /// @param stETHAmount amount of stETH to withdraw\n  /// @return requestIds Ids of the withdrawal requests\n  function _requestWithdraw(address user, uint256 stETHAmount) internal returns (uint256[] memory) {\n    require(stETHAmount >= MIN_STETH_WITHDRAWAL_AMOUNT, \"WM\");\n\n    // Approve the withdrawal queue contract to pull the stETH tokens\n    bool approved = lido.approve(address(lidoWithdrawalQueue), stETHAmount);\n    require(approved, \"AF\");\n\n    uint256[] memory amounts = new uint256[](calculateWithdrawals(stETHAmount));\n    if (stETHAmount > MAX_STETH_WITHDRAWAL_AMOUNT) {\n      uint256 amountLeft = stETHAmount;\n      uint256 i = 0;\n      while (amountLeft > 0) {\n        if (amountLeft >= MAX_STETH_WITHDRAWAL_AMOUNT) {\n          amounts[i] = MAX_STETH_WITHDRAWAL_AMOUNT;\n          amountLeft -= MAX_STETH_WITHDRAWAL_AMOUNT;\n        } else {\n          amounts[i] = amountLeft;\n          amountLeft = 0;\n        }\n        i++;\n      }\n    } else {\n      amounts[0] = stETHAmount;\n    }\n\n    //@audit - the following will revert if last withdrawal request is less than 100 wei\n    // Submit the stETH to the withdrawal queue\n    uint256[] memory requestIds = lidoWithdrawalQueue.requestWithdrawals(amounts, address(this));\n    require(requestIds.length > 0, \"IWR\");\n\n    emit WithdrawalRequested(stETHAmount, requestIds, user);\n\n    return requestIds;\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, the issue will prevent withdrawal of stETH"
    ],
    "Likelihood": [
        " Medium, when last withdrawal request is < 100 wei"
    ],
    "Description": [
        "",
        "When LidoVault ends, LidoVault.finalizeVaultEndedWithdrawals() can be called to withdraw its entire stETH balance from Lido. That will trigger LidoAdapter.requestEntireBalanceWithdraw(), which will then calls _requestWithdraw() to perform the withdrawals. As the max withdrawal is 1000 stETH (MAX_STETH_WITHDRAWAL_AMOUNT), the withdrawal will be splitted into multiple withdrawal requests of 1000 stETH as shown in the code below. Note that the min withdrawal amount is 100 wei (in stETH), as shown by the require statement.",
        "The issue is the call lidoWithdrawalQueue.requestWithdrawals(amounts, address(this)) will revert if the last withdrawal request is less than 100 wei (in stETH).",
        "This will prevent LidoVault from completing the vault end withdrawals, causing all the stETH to be locked within the LidoAdapter."
    ],
    "Recommendations": [
        "",
        "Ensure that all withdrawal requests are at least 100 wei."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-finalizevaultendedwithdrawals-would-be-dosed-if-at-least-one-fixed-participant-would-withdraw-from-the-ongoing-vault-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n458:   function withdraw(uint256 side) external nonReentrant {\n..\n516:       // Vault started and in progress\n517:     } else if (!isEnded()) {\n518:       if (side == FIXED) {\n519:         require(\n520:           fixedToVaultOngoingWithdrawalRequestIds[msg.sender].requestIds.length == 0 &&\n521:             fixedToVaultNotStartedWithdrawalRequestIds[msg.sender].length == 0,\n522:           \"WAR\"\n523:         );\n524:\n525:         // require that they have claimed their upfront premium to simplify this flow\n526:         uint256 bearerBalance = fixedBearerToken.balanceOf(msg.sender);\n527:         require(bearerBalance > 0, \"NBT\");\n528:\n529:         uint256 initialDepositAmount = fixedETHDepositToken.balanceOf(msg.sender);\n530:         require(initialDepositAmount > 0, \"NET\");\n531:\n532:         // since the vault has started only withdraw their initial fixed deposit - unless we are in a loss\n533:         uint256 withdrawAmount = initialDepositAmount;\n534:         uint256 lidoStETHBalance = lidoAdapter.stakingBalance();\n535:         uint256 fixedETHDeposits = fixedETHDepositToken.totalSupply();\n536:\n537:         if (fixedETHDeposits > lidoStETHBalance) {\n538:           // our staking balance if less than our initial ETH deposits only return a proportional amount of the balance to the fixed user\n539:           withdrawAmount = lidoStETHBalance.mulDiv(initialDepositAmount, fixedETHDeposits);\n540:         }\n541:\n542:         fixedBearerToken.burn(msg.sender, bearerBalance);\n543:         fixedETHDepositToken.burn(msg.sender, initialDepositAmount);\n544:\n545:         fixedToVaultOngoingWithdrawalRequestIds[msg.sender] = WithdrawalRequest({\n546:           requestIds: lidoAdapter.requestWithdrawViaETH(msg.sender, withdrawAmount),\n547:           timestamp: block.timestamp\n548:         });\n549:         fixedOngoingWithdrawalUsers.push(msg.sender);\n...\n",
        "File: LidoVault.sol\n637:   function finalizeVaultOngoingFixedWithdrawals() external nonReentrant {\n638:     uint256 sendAmount = claimFixedVaultOngoingWithdrawal(msg.sender);\n639:\n640:     sendFunds(sendAmount);\n641:\n642:     emit FixedFundsWithdrawn(sendAmount, msg.sender, isStarted(), isEnded());\n643:   }\n...\n863:   function claimFixedVaultOngoingWithdrawal(address user) internal returns (uint256) {\n864:     WithdrawalRequest memory request = fixedToVaultOngoingWithdrawalRequestIds[user];\n865:     uint256[] memory requestIds = request.requestIds;\n866:     require(requestIds.length != 0, \"WNR\");\n867:\n868:     uint256 upfrontPremium = userToFixedUpfrontPremium[user];\n869:\n870:     delete userToFixedUpfrontPremium[user];\n871:     delete fixedToVaultOngoingWithdrawalRequestIds[user];\n872:\n873:     uint256 arrayLength = fixedOngoingWithdrawalUsers.length;\n874:     for (uint i = 0; i < arrayLength; i++) {\n875:       if (fixedOngoingWithdrawalUsers[i] == user) {\n876:         delete fixedOngoingWithdrawalUsers[i];\n877:       }\n878:     }\n..\n",
        "File: LidoVault.sol\n665:   function finalizeVaultEndedWithdrawals(uint256 side) external nonReentrant {\n...\n671:     // claim any ongoing fixed withdrawals too\n672:     uint256 arrayLength = fixedOngoingWithdrawalUsers.length;\n673:     for (uint i = 0; i < arrayLength; i++) {\n674:       address fixedUser = fixedOngoingWithdrawalUsers[i];\n675:       fixedToPendingWithdrawalAmount[fixedUser] = claimFixedVaultOngoingWithdrawal(fixedUser);\n676:     }\n...\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, since withdrawing from the vault would be blocked temporarily"
    ],
    "Likelihood": [
        " High, since withdraws from ongoing vault could be expected as regular user flow"
    ],
    "Description": [
        "",
        "Fixed participants can request a withdrawal from the ongoing vault using the withdraw function. It would invoke a withdrawal request on Lido on behalf of the user and push the address of such user to the fixedOngoingWithdrawalUsers array at L549:",
        "Later user can finalize their withdrawal using the finalizeVaultOngoingFixedWithdrawals function that would call the claimFixedVaultOngoingWithdrawal helper function. The last one would claim the user's request, calculate the corresponding amount of fee, etc. Most importantly this helper function would delete the user's address from the fixedOngoingWithdrawalUsers array at L876:",
        "Solidity delete keyword only assigns the array element to zero value, while the length of the array remains the same. So this deleting will cause the DOS in a later call to finalizeVaultEndedWithdrawals.\nAt L675 contract would try to call the helper function for all addresses in the fixedOngoingWithdrawalUsers array, one of which now is address(0) that stays in the array after deleting the user address previously:",
        "claimFixedVaultOngoingWithdrawal on its turn would revert to the address(0) parameter since this address has no withdrawal requests associated with it (L866). Only the admin would be able to restore the vault withdrawing flow using the adminSettleDebt function."
    ],
    "Recommendations": [
        "",
        "claimFixedVaultOngoingWithdrawal should return 0 in case if address(0) is provided as user parameter."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-fixed-participants-will-be-incorrectly-penalized-during-adminsettledebt-timelock-period-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function calculateFixedEarlyExitFees(\n    uint256 upfrontPremium,\n    uint256 timestampRequested\n  ) internal view returns (uint256) {\n    uint256 remainingProportion = (endTime > timestampRequested ? endTime - timestampRequested : 0).mulDiv(\n      1e18,\n      duration\n    );\n\n    //@audit the scaling fees will should not be applied after initiatingAdminSettleDebt() is called\n    // Calculate the scaling fee based on the quadratic scaling factor and earlyExitFeeBps\n    uint256 earlyExitFees = upfrontPremium.mulDiv(\n      earlyExitFeeBps.mulDiv(remainingProportion.mulDiv(remainingProportion, 1e18), 1e18),\n      10000\n    );\n\n    // Calculate the amount to be paid back of their original upfront claimed premium, not influenced by quadratic scaling\n    earlyExitFees += upfrontPremium - upfrontPremium.mulDiv(timestampRequested - startTime, duration);\n\n    return earlyExitFees;\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, fixed participants will incur losses"
    ],
    "Likelihood": [
        " Medium, occurs when admin settles debt"
    ],
    "Description": [
        "",
        "When initiatingAdminSettleDebt() is called, the settle debt process is initialized. That will start the timelock of 3 days (based on adminSettleDebtLockPeriod), before the admin can call adminSettleDebt() and transfer the stETH balance to AdminLidoAdapter. I believe the timelock is designed to allow fixed/variable participants to withdraw before adminSettleDebt(), when the settleDebtAmount set during initialization does not properly compensate them (e.g. a rogue admin try to settle debt with a heavy loss).",
        "However, when fixed participants withdraw their deposit after initiatingAdminSettleDebt() and before vault ends, they will be penalized with the early withdrawal fees as calculated in calculateFixedEarlyExitFees(). That is incorrect as it defeats the purpose of the timelock, causing fixed participants to be under-compensated regardless of the timelock."
    ],
    "Recommendations": [
        "",
        "After initiatingAdminSettleDebt() is called, calculateFixedEarlyExitFees() should not apply the scaling fee."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-04-fixed-participants-will-earn-full-premium-even-when-vault-ends-early-from-debt-settlement-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function vaultEndedWithdraw(uint256 side) internal {\n    ...\n\n    // have to call finalizeVaultEndedWithdrawals first\n    require(vaultEndedWithdrawalsFinalized, \"WNF\");\n\n    if (side == FIXED) {\n      require(\n        fixedToVaultOngoingWithdrawalRequestIds[msg.sender].requestIds.length == 0 &&\n          fixedToVaultNotStartedWithdrawalRequestIds[msg.sender].length == 0,\n        \"WAR\"\n      );\n\n      uint256 sendAmount = fixedToPendingWithdrawalAmount[msg.sender];\n\n      // they submitted a withdraw before the vault had ended and the vault ending should have claimed it\n      if (sendAmount > 0) {\n        delete fixedToPendingWithdrawalAmount[msg.sender];\n      } else {\n        uint256 bearerBalance = fixedBearerToken.balanceOf(msg.sender);\n        require(bearerBalance > 0, \"NBT\");\n\n        //@audit fixed participants will obtain the full deposit as vaultEndedFixedDepositsFunds\n        //        will be equal to fixedETHDepositToken.totalSupply() when debt is settled with positive earnings\n        sendAmount = fixedBearerToken.balanceOf(msg.sender).mulDiv(\n          vaultEndedFixedDepositsFunds,\n          fixedLidoSharesTotalSupply()\n        );\n\n        fixedBearerToken.burn(msg.sender, bearerBalance);\n        fixedETHDepositToken.burn(msg.sender, fixedETHDepositToken.balanceOf(msg.sender));\n        vaultEndedFixedDepositsFunds -= sendAmount;\n      }\n\n      sendFunds(sendAmount);\n\n      emit FixedFundsWithdrawn(sendAmount, msg.sender, isStarted(), true);\n      return;\n    } else {\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, premium can be stolen from variable participants"
    ],
    "Likelihood": [
        " Medium, occurs when admin settles debt"
    ],
    "Description": [
        "",
        "When adminSettleDebt() is called before the full vault duration, it will end the vault early, allowing all participants to withdraw their deposits.",
        "In that scenario, the debt will be settled with a positive staking earnings, to ensure that variable participants can withdraw both earnings and part of the fixed premium based on the early vault end time.",
        "The problem is, fixed participants do not pay back the partial premium based on remaining time (not in vault), allowing them to withdraw both full initial deposits and full fixed premium even when vault ended early. This is due to missing calculation in vaultEndedWithdraw() to return the partial premium, as shown below.",
        "So variable participants will incur a loss as they are not paid back the partial premium.",
        "Furthermore, a malicious admin can exploit this and earn the full premium by depositing and withdrawing as a fixed participant."
    ],
    "Recommendations": [
        "",
        "When admin settle debt ends the vault early, deduct vaultEndedFixedDepositsFunds by the amount of premium to be returned to variable participants as part of feeEarnings."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-05-funds-in-vault-can-be-temporarily-locked-by-spamming-dust-deposits-and-withdrawals-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, funds in vault will be temporarily locked"
    ],
    "Likelihood": [
        " High, can always occur"
    ],
    "Description": [
        "",
        "finalizeVaultEndedWithdrawals() is required to be called to finalize all fixed withdrawals, including on-going fixed withdrawals.",
        "The issue is that it iterates through fixedOngoingWithdrawalUsers, which can be manipulated and become unbounded. An attacker can make fixedOngoingWithdrawalUsers extremely large by spamming dust fixed deposits of 100 wei (with multiple EOA) and then withdraw them when vault is on-going. This will cause finalizeVaultEndedWithdrawals() to be DoS, which prevents withdrawals when vault ends, resulting in the vault funds locked.",
        "I have classified this as Medium impact as admin can recover the issue with settle debt function.",
        "Another issue that can occur with dust deposits and withdrawals is that an attacker can prevent vault from starting. The attack can conducted by spamming multiple 1 wei variable deposits and then withdraw one of them whenever vault is going to start by frontrunning the last depositor."
    ],
    "Recommendations": [
        "",
        "One possible mitigation is to increase the attack cost by setting a higher minimum deposit amount (e.g. 0.1 ETH) for fixed/variable participants.",
        "Take note to ensure deposits do not cause unfilled capacity to be less than the minimum deposit amount, otherwise it will prevent vault from starting."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-06-variable-participants-could-lose-their-fee-earnings-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function calculateVariableWithdrawState(\n    uint256 totalEarnings,\n    uint256 previousWithdrawnAmount\n  ) internal view returns (uint256, uint256) {\n    uint256 bearerBalance = variableBearerToken.balanceOf(msg.sender);\n    require(bearerBalance > 0, \"NBT\");\n\n    //@audit this can revert if participant share of earnings is less than previousWithdrawnAmount\n    uint256 ethAmountOwed = bearerBalance.mulDiv(totalEarnings, variableBearerToken.totalSupply()) -\n      previousWithdrawnAmount;\n\n    return (ethAmountOwed + previousWithdrawnAmount, ethAmountOwed);\n  }\n",
        "  function vaultEndedWithdraw(uint256 side) internal {\n    ...\n      if (totalEarnings > 0) {\n        //@audit this could reverts due to edge cases where participant share of totalEarnings < previous withdrawn earnings\n        //       that will prevent the affected participants from withdrawing fee earnings, which is executed below\n        (uint256 currentState, uint256 stakingEarningsShare) = calculateVariableWithdrawState(\n          totalEarnings,\n          variableToWithdrawnStakingEarnings[msg.sender]\n        );\n        stakingShareAmount = stakingEarningsShare;\n        variableToWithdrawnStakingEarnings[msg.sender] = currentState;\n      }\n\n      uint256 feeShareAmount = 0;\n      uint256 totalFees = withdrawnFeeEarnings + feeEarnings;\n\n      if (totalFees > 0) {\n        (uint256 currentState, uint256 feesShare) = calculateVariableWithdrawState(\n          totalFees,\n          variableToWithdrawnFees[msg.sender]\n        );\n        feeShareAmount = feesShare;\n        variableToWithdrawnFees[msg.sender] = currentState;\n      }\n\n       vaultEndedStakingEarnings -= stakingShareAmount;\n      feeEarnings -= feeShareAmount;\n\n      variableBearerToken.burn(msg.sender, bearerBalance);\n\n      uint256 sendAmount = stakingShareAmount + feeShareAmount;\n      sendFunds(sendAmount);\n\n      emit VariableFundsWithdrawn(sendAmount, msg.sender, isStarted(), isEnded());\n      return;\n    }\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, affected variable participants will lose their fee earnings"
    ],
    "Likelihood": [
        " Medium, occurs when final total staking earnings is lower than on-going period"
    ],
    "Description": [
        "",
        "calculateVariableWithdrawState() is used to calculate the ethAmountOwed, which is the balance of unwithdrawn earnings. This is computed using the variable particpant share of the totalEarnings, subtracted by previousWithdrawnAmount (see code below).",
        "The issue is that the computation assumes that bearerBalance.mulDiv(totalEarnings, variableBearerToken.totalSupply()) will always be greater than previousWithdrawnAmount.",
        "However, there are edge cases that breaks that assumption,",
        "When these occur, it will cause calculateVariableWithdrawState() to revert in vaultEndedWithdraw(), preventing the affected variable participant from withdrawing his share of feeEarnings (see code below)."
    ],
    "Recommendations": [
        "",
        "Set ethAmountOwed to zero when previousWithdrawnAmount >= bearerBalance.mulDiv(totalEarnings, variableBearerToken.totalSupply())."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-07-admin-could-incur-a-loss-with-debt-settlement-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function adminSettleDebt(address adminLidoAdapterAddress) external onlyAdmin {\n    require(block.timestamp > adminSettleDebtLockPeriodEnd, \"ANM\");\n\n    vaultEndedWithdrawalsFinalized = true;\n    adminSettledDebt = true;\n\n    //@audit adminSettleDebtAmount is set during initiatingAdminSettleDebt(),\n    //        which could be higher than required when withdrawals are made during the timelock period\n    vaultEndedStakingEarnings = fixedETHDepositToken.totalSupply() < adminSettleDebtAmount\n      ? adminSettleDebtAmount - fixedETHDepositToken.totalSupply()\n      : 0;\n    vaultEndedFixedDepositsFunds = adminSettleDebtAmount - vaultEndedStakingEarnings;\n\n    //@audit the stETH transferred to admin will be lesser than adminSettleDebtAmount due to withdrawals\n    if (vaultEndedWithdrawalRequestIds.length > 0) {\n      IAdminLidoAdapter adminLidoAdapter = IAdminLidoAdapter(adminLidoAdapterAddress);\n      adminLidoAdapter.setLidoWithdrawalRequestIds(vaultEndedWithdrawalRequestIds);\n      for (uint i = 0; i < vaultEndedWithdrawalRequestIds.length; i++) {\n        lidoAdapter.transferWithdrawalERC721(adminLidoAdapterAddress, vaultEndedWithdrawalRequestIds[i]);\n      }\n    } else {\n      lidoAdapter.transferStETH(adminLidoAdapterAddress, lidoAdapter.stakingBalance());\n    }\n\n    emit AdminSettledDebt(msg.sender);\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, admin will incur a loss as he will pay more than required to settle debts"
    ],
    "Likelihood": [
        " Medium, occurs when admin settles debt"
    ],
    "Description": [
        "",
        "An admin of LidoVault can perform a debt settlement to end the vault early due to unexpected issues with Lido. The process is initiated using initiatingAdminSettleDebt() with the adminSettleDebtAmount paid by admin in ETH. After the timelock, the debt is settled upon calling adminSettleDebt(), which will transfer the stETH balance to admin, in exchange for what was paid with adminSettleDebtAmount.",
        "Basically with the above exchange, the correct adminSettleDebtAmount paid should be equivalent to the unwithdrawn fixed deposit and staking/fee earnings in the LidoAdapter.",
        "However, the issue is that after payment of adminSettleDebtAmount, the participants could still withdraw the fixed deposits and staking/fee earnings, reducing the stETH balance in LidoAdapter. When that occur, admin will actually receive a lower amount of stETH than what was expected during initiatingAdminSettleDebt().",
        "Furthermore, the calculation of vaultEndedStakingEarnings and vaultEndedFixedDepositsFunds will be incorrect as they are based on the incorrect adminSettleDebtAmount."
    ],
    "Recommendations": [
        "",
        "In adminSettleDebt(), leave an amount of ETH equivalent to LidoAdapter's sETH balance in the vault and refund the balance amount of adminSettleDebtAmount to AdminLidoAdapter."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-08-protocol-will-miss-part-of-its-fee-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n458:   function withdraw(uint256 side) external nonReentrant {\n...\n516:       // Vault started and in progress\n517:     } else if (!isEnded()) {\n518:       if (side == FIXED) {\n...\n559:       } else {\n560:         require(variableToVaultOngoingWithdrawalRequestIds[msg.sender].length == 0, \"WAR\");\n561:\n562:         if (msg.sender == protocolFeeReceiver && appliedProtocolFee > 0) {\n563:           return protocolFeeReceiverWithdraw();\n564:         }\n565:\n566:         uint256 lidoStETHBalance = lidoAdapter.stakingBalance();\n567:         uint256 fixedETHDeposits = fixedETHDepositToken.totalSupply();\n568:\n569:         // staking earnings have accumulated on Lido\n570:         if (lidoStETHBalance > fixedETHDeposits) {\n571:           (uint256 currentState, uint256 ethAmountOwed) = calculateVariableWithdrawState(\n572:             (lidoStETHBalance - fixedETHDeposits) + withdrawnStakingEarnings + totalProtocolFee,\n573:             variableToWithdrawnStakingEarnings[msg.sender]\n574:           );\n575:\n576:           if (ethAmountOwed >= lidoAdapter.minStETHWithdrawalAmount()) {\n577:             // estimate protocol fee and update total - will actually be applied on withdraw finalization\n578:             uint256 protocolFee = ethAmountOwed.mulDiv(protocolFeeBps, 10000);\n579:             totalProtocolFee += protocolFee;\n580:\n581:             withdrawnStakingEarnings += ethAmountOwed - protocolFee;\n582:             variableToWithdrawnStakingEarnings[msg.sender] = currentState - protocolFee;\n583:\n584:             variableToVaultOngoingWithdrawalRequestIds[msg.sender] = lidoAdapter.requestWithdrawViaETH(\n585:               msg.sender,\n586:               ethAmountOwed\n587:             );\n588:\n589:             emit LidoWithdrawalRequested(\n590:               msg.sender,\n591:               variableToVaultOngoingWithdrawalRequestIds[msg.sender],\n592:               VARIABLE,\n593:               isStarted(),\n594:               isEnded()\n595:             );\n596:             return;\n597:           }\n598:         }\n...\n",
        "File: LidoVault.sol\n907:   function calculateVariableWithdrawState(\n908:     uint256 totalEarnings,\n909:     uint256 previousWithdrawnAmount\n910:   ) internal view returns (uint256, uint256) {\n911:     uint256 bearerBalance = variableBearerToken.balanceOf(msg.sender);\n912:     require(bearerBalance > 0, \"NBT\");\n913:\n914:     uint256 ethAmountOwed = bearerBalance.mulDiv(totalEarnings, variableBearerToken.totalSupply()) -\n915:       previousWithdrawnAmount;\n916:\n917:     return (ethAmountOwed + previousWithdrawnAmount, ethAmountOwed);\n918:   }\n",
        "     variableToWithdrawnStakingEarnings[msg.sender] = currentState - currentState.mulDiv(protocolFeeBps, 10000) ;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, part of the protocol fee would missed"
    ],
    "Likelihood": [
        " High, each user that will claim his earnings in ongoing vault more than ones would pay less fees"
    ],
    "Description": [
        "",
        "Vault allows variable stakers to claim earnings during the ongoing stage using the withdraw function:",
        "The amount for claiming is calculated at L571 based on the current staking earnings accumulated on Lido and the already withdrawn amount for the caller using the calculateVariableWithdrawState helper function:",
        "However, at L582 we can see that the protocol fee is substructed from the withdrawn amount that is saved in the variableToWithdrawnStakingEarnings. On the next call after the first earning withdrawal, this value would be used inside calculateVariableWithdrawState at L915, resulting in ethAmountOwed bigger than it should be, it would include the protocol fee amount from the previous earning withdrawal, since previousWithdrawnAmount would correspond to user's only withdrawn amount while protocol fee from previous withdraw call would be encountered as user's earnings.",
        "This would result in receiving bigger amounts for users who would withdraw their staking earnings more than once on an ongoing vault."
    ],
    "Recommendations": [
        "",
        "At L573 use variableToWithdrawnStakingEarnings[msg.sender].mulDiv(10000, 10000 - protocolFeeBps), this way calculateVariableWithdrawState function would calculate the correct earnings for the user since the protocol fee would be included in the previousWithdrawnAmount parameter value. Also, L582 should be updated to store the correct amount of the user's withdrawn earnings:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-09-funds-could-stuck-in-lidoadapter-if-the-user-requests-withdrawal-before-adminsettledebt-execution-and-finalized-after-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n458:   function withdraw(uint256 side) external nonReentrant {\n...\n461:     // Vault has not started\n462:     if (!isStarted()) {\n463:       if (side == FIXED) {\n...\n489:           fixedToVaultNotStartedWithdrawalRequestIds[msg.sender] = lidoAdapter.requestWithdrawViaShares(\n490:             msg.sender,\n491:             claimBalance\n492:           );\n...\n516:       // Vault started and in progress\n517:     } else if (!isEnded()) {\n518:       if (side == FIXED) {\n...\n545:         fixedToVaultOngoingWithdrawalRequestIds[msg.sender] = WithdrawalRequest({\n546:           requestIds: lidoAdapter.requestWithdrawViaETH(msg.sender, withdrawAmount),\n547:           timestamp: block.timestamp\n548:         });\n549:         fixedOngoingWithdrawalUsers.push(msg.sender);\n...\n558:         return;\n559:       } else {\n...\n584:             variableToVaultOngoingWithdrawalRequestIds[msg.sender] = lidoAdapter.requestWithdrawViaETH(\n585:               msg.sender,\n586:               ethAmountOwed\n587:             );\n...\n",
        "File: LidoVault.sol\n712:   function adminSettleDebt(address adminLidoAdapterAddress) external onlyAdmin {\n...\n723:     if (vaultEndedWithdrawalRequestIds.length > 0) {\n724:       IAdminLidoAdapter adminLidoAdapter = IAdminLidoAdapter(adminLidoAdapterAddress);\n725:       adminLidoAdapter.setLidoWithdrawalRequestIds(vaultEndedWithdrawalRequestIds);\n726:       for (uint i = 0; i < vaultEndedWithdrawalRequestIds.length; i++) {\n727:         lidoAdapter.transferWithdrawalERC721(adminLidoAdapterAddress, vaultEndedWithdrawalRequestIds[i]);\n728:       }\n729:     } else {\n730:       lidoAdapter.transferStETH(adminLidoAdapterAddress, lidoAdapter.stakingBalance());\n731:     }\n...\n",
        "File: LidoVault.sol\n845:   function sendFunds(uint256 ethSendAmount) internal {\n846:     if (adminSettledDebt) {\n847:       (bool sent, ) = msg.sender.call{value: ethSendAmount}(\"\");\n848:       require(sent, \"ETF\");\n849:     } else {\n850:       lidoAdapter.transferWithdrawnFunds(msg.sender, ethSendAmount);\n851:     }\n852:   }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, users could lose their deposits"
    ],
    "Likelihood": [
        " Medium, scenario requires admin settle debt execution and specific order of transactions"
    ],
    "Description": [
        "",
        "When the admin calls initiatingAdminSettleDebt users have a timelock period to withdraw their deposits. They will use the withdraw function for this. Depending on what stage the vault is, the contact would burn the appropriate user's tokens balance, request a withdrawal from Lido using lidoAdapter, and save request IDs in the associate array slot:",
        "After admin calls adminSettleDebt all stEth balances or vaultEndedWithdrawalRequestIds would be transferred from the lidoAdapter to the adminLidoAdapterAddress:",
        "At the same time since adminSettledDebt is now equal to true, all calls to the sendFunds function would be executed using vault balance, but not lidoAdapter as previously:",
        "This means that withdrawal requests that would be finalized after adminSettleDebt() execution would be claimed to the lidoAdapter and stay there, while the vault would try to repay the user's withdrawals with its balance.",
        "Consider the next scenario:",
        "In this scenario, Admin loses a portion of funds in the same way described in [H-07] by overpaying Charlie, but at the same time - Bob's balance is now completely stuck."
    ],
    "Recommendations": [
        "",
        "LidoAdapter#_claimWithdrawals function should send all withdrawn eth to the msg.sender (vault in this case). This way all previously requested withdrawals would guaranteed to end on vault balance."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-deposit-function-can-be-dosed-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n383:   function deposit(uint256 side) external payable isInitialized nonReentrant {\n384:     require(!isStarted(), \"DAS\");\n385:     // don't allow deposits once settle debt process has been initialized to prevent vault from starting\n386:     require(!isAdminSettleDebtInitialized(), \"AAI\");\n387:     require(side == FIXED || side == VARIABLE, \"IS\");\n388:     require(msg.value > 0, \"NZV\");\n389:\n390:     uint256 amount = msg.value;\n391:     if (side == FIXED) {\n392:       // Fixed side deposits\n393:\n394:       // no refunds allowed\n395:       require(amount <= fixedSideCapacity - fixedETHDepositToken.totalSupply(), \"OED\");\n396:\n397:       // Stake on Lido\n398:       uint256 shares = lidoAdapter.stakeFunds{value: amount}(msg.sender);\n399:\n400:       // Mint claim tokens\n401:       fixedClaimToken.mint(msg.sender, shares);\n402:       fixedETHDepositToken.mint(msg.sender, amount);\n403:\n404:       emit FixedFundsDeposited(amount, shares, msg.sender);\n405:     } else {\n406:       // Variable side deposits\n407:\n408:       // no refunds allowed\n409:       require(amount <= variableSideCapacity - variableBearerToken.totalSupply(), \"OED\");\n410:\n411:       // Mint bearer tokens\n412:       variableBearerToken.mint(msg.sender, amount);\n413:\n414:       emit VariableFundsDeposited(amount, msg.sender);\n415:     }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, while core contract functionality would be DOSed, it's still possible to bypass attack using a private relayer"
    ],
    "Likelihood": [
        " Medium, the attack vector is cheap, but at the same time malicious actor has no incentive except griefing users"
    ],
    "Description": [
        "",
        "The deposit function requires that the sum of fixed and variable deposits be strictly equal to the fixedSideCapacity and variableSideCapacity correspondingly. This is done by checking the supply of deposit tokens and current msg.value (L395 and L409). But if the msg.value is bigger than the difference between the total supply of deposit tokens and side capacity - the whole deposit tx would be reverted.",
        "This opens a griefing attack vector when malicious actors could DOS deposit function. Since the vault is permissionless - an attacker could spot users' tx that would start the vault and front-run it with a dust amount deposit, causing reverting of the first one. This could be repeated many times, effectively preventing the vault from being started."
    ],
    "Recommendations": [
        "",
        "Deposit function should refund user in case if msg.value is greater than the current vault capacity."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-race-condition-with-initiatingadminsettledebt-could-under-compensate-participants-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function deposit(uint256 side) external payable isInitialized nonReentrant {\n    require(!isStarted(), \"DAS\");\n    //@audit this check can be bypassed by frontrunning `initiatingAdminSettleDebt()`\n    // don't allow deposits once settle debt process has been initialized to prevent vault from starting\n    require(!isAdminSettleDebtInitialized(), \"AAI\");\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, participants will incur loss on withdrawal as admin underpaid for debt settlement. But admin (trusted) can make up the loss by refunding them the difference separately."
    ],
    "Likelihood": [
        " Medium, occurs when admin settles debt"
    ],
    "Description": [
        "",
        "Within LidoVault.deposit(), there is a check require(!isAdminSettleDebtInitialized(), \"AAI\") that prevents fixed/variable participants from starting the vault with the last deposit when the admin settle debt process has been initialized.",
        "However, the check can be bypassed due to a race condition, where an unexpected vault-starting deposit() occurs before initiatingAdminSettleDebt(), forcing the vault to start.",
        "The race condition could occur as follows,"
    ],
    "Recommendations": [
        "",
        "Add an expectedVaultStarted (bool) as a parameter for initiatingAdminSettleDebt() with a check require(expectedVaultStarted == isStarted()); to ensure the vault start status is what the admin expected.",
        "If the check fails, initiatingAdminSettleDebt() should revert, which will then allow admin to repeat initiatingAdminSettleDebt() with a correct msg.value that compensates the participants."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-adminsettledebtlockperiod-might-not-be-long-enough-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High as users might not be able to withdraw in time before their stETH is transferred to AdminLidoAdapter"
    ],
    "Likelihood": [
        " Low, as it needs to be a delay in the queue for lido withdrawals and an event that causes admin to trigger settle debt"
    ],
    "Description": [
        "",
        "admin has the ability to end the vault early in case of unforeseen circumstances. This is done by first calling initiatingAdminSettleDebt which triggers a timelock before adminSettleDebt can be called. This so that users can chose to withdraw before all stETH and pending withdraw requests are transferred to AdminLidoAdapter.",
        "The timelock, adminSettleDebtLockPeriod, is set in VaultFactory to 3 days.",
        "This might however not be enough. Looking at what lido says the withdrawal requests can take anything between 1-5 days:\nhttps://blog.lido.fi/ethereum-withdrawals-overview-faq/#:~:text=How%20does%20the,1%2D5%20days."
    ],
    "Under normal circumstances, this can take anywhere between 1-5 days.": [],
    "Recommendations": [
        "",
        "Consider increasing the timelock to 5 days, or 6 days to give stakers a day to react as well. As well as addressing [H-09]."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-adminsettledebt-could-be-called-multiple-times-leading-to-the-loss-of-funds-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n712:   function adminSettleDebt(address adminLidoAdapterAddress) external onlyAdmin {\n713:     require(block.timestamp > adminSettleDebtLockPeriodEnd, \"ANM\");\n714:\n715:     vaultEndedWithdrawalsFinalized = true;\n716:     adminSettledDebt = true;\n717:\n718:     vaultEndedStakingEarnings = fixedETHDepositToken.totalSupply() < adminSettleDebtAmount\n719:       ? adminSettleDebtAmount - fixedETHDepositToken.totalSupply()\n720:       : 0;\n721:     vaultEndedFixedDepositsFunds = adminSettleDebtAmount - vaultEndedStakingEarnings;\n722:\n723:     if (vaultEndedWithdrawalRequestIds.length > 0) {\n724:       IAdminLidoAdapter adminLidoAdapter = IAdminLidoAdapter(adminLidoAdapterAddress);\n725:       adminLidoAdapter.setLidoWithdrawalRequestIds(vaultEndedWithdrawalRequestIds);\n726:       for (uint i = 0; i < vaultEndedWithdrawalRequestIds.length; i++) {\n727:         lidoAdapter.transferWithdrawalERC721(adminLidoAdapterAddress, vaultEndedWithdrawalRequestIds[i]);\n728:       }\n729:     } else {\n730:       lidoAdapter.transferStETH(adminLidoAdapterAddress, lidoAdapter.stakingBalance());\n731:     }\n...\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, since some users could lose their funds by others users claiming these funds"
    ],
    "Likelihood": [
        " Low, since multiple call of adminSettleDebt() could be done only accidently or by malicious admin"
    ],
    "Description": [
        "",
        "adminSettleDebt lack of check if it was already called:",
        "This could lead to a scenario when:"
    ],
    "Recommendations": [
        "",
        "Add a check that would prevent multiple calls to the adminSettleDebt() function."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-admin-could-call-adminsettledebt-anytime-without-previous-call-initiatingadminsettledebt-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: LidoVault.sol\n712:   function adminSettleDebt(address adminLidoAdapterAddress) external onlyAdmin {\n713:     require(block.timestamp > adminSettleDebtLockPeriodEnd, \"ANM\");\n714:\n715:     vaultEndedWithdrawalsFinalized = true;\n716:     adminSettledDebt = true;\n717:\n718:     vaultEndedStakingEarnings = fixedETHDepositToken.totalSupply() < adminSettleDebtAmount\n719:       ? adminSettleDebtAmount - fixedETHDepositToken.totalSupply()\n720:       : 0;\n721:     vaultEndedFixedDepositsFunds = adminSettleDebtAmount - vaultEndedStakingEarnings;\n...\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, core functionality related to timelock would be bypassed"
    ],
    "Likelihood": [
        " Low, since could be done by admin only accidentally or in case of malicious action"
    ],
    "Description": [
        "",
        "The adminSettleDebt function is designed to allow the admin to settle debt after finishing timelock. The last one should be initiated during initiatingAdminSettleDebt. While adminSettleDebt successfully checks if timelock is ended, it fails to check if timelock was ever initiated, this way check at L713 would compare the current timestamp with the default value for uint256 type - 0, meaning adminSettleDebt could be executed by admin anytime if timelock wasn't yet initiated. Also, vaultEndedStakingEarnings and vaultEndedFixedDepositsFunds would be set to 0 values, breaking withdrawal flow for users."
    ],
    "Recommendations": [
        "",
        "Add condition to L713 require statement that adminSettleDebtLockPeriodEnd > 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-accrual-before-vault-start-can-be-used-as-honeypot-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "397:      // Stake on Lido\n398:      uint256 shares = lidoAdapter.stakeFunds{value: amount}(msg.sender);\n",
        "489:          fixedToVaultNotStartedWithdrawalRequestIds[msg.sender] = lidoAdapter.requestWithdrawViaShares(\n490:            msg.sender,\n491:            claimBalance\n492:          );\n",
        "627:    // give fixed depositor all of their principal + any staking earnings\n628:    uint256 sendAmount = lidoAdapter.claimWithdrawals(msg.sender, requestIds);\n629:\n630:    sendFunds(sendAmount);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " : low, as you can argue that the victim should know better"
    ],
    "Likelihood": [
        " : high, as it is very easy to perform at low risk for the attacker"
    ],
    "Description": [
        "",
        "As soon as a fixed side staker deposits, their funds are sent to lido and start accruing rewards:",
        "Anyone on the fixed side can chose to unstake before the vault starts and receive their share and the accrued rewards:",
        "Hence, joining the vault before it beings is the same as just staking in lido directly.",
        "Thus, an attacker can create a vault with a high premium, deposit the full fixed premium side which will slowly accrue.",
        "At one point a victim sees that there is a vault with large earnings already built up and choses to join. Even though the premium is high, there are already earnings covering the high premium so they join on the variable side.",
        "The attacker then front runs the variable deposit and withdraws their deposit and staking earnings. They can then in the same tx rejoin the vault with a fresh deposit, starting over from scratch.",
        "Thus they have lured a victim to join a vault at an unfair premium with little to no risk for the fixed side attacker."
    ],
    "Recommendations": [
        "",
        "There is no real good on chain mitigation for this so our suggestion is to make it clear in the documentation that earnings before the vault start is not guaranteed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-ongoing-withdrawals-from-variable-side-hurts-variable-earnings-pashov-none-saffron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "571:          (uint256 currentState, uint256 ethAmountOwed) = calculateVariableWithdrawState(\n572:            (lidoStETHBalance - fixedETHDeposits) + withdrawnStakingEarnings + totalProtocolFee,\n573:            variableToWithdrawnStakingEarnings[msg.sender]\n574:          );\n575:\n576:          if (ethAmountOwed >= lidoAdapter.minStETHWithdrawalAmount()) {\n...\n584:            variableToVaultOngoingWithdrawalRequestIds[msg.sender] = lidoAdapter.requestWithdrawViaETH(\n585:              msg.sender,\n586:              ethAmountOwed\n587:            );\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as it can be argued that his is part of the risk on the variable side"
    ],
    "Likelihood": [
        " Medium, as it also hurts the one withdrawing"
    ],
    "Description": [
        "",
        "When the vault is active, a variable side staker can chose to withdraw their share of the, so far, accrued earnings:",
        "On L584 this unstakes from lido, meaning it will lessen the rewards gained by other variable stakers (and themselves) going forward. This mainly makes it difficult for variable side stakers to calculate expected earnings as accounting for how many early withdrawals might be made is hard."
    ],
    "Recommendations": [
        "",
        "There are a couple ways of mitigating this, either an early withdrawal fee on the variable side, similar to early exit fee on the fixed side. Another way is to have the vault creator chose if its allowed or not by adding a flag, ongoing variable withdrawals true/false."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-attacker-can-prevent-sdaistrategy-fees-from-ever-being-collected-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _deposited(uint256 amount) internal override nonReentrant {\n        if (paused) revert Paused();\n\n        // Assume that YieldBox already transferred the tokens to this address\n        uint256 queued = IERC20(contractAddress).balanceOf(address(this));\n        totalActiveDeposits += queued; // Update total deposits\n\n        if (queued >= depositThreshold) {\n            ITDai(contractAddress).unwrap(address(this), queued);\n            dai.approve(address(sDai), queued);\n            sDai.deposit(queued, address(this));\n            emit AmountDeposited(queued);\n            return;\n        }\n        emit AmountQueued(amount);\n    }\n",
        "// Compute the fees\n        {\n            uint256 _totalActiveDeposits = totalActiveDeposits; // Cache total deposits\n            (uint256 fees, uint256 accumulatedTokens) = _computePendingFees(_totalActiveDeposits, maxWithdraw); // Compute pending fees\n            if (fees > 0) {\n                feesPending += fees; // Update pending fees\n            }\n\n            // Act as an invariant, totalActiveDeposits should never be lower than the amount to withdraw from the pool\n            totalActiveDeposits = _totalActiveDeposits + accumulatedTokens - amount; // Update total deposits\n        }\n",
        "function _computePendingFees(uint256 _totalDeposited, uint256 _amountInPool)\n        internal\n        view\n        returns (uint256 result, uint256 accumulated)\n    {\n        if (_amountInPool > _totalDeposited) {\n            accumulated = _amountInPool - _totalDeposited; // Get the occurred gains amount\n            (, result) = _processFees(accumulated); // Process fees\n        }\n    }\n",
        "uint256 queued = IERC20(contractAddress).balanceOf(address(this));\ntotalActiveDeposits += queued; // Update total deposits\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, since zero fees will be captured by the strategy"
    ],
    "Likelihood": [
        " High, since this attack can be easily performed and persisted by a single attacker"
    ],
    "Description": [
        "",
        "In the sDaiStrategy, when a user deposits assets into the strategy, the deposited assets are only placed into the underlying pool when the depositThreshold (which is set by the owner) is reached:",
        "During this flow, the totalActiveDeposits variable is incremented by the contract balance of the deposited asset.",
        "Now, during withdrawals, this variable is used to calculate how many fees are still pending:",
        "This logic is important because it makes sure that we're not charging fees multiple times over the same capital deposited in the strategy. The _computePendingFees method only charges fees when maxWithdraw is greater than _totalActiveDeposits (i.e. the strategy has generated yield, of which the fee recipient is due a percentage):",
        "So, totalActiveDeposits should never be greater than maxWithdraw otherwise no fees will ever be charged.",
        "An attacker can force this situation to occur by doing the following:",
        "This is a problem because of the following logic:",
        "The totalActiveDeposits variable is increased by ~depositThreshold every time the attacker makes a tiny deposit, yet there are no deposits being made into the underlying sDai pool. As a result the totalActiveDeposits variable is now significantly larger than the maxWithdraw from the pool and no fees will be collected from the generated yield. This attack could be performed again in the future once accumulated rewards catch up with the inflated active deposit accounting."
    ],
    "Recommendations": [
        "",
        "In the _deposited method the totalActiveDeposits variable should only be incremented if the queued deposits are actually greater than the depositThreshold and deposited into the sDai pool."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-attackers-can-steal-unclaimed-rewards-from-glpstrategy-because-the-accounted-balance-does-not-include-unclaimed-rewards-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        uint256 totalAmount = _tokenBalanceOf(asset);\n        if (share == 0) {\n            // value of the share paid could be lower than the amount paid due to rounding, in that case, add a share (Always round up)\n            share = amount._toShares(totalSupply[assetId], totalAmount, true);\n        } else {\n            // amount may be lower than the value of share due to rounding, that's ok\n            amount = share._toAmount(totalSupply[assetId], totalAmount, false);\n        }\n\n        _burn(from, assetId, share);\n\n        // Interactions\n        asset.strategy.withdraw(to, amount);\n\n",
        "function _currentBalance() internal view override returns (uint256 amount) {\n        amount = sGLP.balanceOf(address(this));\n        amount += pendingRewards();\n    }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, since users can steal unclaimed rewards"
    ],
    "Likelihood": [
        " High, since this can be performed by any user and the only requirement is that there are some unclaimed rewards. The higher the number of unclaimed rewards and the larger the deposit of the user, the higher the impact. A strategy with less frequent deposits is more likely to suffer from this attack."
    ],
    "Description": [
        "",
        "When a user wants to withdraw assets they have deposited into a YieldBox, the following logic is used in the YieldBox contract:",
        "Here we're mapping the shares owned by the user to their share of the assets in the strategy, and then burning the shares and withdrawing the corresponding number of assets from the strategy. The deposit flow uses a similar pattern. The _tokenBalanceOf method calls into the strategy, which in the GlpStrategy case looks like:",
        "So the asset balance of the strategy is the sum of the GLP balance in the strategy and the pending rewards of the strategy, where the pending WETH rewards are exchanged to GLP based on the current exchange rate.",
        "However, these \"pending rewards\" are actually not technically pending rewards since they have already been harvested from GMX, they just haven't been converted into GLP yet. As a result, the asset <-> share conversion logic in the YieldBox isn't taking into account the actual pending rewards that are still in GMX waiting to be claimed. This is a problem since it allows an attacker to steal a non-proportional amount of the unclaimed rewards for themselves by:",
        "Since this all happens atomically, the attacker could use flashloans to steal a significant portion of unclaimed rewards from the strategy."
    ],
    "Recommendations": [
        "",
        "The _currentBalance method should be updated to include actual pending rewards that are still locked in GMX. This would involve querying the appropriate methods on the GMX contracts."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-emergency-withdrawal-allows-depositing-again-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function emergencyWithdraw() external onlyOwner {\n        paused = true; // Pause the strategy\n\n        // Withdraw from the pool, convert to Dai and wrap it into tDai\n        uint256 maxWithdraw = sDai.maxWithdraw(address(this));\n        sDai.withdraw(maxWithdraw, address(this), address(this));\n        dai.approve(contractAddress, maxWithdraw);\n        ITDai(contractAddress).wrap(address(this), address(this), maxWithdraw);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, tokens can be deposited again after emergency withdrawal, mass withdrawal will not be finalized"
    ],
    "Likelihood": [
        " Medium, emergency withdrawal is an important admin function, but still not a usual operation"
    ],
    "Description": [
        "",
        "The last step of sDaiStrategy.emergencyWithdraw() is the conversion to tDai and setting a pause.",
        "It means that the Owner will have to disable pause so that users can withdraw tDai (otherwise tDai will stuck on the strategy).\nBut if the Owner disables pause it will also enable deposits again. Moreover, the first deposit will trigger the strategy to deposit all tDai balance again, requiring emergencyWithdraw() again."
    ],
    "Recommendations": [
        "",
        "Consider either managing different pause types for deposits and withdrawals separately or disabling deposits after emergencyWithdraw() is called leaving withdrawals enabled.\nAlso, one of the simplest solutions would be just removing the pause for withdrawals."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-baseleverageexecutor-doesnt-have-a-receive-method-to-receive-eth-withdrawals-from-weth-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _handleToftWrapToSender(bool sendBack, address tokenOut, uint256 amountOut) internal {\n        address toftErc20 = ITOFT(tokenOut).erc20();\n        address wrapsTo = sendBack == true ? msg.sender : address(this);\n\n        if (toftErc20 == address(0)) {\n            // If the tOFT is for ETH, withdraw from WETH and wrap it.\n            weth.withdraw(amountOut);\n            ITOFT(tokenOut).wrap{value: amountOut}(address(this), wrapsTo, amountOut);\n        } else {\n            // If the tOFT is for an ERC20, wrap it.\n            toftErc20.safeApprove(tokenOut, amountOut);\n            ITOFT(tokenOut).wrap(address(this), wrapsTo, amountOut);\n            toftErc20.safeApprove(tokenOut, 0);\n        }\n    }\n",
        "receive() external payable {}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, since it breaks the leverage executor when the output token is the tOFT for ETH"
    ],
    "Likelihood": [
        " High, since it will always happen for this output token"
    ],
    "Description": [
        "",
        "The BaseLeverageExecutor.sol contract is the base contract that is inherited by all the other leverage executor contracts. It contains the logic for handling token swapping and tOFT wrapping and unwrapping that is common to all the leverage executors.",
        "When the final token of a leverage action is the ETH tOFT, the WETH from the swap is converted to ETH, and the ETH is wrapped in the tOFT:",
        "The issue here is the call to weth.withdraw includes a callback to this contract with the amount of ETH corresponding to the amount of WETH we want to burn. In order to receive this ETH we need a fallback or receive method, however, this contract has neither. As a result, the withdraw call will revert and so any leverage calls that finish with the ETH tOFT will always revert.",
        "This applies to both AssetTotsDaiLeverageExecutor and AssetToSGLPLeverageExecutor. Any calls to getAsset where the assetAddress is the tOFT for ETH will always fail."
    ],
    "Recommendations": [
        "",
        "The following snippet should be added to the BaseLeverageExecutor.sol contract:",
        "It can be removed from the SimpleLeverageExecutor.sol contract (since it inherits BaseLeverageExecutor)."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-assettotsdaileverageexecutorgetasset-should-use-redeemcollateralamountin-instead-of-redeemconverttosharescollateralamountin-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "//unwrap tsDai\n        ITOFT(collateralAddress).unwrap(address(this), collateralAmountIn);\n        //redeem from sDai\n>       uint256 obtainedDai = ISavingsDai(sDaiAddress).redeem(\n>           ISavingsDai(sDaiAddress).convertToShares(collateralAmountIn), address(this), address(this)\n        );\n",
        "- uint256 obtainedDai = ISavingsDai(sDaiAddress).redeem(\n-             ISavingsDai(sDaiAddress).convertToShares(collateralAmountIn), address(this), address(this)\n+ uint256 obtainedDai = ISavingsDai(sDaiAddress).redeem(collateralAmountIn, address(this), address(this));\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, users will get lesser DAI when converting their sDAI."
    ],
    "Likelihood": [
        " High, will happen every time getAsset() is called."
    ],
    "Description": [
        "",
        "sDai is an ERC4626 contract. Dai is the native asset and sDai is the share. When withdrawing assets, if withdraw() is called, the function takes in the asset value and returns the amount of the underlying asset. When redeem() is called, the function takes in the share value and returns the amount of the underlying asset. Usually, the shares are worth more than the asset, eg 1 sDai : 1.05 Dai.",
        "In AssetTotsDaiLeverageExecutor.getAsset(), the function intends to unwrap tsDai > withdraw sDai > Dai > USDO. When withdrawing sDai, it calls redeem(convertToShares()).",
        "Since sDai is already the share, by calling convertToShares(), it returns lesser Dai than intended since convertToShares() takes in an asset amount and returns the amount of the share. The user will get back lesser Dai and the remaining shares will be stuck in the AssetTotsDaiLeverageExecutor contract."
    ],
    "Recommendations": [
        "",
        "Recommend not calling convertToShares() in getAsset()"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-fees-are-improperly-calculated-in-sdaistrategysol-and-thus-subsequent-depositors-cannot-withdraw-their-full-deposits-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "> (uint256 fees, uint256 accumulatedTokens) = _computePendingFees(_totalActiveDeposits, maxWithdraw); // Compute pending fees\n            if (fees > 0) {\n                feesPending += fees; // Update pending fees\n            }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, some users may not get their full deposit back."
    ],
    "Likelihood": [
        " High, will happen everytime _withdraw() is called."
    ],
    "Description": [
        "",
        "The fees in sDaiStrategy.sol are targeted at the yield from depositing Dai to sDai.",
        "If the protocol deposits 1000 Dai for x sDai and gets back 1010 Dai for x sDai in one year, the yield is 10 Dai and if the fee is set at 10%, then the protocol will earn 1 Dai of fees.",
        "The problem is that it is extremely difficult to calculate how much fees to deduct since there are many depositors to sDaiStrategy but only the sDaiStrategy interacts with the sDai contract. This issue is better explained through an example. Assume fees are set at 10%.",
        "There are two depositors, depositor A and depositor B. Depositor A deposits 9990 Dai through sDaiStrategy, and depositor B deposits 10 Dai through sDaiStrategy. The sDaiStrategy then deposits 10000 Dai and gets back x number of sDai shares.",
        "1 year later, assuming the yield is 5%, the x number of sDai shares can now be redeemed for 10500 Dai. For depositor A, he can get back 10,489.5 Dai and for depositor B, he can get back 10.5 Dai. Depositor A tries to withdraw ~10,489.5 (5% yield) Dai. The sDaiStrategy calculates the fee and since the fee is 10%, the feesPending variable will be 50 Dai.",
        "Once depositor A withdraws his sum, the sDaiStrategy has 10.5 Dai left inside. There is not enough Dai to withdraw the fees and subsequent depositors will not be able to get their withdrawal back because the owner will withdraw the fees.",
        "Instead of making depositor A pay the fees, depositor A can withdraw his full amount + yield, leaving subsequent depositors to pay the fee for him.",
        "In summary, this is what should happen, with a 500 Dai yield:",
        "This is what happens instead"
    ],
    "Recommendations": [
        "",
        "Recommend the sDaiStrategy to have its own accounting system, so that when a user withdraws his deposited amount + yield, the contract can tax the yield directly, instead of having to use a global maxWithdraw."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-glpstrategy-withdrawals-can-fail-if-shouldbuyglp-is-false-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        uint256 totalAmount = _tokenBalanceOf(asset);\n        if (share == 0) {\n            // value of the share paid could be lower than the amount paid due to rounding, in that case, add a share (Always round up)\n            share = amount._toShares(totalSupply[assetId], totalAmount, true);\n        } else {\n            // amount may be lower than the value of share due to rounding, that's ok\n            amount = share._toAmount(totalSupply[assetId], totalAmount, false);\n        }\n\n        _burn(from, assetId, share);\n\n        // Interactions\n        asset.strategy.withdraw(to, amount);\n\n",
        "function _currentBalance() internal view override returns (uint256 amount) {\n        amount = sGLP.balanceOf(address(this));\n        amount += pendingRewards();\n    }\n\n",
        "function _withdraw(address to, uint256 amount) internal override {\n        if (amount == 0) revert NotValid();\n        _claimRewards(); // Claim rewards before withdrawing\n        if (shouldBuyGLP) {\n            _buyGlp(); // Buy GLP with WETH rewards\n        }\n        sGLP.safeApprove(contractAddress, amount);\n        ITapiocaOFTBase(contractAddress).wrap(address(this), to, amount); // wrap the sGLP to tsGLP to `to`, as a transfer\n        sGLP.safeApprove(contractAddress, 0);\n    }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, since withdrawals can fail until shouldBuyGLP is set to true"
    ],
    "Likelihood": [
        " Medium, since shouldBuyGLP has to be set to false by the owner"
    ],
    "Description": [
        "",
        "When a user wants to withdraw assets they have deposited into a YieldBox, the following logic is used in the YieldBox contract:",
        "Here we're mapping the shares owned by the user to their share of the assets in the strategy, and then burning the shares and withdrawing the corresponding number of assets from the strategy. The _tokenBalanceOf method calls into the strategy, which in the GlpStrategy case looks like:",
        "So the asset balance of the strategy is the sum of the GLP balance in the strategy and the pending rewards of the strategy, where the pending WETH rewards are exchanged to GLP based on the current exchange rate.",
        "Now, in the withdraw logic in the strategy, the rewards are claimed and the GLP is wrapped into the tOFT for the withdrawer:",
        "However, the problem here is that the WETH rewards are only used to buy more GLP when shouldBuyGLP is true.",
        "So, this is a problem because the last withdrawers from the strategy may be unable to withdraw altogether in the case where there is a large amount of pending rewards relative to the balance of GLP in the contract. This is because they will try to claim more GLP than the contract holds based on the conversion from shares to assets in YieldBox."
    ],
    "Recommendations": [
        "",
        "I can't see why we would ever want shouldBuyGLP to be false. Since there is no method to withdraw WETH (besides accrued fees) we always want the WETH rewards to be used to buy more GLP.",
        "Either shouldBuyGLP should always be true (we could remove this variable altogether), or the WETH balance needs to be accounted for and there needs to be special logic to handle the case where there is not sufficient GLP left in the contract to handle withdrawals entirely in GLP; so the withdrawal would have to be part GLP, part WETH. This latter option adds a fair bit of complexity which is why the former might make more sense."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-slippage-in-glpstrategy-will-impact-the-value-of-shares-for-different-users-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _currentBalance() internal view override returns (uint256 amount) {\n        amount = sGLP.balanceOf(address(this));\n        amount += pendingRewards();\n    }\n",
        "function pendingRewards() public view returns (uint256 amount) {\n        uint256 wethAmount = weth.balanceOf(address(this));\n        uint256 _feesPending = feesPending;\n        if (wethAmount > _feesPending) {\n            wethAmount -= _feesPending;\n            uint256 fee = (wethAmount * FEE_BPS) / 10_000;\n            wethAmount -= fee;\n\n            uint256 glpPrice;\n            (, glpPrice) = wethGlpOracle.peek(wethGlpOracleData);\n\n            uint256 amountInGlp = (wethAmount * glpPrice) / 1e18;\n            amount = amountInGlp - (amountInGlp * _slippage) / 10_000; //0.5%\n        }\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, since the value of shares changes depending on market conditions and the ordering of withdrawals"
    ],
    "Likelihood": [
        " Medium, since this behavior will be induced at every withdrawal/harvest, but the impact is dependent on the current slippage"
    ],
    "Description": [
        "",
        "When users want to withdraw their assets from the GlpStrategy, the value of their shares is calculated based on their portion of shares and the current balance of the strategy:"
    ],
    "estimate": [
        "This is an  because the slippage is set to 0.5% (since this is the maximum slippage we'll accept on the actual mintAndStakeGlp call). However, the problem with this logic is that the slippage is subject to change and is impacted by market conditions and it can also be influenced by other users and protocols interacting with GMX.",
        "For example, a user who wants to withdraw their shares from the strategy will be quoted based on slippage of 0.5%, but if the market conditions dictate that the actual slippage is 0.1%, then the user still receives the same number of assets, but now the proportional value of every share left in the pool has increased. In low slippage conditions, the first users to withdraw are impacted the most."
    ],
    "Recommendations": [
        "",
        "Arguably this could be the intended behaviour by the protocol since you're incentivising users to remain staked in the strategy during low slippage market conditions. However, the fact that this is unfair to some end users does violate the ethics of the protocol.",
        "A potential solution is to keep all accounting (and reward claiming) in sGLP, including fee recipient rewards. The burden of swapping to WETH (if required) can be moved to the fee recipient, which has 2 benefits:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-sdaistrategy-can-be-bricked-by-a-single-attacker-requiring-manual-intervention-to-resolve-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "return queued + maxWithdraw - feesPending;\n",
        "queued + maxWithdraw - feesPending = 0 + assetsDeposited - 0 = assetsDeposited\n",
        "return feesPending > queued + maxWithdraw ? 0 : queued + maxWithdraw - feesPending;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, since the contract can be bricked, and this is most easily achieved when minimal funds are at risk"
    ],
    "Likelihood": [
        " Medium, since this can be easily achieved with minimal stake by a single attacker or inadvertently during normal operation"
    ],
    "Description": [
        "",
        "For both deposit and withdrawal interactions, the _currentBalance method is called from the YieldBox to exchange assets for shares and vice versa. If this method were to revert, then all deposits and withdrawals would fail. One potential scenario that would cause a revert is in the following line if feesPending was greater than the sum preceding it (since we'll revert on the underflow):",
        "So the pending fees to be withdrawn by the admin would have to be greater than the deposits into the strategy. This isn't especially likely during normal operations, but it can be induced by a single attacker.",
        "This can be achieved most easily if the attacker is the first to deposit into the strategy. At this time the exchange rate between assets and shares is 1:1, so if the attacker deposited 100 assets they would receive 100 shares. The attacker would deposit at least depositThreshold assets into the strategy to ensure that the assets are actually deposited into sDai and are accruing yield. Now, after some short period of time, the sDai would have accrued yield and the attacker can now withdraw their assets. Since they own 100% of the shares they are able to withdraw all of the assets where:",
        "because there are no assets queued and no fees have been captured yet since no withdrawals have taken place. So now, during the withdrawal, the fees are accounted for by incrementing feesPending, but the user still withdrawals all the assets that were deposited into the strategy.",
        "After this withdrawal, there are zero assets in the strategy but the feesPending variable is >0. As a result, all calls to _currentBalance will revert due to underflow. This can be resolved with a manual interaction by the admin to send assets directly to the strategy, but this scenario should never be allowed to occur in the first place."
    ],
    "Recommendations": [
        "",
        "The final line of _currentBalance should be changed to avoid the potential for underflow. Here is a suggested fix:",
        "The pending fees should also be properly accounted for as suggested in the other issue."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-users-cant-withdraw-from-sdaistrategy-when-it-is-paused-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (paused) revert Paused();\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, reverts when integrating with strategy shares"
    ],
    "Likelihood": [
        " Medium, since this only applies when the sDaiStrategy is paused, which shouldn't happen too frequently and should be transient"
    ],
    "Description": [
        "",
        "At any point in time the owner of the sDaiStrategy can either pause the strategy or emergency withdraw (which enables a pause). When the strategy is marked as paused, both deposits and withdrawals cannot be executed.",
        "However, the problem with this logic is that blocking withdrawals from a YieldBox strategy at any time is a big no-no. Even in the event of an exploit scenario, a user should be able to be able to withdraw their share of assets. Even if the relative value of the shares is lower than it could be, a user might want to make that sacrifice in order to pay back borrows elsewhere or fulfill other commitments."
    ],
    "Recommendations": [
        "",
        "The following line should be removed from the _withdraw method:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-using-a-permit-together-with-an-external-call-allows-for-griefing-attacks-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low, the function caller will be frontrun but no funds will be lost"
    ],
    "Likelihood": [
        " High, anyone can grief a permit."
    ],
    "Description": [
        "",
        "When calling a permit, the data of the permit will be logged in the blockchain, and anyone is able to frontrun the permit by duplicating the TX arguments. This is not an issue according to the EIP since the permit creator can just create another permit.",
        "However, if the permit is used in conjunction with an external function call, like a transfer() call, frontrunning the permit will cause the function to be griefed.",
        "Reference: https://www.trust-security.xyz/post/permission-denied"
    ],
    "Recommendations": [
        "",
        "Check that the allowance of the tokens is still available when calling _checkBatchPermitData(). Make sure the user still has the proper allowance before calling transfer()."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-approvedcreditor-not-reset-after-account-transfer-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function auctionBoughtIn(\n    address recipient\n) external onlyLiquidator nonReentrant {\n    _transferOwnership(recipient);\n}\n",
        "else if (block.timestamp > auctionInformation_.cutoffTimeStamp) {\nILendingPool(creditor).settleLiquidationUnhappyFlow(\n    account,\n    startDebt,\n    msg.sender\n);\nIAccount(account).auctionBoughtIn(\n    creditorToAccountRecipient[creditor]\n);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, user can steal funds from liquidated account"
    ],
    "Likelihood": [
        ": Medium, requires either a bad debt account, or L2 to be offline for some time"
    ],
    "Description": [
        "",
        "The Arcadia accounts support a secondary backup creditor which is stored in the approvedCreditor storage variable, and can be set by the owner. The issue is that when an account is transferred, this variable is not reset, and the old owner essentially can have a backdoor to the system.",
        "The approvedCreditor can call the function flashActionByCreditor and change the current creditor of the account. This function also calls the _withdraw function with some actionTarget, and can essentially transfer all assets in the account to that target, provided there are no outstanding loans from the old creditor. So the approvedCreditor can basically act like a new creditor and instead empty all the assets in an account.",
        "The protocol prevents users from forcing this upon buyers of positions on secondary markets by requiring a minimum time elapsed between the setting of the approvedCreditor and a transfer of the account, and the buyers are expected to be aware of this when buying an account. However, account transfers also happen during liquidations when the lending pool internalizes a bad loan via the auctionBoughtIn function.",
        "This transfers the account to the lendingPool and needs to be manually liquidated later. But due to the backdoor via approvedCreditor, users can steal the assets present in this account.",
        "The auctionBoughtIn function is called during liquidation when the liquidation window has passed.",
        "This can happen if liquidators are not interested in the assets being held in the account, or if the L2 sequencer has been down for some time, preventing liquidations from happening. Since most liquidations happen via MEV bots, during times of high traffic and gas fees MEV bots might not be interested in liquidating small accounts as well, letting the timer hit the cutoff timestamp.",
        "In this case, instead of a safe manual liquidation, the assets can be stolen via the backdoor in the account."
    ],
    "Recommendations": [
        "",
        "Either reset the approvedCreditor variable when transferring an account, or have a per-owner based approvedCreditor, like handled in isAssetManager."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-contract-lacks-graceful-retirement-feature-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function unpause() external override afterCoolDownOf(30 days) {\n    emit PauseFlagsUpdated(\n        repayPaused = false,\n        withdrawPaused = false,\n        borrowPaused = false,\n        depositPaused = false,\n        liquidationPaused = false\n    );\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, Users can still borrow assets from pools deemed too unsafe or unstable"
    ],
    "Likelihood": [
        ": Medium, retirements of pools are common on other platforms"
    ],
    "Description": [
        "",
        "Commonly in lending platforms, when a certain token or lending pool has been deemed to be too risky or have been hacked, it is retired. This means that all deposits and borrows from the pool are stopped, however the pool is still kept in the system for users to withdraw and repay their loans. This is a common feature in lending platforms and is a good way to deleverage the system from risky assets while preventing users from being locked out of their funds.",
        "This has happened multiple times in Aave, with some other examples below:",
        "The main idea being that protocols often delist tokens, and they do that by disabling deposits and borrows, but still allowing users to withdraw and repay their loans.",
        "The issue is that this functionality does not exist in this protocol.",
        "In the current protocol, each operation of borrow, deposit, repay and withdraw are controlled by the variables repayPaused, withdrawPaused, borrowPaused, depositPaused. These are defined and controlled in the LendingPoolGuardian.sol contract. However, there is an auto-unlock feature which can trigger after a cooldown period.",
        "Thus while the protocol can pause a pool to only allow withdrawals and repays they can only do so for a period of 30 days. After that, the pool is automatically unpaused and users can deposit and borrow from the pool again.",
        "The only other way to suspend deposits is by manipulating the lock variable in the Tranche contracts. However, that will also prevent withdrawals.",
        "So there is no way for the protocol to selectively disable only deposits and borrows for a pool for a long period of time. This issue can be ignored if it is a design decision by the team, however, it is being flagged here since it is a common feature in other lending protocols."
    ],
    "Recommendations": [
        "",
        "Have a retire option in the lending pool guardian which disables only deposits and borrows and cannot be unlocked after a cooldown period."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-tranche-share-ratios-can-be-manipulated-by-donating-via-liquidations-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "unchecked {\n    // Pay out any surplus to the current Account Owner.\n    if (surplus > 0)\n        realisedLiquidityOf[IAccount(account).owner()] += surplus;\n    // Pay out the \"terminationReward\" to the \"terminator\".\n    realisedLiquidityOf[terminator] += terminationReward;\n}\n",
        "function totalAssetsAndSync() public returns (uint256 assets) {\n    assets = LENDING_POOL.liquidityOfAndSync(address(this));\n}\n\n//@audit inside lending pool\nfunction liquidityOfAndSync(\n    address owner_\n) external returns (uint256 assets) {\n    _syncInterests();\n    assets = realisedLiquidityOf[owner_];\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, share ratio manipulation of ERC4626 vaults"
    ],
    "Likelihood": [
        ": Low, Requires precise timing and other conditions"
    ],
    "Description": [
        "",
        "The contracts use the solmate ERC4626 contracts in order to prevent the share ratio manipulation attacks on the various vaults.",
        "Here's a brief summary of the share ratio manipulation attack, useful for understanding the attack vector in the current context:",
        "The solmate library attempts to prevent this attack by blocking the donation of the tokens. Normally, the total assets are calculated via the ERC20.balanceOf function. However, in solmate, it's kept track of in a storage variable. This makes the donation harder since a direct transfer of tokens will not update the total assets.",
        "However, if there is a way to still donate tokens, i.e. pump up the totalAssets without affecting the totalShares, the share ratio can still be manipulated.",
        "The liquidation mechanism in the contracts credits tokens to the owner of accounts if there is a surplus.",
        "If the tranche is made to be the owner of such an account, which can be done via a simple transfer, then the realisedLiquidityOf of the tranche can be pumped up without minting any shares. The tranche also tracks its own assets via the functions below.",
        "So pumping up realisedLiquidityOf of a tranche via liquidations can increase the assets in the account without increasing shares. This can be used to manipulate the share ratio.",
        "An attack can be done in the following steps. We assume that the tranche is empty.",
        "Attackers can also prep tranch accounts even before deployment. Attackers can predict the address of future tranche addresses, since it is very likely that tranches will be deployed by the same protocol wallet in the future. Thus attackers can call liquidations and pre-fund future tranche accounts with this surplus. Then when a tranch finally gets added, it can have very large share ratios from the very beginning, preventing small deposits from being made due to rounding errors."
    ],
    "Recommendations": [
        "",
        "Since there is a way to donate tokens, the share ratio manipulation attack is still possible. This can be fixed via multiple ways:",
        "Due to the simple nature, the main recommendation is to either mint ghost shares, or burn the first 1e10 initial minted shares.",
        "Note: The inability for solmate-style asset tracking to prevent share ratio exploits has been highlighted in the recent Wise Lending hack, and has been commented on by alcueca here, a contributor to the original ERC4626 EIP. The current recommendation is to burn initial amounts of tokens, as referenced here or follow the latest openzeppelin or yieldbox implementations, which effectively does the same thing."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-liquidators-can-earn-extra-yield-by-flash-depositing-into-tranches-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, Liquidation yields can be denied to liquidity providers"
    ],
    "Likelihood": [
        ": Medium, Not applicable in current deployment configuration, but valid in general"
    ],
    "Description": [
        "",
        "The liquidationPenalty part of the liquidation incentives is dealt out to the tranches as extra yield according to their weights via the _syncLiquidationFeeToLiquidityProviders function. This increases the amount corresponding to each tranch share. The issue is that liquidators can snipe this extra yield at no extra cost via flash deposits.",
        "During liquidations, only the juinor-most tranche is locked, while other tranches are open and can be deposited into. The liquidationPenalty is given at an instant of time, thus users can theoretically deposit a very large amount to these tranche pools, collect the yield, and then withdraw it all out and pay off the flash loan.",
        "However, the liquidators themselves can do this at no cost. So when a liquidator sees a profitable liquidation position, they can flash deposit into the tranches in the very same transaction, carry out the liquidation, and collect the termination fee, a large part of the liquidation penalty, and any discounts on the collateral price. This is a very profitable attack, and can be carried out by any liquidator.",
        "This affects all the unlocked tranches, i.e. all except the junior-most tranche. This attack requires no frontrunning, so can be executed on all chains, irrespective of the visibility of transactions. Yield from liquidations can be denied to liquidity providers at no extra cost for the attacker."
    ],
    "Recommendations": [
        "",
        "Forbid deposits and withdrawals to a tranche in the same transaction / block."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-pending-interests-not-processed-when-updating-treasury-weight-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setTreasuryWeights(\n    uint16 interestWeightTreasury_,\n    uint16 liquidationWeightTreasury_\n) external onlyOwner {\n    totalInterestWeight =\n        totalInterestWeight -\n        interestWeightTreasury +\n        interestWeightTreasury_;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, Can lead to loss of yield for the treasury or pool participants"
    ],
    "Likelihood": [
        ": Medium, loss only happens between the weight update and next deposit/withdrawal"
    ],
    "Description": [
        "",
        "The function setTreasuryWeights sets the interest weight of the treasury and also updates the global totalInterestWeight.",
        "However, it is missing the processInterests modifier. This means that the next time processInterests is called the updated treasury weights will be applied from the last interest calculation point, instead of being applied from the point of the weight update."
    ],
    "Recommendations": [
        "",
        "Add the processInterests modifier to the setTreasuryWeights function."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-supporting-fee-on-transfer-tokens-can-lead-to-bad-debt-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "- The Accounts will indeed be overvalued, since we store the \u2018amount transferred\u2019 (which would be higher than the amount received on the account) to calculate the value of the Account.\n- If enabled, the collateral and liquidation factors (haircut on the value) will be adjusted to accommodate for the value loss due to fees.\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, FOT tokens will incur bad debt"
    ],
    "Likelihood": [
        ": Low, FOT tokens are rare"
    ],
    "Description": [
        "",
        "The protocol claims it can support fee-on-transfer (FOT) tokens if necessary. According to the pre-audit questionlist,",
        "The issue is that changing the liquidation and collateral factors will not be enough to resolve the issue. This can be explained by a simple example.",
        "Say Token A is a FOT token, with a 1% fee.",
        "With deposits and successive withdrawals, FOT tokens can be used to create bad debt positions at very minimal costs. Since this directly affects the health of the system, this is a problem."
    ],
    "Recommendations": [
        "",
        "FOT tokens should always be used with post-transfer accounting logic. Since the protocol doesn't have that, it is recommended not to support FOT tokens at all, despite the claim in the Questionlist."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-first-tranche-depositor-can-withdraw-all-the-previously-earned-interest-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    /**\n     * @notice Syncs interest payments to the liquidity providers and the treasury.\n     * @param assets The total amount of underlying assets to be paid out as interests.\n     * @dev The interest weight of each Tranche determines the relative share of yield (interest payments)\n     * that goes to its liquidity providers.\n     */\n    function _syncInterestsToLiquidityProviders(uint256 assets) internal {\n        uint256 remainingAssets = assets;\n\n        uint256 trancheShare;\n        uint24 totalInterestWeight_ = totalInterestWeight;\n        uint256 trancheLength = tranches.length;\n        for (uint256 i; i < trancheLength; ++i) {\n            trancheShare = assets.mulDivDown(interestWeightTranches[i], totalInterestWeight_);\n            unchecked {\n                realisedLiquidityOf[tranches[i]] += trancheShare;\n                remainingAssets -= trancheShare;\n            }\n        }\n        unchecked {\n            totalRealisedLiquidity = SafeCastLib.safeCastTo128(totalRealisedLiquidity + assets);\n\n            // Add the remainingAssets to the treasury balance.\n            realisedLiquidityOf[treasury] += remainingAssets;\n        }\n    }\n",
        "    /**\n     * @notice Returns the total amount of underlying assets, to which liquidity providers have a claim.\n     * @return assets The total amount of underlying assets.\n     * @dev Modification of totalAssets() where interests are realised (state modification).\n     */\n    function totalAssetsAndSync() public returns (uint256 assets) {\n        assets = LENDING_POOL.liquidityOfAndSync(address(this));\n    }\n",
        "    /**\n     * @notice Modification of the standard ERC-4626 redeem implementation.\n     * @param shares The amount of shares being redeemed.\n     * @param receiver The address of the receiver of the underlying ERC20 tokens.\n     * @param owner_ The address of the owner of the shares being redeemed.\n     * @return assets The corresponding amount of assets withdrawn.\n     */\n    function redeem(uint256 shares, address receiver, address owner_)\n        public\n        override\n        notLocked\n        notDuringAuction\n        returns (uint256 assets)\n    {\n        if (msg.sender != owner_) {\n            // Saves gas for limited approvals.\n            uint256 allowed = allowance[owner_][msg.sender];\n\n            if (allowed != type(uint256).max) allowance[owner_][msg.sender] = allowed - shares;\n        }\n\n        // Check for rounding error since we round down in previewRedeem.\n        if ((assets = previewRedeemAndSync(shares)) == 0) revert TrancheErrors.ZeroAssets();\n\n        _burn(owner_, shares);\n\n        LENDING_POOL.withdrawFromLendingPool(assets, receiver);\n\n        emit Withdraw(msg.sender, receiver, owner_, assets, shares);\n    }\n",
        "   /**\n     * @notice Syncs interest payments to the liquidity providers and the treasury.\n     * @param assets The total amount of underlying assets to be paid out as interests.\n     * @dev The interest weight of each Tranche determines the relative share of yield (interest payments)\n     * that goes to its liquidity providers.\n     */\n    function _syncInterestsToLiquidityProviders(uint256 assets) internal {\n        uint256 remainingAssets = assets;\n\n        uint256 trancheShare;\n        uint24 totalInterestWeight_ = totalInterestWeight;\n        uint256 trancheLength = tranches.length;\n        for (uint256 i; i < trancheLength; ++i) {\n            trancheShare = assets.mulDivDown(interestWeightTranches[i], totalInterestWeight_);\n            unchecked {\n                realisedLiquidityOf[tranches[i]] += trancheShare;\n                remainingAssets -= trancheShare;\n            }\n        }\n        unchecked {\n            totalRealisedLiquidity = SafeCastLib.safeCastTo128(totalRealisedLiquidity + assets);\n\n            // Add the remainingAssets to the treasury balance.\n            realisedLiquidityOf[treasury] += remainingAssets;\n        }\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, because it only affects the initially earned interest of the tranche."
    ],
    "Likelihood": [
        " Medium, because the issue is only present if there's a larger gap between the time in which the tranche starts to earn interest and time of the first deposit."
    ],
    "Description": [
        "",
        "When a Tranche is added to the LendingPool it's eligible to earn interest:",
        "After the first user deposits funds, the Tranche's totalAssets will be the deposit + the previously earned interest.",
        "Because the depositor holds all of the Tranche's shares, they can withdraw the whole amount by burning their tranche shares:"
    ],
    "Recommendations": [
        "",
        "Tranche shouldn't earn any interest if it didn't provide any liquidity to the creditor, i.e. check whether realisedLiquidityOf[tranche] != 0 in"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-borrower-pays-interest-on-their-debt-while-liquidation-is-running-pashov-none-arcadia-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function startLiquidation(address initiator, uint256 minimumMargin_)\n        external\n        override\n        whenLiquidationNotPaused\n        processInterests\n        returns (uint256 startDebt)\n    {\n        // Only Accounts can have debt, and debtTokens are non-transferrable.\n        // Hence by checking that the balance of the msg.sender is not 0,\n        // we know that the sender is indeed an Account and has debt.\n        startDebt = maxWithdraw(msg.sender);\n        if (startDebt == 0) revert LendingPoolErrors.IsNotAnAccountWithDebt();\n\n        // Calculate liquidation incentives which have to be paid by the Account owner and are minted\n        // as extra debt to the Account.\n        (uint256 initiationReward, uint256 terminationReward, uint256 liquidationPenalty) =\n            _calculateRewards(startDebt, minimumMargin_);\n\n        // Mint the liquidation incentives as extra debt towards the Account.\n        _deposit(initiationReward + liquidationPenalty + terminationReward, msg.sender);\n\n        // Increase the realised liquidity for the initiator.\n        // The other incentives will only be added as realised liquidity for the respective actors\n        // after the auction is finished.\n        realisedLiquidityOf[initiator] += initiationReward;\n        totalRealisedLiquidity = SafeCastLib.safeCastTo128(totalRealisedLiquidity + initiationReward);\n\n        // If this is the sole ongoing auction, prevent any deposits and withdrawals in the most jr tranche\n        if (auctionsInProgress == 0 && tranches.length > 0) {\n            unchecked {\n                ITranche(tranches[tranches.length - 1]).setAuctionInProgress(true);\n            }\n        }\n\n        unchecked {\n            ++auctionsInProgress;\n        }\n\n        // Emit event\n        emit AuctionStarted(msg.sender, address(this), uint128(startDebt));\n    }\n",
        "    /**\n     * @notice Syncs interest to LPs and treasury and updates the interest rate.\n     */\n    modifier processInterests() {\n        _syncInterests();\n        _;\n        // _updateInterestRate() modifies the state (effect), but can safely be called after interactions.\n        // Cannot be exploited by re-entrancy attack.\n        _updateInterestRate(realisedDebt, totalRealisedLiquidity);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, because the additional interest is limited by the auction cut off time."
    ],
    "Likelihood": [
        " Medium, only an issue if the user is fully liquidated."
    ],
    "Description": [
        "",
        "The LendingPool doesn't pause interest payments while a user's position is liquidated. When the liquidation is initiated, the user's debt position is increased to cover the initiation + termination reward as well as the liquidation penalty.",
        "The user still holds lending pool shares representing their share of the total debt. While the auction is running, interest is paid by all the debt token holders through the following modifier:",
        "At most, the auction can run for up to 4 hours so the user only pays up to 4 hours more interest than they should. For example, MakerDAO stops accruing interest for a borrower's position as soon as the auction is initiated to cover the liquidation."
    ],
    "Recommendations": [
        "",
        "Positions that are liquidated shouldn't accrue additional interest."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-result-from-getswapoutput-is-inaccurate-to-be-used-as-the-minoutput-in-the-swap-operation-pashov-none-brrito-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function harvest() external {\n    // ...\n    // Fetching the quote onchain means that we're subject to front/back-running but the\n    // assumption is that we will harvest so frequently that the rewards won't justify the effort.\n>>  (uint256 index, uint256 quote) = router.getSwapOutput(\n        keccak256(abi.encodePacked(rewardConfig.token, _WETH)),\n        rewards\n    );\n\n    // `swap` returns the entire WETH amount received from the swap.\n    uint256 supplyAssets = router.swap(\n        rewardConfig.token,\n        _WETH,\n        rewards,\n>>      quote,\n        index,\n        // Receives half of the swap fees (the other half remains in the router contract for the protocol).\n        feeDistributor\n    );\n    // ...\n}\n",
        "    function getSwapOutput(\n        bytes32 pair,\n        uint256 input\n    ) external view returns (uint256 index, uint256 output) {\n        IPath[][] memory routes = _routes[pair];\n        uint256 routesLength = routes.length;\n\n        unchecked {\n            for (uint256 i = 0; i < routesLength; ++i) {\n                IPath[] memory route = routes[i];\n                uint256 routeLength = route.length;\n                uint256 quoteValue = input;\n\n                for (uint256 j = 0; j < routeLength; ++j) {\n                    quoteValue = route[j].quoteTokenOutput(quoteValue);\n                }\n\n                if (quoteValue > output) {\n                    index = i;\n                    output = quoteValue;\n                }\n            }\n        }\n\n>>      output = output.mulDiv(_FEE_DEDUCTED, _FEE_BASE);\n    }\n",
        "function _swap(\n        address inputToken,\n        address outputToken,\n        uint256 input,\n        uint256 minOutput,\n        address outputRecipient,\n        uint256 routeIndex,\n        address referrer\n    ) private returns (uint256 output) {\n        IPath[] memory route = _routes[\n            keccak256(abi.encodePacked(inputToken, outputToken))\n        ][routeIndex];\n        uint256 routeLength = route.length;\n        output = outputToken.balanceOf(address(this));\n\n        for (uint256 i = 0; i < routeLength; ) {\n            input = route[i].swap(input);\n\n            unchecked {\n                ++i;\n            }\n        }\n\n        // The difference between the balances before/after the swaps is the canonical output.\n        output = outputToken.balanceOf(address(this)) - output;\n\n>>     if (output < minOutput) revert InsufficientOutput();\n\n        unchecked {\n            uint256 originalOutput = output;\n            output = originalOutput.mulDiv(_FEE_DEDUCTED, _FEE_BASE);\n\n            // Will not overflow since `output` is 99.98% of `originalOutput`.\n            uint256 fees = originalOutput - output;\n\n            outputToken.safeTransfer(outputRecipient, output);\n\n            // If the referrer is non-zero, split 50% of the fees (rounded down) with the referrer.\n            // The remainder is kept by the contract which can later be withdrawn by the owner.\n            if (referrer != address(0) && fees > 1) {\n                // Will not overflow since `fees` is 2 or greater.\n                outputToken.safeTransfer(referrer, fees / 2);\n            }\n\n            emit Swap(inputToken, outputToken, routeIndex, output, fees);\n        }\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low, because it decrease the minOutput by 0.02%"
    ],
    "Likelihood": [
        " High, because it always happened when harvest is called."
    ],
    "Description": [
        "",
        "When harvest called, it will calculate quote amount that will be used for minOutput in the swap operation by calling router.getSwapOutput",
        "Here is the calculation inside router.getSwapOutput, it will compute the output after deducting the fee.",
        "However, within the swap operation inside the router, the check for minOutput is performed before deducting the fee.",
        "Using quote result from getSwapOutput means it will compare the output using value less than it should be."
    ],
    "Recommendations": [
        "",
        "Adjust the swap functionality inside the router to check minOutput after deducting the fee or adjust the qoute result so it is reflect the output amount before fee is deducted."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-harvest-function-is-susceptible-to-sandwich-attacks-and-any-unexpected-market-events-pashov-none-brrito-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function harvest() external {\n        // ...\n\n        // Fetching the quote onchain means that we're subject to front/back-running but the\n        // assumption is that we will harvest so frequently that the rewards won't justify the effort.\n        // @audit - quote here, already deducted by fee, while the minOutput check at swap, is step before fees are deducted\n>>      (uint256 index, uint256 quote) = router.getSwapOutput(\n            keccak256(abi.encodePacked(rewardConfig.token, _WETH)),\n            rewards\n        );\n\n        // `swap` returns the entire WETH amount received from the swap.\n>>      uint256 supplyAssets = router.swap(\n            rewardConfig.token,\n            _WETH,\n            rewards,\n            quote,\n            index,\n            // Receives half of the swap fees (the other half remains in the router contract for the protocol).\n            feeDistributor\n        );\n\n       // ...\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, Because attackers can sandwich the operation and steal swap value, or in unexpected market events, the swap could result in an unexpectedly low value."
    ],
    "Likelihood": [
        " Medium, Because the attack vector is quite common and well-known, and price volatility is typical for non-stable coin tokens."
    ],
    "Description": [
        "",
        "While acknowledged by the protocol team, using getSwapOutput to calculate the minimum output of the swap on-chain is still not recommended under any circumstance or assumption. This method is not only vulnerable to sandwich attacks but also susceptible to any market events, such as rapid price changes.",
        "Besides that, the assumption that harvest will always be callable is not correct, as supply functionality to _COMET can be paused, causing the calls to revert. In the unlikely, but possible, event that the compound pauses the WETH pool, interest would still accrue, and the reward amount would build up, becoming large enough for sandwich attacks to become feasible."
    ],
    "Recommendations": [
        "",
        "Consider putting the minimum output as a parameter inside the harvest function, and if this function is planned to be frequently called by bots, it could be restricted so that only certain roles can invoke it."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-initial-griefing-attack-possible-pashov-none-brrito-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    address bob = makeAddr(\"bob\");\n\n    function testInitialSupplyAttack() public {\n    \t// attacker starts with 13 ether\n        _getCWETH(13e18 + 6);\n\n        // initial small deposit\n        vault.deposit(11,address(this));\n        assertEq(10,vault.balanceOf(address(this)));\n\n        // large deposit to inflate the exchange rate\n        _COMET.safeTransfer(address(vault),11e18-9);\n\n        // share price is not 1e18 assets\n        assertEq(1e18,vault.convertToAssets(1));\n\n        // boilerplate to get cWETHv3\n        deal(_WETH,bob,1e18 + 3);\n        vm.startPrank(bob);\n        _WETH.safeApprove(_COMET,1e18+3);\n        IComet(_COMET).supply(_WETH, 1e18+3);\n        _COMET.safeApproveWithRetry(address(vault), type(uint256).max);\n\n        // victim deposits into the vault\n        vault.deposit(1e18+1,bob);\n        // due to exchange rate gets 0 shares\n        assertEq(0,vault.balanceOf(bob));\n        vm.stopPrank();\n\n        vault.redeem(10, address(this), address(this));\n        console.log(\"exchange rate\",vault.convertToAssets(1));\n        console.log(\"_COMET.balanceOf(address(vault))\",_COMET.balanceOf(address(vault)));\n        console.log(\"_COMET.balanceOf(address(attacker))\",_COMET.balanceOf(address(this)));\n    }\n",
        "Logs:\n  exchange rate 1090909090909090909\n  _COMET.balanceOf(address(vault)) 1090909090909090908\n  _COMET.balanceOf(address(attacker)) 12909090909090909091\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, as the victim loses their funds"
    ],
    "Likelihood": [
        " Low, as it comes at a cost for the attacker"
    ],
    "Description": [
        "",
        "The famous initial deposit attack is largely mitigated by the solady library. However, doing this attack can cause some weird behavior that could grief users (at high cost of the attacker) and leave the vault in a weird state:",
        "Here's a PoC showing the impacts",
        "with the output:",
        "As you can see the attacker needs to pay 0.1 eth for the attack. But they have effectively locked the victims 1 eth in the contract.",
        "Even though this is not profitable for the attacker it will leave the vault in a weird state and the victim will still have lost his tokens."
    ],
    "Recommendations": [
        "",
        "Consider mitigating this with an initial deposit of a small amount."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-users-can-set-feeon-1-to-avoid-fees-pashov-none-kekotron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(bool feeIn, bool feeOut) = fee > 0 ? (feeOn == 0, feeOn == 1) : (false, false);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, less fee received for the protocol"
    ],
    "Likelihood": [
        " High, a simple input change on every swap"
    ],
    "Description": [
        "",
        "feeOn is indicated by users on every swap and is responsible for choosing between feeIn and feeOut.\nfeeOn== 0, means feeIn true and feeOut false.\nfeeOn== 1, means feeIn false and feeOut true.",
        "But if feeOn is above 1, both feeIn and feeOut will be false, even if fee is set.\nAs a result, fees will not be accrued."
    ],
    "Recommendations": [
        "",
        "Consider checking that feeOn is either 0 or 1, or just use boolean for feeOn input (given that in tests it is always converted between boolean and uint8)"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-choosing-feein-is-always-more-beneficial-than-feeout-pashov-none-kekotron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Low, the difference is very small for the majority of swaps"
    ],
    "Likelihood": [
        " High, FeeIn can be chosen on every swap"
    ],
    "Description": [
        "",
        "Users can choose between FeeIn (fee on tokenIn-amountIn), or choose FeeOut (fee on tokenOut-amountOut). If both alternatives are calculated it always happens that choosing FeeIn always results in fewer fees (the user receives more net amountOut).",
        "Technically it happens because FeeIn means less funds to swap, and less loss due to slippage in the end.\nThe difference between the two options is becoming larger when the size of the swap grows (more slippage).",
        "The difference between options is 0.5% for a swap of 100% of reserves, and 0.09% for 10% of reserves.",
        "But, FeeIn is also more beneficial for FeeReceiver as the fee is taken before slippage and DEX fees.",
        "As a result, FeeIn is always financially better for both the protocol and the user."
    ],
    "Recommendations": [
        "",
        "Consider some of the options:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-not-checked-eth-provided-amountin-swapped-pashov-none-kekotron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, loss of funds"
    ],
    "Likelihood": [
        " Low, required mistake in inputted data and choosing native token as tokenIn"
    ],
    "Description": [
        "",
        "RouterV2 does not check that msg.value is equal to amountIn in case of tokenIn == address(0).\nIf a user sends in fact less - the transaction will revert.\nIf a user sends in fact more - some native token will stuck on Router after the swap (the delta will not be swapped)"
    ],
    "Recommendations": [
        "",
        "Consider checking that msg.value == amountIn if the native token is tokenIn."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-missing-deadline-check-in-swap-functions-pashov-none-kekotron-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        "",
        "Impact: Low, the user would not be at a loss and would only miss positive slippage.",
        "Likelihood: High, deadline parameter is missing."
    ],
    "Description": [
        "",
        "Swap functions don't have deadline parameter. This parameter can provide the user an option to limit the execution of their pending transaction.\nWithout a deadline parameter, users can execute their transactions at unexpected times when market conditions are unfavorable.",
        "However, this is not a big problem in this case because the functions have slippage protection. Even though the users will get at least as much as they set, they may still be missing out on positive slippage if the exchange rate becomes favorable when the transaction is included in a block."
    ],
    "Recommendations": [
        "",
        "Introduce a\u00a0deadline\u00a0parameter in all swap functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-missing-payable-function-pashov-none-hytopiawallet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: contracts\\modules\\Calls\\Calls.sol\n80:     function _call(CallsStructs.CallRequest calldata _callRequest) internal returns (bytes memory) {\n81:         (bool success, bytes memory result) = _callRequest.target.call{ value: _callRequest.value }(_callRequest.data);\n82:\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, wallet will not receive native tokens but expected"
    ],
    "Likelihood": [
        " High, because the use of msg.value and sending native token is a frequent operation"
    ],
    "Description": [
        "",
        "_call() could send native token via .call{ value: _callRequest.value }, however, none of the contracts can receive native token, including Main.sol, PreauthorizedCalls.sol, SessionCalls.sol, Calls.sol, Controllers.sol."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-threshold-conflicts-with-removing-controllers-pashov-none-hytopiawallet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _removeController(address _controller) internal {\n        ControllersStorage.layout().totalWeights -= ControllersStorage.layout().weights[_controller];\n        if (\n            ControllersStorage.layout().totalWeights == 0\n                || ControllersStorage.layout().totalWeights < ControllersStorage.layout().threshold\n        ) {\n            revert ThresholdImpossible();\n        }\n        ControllersStorage.layout().weights[_controller] = 0;\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, attack vector to capture the wallet"
    ],
    "Likelihood": [
        " Medium, relevant not for all sets of controllers"
    ],
    "Description": [
        "",
        "There is a drawback to using absolute weights - sometimes we should decrease the Threshold before removing a controller. Decreasing Threshold is a strong voting rules adjustment, and can be maliciously used by any controller.",
        "Imagine we have a set of controllers A=50, B=50. TotalWeight=100, Threshold=100.\nThen, imagine user B asks to exit.",
        "_removeController() will revert, as totalWeight will update to 50, but threshold=100 is not updated, and we require that totalWeight >= threshold.",
        "So, signers should have two transactions:",
        "If user A signs TX 1 - then user B can capture the wallet."
    ],
    "removing controller A": [
        "As a result, Controller B managed to remove Controller A and capture the wallet."
    ],
    "Recommendations": [
        ""
    ],
    "can be": [
        "This issue is hard to fix. Some new rules should be introduced to deal with this scenario.\nIf totalWeight falls below the current threshold, this delta voting power  somehow distributed among other controllers. Or, totalWeight  allowed to fall only to the current threshold.\nConsider the following idea.\nImagine totalWeight of 100 should be decreased by 20, when the current threshold is 95.",
        "Also, it must be noted that the same thing is relevant to updateControllerWeight() as it can be used to decrease weight for a given controller, and totalWeight is decreased there as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-wallet-initialize-frontrun-pashov-none-hytopiawallet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        address _newWalletAddr = _factory.createProxy(_testWalletSalt);\n        Main(payable(_newWalletAddr)).initialize(deployer);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, attack to secretly own new wallets of other users"
    ],
    "Likelihood": [
        " Medium, frontrun required"
    ],
    "Description": [
        "",
        "The deploy script does 2 transactions to deploy a wallet:",
        "Wallet deployments can be tracked and awaited. An attacker can frontrun and call initialize() with malicious input.",
        "One of the ideas:"
    ],
    "Recommendations": [
        "",
        "Ensure the initialize() is called in the same transaction as the wallet deployment."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-restrictedfunction-could-miss-come-cases-pashov-none-hytopiawallet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "File: contracts\\modules\\SessionCalls\\SessionCalls.sol\n448:     function _isRestrictedFunction(bytes4 _functionSelector) private pure returns (bool isRestricted_) {\n449:         if (\n450:             _functionSelector == IERC20.approve.selector || _functionSelector == IERC721.approve.selector\n451:                 || _functionSelector == IERC721.setApprovalForAll.selector\n452:                 || _functionSelector == IERC1155.setApprovalForAll.selector\n453:         ) {\n454:             isRestricted_ = true;\n455:         }\n456:     }\n\n// https://etherscan.io/address/0x1a1fdf27c5e6784d1cebf256a8a5cc0877e73af0#code\n  function increaseApproval(address _spender, uint _addedValue) public returns (bool) {\n    allowed[msg.sender][_spender] = allowed[msg.sender][_spender].add(_addedValue);\n    emit Approval(msg.sender, _spender, allowed[msg.sender][_spender]);\n    return true;\n  }\n\n  function decreaseApproval(address _spender, uint _subtractedValue) public returns (bool) {\n    uint oldValue = allowed[msg.sender][_spender];\n    if (_subtractedValue > oldValue) {\n      allowed[msg.sender][_spender] = 0;\n    } else {\n      allowed[msg.sender][_spender] = oldValue.sub(_subtractedValue);\n    }\n    emit Approval(msg.sender, _spender, allowed[msg.sender][_spender]);\n    return true;\n  }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, because the fund in the contract could all be stolen, much beyond allowed amount."
    ],
    "Likelihood": [
        " Low, because it only applies to cases when MAGIC_CONTRACT_ALL_FUNCTION_SELECTORS being used, and not all tokens have this problem."
    ],
    "Description": [
        "",
        "Only approve and setApprovalForAll are considered restricted function, however it is possible that the token allowance could be chaged by other functions:\nSuch as RNDR, has increaseApproval()/decreaseApproval() function, which is not standard ERC20 functions."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-working-with-signatures-nonce-and-expiry-pashov-none-hytopiawallet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, some signers can extract personal benefits"
    ],
    "Likelihood": [
        " Low, required mistakes and unique parity of voting power"
    ],
    "Description": [
        "",
        "There are some not protected attack vectors.",
        "Some simplified example:",
        "There are two problems why it is possible:"
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-user-cant-unstake-in-case-he-gets-blacklisted-by-reward-token-usdc-pashov-none-gainsnetwork-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function unstakeGns(uint128 _amountGns) external {\n        require(_amountGns > 0, \"AMOUNT_ZERO\");\n\n        harvestDai();\n@>      harvestTokens();\n\n        ... // Main unstake logic\n    }\n",
        "    function _harvestToken(address _token, uint128 _stakedGns) private {\n        ... // Main harvest logic\n\n@>      IERC20(_token).transfer(msg.sender, uint256(pendingTokens));\n\n        emit RewardHarvested(msg.sender, _token, pendingTokens);\n    }\n",
        "mapping (address token => uint256 pendingBalance) pendingBalances;\n"
    ],
    "Severity": [
        "",
        "Impact: High. User can't unstake his Gns",
        "Likelihood: Low. USDC blacklisting is not usual operation."
    ],
    "Description": [
        "",
        "USDC is supposed to be used as reward token, note it has blacklist functionality. Thus USDC tokens can't be transferred to/from blacklisted address.",
        "Currently harvested token rewards are transferred in a force manner to staker on any interaction: claim vested tokens, stake, unstake, revoke vesting. Additionally, in unstakeGns() all the rewards are processed. Therefore if any of token transfers reverts, user will be unable to harvest and therefore unstake.",
        "While unstake it firstly proccesses rewards for all tokens:",
        "And then transfers harvested amount of every reward token, including USDC. As discussed above, USDC transfer can revert:",
        "Thus user who got blacklisted by USDC can't harvest all token rewards and therefore unstake. His stake will exist forever, receiving portion of rewards which will never be claimed.",
        "The same scenario is when user tries to claim vested amount."
    ],
    "Recommendations": [
        "",
        "Use claim pattern: instead of transferring tokens, only increase internal balances. Something like:",
        "And also introduce claim method."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-the-read-function-returns-the-wrong-value-because-it-is-not-properly-scalable-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\u00a0 \u00a0 function read() external view override returns (uint256) {\n\u00a0 \u00a0 \u00a0 \u00a0 return _readUniswapQuote(10 ** inBase);\n\u00a0 \u00a0 }\n",
        "inBase = 10 ** (inCur.decimals());\n",
        "\u00a0 \u00a0 function read() external view override returns (uint256) {\n\u00a0 \u00a0 \u00a0 \u00a0 return _readUniswapQuote(inBase);\n\u00a0 \u00a0 }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, because price data will be very inaccurate."
    ],
    "Likelihood": [
        ": High, because it will always happen."
    ],
    "Description": [
        "",
        "In OracleUniSolo.sol we have the function read():",
        "This function returns the current exchange rate between two tokens from Uniswap. It's also extremely important because provides price data. But there is a big mistake in the argument.",
        "You can see how is inBase variable:",
        "The correct version of the read() function should be using inBase directly as the argument to _readUniswapQuote(). The inBase is already calculated as 10 ** (inCur.decimals()).",
        "Because of the wrong value passed to _readUniswapQuote() the consequences can be huge. In one case you may get an overflow and the function may not work at all, in the other case it will return a totally wrong value."
    ],
    "Recommendations": [
        "",
        "Pass the inBase directly to the function without further scaling:"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-anyone-can-update-the-cluster-address-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\u00a0 \u00a0 function setCluster(ICluster _cluster) external {\n\u00a0 \u00a0 \u00a0 \u00a0 if (address(_cluster) == address(0)) revert NotValid();\n\u00a0 \u00a0 \u00a0 \u00a0 emit ClusterSet(cluster, _cluster);\n\u00a0 \u00a0 \u00a0 \u00a0 cluster = _cluster;\n\u00a0 \u00a0 }\n",
        "\u00a0 \u00a0 function setCluster(ICluster _cluster) external onlyOwner {\n\u00a0 \u00a0 \u00a0 \u00a0 if (address(_cluster) == address(0)) revert NotValid();\n\u00a0 \u00a0 \u00a0 \u00a0 emit ClusterSet(cluster, _cluster);\n\u00a0 \u00a0 \u00a0 \u00a0 cluster = _cluster;\n\u00a0 \u00a0 }\n"
    ],
    "Impact": [
        ": High, because a malicious user would gain access to a very important function."
    ],
    "Likelihood": [
        ": High, the lack of access control makes this function very easy to exploit."
    ],
    "Description": [
        "",
        "In MagnetarV2.sol we have setCluster() function:",
        "This function updates the cluster address, which is extremely important. But this function has no access control. Only the owner should be able to call this function. But currently absolutely anyone can call setCluster() and change the cluster address, which can cause major harm to the protocol."
    ],
    "Recommendations": [
        "",
        "Add the onlyOwner modifier to the setCluster() function:"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-03-approvals-can-be-exploited-due-to-insufficient-checks-in-_exitpositionandremovecollateral-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 tOLPId = 0;\n        if (removeAndRepayData.exitData.exit) { ... }\n",
        "if (removeAndRepayData.unlockData.tokenId != 0) {\n                if (tOLPId != 0) {\n                    if (tOLPId != removeAndRepayData.unlockData.tokenId)\n                        revert tOLPTokenMismatch();\n                }\n                tOLPId = removeAndRepayData.unlockData.tokenId;\n            }\n",
        " ITapiocaOptionLiquidityProvision(\n                removeAndRepayData.unlockData.target\n            ).unlock(tOLPId, externalData.singularity, user);\n",
        "require(\n            _isApprovedOrOwner(msg.sender, _tokenId),\n            \"tOLP: not owner nor approved\"\n        );\n\n        _burn(_tokenId);\n",
        "address ownerOfTapTokenId = IERC721(oTapAddress).ownerOf(\n                removeAndRepayData.unlockData.tokenId\n            );\n\n            if (ownerOfTapTokenId != user && ownerOfTapTokenId != address(this))\n                revert NotValid();\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, loss of provided liquidity tokens due to approval exploit"
    ],
    "Likelihood": [
        ": High, can be called by anyone"
    ],
    "Description": [
        "",
        "The function _exitPositionAndRemoveCollateral in the MagnetarMarketModule carries out a number of operations. It unlocks locked liquidity positions, and then removes assets from the markets. The first two operations are of interest here, called exit and unlock. The caller provides boolean values to the function call which determines if these operations are run. These boolean values are stored in removeAndRepayData.exitData.exit and removeAndRepayData.unlockData.unlock.",
        "The issue is that for a certain combination of values passed, the user can pull liquidity tokens from other users who have given approval to the Magnetar contract. Since the Magnetar contract is a helper contract for user interactions, it is assumed that users have already given allowance of their tokens and ERC721 positions to Magnetar.",
        "Lets look at a scenario where the attacker sets removeAndRepayData.exitData.exit to false, and removeAndRepayData.unlockData.unlock to true.",
        "Due to the first bool being false, the function does not do the exit operation.",
        "In the unlock operation, the tokenId which has to be unlocked is to be set. As the exit operation is skipped, the values stored in tOLPId is still 0 as shown above.",
        "Here, the attacker sets the victim's token id in the field removeAndRepayData.unlockData.tokenId. Since its non-zero, the inner if clause is reached. Since tOLPId is still 0 due to skipping the exit operation, the if clause is skipped, and the tOLPId is set to removeAndRepayData.unlockData.tokenId.",
        "The issue is that there is no check whether the caller actually owns this tokenId! in the next line, unlock is called on this tokenId, and the proceeds are sent to user, who is the attacker.",
        "If the victim has given approval of their liquidity token to Magnetar in the past, which is likely if they have ever interacted with Magnetar, they would lose their token and the liquidity would be unlocked and sent off to the attacker. So the attacker can hijack anyone's liquidity token. The magnetar contract does not even need to own this ERC721 token, because as we can see from the unlock function, the token is burnt directly from the holder's wallet as long as Magnetar has aproval."
    ],
    "Recommendations": [
        "",
        "Add a user check similar to the one present in exit operation."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-stargatelbphelperparticipate-will-send-tokens-to-the-wrong-address-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function participate(\n        StargateData calldata stargateData,\n        ParticipateData calldata lbpData\n    ) external payable nonReentrant {\n        IERC20 erc20 = IERC20(stargateData.srcToken);\n\n        // retrieve source token from sender\n        erc20.safeTransferFrom(msg.sender, address(this), stargateData.amount);\n\n        // compute min amount to be received on destination\n        uint256 amountWithSlippage = stargateData.amount -\n            ((stargateData.amount * stargateData.slippage) /\n                SLIPPAGE_PRECISION);\n\n        // approve token for Stargate router\n        erc20.safeApprove(address(router), stargateData.amount);\n\n        // send over to another layer using the Stargate router\n        router.swap{value: msg.value}(\n            stargateData.dstChainId,\n            stargateData.srcPoolId,\n            stargateData.dstPoolId,\n            payable(msg.sender), //refund address\n            stargateData.amount,\n            amountWithSlippage,\n            IStargateRouterBase.lzTxObj({\n                dstGasForCall: 0,\n                dstNativeAmount: 0,\n                dstNativeAddr: \"0x0\"\n            }),\n            abi.encodePacked(msg.sender), //@audit this should be a parameter to `StargateLbpHelper` address on host chain\n            abi.encode(lbpData, msg.sender)\n        );\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Med, as the tokens incorrectly sent to msg.sender may not be recoverable if the caller do not have control over it (when caller is using a multisig wallet contract)"
    ],
    "Likelihood": [
        " High, as the StargateLbpHelper will perform a stargate swap to the wrong address"
    ],
    "Description": [
        "",
        "StargateLbpHelper.participate() is called on the non-host chain to send tokens via Stargate to StargateLbpHelper on host chain for depositing into Balancer Liquidity Bootstrapping Pool.",
        "This will cause an issue for participate() as it will perform Stargate router.swap() to destination address msg.sender instead of the StargateLbpHelper contract on host chain."
    ],
    "Recommendations": [
        "",
        "Allow participate() to pass in the receiving address of StargateLbpHelper on the host chain.",
        "Note that StargateLbpHelper will be deployed using CREATE2 via TapiocaDeployer, the contracts will not have the same address on the host chain and non-host chains. That is because the constructor parameters for StargateLbpHelper will be different for them, causing the deployed address to be different as CREATE2 precompute address based on creationcode that includes constructor parameters. So it is important to use a parameter for the destination StargateLbpHelper address and not hardcode it."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-stargatelbphelpersgreceive-could-encounter-permanent-error-that-causes-received-tokens-to-be-stuck-in-contract-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, as tokens will be stuck in contract"
    ],
    "Likelihood": [
        " Medium, as it only occur for permanent errors"
    ],
    "Description": [
        "",
        "StargateLbpHelper.sgReceive() receives tokens that are sent across chains via Stargate swap, and then swaps them via LBP pool. StargateLbpHelper has a retryRevert() to allow the owner to retry the execution on stargate swap failure.",
        "However, if the failure is due to a permanent error, retryRevert() will not help with the recovery. When that happens, the tokens received will be stuck in the StargateLbpHelper contract, with no means to retrieve them."
    ],
    "Recommendations": [
        "",
        "Either allow token recipient to retrieve the tokens or transfer to recipient when such a permanent error occurs."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-03-multisig-wallets-that-call-stargatelbphelperparticipate-could-cause-received-token-to-be-stolen-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function participate(\n        StargateData calldata stargateData,\n        ParticipateData calldata lbpData\n    ) external payable nonReentrant {\n       ...\n        router.swap{value: msg.value}(\n            stargateData.dstChainId,\n            stargateData.srcPoolId,\n            stargateData.dstPoolId,\n            payable(msg.sender),\n            stargateData.amount,\n            amountWithSlippage,\n            IStargateRouterBase.lzTxObj({\n                dstGasForCall: 0,\n                dstNativeAmount: 0,\n                dstNativeAddr: \"0x0\"\n            }),\n            abi.encodePacked(msg.sender),\n            abi.encode(lbpData, msg.sender) //@audit receiver address on destination chain should be a parameter and not msg.sender\n        );\n\n\n    function sgReceive(\n        uint16,\n        bytes memory,\n        uint256,\n        address token,\n        uint256 amountLD,\n        bytes memory payload\n    ) external {\n        ...\n        // decode payload\n        (ParticipateData memory data, address receiver) = abi.decode( //@audit receiver is set to msg.sender\n            payload,\n            (ParticipateData, address)\n        );\n       ...\n        IBalancerVault.FundManagement memory fundManagement = IBalancerVault\n            .FundManagement({\n                sender: address(this),\n                recipient: payable(receiver), //@audit token is sent to receiver (which is msg.sender on src chain)\n                fromInternalBalance: false,\n                toInternalBalance: false\n            });\n\n        IERC20(data.assetIn).approve(address(lbpVault), 0);\n        IERC20(data.assetIn).approve(address(lbpVault), amountLD);\n        lbpVault.swap(\n            singleSwap,\n            fundManagement,\n            data.minAmountOut,\n            (data.deadline != 0 ? data.deadline : block.timestamp)\n        );\n    }\n\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, as received tokens on destination chain will be lost"
    ],
    "Likelihood": [
        " Medium, this occurs when caller is a multisig wallet contract"
    ],
    "Description": [
        "",
        "StargateLbpHelper.participate() is used to perform a cross chain transfer to the host chain and then a swap using the Balancer Liquidity Bootstrapping Pool.",
        "The issue is that the receiver address of the LBP swap on the destination chain is hardcoded to msg.sender (passed in by participate()).",
        "This will be a problem if msg.sender is a multisig wallet contract, as the wallet owners may not have control over the same address as msg.sender on the destination chain, causing the received tokens to be lost (if the recipient is not willing to return the funds).",
        "In the worst case, the tokens could be sent to an undeployed address and an attacker could seize the opportunity to possibly steal the received tokens by taking control of the msg.sender address on destination chain (see Wintermute hack article)."
    ],
    "Recommendations": [
        "",
        "Allow caller to pass in the receiver address for the LBP swap."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-04-use-of-only-higher-price-in-seer-makes-it-vulnerable-to-price-manipulation-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function get(\n        bytes calldata\n    ) external virtual nonReentrant returns (bool success, uint256 rate) {\n        // Checking whether the sequencer is up\n        _sequencerBeatCheck();\n\n        //@audit only the higher price is used, while ignoring the lower (first returned variable)\n        (, uint256 high) = _readAll(inBase);\n        return (true, high);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, price manipulation will cause loss of funds"
    ],
    "Likelihood": [
        " Medium, Uniswap pool can be price-manipulated when TWAP duration is too low or liquidity is not spread over a wide range"
    ],
    "Description": [
        "",
        "Seer.sol uses the Angle Protocol's OracleMulti.sol, which is a combination of Chainlink and Uniswap V3 TWAP oracles. The design of OracleMulti.sol is to return both Chainlink and Uniswap prices, and let the protocol choose the price that is most advantageous. For example, Angle uses the lower price between Chainlink and Uniswap, for a mint transaction using collateral. (see Angle's Oracle Design)",
        "The issue is that Seer.sol only uses the higher price for its price retrieval functions like get(), peek(), peekSpot(). It ignores the lower price and do not return it at all. That means it could use the price that is disadvantageous to the protocol.",
        "This causes contracts that use Seer.sol to be vulnerable to price manipulation attacks.",
        "For example, when retrieving the price of payment token for exercising oTAP options, it is more advantageous to use the lower price. By using a higher price, it allows an attacker to artificially inflate the price of the payment token by manipulating the price for the Uniswap V3 pool. That means the attacker will be able to exercise the option with significantly lower amount of payment tokens."
    ],
    "Recommendations": [
        "",
        "Return both higher and lower values for price functions in Seer.sol and use the appropriate price in the protocol."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-05-incorrect-address-for-toft-debit-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(\n                    address from,\n                    uint16 dstChainId,\n                    bytes32 to,\n                    uint256 amount,\n                    ICommonOFT.LzCallParams memory lzCallParams\n                ) = abi.decode(\n                        _action.call[4:],\n                        (\n                            address,\n                            uint16,\n                            bytes32,\n                            uint256,\n                            (ICommonOFT.LzCallParams)\n                        )\n                    );\n                _checkSender(from);\n\n                ISendFrom(_action.target).sendFrom{value: _action.value}(\n                    msg.sender,\n                    dstChainId,\n                    to,\n                    amount,\n                    lzCallParams\n                );\n",
        "function _checkSender(address _from) internal view {\n        if (_from != msg.sender && !cluster.isWhitelisted(0, msg.sender))\n            revert NotAuthorized();\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, transaction either reverts, or debits from wrong account"
    ],
    "Likelihood": [
        ": Medium, only happens when the caller is a whitelisted relayer"
    ],
    "Description": [
        "",
        "The Magnetar contract handles the operation id TOFT_SEND_FROM to trigger a sending of TOFT tokens cross chain. First the parameters are extracted from the user's call, and then the actual call is done.",
        "As seen from the snippet, there are 2 important addresses: msg.sender and from. from is supposed to be the address from which the tokens are debited. msg.sender is the address which can have special permissions and can act as just the caller of the function. This is further supported by the implementation in the checkSender function.",
        "As we can see, either msg.sender and from are the same person, or msg.sender is a whitelisted address with special permissions.",
        "However when the tokens are deducted in the sendFrom call, the function mistakenly deducts the token from the msg.sender address, instead of the from address. This will be an issue when msg.sender is such a whitelisted relayer, and the wrong account will have tokens debited from it. If this account has no tokens, the transaction will revert and make the whitelisted role useless.",
        "This issue is present in multiple instances:"
    ],
    "Recommendations": [
        "",
        "Deduct tokens from the from account instead of msg.sender, since msg.sender can just be a whitelisted relayer."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-06-incorrect-leveraging-operations-call-in-magnetar-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function buyCollateral(\n        address from,\n        uint256 borrowAmount,\n        uint256 supplyAmount,\n        bytes calldata data\n    ){...}\nfunction sellCollateral(\n        address from,\n        uint256 share,\n        bytes calldata data\n    ){...}\n",
        "IMarket(_action.target).buyCollateral(\n                    from,\n                    borrowAmount,\n                    supplyAmount,\n                    minAmountOut,\n                    swapper,\n                    dexData\n                );\n\nIMarket(_action.target).sellCollateral(\n                    from,\n                    share,\n                    minAmountOut,\n                    swapper,\n                    dexData\n                );\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, broken functionality"
    ],
    "Likelihood": [
        ": High, broken functionality never works"
    ],
    "Description": [
        "",
        "The Magnetar contract has helper functions to interact with the Singularity and BigBang markets which also does multiple compounded operations at the same time for added functionality. One such operation which is supported by the BigBang and Singularity markets is the ability to buy and sell the collateral tokens. This is supported in the BigBang and Singularity markets as shown by the function prototypes below.",
        "The issue is that the Magnetar contracts use the wrong interface from a previous iteration of the protocol which does not work with the current version of the contracts. This evident from the calls seen in the Magnetar contracts.",
        "As we can see from the function calls, the caller passes in 5 values but the function actually expects only 3 values in its function prototype, thus leading to broken functionality.",
        "There are two instances of this issue in MagnetarV2.sol."
    ],
    "Recommendations": [
        "",
        "Change the function calls to conform to the current version of the markets."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-07-underpayingoverpaying-of-stargate-fee-will-occur-in-stargatelbphelperparticipate-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function participate(\n        StargateData calldata stargateData,\n        ParticipateData calldata lbpData\n    ) external payable nonReentrant {\n        IERC20 erc20 = IERC20(stargateData.srcToken);\n\n        // retrieve source token from sender\n        erc20.safeTransferFrom(msg.sender, address(this), stargateData.amount);\n\n        // compute min amount to be received on destination\n        uint256 amountWithSlippage = stargateData.amount -\n            ((stargateData.amount * stargateData.slippage) /\n                SLIPPAGE_PRECISION);\n\n        // approve token for Stargate router\n        erc20.safeApprove(address(router), stargateData.amount);\n\n        // send over to another layer using the Stargate router\n        router.swap{value: msg.value}(\n            stargateData.dstChainId,\n            stargateData.srcPoolId,\n            stargateData.dstPoolId,\n            payable(msg.sender), //refund address\n            stargateData.amount,\n            amountWithSlippage,\n            //@audit the _lzTxParams parameter should not be hardcoded to zero\n            IStargateRouterBase.lzTxObj({\n                dstGasForCall: 0,\n                dstNativeAmount: 0,\n                dstNativeAddr: \"0x0\"\n            }),\n            abi.encodePacked(msg.sender), // StargateLbpHelper.sol destination address\n            abi.encode(lbpData, msg.sender)\n        );\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as it will underpay/overpay Stargate fee"
    ],
    "Likelihood": [
        " High, it will always occur"
    ],
    "Description": [
        "",
        "StargateLbpHelper.participate() uses Stargate router.swap() to send tokens to host chain for LBP swap.",
        "However, the _lzTxParams parameters are hardcoded to zero, which will cause Stargate to undercharge/overcharge for the cross chain swap fee. That will occur as Stargate uses LayerZero for the cross chain messaging, which will compute the underlying LZ fee based on the dstGasForCall. When dstGasForCall == 0, it will charge the fee based on a default value of 200,000 gas for the execution in the destination chain.",
        "That means participate() will overpay for the Stargate fee if it consumes < 200,000 gas for the destination chain. On the other hand, when destination chain gas consumption > 200,000 gas, it will underpay and cause the destination chain execution to fail due to OOG error."
    ],
    "Recommendations": [
        "",
        "Pass in _lzTxParams parameters instead of hardcoding them."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-tickmath-and-fullmath-libraries-are-missing-unchecked-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as it will cause the swap to revert."
    ],
    "Likelihood": [
        " Medium, as it will occur when there is phantom overflow."
    ],
    "Description": [
        "",
        "Both FullMath and TickMath are missing unchecked, which causes it to incorrectly revert on phantom overflow. These libraries are supposed to handle \"phantom overflow\" by allowing multiplication and division even when the intermediate value overflows 256 bits as documented by UniswapV3. In the original UniswapV3 code, unchecked is not used as solidity version is < 0.8.0, which does not revert on overflow.",
        "TickMath will affect UniswapV3Swapper, which uses OracleLibrary that utilizes TickMath. Same issue for FullMath, which will affect Seer."
    ],
    "Recommendations": [
        "",
        "Add in unchecked for both libraries."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-magnetar-exitpositionandremovecollateral-could-fail-when-withdrawing-removed-assetscollateral-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        if (removeAndRepayData.removeCollateralFromBB) {\n            //@audit collateralShare could be rounded down here after toShare() conversion\n            uint256 collateralShare = yieldBox.toShare(\n                bigBang.collateralId(),\n                removeAndRepayData.collateralAmount,\n                false\n            );\n            address removeCollateralTo = removeAndRepayData\n                .collateralWithdrawData\n                .withdraw\n                ? address(this)\n                : user;\n\n            //@audit if collateralShare is rounded down, amount removed will be less than\n            //       user provided removeAndRepayData.collateralAmount\n            bigBang.removeCollateral(user, removeCollateralTo, collateralShare);\n\n            //withdraw\n            if (removeAndRepayData.collateralWithdrawData.withdraw) {\n                bytes memory withdrawCollateralBytes = abi.encode(\n                    removeAndRepayData\n                        .collateralWithdrawData\n                        .withdrawOnOtherChain,\n                    removeAndRepayData.collateralWithdrawData.withdrawLzChainId,\n                    LzLib.addressToBytes32(user),\n                    removeAndRepayData\n                        .collateralWithdrawData\n                        .withdrawAdapterParams\n                );\n                _withdraw(\n                    address(this),\n                    withdrawCollateralBytes,\n                    singularity,\n                    yieldBox,\n                    //@audit when amount from removeCollateral() < removeAndRepayData.collateralAmount\n                    //      _withdraw() will fail as it tries to withdraw more than what was removed above\n                    removeAndRepayData.collateralAmount,\n                    true,\n                    valueAmount,\n                    removeAndRepayData.collateralWithdrawData.unwrap\n                );\n            }\n        }\n        _revertYieldBoxApproval(address(bigBang), yieldBox);\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as this will cause the function to revert\nLikelihood: Medium, as this occurs when user wish to withdraw the underlying collateral from YieldBox"
    ],
    "Description": [
        "",
        "In MagnetarMarketModule._exitPositionAndRemoveCollateral(), the user can set removeAndRepayData.removeCollateralFromBB = true and removeAndRepayData.collateralWithdrawData.withdraw = true to remove collateral shares from BigBang and then use those shares to withdraw the underlying collateral from YieldBox.",
        "The amount of underlying collateral to be removed is indicated by the parameter removeAndRepayData.collateralAmount.",
        "However, the actual collateral amount withdrawn could be lesser than what is provided by the parameter removeAndRepayData.collateralAmount. That is because a yieldBox.toShare() conversion is required due to bigBang.removeCollateral() taking in a collateralShare parameter.",
        "When that occurs, it will cause _withdraw() to fail as the user provided removeAndRepayData.collateralAmount is more than what was removed from BigBang.",
        "The same issue also applies when removeAndRepayData.removeAssetFromSGL = true.\nSimilarly for _depositRepayAndRemoveCollateralFromMarket() as well."
    ],
    "Recommendations": [
        "",
        "The amount to withdraw from YieldBox should be derived from the collateralShare returned by yieldBox.toShare()."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-lack-of-sequencer-uptime-check-for-taporacle-can-cause-stale-prices-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, oracle price will be stale\nLikelihood: Medium, occurs during period of sequencer downtime"
    ],
    "Description": [
        "",
        "TapOracle takes an average of 3 TWAP prices from UniswapV3 pool with an interval of at least 4 hours (based on FETCH_TIME). The 3 TWAP prices are stored in lastPrices[] and updated when get() is called to retrieve TAP price.",
        "The issue is that when the L2 sequencer is down for an extended period, there will be no interaction with the oracle via get(), preventing lastPrices[] from being updated with the latest prices. This will cause TapOracle to return stale prices when the sequencer recovers."
    ],
    "Recommendations": [
        "",
        "Add _sequencerBeatCheck(); in the function get(). This is to provide a grace period when sequencer recovers from downtime for TapOracle to be updated with the latest prices.",
        "It is recommended that FETCH_TIME be at most 1/3 of the grace period, to allow sufficient time for all 3 lastPrices[] to be updated when sequencer recovers."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-uniswapv3swapper-should-not-use-the-same-poolfee-for-all-token-pairs-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    /// @dev Returns the pool for the given token pair and fee. The pool contract may or may not exist.\n    function getPool(\n        address tokenA,\n        address tokenB,\n        uint24 fee\n    ) private view returns (IUniswapV3Pool) {\n        return IUniswapV3Pool(PoolAddress.computeAddress(factory, PoolAddress.getPoolKey(tokenA, tokenB, fee)));\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, swap will fail when pool fee is wrong\nLikelihood: Medium, only occur for swap where pool fee is not 3000 (default value)"
    ],
    "Description": [
        "",
        "UniswapV3Swapper uses the same poolFee for all token pairs.",
        "The issue is that Uniswap V3 pool address is tied to both token addresses and the pool fee as shown in UniswapV3 SwapRouter.getPool() below. This means that the swap may fail if the token pair to swap is not available for the configured poolFee."
    ],
    "Recommendations": [
        "",
        "Allow poolFee to be passed in as a parameter so that the correct pool will be used for the swap."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-uniswapv3swapper-and-uniswapv2swapper-will-fail-when-depositing-received-eth-into-yieldbox-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        amountOut = _swap(\n            tokenOut,\n            params,\n            swapData.yieldBoxData.depositToYb,\n            to\n        );\n\n        if (swapData.yieldBoxData.depositToYb) {\n            if (tokenOut != address(0)) {\n                _safeApprove(tokenOut, address(yieldBox), amountOut);\n            }\n            (, shareOut) = yieldBox.depositAsset(\n                swapData.tokensData.tokenOutId,\n                address(this),\n                to,\n                amountOut,\n                0\n            );\n        }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as it causes swap to fail"
    ],
    "Likelihood": [
        " Medium, as it occurs when depositing WETH to YieldBox"
    ],
    "Description": [
        "",
        "When UniswapV3Swapper.swap() is called with depositToYb = true and tokenOut = address(0) (WETH), it will swap the Input Token for WETH and then unwrap the WETH before depositing ETH into YieldBox.",
        "However, yieldBox.depositAsset() is used to deposit the unwrapped ETH, which is incorrect and will revert as it does not support deposit of native asset.",
        "Same issue also apply for UniswapV2Swapper."
    ],
    "Recommendations": [
        "",
        "Do not unwrap WETH when depositToYb = true, so that WETH is directly deposited into YieldBox without unwrapping and re-wrapping.\nAlternatively, use yieldBox.depositETHAsset() instead when tokenOut is address(0) but this will unwrap and rewrap."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-using-buildswapdata-with-tokenintokenout-will-cause-swap-to-fail-when-depositing-intowithdrawing-from-yieldbox-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as swap() will fail"
    ],
    "Likelihood": [
        " Medium, as it only occurs when using swap with yieldbox deposit."
    ],
    "Description": [
        "",
        "When buildSwapData(address tokenIn, address tokenOut, ...) is used to populate SwapData, both tokenInId and tokenOutId will be set to zero.",
        "However, when using swap() with depositToYb = true, it will deposit to YieldBox based on the tokenOutId. That will fail as tokenOutId is zero.",
        "Same issue for withdrawToYb = true, which will fail as tokenInId will be zero as well."
    ],
    "Recommendations": [
        "",
        "For buildSwapData(address tokenIn, address tokenOut, ...) , set withdrawFromYb and depositToYb to false, and remove these parameters, as it is not supported."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-fetch_time-is-too-large-and-this-can-lead-to-a-stale-price-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint32 public FETCH_TIME = 4 hours;\n",
        "uint32 public FETCH_TIME = 1 hours;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, because it might return an stale price"
    ],
    "Likelihood": [
        ": Low, it can happen in highly volatile markets"
    ],
    "Description": [
        "",
        "The FETCH_TIME value in the TapOracle.sol contract is set to 4 hours, which determines the minimum interval between updates of the oracle price.",
        "But this interval is too large and can lead to an outdated price. In highly volatile markets, price data can become outdated quickly. A 4-hour interval may not be sufficient to capture important market movements, potentially leading to the oracle providing stale or inaccurate data.",
        "Change it to 1 hour exactly as you described it in the NatSpec and in the documentation."
    ],
    "Recommendations": [
        "",
        "Change FETCH_TIME to 1 hour:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-08-missing-implementation-of-the-quotelayerzerofee-in-stargatelbphelpersol-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\u00a0 \u00a0 \u00a0 \u00a0 router.swap{value: msg.value}(\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 stargateData.dstChainId,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 stargateData.srcPoolId,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 stargateData.dstPoolId,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 payable(msg.sender), //refund address\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 stargateData.amount,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 amountWithSlippage,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 IStargateRouterBase.lzTxObj({\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dstGasForCall: 0,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dstNativeAmount: 0,\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 dstNativeAddr: \"0x0\"\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 }),\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 abi.encodePacked(msg.sender), // StargateLbpHelper.sol destination address\n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 abi.encode(lbpData, msg.sender)\n\u00a0 \u00a0 \u00a0 \u00a0 );\n",
        "swap{value:msg.value}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Low, because the user can still use participate() without this implementation."
    ],
    "Likelihood": [
        ": High, because there is no implementation of this function."
    ],
    "Description": [
        "",
        "We use the participate() function when we want to do a cross-chain transfer. The function calls the swap method using Stargate router:",
        "To pay fee we send msg.value:",
        "From Stargate documentation we see that we have to call quoteLayerZero() to calculate the fee.",
        "But such a function is missing. Because of this, we don't know how many fees to send for the transfer to be successful. If we send more than needed it will refund, but if we send less than needed the cross-chain transfer will fail."
    ],
    "Recommendations": [
        "",
        "Implement the quoteLayerZeroFee() function. See the documentation for more information."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-09-_withdrawtochain-will-refund-excess-gas-for-lz-call-to-the-wrong-address-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        // build LZ params\n        bytes memory _adapterParams;\n        ICommonOFT.LzCallParams memory callParams = ICommonOFT.LzCallParams({\n            refundAddress: msg.value == gas ? refundAddress : payable(this),  //@audit this does not handle all cases\n            zroPaymentAddress: address(0),\n            adapterParams: ISendFrom(address(asset)).useCustomAdapterParams()\n                ? adapterParams\n                : _adapterParams\n        });\n",
        "EOA -> MagnetarV2.withdrawToChain()\n\t-> MagnetarMarketModule._withdrawToChain() // delegatecall\n",
        "LZ (dest) -> BaseTOFT._nonblockingLzReceive()\n\t\t-> BaseTOFTMarketDestinationModule.remove() //delegatecall\n\t\t\t-> MagnetarV2.withdrawToChain()\n\t\t\t\t-> MagnetarMarketModule._withdrawToChain() // delegatecall\n",
        "LZ (dest) -> BaseTOFT._nonblockingLzReceive()\n\t\t-> BaseTOFTMarketDestinationModule.borrowInternal() //delegatecall\n\t\t\t-> MagnetarV2.depositAddCollateralAndBorrowFromMarket()\n\t\t\t\t-> MagnetarMarketModule.depositAddCollateralAndBorrowFromMarket() // delegatecall\n\t\t\t\t\t-> MagnetarMarketModule._withdraw()\n\t\t\t\t\t\t-> MagnetarMarketModule._withdrawToChain()\n",
        "\nEOA -> MagnetarV2.burst()\n\t-> MagnetarV2.depositAddCollateralAndBorrowFromMarket()\n\t\t-> MagnetarMarketModule.depositAddCollateralAndBorrowFromMarket() // delegatecall\n\t\t\t-> MagnetarMarketModule._withdraw()\n\t\t\t\t-> MagnetarMarketModule._withdrawToChain()\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " Medium, as refunded gas will be lost"
    ],
    "Likelihood": [
        " Medium, happens for certain cases when performing cross chain withdrawals"
    ],
    "Description": [
        "",
        "As MagnetarMarketModule._withdrawToChain() allows withdrawal to another chain, it requires refundAddress to be specified so that excess gas can be refunded to an address on the source chain. However, refundAddress is incorrectly set as it does not handle all cases.",
        "I have determined 4 different cases of how _withdrawToChain() can be called, and the following shows that cases 2/3/4 are incorrect.",
        "gas == msg.value and refundAddress will be from parameter\nThis is correct, assuming no user error.",
        "gas == msg.value and refundAddress will be payable(to) due to BaseTOFTMarketDestinationModule.sol#L247\nThis is incorrect as refundAddress should a user provided address on the source chain.",
        "gas == msg.value and refundAddress will be payable(this) due to MagnetarMarketModule.sol#L858\nThis is incorrect as refundAddress should be a user provided address on the source chain.",
        "gas == _action.value and refundAddress will be payable(this) due to MagnetarMarketModule.sol#L800\nThis is incorrect as refundAddress should be msg.sender."
    ],
    "Recommendations": [
        "",
        "Allow refundAddress to be passed in as a parameter from the first MagnetarV2 function. As there are multiple cases as mentioned, this makes it easier to determine the correct refundAddress, instead of inferring it via gas or msg.value.",
        "For cross chain calls (case 2 & 3), the refundAddress should actually be a user provided address on the source chain, and not payable(to). That is because when withdrawing to a different chain, payable(to) will be the address on dest chain, which may not be a user controlled address on the source chain (in the case of a multisig wallet)."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-10-taporacle-twap-duration-for-uniswap-oracle-should-be-at-least-30-mins-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    const args: Parameters<Seer__factory['deploy']> = [\n        'TAP/USDC', // Name\n        'TAP/USDC', // Symbol\n        18, // Decimals\n        [\n            ARGS_CONFIG[chainID].TAP_ORACLE.TAP_ADDRESS, // TAP\n            ARGS_CONFIG[chainID].MISC.USDC_ADDRESS, // USDC\n        ],\n        [\n            ARGS_CONFIG[chainID].TAP_ORACLE.TAP_USDC_LP_ADDRESS, /// LP TAP/USDC\n        ],\n        [1], // Multiply/divide Uni\n        600, // @audit Uniswap V3 TWAP duration 600 seconds is lower than typical 30 mins\n        10, // Observation length that each Uni pool should have\n        0, // Whether we need to use the last Chainlink oracle to convert to another\n        // CL path\n        [],\n        [], // Multiply/divide CL\n        86400, // CL period before stale, 1 day\n        [deployer.address], // Owner\n        hre.ethers.utils.formatBytes32String('TAP/USDC'), // Description,\n        ARGS_CONFIG[chainID].MISC.CL_SEQUENCER, // CL Sequencer\n        deployer.address, // Owner\n    ];\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        " High, will cost loss of funds for oTAP options exercise"
    ],
    "Likelihood": [
        " Low, this could occur when liquidity is not spread over a wide range (e.g. during protocol launch)"
    ],
    "Description": [
        "",
        "TapOracle uses a single price feed based on Uniswap V3 TWAP oracle for TAP/USDC pool.",
        "However, the deploy script for TapOracle indicates a TWAP duration of 600 secs (10mins), which is lower than typical 1,800 secs (30mins) that is used by Euler[1] and Uniswap[2] in their studies. This puts TapOracle at a higher risk of price manipulation when liquidity of the TAP/USDC pool is not spread over a wide range. This could occur during protocol launch where the Uniswap pool has limited liquidity.",
        "One may argue that such price manipulation is risky for the attacker, as the attacker has to use their own capital (instead of flash loan) to keep the price manipulated for more than a block, making them vulnerable to arbitrage. But that is not a total deterrence as shown in Rari's Fuse hack[3], where the attacker risked their capital and waited for multiple blocks. The root cause of that hack was due to price manipulation of the Uniswap V3 TWAP oracle, which had a TWAP duration of 600 secs and the Uniswap pool did not have liquidity over a wide range."
    ],
    "References": [
        "",
        "[1] https://docs.euler.finance/euler-protocol/eulers-default-parameters#twap-length",
        "[2] https://blog.uniswap.org/uniswap-v3-oracles",
        "[3] https://cmichel.io/replaying-ethereum-hacks-rari-fuse-vusd-price-manipulation/"
    ],
    "Recommendations": [
        "",
        "Set the TapOracle Uniswap V3 Oracle TWAP duration to be at least 30 mins. Note that it is also important to ensure the TAP/USDC pool liquidity is spread over a wide range to increase the attack cost."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-11-missing-gas-forwarding-in-cross-chain-call-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (_action.id == TOFT_REMOVE_AND_REPAY) {\n                HelperTOFTRemoveAndRepayAsset memory data = abi.decode(\n                    _action.call[4:],\n                    (HelperTOFTRemoveAndRepayAsset)\n                );\n\n                _checkSender(data.from);\n                IUSDOBase(_action.target).removeAsset(\n                    data.from,\n                    data.to,\n                    data.lzDstChainId,\n                    data.zroPaymentAddress,\n                    data.adapterParams,\n                    data.externalData,\n                    data.removeAndRepayData,\n                    data.approvals,\n                    data.revokes\n                );\n",
        "bytes memory lzPayload = abi.encode(\n            PT_MARKET_REMOVE_ASSET,\n            to,\n            externalData,\n            removeAndRepayData,\n            approvals,\n            revokes,\n            airdropAmount\n        );\n\n        _checkAdapterParams(\n            lzDstChainId,\n            PT_MARKET_REMOVE_ASSET,\n            adapterParams,\n            NO_EXTRA_GAS\n        );\n\n        _lzSend(\n            lzDstChainId,\n            lzPayload,\n            payable(from),\n            zroPaymentAddress,\n            adapterParams,\n            msg.value\n        );\n",
        " IUSDOBase(_action.target).removeAsset{value: _action.value}(...)\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, broken functionality of an important function"
    ],
    "Likelihood": [
        ": Medium, TOFT_REMOVE_AND_REPAY operation always reverts when called"
    ],
    "Description": [
        "",
        "The operation TOFT_REMOVE_AND_REPAY is used to exit a position and then remove collateral from a market. The issue is that the function being called sends out a LayerZero call, but no gas is forwarded to it.",
        "The function call can be found in MagnetarV2.sol contract under the action id TOFT_REMOVE_AND_REPAY as shown below.",
        "Since no gas is forwarded to the external call, the external call will have msg.value of 0. However if we check the removeAsset function in BaseUSDO.sol, we see a subsequent layerzero call via the USDOMarketModule.",
        "The issue here is that msg.value is 0, hence no gas will be sent to the layerzero endpoint, failing the cross-chain call."
    ],
    "Recommendations": [
        "",
        "Modify the call in magnetar to forward the gas."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-12-not-maximizing-glp-in-glporacle-miscalculates-_minglp-when-adding-liquidity-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " function _get() internal view returns (uint256) {\n        return glpManager.getPrice(false);\n    }\n",
        " (success, glpPrice) = wethGlpOracle.get(wethGlpOracleData);\n            if (!success) revert Failed();\n            uint256 amountInGlp = (wethAmount * glpPrice) / 1e18;\n            amountInGlp = amountInGlp - (amountInGlp * _slippage) / 10_000;\n",
        " function _get() internal view returns (uint256) {\n-       return glpManager.getPrice(false);\n+       return glpManager.getPrice(true);\n    }\n"
    ],
    "Severity": [
        "",
        "Impact: Medium. The rounding will be incorrect affecting the price.",
        "Likelihood: High. False is hardcoded so it is very likely it will happen."
    ],
    "Description": [
        "",
        "Currently, in the GlpOracle contract, there is a function that fetches Glp price from the Glp Manager:",
        "The price maximation is set to false glpManager.getPrice(false); . This price is then fetched from the GlpStrategy in the Yieldbox module. In this case, the price has a part on the amountOut or the _minGlp that we expect when adding liquidity to GMX.",
        "Given that the price maximation is set to false, it will return a slightly smaller price, which will set the slippage as lower than if it were set with maximize = true.",
        "This will allow the GlpManager to mint less Glp to the user without reverting as _minGlp with maximize set to false:",
        "require(mintAmount >= _minGlp, \"GlpManager: insufficient GLP output\");"
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/m-13-any-tokens-or-eth-in-magnetar-can-be-drained-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdrawToChain(\n        IYieldBoxBase yieldBox,\n        address from,\n        uint256 assetId,\n        uint16 dstChainId,\n        bytes32 receiver,\n        uint256 amount,\n        bytes memory adapterParams,\n        address payable refundAddress,\n        uint256 gas,\n        bool unwrap\n    )\n",
        "(, address asset, , ) = yieldBox.assets(assetId);\n",
        "if (unwrap) {\n            ICommonData.IApproval[]\n                memory approvals = new ICommonData.IApproval[](0);\n            ITapiocaOFT(address(asset)).triggerSendFromWithParams{value: gas}(\n                address(this),\n                dstChainId,\n                receiver,\n                amount,\n                callParams,\n                true,\n                approvals,\n                approvals\n            );\n",
        "IYieldBoxBase yieldBox = IYieldBoxBase(market.yieldBox());\n\n        uint256 collateralId = market.collateralId();\n        (, address collateralAddress, , ) = yieldBox.assets(collateralId);\n",
        "if (deposit) {\n            // transfers tokens from sender or from the user to this contract\n            collateralAmount = _extractTokens(\n                extractFromSender ? msg.sender : user,\n                collateralAddress,\n                collateralAmount\n);\nIERC20(collateralAddress).approve(address(yieldBox), 0);\n            IERC20(collateralAddress).approve(\n                address(yieldBox),\n                collateralAmount\n            );\n",
        "if (externalContracts.bigBang != address(0)) {\n            //@audit cluster check useless since passed in by the user\n            if (\n                !_cluster.isWhitelisted(\n                    _cluster.lzChainId(),\n                    externalContracts.bigBang\n                )\n            ) revert NotAuthorized();\n        }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": High, funds can be stolen, approvals can be given out to random addresses"
    ],
    "Likelihood": [
        ": Low, Magnetar is not designed to hold user funds"
    ],
    "Description": [
        "",
        "The Magnetar contract issues approvals to certain contracts such as the YieldBox contract and the Singularity and BigBang market contracts to do token transfers. The issue is that it takes all these addresses as user inputs. Thus a malicious user can exploit this to give approvals to malicious contracts which can then drain any tokens present in the Magnetar contract.",
        "While the Magnetar contract itself is not designed to hold any user funds, it does have a recovery function for ETH, and might hold some eth for gas for LZ calls. These funds can also be stolen.",
        "As an example, lets look at the withdrawToChain function in MagnetarMarketModule.sol contract.",
        "The address for yieldBox is taken as an input from the user and never verified. Then in the _withdrawToChain function, this address is interacted with. Lets assume dstChainId passed is non-zero. Then, the contract calls this malicious yieldbox contract to get another address, asset.",
        "This asset address is also malicious user input. Then, if unwrap is set to true, the function calls this asset address with some eth, the amount of which is dictated by gas, another user input.",
        "Since asset is also a malicious address, it can just receive this free eth from the contract and finish this contract call. Thus the attacker has gained free eth from the contract.",
        "Similarly, any other ERC20 tokens can also be drained for example in the _depositAddCollateralAndBorrowFromMarket function, where the contract does calls to the market value passed in by the user as input.",
        "The malicious market contract can return more malicious addresses, and then extractTokens is called to do token transfers which the attacker can use to take out any stored tokens in Magnetar. Approvals are also given to yieldbox which can be a malicious address.",
        "So using a variety of functions, any funds left in Magnetar can be drained."
    ],
    "Recommendations": [
        "",
        "If no funds at all are to be stored in Magnetar, this can be safely ignored. Otherwise, the addresses for yieldbox and markets need to be checked against a whitelist of contracts. Such a pattern already exists using the cluster variable in the _mintFromBBAndLendOnSGL function."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-14-magnetar-_depositrepayandremovecollateralfrommarket-can-fail-due-to-rounding-errors-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (collateralAmount > 0) {\n            address collateralWithdrawReceiver = withdrawCollateralParams\n                .withdraw\n                ? address(this)\n                : user;\n            uint256 collateralShare = yieldBox.toShare(\n                marketInterface.collateralId(),\n                collateralAmount,\n                false\n            );\n            marketInterface.removeCollateral(\n                user,\n                collateralWithdrawReceiver,\n                collateralShare\n            );\n\n            //withdraw\n            if (withdrawCollateralParams.withdraw) {\n                _withdrawToChain(\n                    yieldBox,\n                    collateralWithdrawReceiver,\n                    marketInterface.collateralId(),\n                    withdrawCollateralParams.withdrawLzChainId,\n                    LzLib.addressToBytes32(user),\n                    collateralAmount,\n                    withdrawCollateralParams.withdrawAdapterParams,\n                    valueAmount > 0 ? payable(msg.sender) : payable(this),\n                    valueAmount,\n                    withdrawCollateralParams.unwrap\n                );\n            }\n        }\n",
        "yieldBox.withdraw(\n                assetId,\n                from,\n                LzLib.bytes32ToAddress(receiver),\n                amount,\n                0\n            );\n",
        "uint256 collateralShare = yieldBox.toShare(\n                marketInterface.collateralId(),\n                collateralAmount,\n                true\n            );\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        ": Medium, can cause function to revert"
    ],
    "Likelihood": [
        ": Medium, happens when user tries to remove collateral and withdraw from yieldbox"
    ],
    "Description": [
        "",
        "If collateralAmount is set to be more than 0 while calling the _depositRepayAndRemoveCollateralFromMarket function, the following snippet is executed.",
        "In the first bit, collateralShare is calculated from the yieldBox rebase calculations. since the last parameter is false, the answer is rounded down. Lets assume collateralAmount is set to 100, and the collateralShare calculated is between 49 and 50, and is set as 49 due to the rounding down.",
        "Later in the _withdrawToChain call, the contract tries to withdraw the full collateralAmount amount of tokens. Here the yieldBox is called again to take those tokens out of it.",
        "But in this call, due to it being a withdraw, the amount of shares to be deducted is rounded up. So now for withdrawing the same 100 units of collateralAmount, the amount of shares to be burnt is calculated as 50 due to the rounding up. Since the contract has withdrawn only 49 shares but the yieldBox is trying to burn 50, this function will revert.",
        "This is similar to the M-02 report showing a similar rounding error forcing a revert but in a different scenario."
    ],
    "Recommendations": [
        "",
        "Calculate collateralShare by rounding it up. This will ensure enough shares are present to burn during withdrawal."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-15-using-only-dex-swappers-is-suboptimal-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        "",
        "Impact: Medium, swaps without aggregator might have a high price impact for large amounts.",
        "Likelihood: Medium. Depending on how much amount it is being swapped this can be a frequent problem."
    ],
    "Description": [
        "",
        "Currently, most of the actions that need tokens to be swapped across Tapioca's codebases use the swappers, which currently, they are 3.",
        "Each swapper uses a different DEX, UniV2, Univ3 and Curve DeFi pools. This is not the ideal scenario for most cases as when you are swapping you are trying to maximize the amountOut that you get in exchange for the tokens you swapped. To accomplish this and get better rates for your swaps, at least one aggregator should be added to the list of swappers."
    ],
    "Recommendations": [
        "",
        "Add at least one aggregator to the list of swappers. 1inch is my preferred one, but you could also go with 0x."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-16-incorrect-order-when-calculating-the-transferred-amount-to-stargate-makes-the-participate-function-unusable-pashov-none-tapiocadao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 transferred = balanceAfter - balanceBefore;\n",
        "uint256 balanceAfter = IERC20(stargateData.srcToken).balanceOf(\n            address(this)\n        );\n+        uint256 transferred = balanceBefore  - balanceAfter;\n-        uint256 transferred = balanceAfter - balanceBefore;\n"
    ],
    "Severity": [
        "",
        "Impact: Medium, as the functionality will always revert",
        "Likelihood: Medium, as it only occurs when calling participate"
    ],
    "Description": [
        "",
        "The participate() function in Stargate helper contract will not work.",
        "The cause of this, is the way on how you Tapioca is calculating the amount transferred to Stargate to refund the dust amounts that Stargate returns:",
        "Let's put an example without decimals for simplicity.",
        "therefore the calculation will always revert."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-protocol-assets-can-be-stolen-through-sandwich-attacks-pashov-none-nftcapsule-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 expectedAmount = curvePoolWETHCRV.get_dy(2, 1, crvBal); // Estimate WETH received for CRV:WETH exchange\n// Exchange CRV for WETH within the slippage limit\ncurvePoolWETHCRV.exchange(2, 1, crvBal, expectedAmount * LPslippageNum / LPslippageDen);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as protocol assets will be lost"
    ],
    "Likelihood": [
        "\nHigh, as sandwich attacks are very common and easy to execute"
    ],
    "Description": [
        "",
        "The Capsule contract is currently vulnerable to sandwich attack in many places. Every place which does a swap or provides/removes liquidity is done in a manner that is vulnerable. While the code has slippage checks, they are flawed. Take for example the tradeCRVtoWETH method, here is how a swap is done:",
        "The problem is that if an attacker sees you calling tradeCRVtoWETH he can imbalance the pool with a very big front-run transaction, which will give you a much smaller expectedAmount, and then after you do the swap he will execute a back-run transaction putting the price back to normal, essentially sandwiching your bad trade and profiting your loss. This is a problem in all methods that have an underlying call to add_liquidity, remove_liquidity_one_coin, calc_withdraw_one_coin and calc_token_amount."
    ],
    "Recommendations": [
        "",
        "Instead of doing on-chain same transaction calculations to calculate slippage tolerance, add an argument to all methods that use slippage calculations called \"minAmountReceived\" - it has to be calculated off-chain so it is not prone to on-chain manipulation."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-incorrect-ipethnftvaultborrow-assumption-breaks-the-protocol-pashov-none-nftcapsule-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as the protocol will have to be redeployed"
    ],
    "Likelihood": [
        "\nHigh, as it it certain to happen"
    ],
    "Description": [
        "",
        "The depositNft method in Capsule calls IPETHNFTVault::borrow with a _borrowAmount argument. Later, the code actually tries using the _borrowAmount value as the amount of PETH to provide as liquidity to a Curve pool. The problem is that the borrow method of those vaults always takes a fee, so Capsule will have received less than _borrowAmount of PETH. Quoted from IPETHNFTVault::borrow's NatSpec:",
        "This means that the liquidity provision will always fail due to insufficient PETH balance, making the protocol unusable.",
        "Even if the fee value is currently zero it can be changed and the protocol will be broken."
    ],
    "Recommendations": [
        "",
        "Use only the PETH received from borrowing for providing liquidity as well as for the newPosition.amountBorrowed value in depositNft. The issue is also present in increaseBorrowAmount and should be addressed there as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-user-supplying-a-fake-vault-can-steal-protocol-assets-as-a-grief-attack-pashov-none-nftcapsule-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "PETH.approve(address(_vault), tokensWithdrawn); // Approve JPEGD to take PETH\n_vault.repay(_id, tokensWithdrawn); // Repay desired amount of loan based on desired repayment size\nePosition.lpSize -= LPcostToRepay; // No need to adjust profit index here, previous check requires they either withdraw or forfeit profits beforehande the users amount borrowed\nePosition.amountBorrowed -= tokensWithdrawn; // Decrease the users amount borrowed\nemit DecreaseBorrowAmount(owner, _nft, _id, tokensWithdrawn);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as a malicious actor can drain protocol assets"
    ],
    "Likelihood": [
        "\nLow, as it is a common attack vector and it requires no preconditions"
    ],
    "Description": [
        "",
        "The _vault argument in the repay method (and in all others) has no input validation, meaning a user can supply a fake vault which he himself created. By calling repay with a fake _vault argument for an NFT borrowing position he owns, when amountBorrowed > repayment he will go through this code:",
        "this would send the protocol's PETH to the user's fake vault, which would be a steal of protocol assets, even though his NFT wouldn't be withdrawable anymore."
    ],
    "Recommendations": [
        "",
        "Use a whitelisting approach to the _vault argument in all methods of the contract so that users can't provide fake vaults to them."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-emergencywithdraw-method-can-leave-pirexeth-in-a-broken-state-pashov-none-pirex-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as the logic in PirexEth will be broken"
    ],
    "Likelihood": [
        "\nLow, as it requires an emergency and using the contract after it"
    ],
    "Description": [
        "",
        "The emergencyWithdraw method in PirexEth allows for withdrawal of ETH. This ETH could have been the pendingDeposit balance, which is not yet deposited to the ETH 2.0 deposit contract, and if it is withdrawn from the emergencyWithdraw method then the contract will be in a broken state. The pendingDeposit variable will have a value that is more than the ETH balance in the contract which will make deposit transactions revert if they are used post emergencyWithdraw call."
    ],
    "Recommendations": [
        "",
        "Change the emergencyWithdraw method so that it can withdraw only excessive balance without the pendingDeposit one, or when using pendingDeposit force it to withdraw the whole balance and zero out the state variable."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-protocol-will-not-be-compatible-with-commonly-used-erc20-tokens-pashov-none-pump-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (order.isBuy) {\n    ERC20(order.baseToken).transferFrom(order.maker, msg.sender, baseTokenAmount - fee);\n    ERC20(order.baseToken).transferFrom(order.maker, owner(), fee);\n    Token(order.assetToken).transferFrom(msg.sender, order.recipient, amount);\n} else {\n    ERC20(order.baseToken).transferFrom(msg.sender, order.recipient, baseTokenAmount - fee);\n    ERC20(order.baseToken).transferFrom(msg.sender, owner(), fee);\n    Token(order.assetToken).transferFrom(order.maker, msg.sender, amount);\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as it most probably won't result in value loss but it limits the protocol usability"
    ],
    "Likelihood": [
        "\nMedium, as it will not work with some commonly used tokens, but will work with others"
    ],
    "Description": [
        "",
        "Here is a code snippet from PumpV1::fulfill:",
        "The code is calling the transferFrom method of the ERC20 implementation (ERC20 imported from the solady dependency), which expects a bool return value. Tokens like USDT, BNB and others are missing a return value on transfer and transferFrom, which would break integration with the application. There are also tokens that do not revert on failure in transfer but return a false boolean value like EURS. You can read more about such tokens here.",
        "Another issue is that the math to compute baseTokenAmount and fee in the fulfill method of PumpV1 rely on the baseToken decimals to be exactly 18, since the code is using wad-based math when calculating baseTokenAmount and fee. Many commonly used tokens have lower than 18 decimals (USDC and USDT have 6 decimals) and some tokens have more than 18 decimals (YAM-V2 has 24 decimals). While lower decimal tokens transactions can at most revert, the high decimal token transactions can possibly lead to more tokens spent from a user than what he intended."
    ],
    "Recommendations": [
        "",
        "Use OpenZeppelin's SafeERC20 library and its safeTransferFrom method to handle such tokens. Also scale all token amounts to 18 decimals or forbid using non-18 decimals tokens in the application with an explicit check in fulfill."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-fee-can-be-set-to-100-before-order-fulfillment-pashov-none-pump-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can mean the order recipient will receive nothing in exchange for his tokens"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or compromised admin"
    ],
    "Description": [
        "",
        "The setFeeRate method in PumpV1 currently has no input validation on the _feeRate parameter. If the value given is 1e18 this would set the fee to 100%. An admin can see a call to fulfill by monitoring the blockchain's pending transaction pool and front-run it by setting the fee to 100%, essentially stealing all of the tokens that the order recipient should have gotten."
    ],
    "Recommendations": [
        "",
        "Limit the fee rate to have a maximum value, for example 3%."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-dos-attack-on-initialization-is-possible-pashov-none-tokendistributor-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(token.balanceOf(address(this)) == _totalTokensToDistribute, \"totalTokensToDistribute must match token balance of contract\");\n",
        "- require(\n-    token.balanceOf(address(this)) == _totalTokensToDistribute,\n-    \"totalTokensToDistribute must match token balance of contract\"\n- );\n+ token.safeTransferFrom(msg.sender, address(this), _totalTokensToDistribute);\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as the initialization can be blocked"
    ],
    "Likelihood": [
        "\nLow, as it a front-running type of an attack with no benefit for the attacker"
    ],
    "Description": [
        "",
        "The initializeDistributor method in TokenDistributor has the following check:",
        "This gives the expectation that the owner will pre-transfer let's say 10 tokens to the contract and then set the _totalTokensToDistribute argument to 10 when calling initializeDistributor. The problem with this is that if a malicious user front-runs the owner call with a transfer of 1 wei worth of token to the contract, the check and the transaction will revert as the balance will not be equal anymore."
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:",
        "and do not pre-transfer tokens to the contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-centralization-attack-vector-is-present-in-setenabledstate-pashov-none-wrappedelon-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as an owner can block unwrapping of wrapped assets"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or a compromised owner"
    ],
    "Description": [
        "",
        "The setEnabledState method of WrappedElon allows the owner of the contract to disable (or enable) wrapping and unwrapping of tokens. The issue is that a malicious or a compromised owner can decide to act in a bad way towards users and block unwrapping of the tokens, essentially locking them out of their funds. If the ownership is burned then (or private keys are lost) it will be irreversible."
    ],
    "Recommendations": [
        "",
        "Potential mitigations here are to use governance or a multi-sig as the contract owner. Even better is to use a Timelock contract that allows users to be notified prior to enabling/disabling wrapping/unwrapping so that they can take action, although this removes the benefit of using the method as a risk mitigation for bridge attacks."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-createvestingschedule-can-be-front-ran-by-another-holder-of-role_create_schedule-role-pashov-none-yhairvesting-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as vesting token balance can be stolen"
    ],
    "Likelihood": [
        "\nMedium, as it requires front-running"
    ],
    "Description": [
        "",
        "The createVestingSchedule method of TokenVestingV2 expects to have a pre-transferred balance before initializing a vesting schedule. The problem with the current contract version is that multiple accounts can hold the ROLE_CREATE_SCHEDULE role. Since two transactions are expected to create a vesting schedule (transferring funds to the TokenVestingV2 contract and then calling createVestingSchedule) this means that between them another holder of the role can come in and create a vesting schedule of his own (with himself as beneficiary for example, non-revokable with just 7 days of duration) and in this way steal the funds of the other role holder."
    ],
    "Recommendations": [
        "",
        "Either change createVestingSchedule to itself transfer the vesting schedule tokens from the caller to the contract or make it callable by just 1 address"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-minting-and-burning-of-beamtoken-is-centralized-pashov-none-beam-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as token supply can be endlessly inflated and user tokens can be burned on demand"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or compromised admin/minter/burner"
    ],
    "Description": [
        "",
        "Currently the mint and burn methods in BeamToken are controlled by MINTER_ROLE and BURNER_ROLE respectively. Those roles are controlled by the DEFAULT_ADMIN_ROLE which is given to the BeamToken deployer. This means that if the admin or minter or burner account is malicious or compromised it can decide to endlessly inflate the token supply or to burn any user's token balance, which would lead to a loss of funds for users."
    ],
    "Recommendations": [
        "",
        "Give those roles only to contracts that have a Timelock mechanism so that users have enough time to exit their BeamToken positions if they decide that they don't agree with a transaction of the admin/minter/burner."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-burned-tokens-can-be-re-minted-into-the-totalsupply-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nLow, as it won't lead to funds loss but breaks a protocol invariant/assumption"
    ],
    "Likelihood": [
        "\nHigh, as it becomes a problem whenever someone burns their tokens"
    ],
    "Description": [
        "",
        "The FlorenceFinanceMediciToken contract inherits from ERC20CappedUpgradeable and has a max supply limit of \"1_000_000_000 * 10 ** 18\" token units. The issue is that the contract also inherits from the ERC20BurnableUpgradeable contract, which means that when a user calls the burn method, the totalSupply will be subtracted from, meaning if 10 tokens existed and are all burned, but then 10 new tokens are minted, now totalSupply = 10 which is not the assumption that the protocol has, which is that the total supply of minted tokens can be maximum \"1_000_000_000 * 10 ** 18\"."
    ],
    "Recommendations": [
        "",
        "Remove the inheritance from ERC20BurnableUpgradeable in FlorenceFinanceMediciToken so that burning tokens with subtracting from totalSupply is not possible."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-last-nft-from-the-supply-cant-be-minted-pashov-none-museumofmahomes-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (nextId + amount >= MAX_SUPPLY) revert ExceedsMaxSupply();\n",
        "    function testNotAllNFTsCanBeMinted() public {\n        museum.setPrice(PRICE);\n        uint256 allButOneNFTSupply = 3089;\n\n        // mint all but one from the NFT `MAX_SUPPLY` (3090)\n        museum.mint{value: allButOneNFTSupply * PRICE}(address(this), allButOneNFTSupply);\n        require(allButOneNFTSupply == museum.balanceOf(address(this)), \"Mint did not work\");\n\n        // try to mint the last NFT from the supply, but it doesn't work\n        vm.expectRevert(MuseumOfMahomes.ExceedsMaxSupply.selector);\n        museum.mint{value: PRICE}(address(this), 1);\n    }\n",
        "- if (nextId + amount >= MAX_SUPPLY) revert ExceedsMaxSupply();\n+ if (nextId + amount > MAX_SUPPLY) revert ExceedsMaxSupply();\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as only one NFT won't be available for minting, but this is value loss to the protocol"
    ],
    "Likelihood": [
        "\nHigh, as it's impossible to mint the last NFT"
    ],
    "Description": [
        "",
        "Currently both the mint and mintPhysical methods have the following check:",
        "This is incorrect, as even when the nextId is MAX_SUPPLY - 1 then an amount of 1 should be allowed but with the current check the code will revert. This is due to the equal sign in the check, which shouldn't be there. Here is a Proof of Concept unit test demonstrating the issue (add it to MuseumOfMahomes.t.sol):"
    ],
    "Recommendations": [
        "",
        "Do the following change in both mint and mintPhysical:"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-collateral-double-spend-post-liquidation-is-possible-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function test_LiquidateExploit() public {\n    // because of the `setUp` method, at this point Bob has taken a loan from Alice through Lumin\n    uint256 bobDeposit = wrappedAssetManager.depositOf(assetId[1], bob).depositAmount;\n\n    // make loan expire\n    vm.warp(block.timestamp + 300 days + 1);\n    // random user liquidates Bob's loan, so collateral (asset[1]) should be transferred to the lender\n    vm.prank(0x1111111111111111111111111111111111111111);\n    wrappedLoanManagerDelegator.liquidate(1);\n\n    // Bob can withdraw his whole deposit even though part of it was used as collateral and was liquidated\n    uint256 bobCollateralWalletBalance = mockERC20Token[1].balanceOf(bob);\n    vm.prank(bob);\n    wrappedAssetManager.assetDepositWithdraw(assetId[1], IAssetManager.AssetActionType.Withdraw, bobDeposit);\n\n    assertEq(mockERC20Token[1].balanceOf(bob) - bobCollateralWalletBalance, bobDeposit);\n}\n",
        "else if (action == AssetActionType.Seize) {\n        userDepositFrom.lockedAmount -= amount;\n+       userDepositFrom.depositAmount -= amount;\n        userDepositTo.depositAmount += amount;\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as a borrower can double-spend his collateral"
    ],
    "Likelihood": [
        "\nHigh, as liquidations never subtract the collateral amount"
    ],
    "Description": [
        "",
        "In AssetManager::assetTransferOnLoanAction in the if (action == AssetActionType.Seize) statement, the transferred amount is only subtracted from userDepositFrom.lockedAmount, but it should have also been subtracted from userDepositFrom.depositAmount as well. This means that a borrower's collateral balance won't be decreased on liquidation, even though the loan shareholders will receive most of the collateral.",
        "Here is an executable Proof of Concept unit test that demonstrates the vulnerability (you can add this in the end of your LoanManager.Repay test file):"
    ],
    "Recommendations": [
        "",
        "Change the code in assetTransferOnLoanAction in the following way:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-disabled-lenders-loan-configuration-can-be-used-by-a-borrower-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function test_DisabledLoanConfigCanStillBeUsed() public {\n    // Alice disables her loan config\n    vm.prank(alice);\n    wrappedLoanManagerDelegator.updateLoanConfigEnabledStatus(loan.configId, false);\n    vm.startPrank(bob);\n\n    // there are no current loans\n    assertEq(0, wrappedLoanManagerDelegator.getLoanCounter());\n\n    vm.expectEmit();\n    emit LoanCreated(1, 1);\n    wrappedLoanManagerDelegator.createLoan(loan, collateralAssets);\n\n    // a loan was created\n    assertEq(1, wrappedLoanManagerDelegator.getLoanCounter());\n\n    // Alice's free deposit was lowered\n    IAssetManager.DepositData memory aliceDepositAfterLending = wrappedAssetManager.depositOf(assetId[0], alice);\n    assertEq(aliceDepositAfterLending.depositAmount, userDepositAlice[0] - loan.principalAmount);\n    assertEq(aliceDepositAfterLending.lockedAmount, 0);\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as a borrower can use a disabled loan configuration but it will still work as a normal loan, so no lender value loss"
    ],
    "Likelihood": [
        "\nHigh, as the disabling functionality can never work with the current code"
    ],
    "Description": [
        "",
        "In the LoanConfig struct we have the enabled field, which is set to true for newly created loan config and can be set to true/false in LoanConfigManager::updateLoanConfigEnabledStatus. The problem is that in LoanManager::createLoan, when a borrower takes in a loan from a lender, a configId is given as an argument and then the corresponding LoanConfig struct object is used in the method, but the enabled property is never checked. This means that even when a lender has called LoanConfigManager::updateLoanConfigEnabledStatus with enabled == false for a loan configuration they created, the configuration can still be used by borrowers.",
        "Here is an executable Proof of Concept unit test that demonstrates the vulnerability (you can add this in the end of your LoanManager test file):"
    ],
    "Recommendations": [
        "",
        "Check if a loan config is enabled in LoanManager::createLoan and revert the transaction if it is not."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-asset-loan-config-can-never-be-removed-from-its-enumerableset-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function deleteLoanConfig(uint256 configId) external {\n    LoanConfig storage config = loanConfigs[configId];\n    if (config.lender != msg.sender) {\n        revert NotAuthorized();\n    }\n\n    if (config.totalPendingPrincipalAmount > 0) {\n        revert LoanConfigInUse();\n    }\n\n    delete (loanConfigs[configId]);\n    userConfigIds[msg.sender][config.config.principalAssetId].remove(configId);\n\n    emit LoanConfigDeleted(configId);\n}\n",
        "if (userConfigIds[msg.sender][config.principalAssetId].length() >= limits.maxLoanConfigsPerAsset) {\n    revert MaxConfigsReached();\n}\n",
        "function test_AssetLoanConfigIsNotRemovedFromEnumerableSet() public {\n    uint256 amount = 100_000;\n\n    vm.startPrank(alice);\n    mockERC20Token[0].approve(address(assetManagerProxy), amount);\n    wrappedAssetManager.assetDepositWithdraw(\n        loanConfigUser.principalAssetId, IAssetManager.AssetActionType.Deposit, amount\n    );\n\n    // Create 10 (the maximum total allowed for a single asset) loan configs for the same asset\n    for (uint256 i = 0; i < 10; i++) {\n        wrappedLoanManagerDelegator.createLoanConfig(loanConfigUser, loanConfigAssetUsage);\n    }\n\n    // Remove one of the loan configs\n    wrappedLoanManagerDelegator.deleteLoanConfig(1);\n\n    // Try to create another loan config for the same asset, but\n    // it reverts since the count (length of the EnumerableSet) wasn't decremented\n    vm.expectRevert(abi.encodeWithSelector(ILoanConfigManager.MaxConfigsReached.selector));\n    wrappedLoanManagerDelegator.createLoanConfig(loanConfigUser, loanConfigAssetUsage);\n}\n",
        "function deleteLoanConfig(uint256 configId) external {\n    LoanConfig storage config = loanConfigs[configId];\n    if (config.lender != msg.sender) {\n        revert NotAuthorized();\n    }\n\n    if (config.totalPendingPrincipalAmount > 0) {\n        revert LoanConfigInUse();\n    }\n\n-    delete (loanConfigs[configId]);\n-    userConfigIds[msg.sender][config.config.principalAssetId].remove(configId);\n+    userConfigIds[msg.sender][config.config.principalAssetId].remove(configId);\n+    delete (loanConfigs[configId]);\n\n    emit LoanConfigDeleted(configId);\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as a user will be limited in his platform usage but won't lose value"
    ],
    "Likelihood": [
        "\nMedium, as it happens when a user has created the max total loan configs for an asset"
    ],
    "Description": [
        "",
        "The LoanConfigManager contract uses the userConfigIds mapping to keep track of the count of loan configurations a user created for an asset and limit them up until maxLoanConfigsPerAsset (which is set to 10 in the LuminDeploy deployment script). The problem is with the deleteLoanConfig method, which looks like this:",
        "The issue here is quite subtle - on the line using userConfigIds, where the config storage pointer is used, the value in the storage cells it points to is already zeroed-out because of the previous delete command, which deletes the storage slots to which the config pointer points to. This means that no actual removal will be executed, since config.config.principalAssetId will be 0 and the EnumerableSet::remove method does not revert when item to remove is not in the set. This means that the set in userConfigIds can only grow, but since it is limited to 10 items at a certain point the user will hit this check in createLoanConfig:",
        "This means that the user won't be able to add more loan configurations for a given asset any more, no matter what he does.",
        "Here is an executable Proof of Concept unit test that demonstrates the vulnerability (you can add this in the end of your LoanConfigManager test file):"
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:",
        "And also, as a best practice, always check the remove method's return value and revert if equals false."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-instant-liquidations-can-happen-after-unpausing-the-protocol-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as users can be instantly liquidated and lose value"
    ],
    "Likelihood": [
        "\nLow, as it requires a long pause from the protocol admin"
    ],
    "Description": [
        "",
        "The LoanManagerDelegator contract through which all protocol interactions happen is pausable by the Lumin admin. In the case that the protocol is paused for a long time, borrowers' collateral assets can fall in price and their loans might become liquidateable without a way for them to repay them or to add collateral, or even their loan term can pass. This means when the protocol is unpaused the loan can get instantly liquidated resulting in a loss for the borrower."
    ],
    "Recommendations": [
        "",
        "Add a post-unpause grace period for liquidations to give time for users to repay their loans or add collateral."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-price-feed-oracle-data-validation-is-missing-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "- if (intPrice < 0) {\n+ if (intPrice <= 0) {\n    revert ImplausiblePrice();\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can possibly result in unfair liquidations"
    ],
    "Likelihood": [
        "\nLow, as it only happens in specific rare conditions"
    ],
    "Description": [
        "",
        "There are multiple problems when validating the price feed data in PriceFeedProxyChainlink:",
        "Using an incorrect price can be detrimental for the protocol as it can lead to unfair loans/liquidations."
    ],
    "Recommendations": [
        "",
        "For the sequencer GRACE_PERIOD make sure to follow the Chainlink docs. Also iplement the following change:",
        "Finally, check the timestamp value of the latestRoundData call and make sure it hasn't been longer than the heartbeat interval for the price feed (plus 10-30 minutes buffer period)."
    ],
    "Discussion": [
        ""
    ],
    "pashov": [
        " Partially fixed, excluding the price staleness check."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-lumin-admin-can-exploit-user-allowances-to-the-protocol-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as users can get their allowance stolen"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or compromised owner"
    ],
    "Description": [
        "",
        "The AssetManager contract is used by users to deposit assets into the platform by giving allowance to the contract to execute an ERC20::transferFrom call. The problem is that the contract is upgradeable, meaning the Lumin admin can back-run a user approval to the AssetManager with an upgrade that adds functionality to execute a transferFrom from the user to his address through the contract."
    ],
    "Recommendations": [
        "",
        "Put the Lumin Admin role holder address to be behind a Timelock contract so that users can react to admin actions."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-protocol-does-not-support-fee-on-transfer-and-rebasing-tokens-pashov-none-lumin-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _depositWithdraw(address assetAddress, bool deposit, address sender, uint256 amount) private {\n    if (deposit) {\n        IERC20(assetAddress).safeTransferFrom(sender, address(this), amount);\n    } else {\n        IERC20(assetAddress).safeTransfer(sender, amount);\n    }\n}\n",
        "assetDeposit.depositAmount -= amount;\nuserDeposit.depositAmount -= amount;\n",
        "assetDeposit.depositAmount += amount;\nuserDeposit.depositAmount += amount;\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as this can leave tokens stuck in the protocol"
    ],
    "Likelihood": [
        "\nLow, as a small portion of the commonly used tokens have such mechanisms"
    ],
    "Description": [
        "",
        "The _depositWithdraw method in AssetManager has the following implementation:",
        "Also before/after it is called we have code like this:",
        "and this",
        "This code does not account for tokens that have a fee-on-transfer or a rebasing (token balance going up/down without transfers) mechanisms. By caching (or removing) the amount given to the transfer or transferFrom methods of the ERC20 token, this implies that this will be the actual received/sent out amount by the protocol and that it will be static, but that is not guaranteed to be the case. If fee-on-transfer tokens are used, on deposit action the actual received amount will be less, so withdrawing the same balance won't be possible. For rebasing tokens it is also possible that the contract's balance decreases over time, which will lead to the same problem as with the fee-on-transfer tokens, and if the balance increases then the reward will be stuck in the AssetManager contract."
    ],
    "Recommendations": [
        "",
        "You can either explicitly document that you do not support tokens with a fee-on-transfer or rebasing mechanism or you can do the following:",
        "For fee-on-transfer tokens, check the balance before and after the transfer and validate it is the same as the amount argument provided.\nFor rebasing tokens, when they go down in value, you should have a method to update the cached reserves accordingly, based on the balance held. This is a complex solution.\nFor rebasing tokens, when they go up in value, you should add a method to actually transfer the excess tokens out of the protocol (possibly directly to users)."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-calling-curvewithdraw-will-likely-result-in-users-losing-eth-pashov-none-pino-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    it('User can not claim his ETH liquidity', async () => {\n      const { contract, sign } = await loadFixture(deploy);\n\n      const POOL = '0xdc24316b9ae028f1497c275eb9192a3ea0f67022';\n      const POOL_TOKEN = '0x06325440d014e39736583c165c2963ba99faf14e';\n\n      const proxyFee = 5n;\n      const ethAmount = 1n * 10n ** 18n;\n\n      const amounts = [ethAmount, 0]; // eth - steth\n\n      const poolToken = await ethers.getContractAt(\n        'IERC20',\n        POOL_TOKEN,\n      );\n\n      const poolTokenBalanceBefore = await poolToken.balanceOf(\n        account.address,\n      );\n\n      const addTx = await contract.populateTransaction.deposit(\n        amounts,\n        0,\n        POOL,\n        proxyFee,\n      );\n      const sweepTx = await contract.populateTransaction.sweepToken(\n        POOL_TOKEN,\n        account.address,\n      );\n\n      await contract.multicall([addTx.data, sweepTx.data], 0, {\n        value: ethAmount + proxyFee,\n      });\n\n      const poolTokenBalanceAfter = await poolToken.balanceOf(\n        account.address,\n      );\n\n      expect(poolTokenBalanceAfter).to.gt(poolTokenBalanceBefore);\n\n      await poolToken.approve(PERMIT2_ADDRESS, constants.MaxUint256);\n\n      const { permit, signature } = await sign(\n        {\n          amount: poolTokenBalanceAfter,\n          token: POOL_TOKEN,\n        },\n        contract.address,\n      );\n\n      const approveTx =\n        await contract.populateTransaction.approveToken(POOL_TOKEN, [\n          POOL,\n        ]);\n      const permitTx =\n        await contract.populateTransaction.permitTransferFrom(\n          permit,\n          signature,\n        );\n\n      const removeLiquidityTx =\n        await contract.populateTransaction.withdraw(\n          poolTokenBalanceAfter,\n          [0, 0],\n          POOL,\n        );\n\n      // remove liquidity then try with unwrapping, as if the contract wrapped the received ETH in WETH\n      const unwrapTx = await contract.populateTransaction.unwrapWETH9(\n        account.address,\n      );\n\n      let ethBalanceBefore = await account.getBalance();\n      await contract.multicall(\n        [\n          approveTx.data,\n          permitTx.data,\n          removeLiquidityTx.data,\n          unwrapTx.data,\n        ],\n        0,\n      );\n\n      let ethBalanceAfter = await account.getBalance();\n      expect(ethBalanceBefore).to.gt(ethBalanceAfter); // balance before is actually more than current because of paying gas - it should have been ~1 ETH more, because of `ethAmount`\n    });\n  });\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as users can lose ETH value"
    ],
    "Likelihood": [
        "\nHigh, as all >75 Curve pools that have ETH are problematic"
    ],
    "Description": [
        "",
        "The Curve::withdraw method removes liquidity from a pool to burn LP tokens and receive the underlying assets, after which a user can sweep them to his wallet. The problem with this is that some pools use ETH as an underlying asset and the remove_liquidity method will send back ETH to the caller. When this is the case the ETH will be stuck in the contract (the owner can withdraw it for himself) since the user has no way to sweep the ETH balance of the contracts. This is handled in withdrawOneCoinI and withdrawOneCoinU but not in withdraw.",
        "Below you can see a runnable Proof of Concept unit test, add this to the curve_pool.test.ts file in its Remove Liquidity suite as a last test to run it:"
    ],
    "Recommendations": [
        "",
        "Use the handling as in withdrawOneCoinI and withdrawOneCoinU, namely wrapping the ETH balance to WETH, which the user can sweep to his wallet."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-the-fee-mechanism-is-not-enforced-pashov-none-pino-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function depositETHV2(address _recipient, uint256 _proxyFeeInWei) external payable nonETHReuse {\n        address _cEther = address(cEther);\n\n        ICEther(_cEther).mint{value: msg.value - _proxyFeeInWei}();\n    ....\n    ....\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as the protocol can lose potential yield in the form of fees"
    ],
    "Likelihood": [
        "\nHigh, as users can craft such transactions in a permissionless way"
    ],
    "Description": [
        "",
        "The codebase is using a fee mechanism where the users pay a fee for using some functionality. An example where this is done is the Compound::depositETHV2 method, as we can see here:",
        "The problem with this approach is that the value of the fee is controlled by the user through the _proxyFeeInWei argument, meaning he can always send 0 value to it so he doesn't pay any fees."
    ],
    "Recommendations": [
        "",
        "Rearchitecture the fees approach so that a fee can be enforced on users, for example by using a sensible admin set value for it."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-integration-with-curve-is-flawed-pashov-none-pino-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nLow, as users won't lose funds but the protocol's contract might need new implementation and redeployment"
    ],
    "Likelihood": [
        "\nHigh, as users can't use a big part of Curve pools"
    ],
    "Description": [
        "",
        "Currently, the Curve methods deposit and withdraw are hardcoding the number of underlying tokens in a Curve pool to be exactly two. This is incorrect, as some pools have three or more underlying tokens and with the current implementations users can't make proxy calls to them, which limits the functionality of the protocol."
    ],
    "Recommendations": [
        "",
        "Change the methods in Curve so that they can work for different counts of underlying tokens in a pool, make sure to do this with a proper validations."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-calls-to-methods-with-nonethreuse-modifier-can-be-force-reverted-pashov-none-pino-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function _nonReuseBefore() private {\n        // On the first call to nonETHReuse, _status will be NOT_ENTERED\n        if (_status == ENTERED) {\n            revert EtherReuseGuardCall();\n        }\n\n        // Any calls to nonETHReuse after this point will fail\n        _status = ENTERED;\n    }\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as the user will get its transaction reverted, but it can be replayed through a Multicall call"
    ],
    "Likelihood": [
        "\nMedium, as it can only happen when there is a direct call to such methods, which isn't the usual way to use the app"
    ],
    "Description": [
        "",
        "In the contracts under protocols/ we see a good amount of their methods having the nonETHReuse modifier. The modifier code calls the following method:",
        "This code means that if a method with the modifier is called two times in a row, the second call would be reverted. The only way to \"unlock\" the contracts is through a Multicall::multicall call, which sets _status = NOT_ENTERED;. Because of this, the following attack can be executed:"
    ],
    "Recommendations": [
        "",
        "Consider forbidding direct calls to methods and force them to be done through Multicall."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-the-contracts-owner-can-maliciously-front-run-users-pashov-none-pino-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can result in a loss of funds for users"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or compromised owners"
    ],
    "Description": [
        "",
        "The Swap and Aave contracts have the setNewAddresses functionality, which can be only called by the contracts owner. If users send Multicall calls to the protocol and are using either the Swap or Aave contracts, the owner can front-run their call by updating the addresses to his own controlled malicious contracts, which can receive the user assets and give nothing back in return."
    ],
    "Recommendations": [
        "",
        "Remove the method from both contracts as it is not needed as the contracts shouldn't be holding any value or allowances anyway between transactions - if you wish to update the addresses in them you can just deploy new Swap or Aave contracts and make the front-end forward calls to them."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-operators-can-cast-an-extra-vote-to-get-voting-majority-pashov-none-smoothly-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes32 prevVote = votes[epochNumber][msg.sender];\nuint256 count = ++voteCounter[epochNumber][vote];\nuint256 operatorsLen = operators.length;\n\nvotes[epochNumber][msg.sender] = vote;\n\nif (prevVote != bytes32(0)) --voteCounter[epochNumber][prevVote];\n",
        "it(\"Operators can cast an extra vote to get voting majority\", async () => {\n  await governance.addOperators([\n    operator1.address,\n    operator2.address,\n    operator3.address,\n  ]);\n  await time.increase(week);\n  await governance\n    .connect(operator1)\n    .proposeEpoch([withdrawals.root, exits.root, state, fee]);\n\n  expect(await governance.epochNumber()).to.equal(0);\n  // operator1 casts a second vote to get 66% vote ratio\n  await governance\n    .connect(operator1)\n    .proposeEpoch([withdrawals.root, exits.root, state, fee]);\n\n  // validate that the epoch increased (vote passed)\n  expect(await governance.epochNumber()).to.equal(1);\n});\n",
        "bytes32 prevVote = votes[epochNumber][msg.sender];\n- uint256 count = ++voteCounter[epochNumber][vote];\nuint256 operatorsLen = operators.length;\n\nvotes[epochNumber][msg.sender] = vote;\n\nif (prevVote != bytes32(0)) --voteCounter[epochNumber][prevVote];\n+ uint256 count = ++voteCounter[epochNumber][vote];\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it breaks the votingRatio invariant"
    ],
    "Likelihood": [
        "\nHigh, as operators can cast an extra vote at any time"
    ],
    "Description": [
        "",
        "In PoolGovernance::proposeEpoch, operators can cast an extra vote when this is needed to get to votingRatio. Exploiting this, a single operator in a group of three can execute any proposal he decides on. Also if there are more operators in the group and one extra vote is needed for a proposal, anyone who has already voted can execute the proposal by sending his vote again. This is due to how the mechanism for removing previous votes works:",
        "The count is updated without checking if the user has already voted, meaning if he already voted and casted the same vote, the count value will be 2, instead of 1.",
        "A single operator can directly execute a proposal when:",
        "Bigger operators.length means that a single operator can't execute a proposal by himself, but using a double vote is always possible.",
        "Add this test to PooGovernance.t.ts to run the Proof of Concept"
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:"
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-operator-can-still-claim-rewards-after-being-removed-from-governance-pashov-none-smoothly-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as rewards shouldn't be claimable for operators that were removed from governance"
    ],
    "Likelihood": [
        "\nHigh, as this will happen every time this functionality is used and an operator has unclaimed rewards"
    ],
    "Description": [
        "",
        "The deleteOperators method removes an operator account from the PoolGovernance but it still leaves the operatorRewards mapping untouched, meaning even if an operator is acting maliciously and is removed he can still claim his accrued rewards. This shouldn't be the case, as this functionality is used when operators must be slashed. Also if an operator becomes inactive, even if he is removed, his unclaimed rewards will be stuck in the contract with the current implementation."
    ],
    "Recommendations": [
        "",
        "On operator removal transfer the operator rewards to a chosen account, for example the SmoothlyPool."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-large-centralization-attack-surface-pashov-none-smoothly-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as multiple authorized actors can act maliciously to steal funds"
    ],
    "Likelihood": [
        "\nMedium, as it requires malicious or compromised actors, but it's not just the protocol owner"
    ],
    "Description": [
        ""
    ],
    "Recommendations": [
        "",
        "Make the owner of PoolGovernance be a multi-sig wallet behind a Timelock contract so that users can monitor what transactions are about to be executed by this account and take action if necessary. Also add a limit on the max number of operators, for example 50. For the operators you might need to add some extra security mechanism to protect the centralization, as currently it doesn't have an easy fix."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-operator-might-be-unable-to-withdraw-rewards-due-to-gas-limit-pashov-none-smoothly-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(bool sent, ) = msg.sender.call{value: rewards, gas: 2300}(\"\");\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as operator's yield will be frozen"
    ],
    "Likelihood": [
        "\nLow, as it requires operator to be a special multi-sig wallet or contract"
    ],
    "Description": [
        "",
        "The PoolGovernance:withdrawRewards method allows operators to withdraw their yield, which happens with this external call:",
        "The 2300 gas limit might not be enough for smart contract wallets that have a receive or fallback function that takes more than 2300 gas units, which is too low (you can't do much more than emit an event). If that is the case, the operator won't be able to claim his rewards and they will be stuck in the contract forever."
    ],
    "Recommendations": [
        "",
        "Remove the gas limit from the external call. It can also be removed from the same logic in SmoothlyPool as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-the-stake-fees-are-not-tracked-on-chain-pashov-none-smoothly-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can result in wrong accounting of ETH held by SmoothlyPool"
    ],
    "Likelihood": [
        "\nLow, as it requires off-chain code to be wrong"
    ],
    "Description": [
        "",
        "Every validator who joins the SmoothlyPool should register by paying a STAKE_FEE (with the size of 0.065 ETH) to the contract. The pool does not track how much of a stake fee balance a validator has, which is problematic for the following reasons:"
    ],
    "Recommendations": [
        "",
        "Add a mapping to track validators' stake fee balances in SmoothlyPool."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-insufficient-input-validation-pashov-none-gtrade-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can lead to stuck funds"
    ],
    "Likelihood": [
        "\nLow, as it requires a bad user error"
    ],
    "Description": [
        "",
        "In GNSStakingV6_4_1::createUnlockSchedule we have the UnlockScheduleInput calldata _input parameter, where most of the fields in the struct are properly validated to be in range of valid values. The issue is that the start field of the UnlockScheduleInput is not sufficiently validated, as it can be too further away in the future - for example 50 years in the future, due to a user error when choosing the timestamp. This would result in (almost) permanent lock of the GNS funds sent to the method."
    ],
    "Recommendations": [
        "",
        "Add a validation that the start field is not too further away in the future, for example it should be max 1 year in the future."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-protocol-fees-from-nft-mints-cant-be-claimed-in-batonlaunchpad-pashov-none-baton-launchpad-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (protocolFee != 0) {\n    address(batonLaunchpad).safeTransferETH(protocolFee);\n}\n"
    ],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it results in a loss of value for the protocol"
    ],
    "Likelihood": [
        "\nHigh, as it certain to happen"
    ],
    "Description": [
        "",
        "In Nft::mint the msg.value expected is the price of an NFT multiplied by the amount of NFTs to mint plus a protocol fee. This protocol fee is sent to the BatonLaunchpad contract in the end of the mint method like this:",
        "BatonLaunchpad defines a receive method that is marked as payable, which is correct. The problem is that in BatonLaunchpad there is no way to get the ETH balance out of it - it can't be spent in any way possible, leaving it stuck in the contract forever."
    ],
    "Recommendations": [
        "",
        "In BatonLaunchpad add a method by which the owner of the contract can withdraw its ETH balance."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-missing-user-input-validation-can-lead-to-stuck-funds-pashov-none-baton-launchpad-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as all mint fees can be stuck forever"
    ],
    "Likelihood": [
        "\nMedium, as users can easily misconfigure inputs"
    ],
    "Description": [
        "",
        "There are multiple insufficiencies in the input validation of the arguments of the initialize method in Nft:"
    ],
    "Recommendations": [
        "",
        "Add a validation that the sum of all categories' supply is more than or equal to the maxMintSupply. Also add sensible upper and lower bounds for both duration for the vesting mechanism and mintEndTimestamp for the refund mechanism."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-its-not-possible-to-execute-a-rewards-migration-of-a-batonfarm-pashov-none-baton-launchpad-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can lead to stuck rewards"
    ],
    "Likelihood": [
        "\nLow, as it is not likely that a migration is needed"
    ],
    "Description": [
        "",
        "The BatonFarm contract which is an external dependency of the Nft contract (a BatonFarm is deployed in seedYieldFarm) has a migration mechanism to move the unearned rewards to a new contract. This functionality is currently blocked, because it depends on a call from the BatonFarm owner (the Nft contract in this case) to the initiateMigration method of BatonFarm. Since such a call is not possible as there is no code for it, migrations are currently impossible in the system. This means that if there are rewards left in a BatonFarm contract deployed by some Nft contract, they will be stuck there forever."
    ],
    "Recommendations": [
        "",
        "Add a way for the Nft admin to execute an initiateMigration call."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-possible-front-running-griefing-attack-on-nft-creations-pashov-none-baton-launchpad-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nMedium, as it results in a temporary DoS for users of the protocol"
    ],
    "Likelihood": [
        "\nMedium, as it is easy to execute but attacker doesn't have much incentive to do it"
    ],
    "Description": [
        "",
        "The create method in BatonLaunchpad calls the cloneDeterministically method from LibClone that uses the create2 opcode. The create method also has a salt parameter that is passed to the cloneDeterministically call. A malicious actor can front-run every call to create and use the same salt argument. This will result in reverts of all user transactions, as there is already a contract at the address that create2 tries to deploy to."
    ],
    "Recommendations": [
        "",
        "Adding msg.sender to the salt argument passed to cloneDeterministically will resolve this issue."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-centralization-vulnerabilities-are-present-in-the-protocol-pashov-none-baton-launchpad-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Severity": [
        ""
    ],
    "Impact": [
        "\nHigh, as it can lead to a rug pull"
    ],
    "Likelihood": [
        "\nLow, as it requires a compromised or a malicious owner"
    ],
    "Description": [
        "",
        "The owner of BatonLaunchpad has total control of the nftImplementation and feeRate storage variable values in the contract. This opens up some attack vectors:"
    ],
    "Recommendations": [
        "",
        "Make the nftImplementation method callable only once, so the value can't be updated after initially set. For the feeRate add a MAX_FEE_RATE constant value and check that the new value is less than or equal to it. For the Caviar dependency issue you can call it with try-catch and just complete the locking of LP or seeding of the yield farm if the call throws an error."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-contract-hibernationden-can-receive-eth-but-it-cant-be-withdrawn-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, as it will result in stuck funds, but they will just have the value of gas refunded"
    ],
    "Likelihood": [
        "\nMedium, as it will happen when there is a refund from a cross-chain call"
    ],
    "Description": [
        "",
        "The HibernationDen contract has a receive method. This is mostly expected to be used for LayerZero refunds as the comment above the method says. The problem is that this gas refunds ETH won't be withdrawable as there is no method for ETH withdraw in the contract. Another issue is that anyone can mistakenly send ETH to HibernationDen and it will be stuck there."
    ],
    "Recommendations": [
        "",
        "Add a method that can withdraw ETH from the HibernationDen contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-state-is-not-properly-updated-on-l2-leading-to-stuck-prize-nfts-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (party.numUsed == party.sleepoors.length) revert PartyAlreadyWoke(bundleId_);\n"
    ],
    "Impact": [
        "\nHigh, as winning prize NFTs won't be claimable"
    ],
    "Likelihood": [
        "\nHigh, as functionality is never working correctly"
    ],
    "Description": [
        "",
        "The addToParty method in HibernationDen does not send a cross-chain message, even though it pushes sleepers into the party.sleepoors array on L1. Since the array won't be updated on L2, now all the calculations and validations that are done based on the party.sleepoors.length value will be incorrect. This essentially means that the sleeper NFTs will be stuck as in wakeSleeper there is the following check:",
        "Which means that even though there are actually let's say 10 sleepers (they were 7, but then 3 were added), when numUsed is 7 then no more sleepers would be claimable - the wakeSleeper call will revert will PartyAlreadyWoke."
    ],
    "Recommendations": [
        "",
        "Make sure to send a cross-chain message to add the sleepers to the party.sleeepoors array on the L2."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-anyone-can-burn-any-nft-in-the-honeyjarportal-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (_from != _msgSender()) revert OwnerNotCaller();\n"
    ],
    "Impact": [
        "\nHigh, because the NFTs won't be retrievable from the portal anymore"
    ],
    "Likelihood": [
        "\nHigh, because it does not require any preconditions to be exploited"
    ],
    "Description": [
        "",
        "The _debitFrom method in HoneyJarPortal allows burning of any HoneyJar NFT, given its ID. This method is freely callable through ONFT721Core's sendFrom method, which calls _send which calls the _debitFrom method without an access control check. This results in the ability for anyone to burn any HoneyJar NFT, no matter who holds it. There is the following check in the method:",
        "which shows an access control intention, but is actually redundant as the _from argument is not used in the burning process."
    ],
    "Recommendations": [
        "",
        "The code should check that the caller actually owns the NFT that is about to get burned - the current check does not do this. Update it accordingly."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-accepting-input-after-randomness-is-requested-can-be-exploited-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can result in a griefing attack on an expected game winner"
    ],
    "Likelihood": [
        "\nMedium, as it requires minting a new HoneyJar NFT"
    ],
    "Description": [
        "",
        "The VRF security considerations docs explicitly mention that if an outcome in the contract depends on user-supplied inputs (in this case minting HoneyJar NFTs) and randomness, then the contract should stop accepting any additional user-supplied inputs after it submits the randomness request. The problem here is that in fulfillRandomWords the _setFermentedJars method is called where the number of HoneyJar NFTs minted for a bundle is used for the process of choosing the winning NFT - this means that the fulfillRandomWords transaction can be front-ran with a HoneyJar NFT mint and the winner will be different. This can result in a griefing attack for an expected winner of a game."
    ],
    "Recommendations": [
        "",
        "Decouple the randomness request and the user input from each other. Use only the user input that has been submitted pre-requesting randomness."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-fulfillrandomwords-method-might-revert-with-out-of-gas-error-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (party.assetChainId != getChainId() && address(honeyJarPortal) != address(0) && address(this).balance != 0) {\n    uint256 sendAmount = address(this).balance / party.checkpoints.length;\n    honeyJarPortal.sendFermentedJars{value: sendAmount}(\n        address(this), party.assetChainId, party.bundleId, fermentedJars\n    );\n}\n"
    ],
    "Impact": [
        "\nHigh, as randomness won't be fulfilled"
    ],
    "Likelihood": [
        "\nLow, as it requires misconfiguration of gas"
    ],
    "Description": [
        "",
        "The fulfillRandomWords method in HibernationDen calls the internal _setFermentedJars method which loops over the fermentedJars array and also has an external call. This is a potential problem as this code might require a lot of gas and make the fulfillRandomWords method revert which is problematic for a VRF integration (it is listed in the VRF Security Considerations docs).",
        "Another such issue in the method is this code:",
        "The problem is that when party.assetChainId != getChainId() && address(honeyJarPortal) != address(0) are true, then the only thing left to go into the if statement is address(this).balance != 0 - this is easily exploitable as anyone can send 1 wei of ETH into the contract, which will make the expression evaluate to true. This will add additional gas cost overhead as it will execute an external call that has more logic, and also the cross-chain call is almost certainly failing as the sendAmount is possible to have rounded down to zero (if address(this).balance was 1 but party.checkpoints.length was more than 1)."
    ],
    "Recommendations": [
        "",
        "Consider caching the randomness received and then letting an externally owed account for example to actually make the _setFermentedJars call so it can set the correct gas. Also check that the balance is enough to do the sendFermentedJars call, not just that the balance is non-zero."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-centralization-attack-vectors-are-present-in-the-code-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as some accounts can brick the game"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or compromised owner/admin account"
    ],
    "Description": [
        "",
        "There are multiple centralization attack vectors present in the contracts. Examples are:"
    ],
    "Recommendations": [
        "",
        "Make the methods callable only once or add them to the constructors/initializer methods."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-polygon-chain-reorgs-will-often-change-game-results-pashov-none-nft-loots-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as an already winning user will lose its reward"
    ],
    "Likelihood": [
        "\nHigh, as reorgs with > 3 depth happen often on Polygon"
    ],
    "Description": [
        "",
        "The REQUEST_CONFIRMATION constant in VRFv2Consumer is set to 3. This value is used to tell the Chainlink VRF service how much blocks do you want to wait at a minimum before receiving randomness. The reason this value was added is because of chain reorganizations - when this event happens, blocks and transactions get reorganized and they change. This is a serious problem in this application as it is expected to be launched on Polygon (mentioned in README.md), but as we can see here there are more than 5 block reorganizations a day with depth that is more than 3 blocks. In this article we can even see a recent event where there was a 156 block depth chain reorg on Polygon. This means that it is possible that often the winner of a lootbox game to be changed since when your transaction for requesting randomness from VRF is moved to a different block then the randomness will change as well."
    ],
    "Recommendations": [
        "",
        "Use a larger REQUEST_CONFIRMATIONS value - I would suggest around 60 to be safe. For the past 7 days the deepest chain reorganization had a depth of < 30 blocks. While 60 might not fit your use case for the game, I think anything below 25-30 is potentially dangerous to the project's users and reputation."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-contract-might-not-have-enough-balance-for-winner-to-claim-prize-pashov-none-nft-loots-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "loot.usdPrizes = prizes;\n"
    ],
    "Impact": [
        "\nHigh, as user will not be able to claim prize value"
    ],
    "Likelihood": [
        "\nMedium, as it requires the owner to not input enough balance"
    ],
    "Description": [
        "",
        "The protocol doesn't enforce the actual balance in the NFTLootbox contract to be enough to pay out rewards. The first issue comes in the createLootbox method, where the code does",
        "but it doesn't actually transfer prizes amount of stablecoin into the contract - it just expects it will have it as a balance, which is not enforcing it and is error-prone. Also, the contract is expected to hold the value of each NFT supplied as reward also in its USD value. So if a BAYC NFT was deposited as a reward, not only the BAYC should be held by the contract but also its USD value in stablecoin. Even though winners will be able to claim either the NFT itself or its USD value, this way the capital efficiency gets cut in half. This is also not enforced.",
        "The situation currently is that the contract is not trustless - there might not be enough rewards to pay winners."
    ],
    "Recommendations": [
        "",
        "Ensure that all rewards possible to be won are claimable all of the time in a trustless manner. Enforce the contract to hold at least as much balance as the sum of all possible rewards."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-two-people-might-win-the-same-prize-pashov-none-nft-loots-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256[] storage _probabilities = lootboxes[_lootboxId].probabilities;\nuint256 sum;\n\n// Calculate the cumulative sum of probabilities and find the winning prize\nfor (uint256 i; i < _probabilities.length; ++i) {\n    sum += _probabilities[i];\n    if (_randomNumber <= sum) {\n        return i;\n    }\n}\n\n// If no prize is won, return a missing prize index (100001)\nreturn MAX_PROBABILITY + 1;\n"
    ],
    "Impact": [
        "\nHigh, as people might not get their prizes"
    ],
    "Likelihood": [
        "\nLow, as it requires same prizeIndex wins"
    ],
    "Description": [
        "",
        "The current way in NFTLootbox to decide if a player wins and what it wins is the getPrizeIndex method, which has the following implementation:",
        "This shows that the smaller randomNumber you get, the bigger chance you have of winning. The flaw is that multiple people might draw a small randomNumber and get the same prizeIndex returned, resulting in them being able to claim the same reward. This is also amplified by the fact that the probabilities array is not enforced to be sorted - if the first values in the probabilities array are big then it is more possible that winners will get the same prizeIndex and prize.",
        "While the game currently looks like it handles this, as multiple users can claim the same prize with the same prizeIndex, this shouldn't be the case, as it means there is a race condition for the first person to get an NFT's prizeIndex, because front-running can be used to get the ERC721 token from another winner even if you played later than him (given that you got the same prizeIndex win). Also, if it is a USD based prize, then it is possible that multiple people win it but it is not enforced that the contract has this balance. This can mean some people lose their expected rewards."
    ],
    "Recommendations": [
        "",
        "Enforce only 1 winner per prizeIndex and also enforce the probabilities array to be sorted."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-some-common-non-standard-erc20-tokens-are-incompatible-with-the-protocol-pashov-none-nft-loots-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, because it won't leave to a loss of funds, outside of gas for redeployment"
    ],
    "Likelihood": [
        "\nMedium, because such token is listed in the docs"
    ],
    "Description": [
        "",
        "The code in NFTLootbox is directly using ERC20's transfer and transferFrom methods. There are two problems with this:",
        "The application is incompatible with either of those. The more problematic one is USDT as it is widely known that it has those flaws and it is actually directly listed in the documentation. Still, by looking at the implementation code of the USDT token on Polygon, which is different from the Ethereum one, it looks like the issue is not present there. This is why this issue is only marked as Medium severity, but it still requires handling to be extra safe."
    ],
    "Recommendations": [
        "",
        "Use OpenZeppelin's SafeERC20 library and its safeTransfer/safeTransferFrom methods."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-lootbox-input-validation-should-be-present-pashov-none-nft-loots-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can leave NFTs stuck in the contract forever"
    ],
    "Likelihood": [
        "\nLow, as it requires a fat-finger or misconfiguration by the NFTLootbox owner"
    ],
    "Description": [
        "",
        "Both the _priceForPlay and _duration values should be properly validated in NFTLootbox::createLootbox. The _priceToPlay has to have an upper bound, because if it's too big then no one will want to participate and until the duration passes the NFTs will be stuck in the contract. For the _duration value there should be a lower and an upper bound, as too low of a duration doesn't make sense but too big of a duration can leave NFTs stuck in the contract forever. If the owner fat-fingers the duration and adds one or two digits it can become a big problem."
    ],
    "Recommendations": [
        "",
        "Add a lower & upper bound checks for _duration and a max value check for _priceForPlay in the createLootbox method."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-centralization-attack-vectors-are-present-in-the-code-pashov-none-nft-loots-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as some accounts can execute a rug pull or brick the game"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or compromised owner/admin account"
    ],
    "Description": [
        "",
        "The owner accounts of both NFTLootbox & VRFv2Consumer contracts have the power to break the game while it is running."
    ],
    "Recommendations": [
        "",
        "Limit the usage of those methods by either making them callable only in special conditions or with specific arguments."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-if-strategy-is-losing-money-the-last-person-left-to-claim-from-vault-will-handle-all-losses-pashov-none-protectorate-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as some users will bear substantial value losses"
    ],
    "Likelihood": [
        "\nHigh, as it is possible that strategy is losing money at a given time"
    ],
    "Description": [
        "",
        "Currently, the way that LendingVault is designed, is that the funds in the vault are transferred out to chosen strategies. Due to the fact that users can still withdraw funds from the vault's balance while some of the funds are lent out to a strategy, the following scenario can happen:"
    ],
    "Recommendations": [
        "",
        "Possibly forbid withdraws while funds are lent out to a strategy or think of another design for Vault-Strategy lending."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-vesting-schedule-for-a-beneficiary-can-be-overwritten-pashov-none-protectorate-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as the amount left to be vested will be stuck in the contract forever"
    ],
    "Likelihood": [
        "\nMedium, as it requires more than 1 vesting schedule for the same beneficiary"
    ],
    "Description": [
        "",
        "The vesting schedules in Vesting are saved in schedules mapping, which uses the _beneficiary address as the key. The problem is that if a beneficiary has a scheduled vesting already, if a second schedule is set to it, then the first one will be overwritten but the schedulesTotalAmount will still hold the first scheduled funds to vest. This means they will be stuck in the Vesting contract forever."
    ],
    "Recommendations": [
        "",
        "A possible solution is to use a vesting ID instead of the beneficiary address as the key in the schedules mapping or to disallow multiple schedules set for the same beneficiary."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-vault-depositors-can-be-front-ran-and-lose-their-funds-pashov-none-protectorate-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as a theft of user assets is possible"
    ],
    "Likelihood": [
        "\nMedium, as it works only if the attacker is the first vault depositor"
    ],
    "Description": [
        "",
        "The following attack is possible:",
        "This can be replayed multiple times until the depositors notice the problem."
    ],
    "Recommendations": [
        "",
        "First, make sure that all deposits will go through Flashbots so the transactions are not sandwhichable/front-runnable.",
        "Then we can look at how UniswapV2 fixed this with two types of protection:",
        "First, on the first mint it actually mints the first 1000 shares to the zero-address",
        "Second, it requires that the minted shares are not 0",
        "Implementing all of those solutions will resolve this vulnerability."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-some-vesting-recipients-temporarily-wont-be-able-to-claim-pashov-none-protectorate-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 vestedSeconds = (timeFromStart / SLICE_PERIOD) * SLICE_PERIOD;\n"
    ],
    "Impact": [
        "\nMedium, as funds will be locked for 30 days"
    ],
    "Likelihood": [
        "\nMedium, because it will only happen when the cliff is < 30 day"
    ],
    "Description": [
        "",
        "The SLICE_PERIOD constant in Vesting is set to 30 days. Due to the following math in _computeReleasableAmount",
        "If timeFromStart is less than 30 days this will round down to zero, which means the amount to claim until 30 days have passed will always be zero. This applies especially for vesting schedules that have no cliff (it is 0), which is expected for Investors and Treasury."
    ],
    "Recommendations": [
        "",
        "Make the SLICE_PERIOD smaller, or implement another design for handling no cliff vesting schedules that won't be using this calculation."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-insufficient-input-validation-can-lead-to-loss-of-funds-pashov-none-protectorate-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as funds might be stuck forever in contracts"
    ],
    "Likelihood": [
        "\nLow, as it requires a configuration error from the admin"
    ],
    "Description": [
        "",
        "Multiple places in the codebase have insufficient input validation that can lead to stuck funds.",
        "If either _duration in Vesting is too big or the difference between startTime and endTime in DutchAuction is too big then funds can be stuck forever in the contracts."
    ],
    "Recommendations": [
        "",
        "Call the adjustPerformanceFee method in LendingVault's constructor to use its input validation. When it comes to the _duration parameter in createSchedule, use a minimum of 7 days and a maximum of for example 2 years.",
        "For the AuctionDetails you need to make check multiple things:",
        "Same things for startPrice and minimumPrice:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-malicious-owner-could-arbitrage-sales-pashov-none-punksbids-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it will charge users more than the should be charged"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious/compromised owner"
    ],
    "Description": [
        "",
        "Currently, the setFeeRate and setLocalFeeRate methods do not have an upper bound on the fee rate being set by the owner. This opens up a centralization attack vector, where the owner can front-run trades by setting a bigger fee. Consider the following scenario:"
    ],
    "Recommendations": [
        "",
        "Set upper bounds (limits) to both setFeeRate and setLocalFeeRate methods and revert if the value getting set is higher. This way users will know that fees can maximally go up to a particular number."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-rewards-calculation-error-will-result-in-0-rewards-for-users-pashov-none-topiastaking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "rewardsPerWeight_.accumulated = (rewardsPerWeight_.accumulated +\n    (unaccountedTime * rewardsPerWeight_.rate) / rewardsPerWeight_.totalWeight).toUint96();\n",
        "- (unaccountedTime * rewardsPerWeight_.rate) / rewardsPerWeight_.totalWeight\n+ (unaccountedTime * rewardsPerWeight_.rate).divWadDown(rewardsPerWeight_.totalWeight)\n",
        "- return getUserStakeWeight(userStake) * (rewardsPerWeight_.accumulated - userStake.checkpoint);\n+ return getUserStakeWeight(userStake).mulWadDown(rewardsPerWeight_.accumulated - userStake.checkpoint);\n"
    ],
    "Description": [
        "",
        "The formula to calculate rewards in getUserStakeReward is the following:",
        "It is the same in updateRewardsPerWeight. The problem with this code is that (unaccountedTime * rewardsPerWeight_.rate) / rewardsPerWeight_.totalWeight will round down to zero almost always. Since both totalWeight and rate are measured in 18 decimals tokens (expected), then as more users stake it is highly likely that the totalWeight will grow much more than the static rate. The unaccountedTime variable just holds how many seconds have passed since the last stake/unstake event, which will always be a pretty small number (1 day is 86400 seconds, which is a small, 5 digit number). Now when (unaccountedTime * rewardsPerWeight_.rate) is smaller than rewardsPerWeight_.totalWeight this math will round down to zero and rewardsPerWeight_.accumulated will stay the same value, meaning no new rewards will be accumulated to be distributed to users anymore."
    ],
    "Recommendations": [
        "",
        "In both getUserStakeReward and updateRewardsPerWeight change code like:",
        "And also in getUserStakeReward change code like:",
        "By using FixedPointMathLib from Solmate."
    ],
    "Discussion": [
        ""
    ],
    "pashov": [
        " Fixed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-multiple-centralization-vulnerabilities-can-break-the-protocol-pashov-none-topiastaking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "",
        "Multiple methods in TopiaLpStaking are centralization vulnerabilities and some can be used to break the protocol for users:",
        "The setRewards method has multiple problems in itself:"
    ],
    "Recommendations": [
        "",
        "Make the rewardsToken, uniswapPair and lockupIntervals immutable variables, there shouldn't be a need to change them. Also make sure setRewards is callable just once."
    ],
    "Discussion": [
        ""
    ],
    "pashov": [
        " Fixed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-rewards-can-possibly-be-left-stuck-in-contract-pashov-none-topiastaking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "",
        "Currently in TopliaLpStaking::setRewards we have this comment:",
        "While the issue is pointed out here, it is not enforced in a smart contract native manner and the code is still vulnerable. The problem is that if the rewardsPeriod.start timestamp has passed and no one has staked, the rewards accumulated until the first stake will be forever stuck in the contract, due to the stake method calling updateRewardsPerWeight before actually setting the staker's checkpoint."
    ],
    "Recommendations": [
        "",
        "Add a mechanism to ensure that at least 1 user has staked before rewardsPeriod.start - one possible solution is enforcing that there was at least one stake before calling setRewards and that _start >= block.timestamp."
    ],
    "Discussion": [
        ""
    ],
    "pashov": [
        " Fixed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-staking-wont-work-correctly-with-non-standard-erc20-tokens-pashov-none-topiastaking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "",
        "Some tokens do not revert on failure in transfer or transferFrom but instead return false (example is ZRX). While such tokens are technically compliant with the standard it is a common issue to forget to check the return value of the transfer/transferFrom calls. With the current code, if such a call fails but does not revert it can result in users unstaking without claiming their rewards, even though they wanted to. Those rewards will be forever stuck in the contract.",
        "Some tokens also implement a fee-on-transfer mechanism, meaning on stake, the actual value transferred to the contract's balance won't be _lpAmount but _lpAmount - fee. This will be problematic on unstake as the last users to call it will get their transactions reverted because of insufficient balance in the contract.",
        "Low decimals tokens won't work with setRewards, as the method requires at least 10e18 worth of the reward token as a reward per second, which in the case of just a stable coin would be a crazy daily reward rate, which is close to impossible to fulfill for a prolonged period of time. Using highly valued tokens as ETH or BTC would make it even worse.",
        "While those are expected to not be a problem since the README suggests the staking token will be TOPIA/ETH Uniswap V2 LP tokens and the reward token will be TOPIA, currently the contract has a mechanism to update both tokens and it opens up the attack vector to use ones that are not compatible with the staking contract."
    ],
    "Recommendations": [
        "",
        "Use OpenZeppelin's SafeERC20 library and its safe methods for ERC20 transfers. For fee-on-transfer tokens, check the balance before and after the deposit (stake) and use the difference between the two as the actual transferred value. Consider allowing a lower rewards rate in setRewards.",
        "Or you can just remove the setRewardsToken and setUniswapPair methods."
    ],
    "Discussion": [
        ""
    ],
    "pashov": [
        " Fixed."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-anyone-can-cancel-another-users-scheduled-recovery-pashov-none-ambire-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "scheduledRecoveries[hash] = block.timestamp + recoveryInfo.timelock;\nemit LogRecoveryScheduled(hash, recoveryInfoHash, recoveryKey, currentNonce, block.timestamp, txns);\n"
    ],
    "Impact": [
        "\nHigh, as important protocol feature can be permanently blocked for a victim user"
    ],
    "Likelihood": [
        "\nHigh, as it has no preconditions and can be exploited by anyone"
    ],
    "Description": [
        "",
        "A wallet recovery mechanism in Ambire allows a pre-set account (usually the relayer) to set a new main signer after the initial one was stolen/lost. It works by calling execute with a SIGMODE_RECOVER signature. This will store the request in the contract like this, scheduling it for the future:",
        "The contract also allows an option to cancel a scheduled recovery, by using a SIGMODE_CANCEL signature. The problem is that the hash that is stored as a scheduled recovery does not contain the isCancellation flag (which just checks if the signature mode is SIGMODE_CANCEL). Since the flag isn't part of this hash, anyone can call execute with the same signature parameter as when SIGMODE_RECOVER was used, but just changing the last byte so it uses SIGMODE_CANCEL. This means that anyone can cancel another user's scheduled recovery without any preconditions, which leads to a griefing attack vector on wallet recoveries. An attacker can go to an extend to write a script that will cancel a scheduled recovery a few minutes before it is about to pass."
    ],
    "Recommendations": [
        "",
        "Add the isCancellation flag to the hash so that the initial SIGMODE_RECOVER signature can't be changed into a SIGMODE_CANCEL one and reused."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-invalid-signature-execution-is-possible-if-address0-has-non-zero-privileges-pashov-none-ambire-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "signerKey = SignatureValidator.recoverAddrImpl(hash, signature, true);\nrequire(privileges[signerKey] != bytes32(0), 'INSUFFICIENT_PRIVILEGE');\n"
    ],
    "Impact": [
        "\nHigh, as anyone will be able to steal all funds from a given wallet"
    ],
    "Likelihood": [
        "\nLow, as it requires address(0) to have non-zero privileges"
    ],
    "Description": [
        "",
        "The problem is similar to this issue from a previous audit. The code in SignatureValidator::recoverAddrImpl will return address(0) if it receives a valid Schnorr signature but not one that is for the given hash (transactions hash). Now the result will be checked like this:",
        "Meaning signerKey will be address(0) and now if the value for privileges[address(0)] is non-zero, then anyone will be able to execute any transaction for this wallet, for example stealing all funds.",
        "Also, it is possible to get recoverAddrImpl to return address(0) if you provide a signature with SignatureMode == Multisig and then the signatures inside it to be of type SignatureMode == Spoof. Since allowSpoofing argument will be false, then we will get to the return address(0); code in the end of the method.",
        "A third way to get recoverAddrImpl to return address(0) is if you use SignatureMode == Multisig and just provide an empty array of signatures - then it will return the default value of address signer which is address(0)"
    ],
    "Recommendations": [
        "",
        "Make sure to never have a path where recoverAddrImpl returns address(0), instead just revert the transaction. Also remove the comment // should be impossible to get here as it is false."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-protocol-admin-account-has-a-large-centralization-attack-surface-pashov-none-babylon7-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as creators can lose their raffled items and payouts"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or a compromised admin"
    ],
    "Description": [
        "",
        "A malicious or a compromised admin can execute various rug-like attacks on the protocol:",
        "There are also smaller problems, like:"
    ],
    "Recommendations": [
        "",
        "Use a TimeLock contract to be the protocol owner, so users can actually monitor protocol upgrades or other actions by the admins. Another option is to make the admin a governance controlled address.",
        "Also you should use a MINIMUM_MAX_LISTING_DURATION constant and validate the maxListingDuration value in setMaxListingDuration, doing the same with a MAXIMUM_MIN_DONATION_BPS constant in both initialize and setMinDonationBps for the minDonationBps value. Finally, the setBabylon7Core should be made so it is called only once and core can't be changed later."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-scaling-of-underlyingtokenprice-will-leave-funds-stuck-in-protocol-pashov-none-bloom-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "underlyingTokenPrice =\n    uint256(IOracle(underlyingTokenOracle).latestAnswer()) *\n    1e12;\n"
    ],
    "Impact": [
        "\nHigh, as all deposited funds will be stuck in the protocol"
    ],
    "Likelihood": [
        "\nHigh, as it will always happen"
    ],
    "Description": [
        "",
        "The _getTokenPrices method in SwapFacility has the following code:",
        "This scaling by 1e12 is an error, because most oracle price feeds in Chainlink (and more specifically, the one that is expected to be used, USDC/USD) return an 8 decimals number. Since this underlyingTokenPrice value will be divided by the billyTokenPrice value which again is in 8 decimals, this will result in a calculation error and overinflation of the outAmount in the _swap method. Since the SwapFacility contract won't be holding so many tokens in its balance, the calls to swap will always revert, leaving the BloomPool contract in a stuck state - with all deposited funds in it but without an ability to continue further through its phases."
    ],
    "Recommendations": [
        "",
        "Do not scale the price by 1e12. Clearly define the price feeds that will be used and if they have different decimals only then scale them to the expected decimals count."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-the-protocol-does-not-implement-slippage-checks-on-swaps-pashov-none-bloom-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can result in a substantial loss of value if there is big price movement"
    ],
    "Likelihood": [
        "\nMedium, as slippage is never handled, but it requires specific market conditions"
    ],
    "Description": [
        "",
        "The protocol mentions in its README file that the SwapFacility has to implement slippage checks, but it doesn't. If a swap transaction is sent to the mempool, but it takes a while until it is executed, it is possible that there was big price movement and the swap returned value is substantially lower than what it was initially expected to be, which will be a value loss for the protocol & its users."
    ],
    "Recommendations": [
        "",
        "Add a minOutAmount parameter to SwapFacility::_swap and check that the swap resulted in at least that many tokens, otherwise revert."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-swap-mechanism-does-not-have-a-deadline-parameter-pashov-none-bloom-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as the swap might forcefully result in a big slippage (or maximum allowed one)"
    ],
    "Likelihood": [
        "\nLow, as it requires special conditions"
    ],
    "Description": [
        "",
        "Swap mechanisms should implement a transaction deadline mechanism, due to the following attack vector:",
        "The effects are even worse when there is no slippage as it is the current case in the protocol."
    ],
    "Recommendations": [
        "",
        "Add a deadline timestamp parameter to the SwapFacility::_swap method and revert the transaction if the expiry has passed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-missing-price-feed-validation-and-usage-of-a-deprecated-method-can-lead-to-0-price-pashov-none-bloom-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as using a 0 price would mess the swap calculations"
    ],
    "Likelihood": [
        "\nLow, as it requires a malfunctioning price feed"
    ],
    "Description": [
        "",
        "The _getTokenPrices method in SwapFacility makes use of the latestAnswer method from Chainlink price feeds. The problem is that the NatSpec of latestAnswer says this:",
        "So currently it is possible that latestAnswer returns 0 and the code operates with zero price, leading to miscalculations in the rate of underlyingToken to billyToken which will lead to a loss of funds."
    ],
    "Recommendations": [
        "",
        "As pointed out in the comment, use latestRoundData instead to query a price feed."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-centralization-attack-vectors-are-present-pashov-none-bloom-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can break the protocol for users"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or a compromised owner"
    ],
    "Description": [
        "",
        "The owner of SwapFacility can change the pool variable any time, meaning it can be set to address(0) for example, breaking the protocol's swap functionality. Another such issue is that the setSpreadPrice method does not do any input validation, meaning the spreadPrice can be set to a huge number that is bigger than the token prices, which will make the spread subtraction revert the swap transactions every time."
    ],
    "Recommendations": [
        "",
        "Make setPool callable only once and also put an upper bound of the spreadPrice value."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-tokens-with-a-fee-on-transfer-mechanism-will-break-the-protocol-pashov-none-bloom-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "UNDERLYING_TOKEN.safeTransferFrom(msg.sender, address(this), amount);\n"
    ],
    "Impact": [
        "\nHigh, as some users will lose value"
    ],
    "Likelihood": [
        "\nLow, as such tokens are not common"
    ],
    "Description": [
        "",
        "The ERC20 logic in BloomPool is incompatible with tokens that have a fee-on-transfer mechanism. Such tokens for example is PAXG, while USDT has a built-in fee-on-transfer mechanism that is currently switched off. One example of this BloomPool::depositBorrower where the following code:",
        "This will work incorrectly if the token has a fee-on-transfer mechanism - the contract will cache amount as its expected added balance, but it will actually add amount - fee balance. This will result in a revert in the last person to withdraw tokens out of the contract. Same thing applies for other transferFrom calls that transfer tokens into the protocol, for example in SwapFacility::_swap."
    ],
    "Recommendations": [
        "",
        "You should cache the balance before a transferFrom to the contract and then check it after the transfer and use the difference between them as the newly added balance. This also requires a nonReentrant modifier, as otherwise ERC777 tokens can manipulate this. Another fix is to just document and announce you do not support tokens that can have a fee-on-transfer mechanism."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-sale-creator-can-possibly-steal-bidders-claimable-tokens-pashov-none-ipnft-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it results in a loss of funds for bidders"
    ],
    "Likelihood": [
        "\nMedium, as it requires to claim before cliff expires"
    ],
    "Description": [
        "",
        "In StakedVestedCrowdSale the sale creator can give the address to his own TokenVesting & TimelockedToken contracts. Same in VestedCrowdSale but only for TimelockedToken. Now if the sale creator is malicious he can give the addresses of his own deployed contracts that inherit from either TokenVesting or TimelockedToken but add functionality to pull the funds out on demand, while they are still locked in them. This is even worse when it comes to the token locking logic in VestedCrowdSale, where on sale settlement the TimelockedToken contract is approved to spend all the auctionToken that should be claimed, meaning if it has the functionality it can just pull the funds and transfer them out of the contract on demand. This will result in inability for bidders to claim their tokens and 100% loss of their value."
    ],
    "Recommendations": [
        "",
        "Enforce both TokenVesting & TimelockedToken contracts to be only internally deployed from a predefined bytecode/implementation and do not accept user-supplied contracts."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-auction-tokens-with-approval-race-protection-or-not-returning-a-bool-on-approve-are-incompatible-with-vestedcrowdsale-pashov-none-ipnft-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 currentAllowance = sale.auctionToken.allowance(address(this), address(salesVesting[saleId].vestingContract));\n\n//the poor man's `increaseAllowance`\nsale.auctionToken.approve(address(salesVesting[saleId].vestingContract), currentAllowance + sale.salesAmount);\n"
    ],
    "Impact": [
        "\nHigh, as sale won't be possible to be settled"
    ],
    "Likelihood": [
        "\nLow, as such tokens are rare, but they do exist"
    ],
    "Description": [
        "",
        "Some tokens, for example USDT (not a good example because auction tokens have to have 18 decimals) and KNC (18 decimals) have approval race protection mechanism and require the allowance to be either 0 or uint256.max when it is updated. The problem is that in VestedCrowdSale the following code is present:",
        "This will not work with tokens that have such a mechanism and will revert when currentAllowance is non-zero.",
        "Another issue is that there are tokens that do not follow the ERC20 standard (like USDT again) that do not return a bool on approve call. Those tokens are incompatible with the protocol because Solidity will check the return data size, which will be zero and will lead to a revert."
    ],
    "Recommendations": [
        "",
        "Do the approvals only in VestedCrowdSale::_claimAuctionTokens just before tokens are about to be locked, or just approve to zero first. Make sure to use forceApprove from SafeERC20."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-insufficient-input-validation-in-crowdsale-configuration-pashov-none-ipnft-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can lock up valuable tokens almost permanently"
    ],
    "Likelihood": [
        "\nLow, as it requires a fat-finger or a big configuration error"
    ],
    "Description": [
        "",
        "There are two flaws in the configuration validation of a new CrowdSale. It is currently possible to create a never ending Sale as the closingTime field does not have a max value check. It is also possible that a never ending lock or a 0 duration lock is used in VestedCrowdSale as the cliff argument of startSale is not validated as in StakedVestedCrowdSale::startSale. Both can result in almost permanently locked tokens which is a value loss for users."
    ],
    "Recommendations": [
        "",
        "Add proper min & max value bounds for both closingTime and cliff parameters."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-tokens-with-a-fee-on-transfer-mechanism-will-break-the-protocol-pashov-none-ipnft-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "sale.auctionToken.safeTransferFrom(msg.sender, address(this), sale.salesAmount);\n"
    ],
    "Impact": [
        "\nHigh, as some users will lose value"
    ],
    "Likelihood": [
        "\nLow, as such tokens are not common"
    ],
    "Description": [
        "",
        "The ERC20 logic in all crowd sale contracts as well as in TimelockedToken is incompatible with tokens that have a fee-on-transfer mechanism. Such tokens for example is PAXG, while USDT has a built-in fee-on-transfer mechanism that is currently switched off. One example of this CrowdSale::startSale where the following code:",
        "Will work incorrectly if the token has a fee-on-transfer mechanism - the contract will cache sale.salesAmount as it's expected balance, but it will actually have sale.salesAmount - fee balance. This will result in a revert in the last person to transfer auctionTokens out of the contract. Same thing applies for other transferFrom calls that transfer tokens into the protocol, for example in TimelockedToken::lock."
    ],
    "Recommendations": [
        "",
        "You should cache the balance before a transferFrom to the contract and then check it after the transfer and use the difference between them as the newly added balance. This also requires a nonReentrant modifier, as otherwise ERC777 tokens can manipulate this. Another fix is to just document and announce you do not support tokens that can have a fee-on-transfer mechanism."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-the-protocol-uses-_msgsender-extensively-but-not-everywhere-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nLow, because protocol will still function normally, but an expectedly desired types of transactions won't work"
    ],
    "Likelihood": [
        "\nHigh, because it is certain that he issue will occur as code is"
    ],
    "Description": [
        "",
        "The code is using OpenZeppelin's Context contract which is intended to allow meta-transactions. It works by using doing a call to _msgSender() instead of querying msg.sender directly, because the method allows those special transactions. The problem is that the onlyDelegate and onlyFundApprover modifiers in LoanVault use msg.sender directly instead of _msgSender(), which breaks this intent and will not allow meta-transactions at all in the methods that have those modifiers, which are one of the important ones in the LoanVault contract."
    ],
    "Recommendations": [
        "",
        "Change the code in the onlyDelegate and onlyFundApprover modifiers to use _msgSender() instead of msg.sender."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-the-erc4626-standard-is-not-followed-correctly-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, as functionality is not working as expected but without a value loss"
    ],
    "Likelihood": [
        "\nMedium, as multiple methods are not compliant with the standard"
    ],
    "Description": [
        "",
        "As per EIP-4626, the maxDeposit method \"MUST factor in both global and user-specific limits, like if deposits are entirely disabled (even temporarily) it MUST return 0.\". This is not the case currently, as even if the contract is paused, the maxDeposit method will still return what it usually does.",
        "When it comes to the decimals method, the EIP says: \"Although the convertTo functions should eliminate the need for any use of an EIP-4626 Vault\u2019s decimals variable, it is still strongly recommended to mirror the underlying token\u2019s decimals if at all possible, to eliminate possible sources of confusion and simplify integration across front-ends and for other off-chain users.\"\nThe LoanVault contract has hardcoded the value of 18 to be returned when decimals are called, but it should be the decimals of the underlying token (it might not be 18 in some case maybe)."
    ],
    "Recommendations": [
        "",
        "Go through the standard and follow it for all methods that override methods from the inherited ERC4626 implementation."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-anyone-can-move-eurs-tokens-that-the-user-allowed-florintreasury-to-spend-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function depositEUR(address from, uint256 eurTokens) external whenNotPaused {\n    eurTokens = Util.convertDecimals(eurTokens, 18, Util.getERC20Decimals(eurToken));\n    SafeERC20Upgradeable.safeTransferFrom(florinToken, from, address(this), eurTokens);\n    emit DepositEUR(_msgSender(), from, eurTokens);\n}\n"
    ],
    "Impact": [
        "\nHigh, as funds will be moved from a user's wallet unwillingly"
    ],
    "Likelihood": [
        "\nHigh, as it requires no preconditions and is a common attack vector"
    ],
    "Description": [
        "",
        "The depositEUR method in FlorinTreasury looks like this:",
        "The problem is that the from argument is user controlled, so anyone can check who has allowed the FlorinTreasury contract to spend his tokens and then pass that address as the from argument of the method. This will move eurTokens amount of EURS tokens from the exploited user to the FlorinTreasury contract, even though the user did not do this himself. The depositEUR method is expected to be called by LoanVault::repayLoan or LoanVault::depositRewards, where the user should first approve the FlorinTreasury contract to spend his EURS tokens. This is especially problematic if the user set type(uint256).max as the allowance of the contract, because in such case all of his EURS balance can be drained."
    ],
    "Recommendations": [
        "",
        "Use msg.sender instead of a user-supplied from argument, so tokens can only be moved from the caller's account."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-stakersvault-depositors-can-be-front-run-and-lose-their-funds-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it results in a theft of user assets"
    ],
    "Likelihood": [
        "\nMedium, as it works only if the attacker is the first staker"
    ],
    "Description": [
        "",
        "Let's look at the following example:",
        "This can be replayed multiple times until the depositors notice the problem."
    ],
    "Note": [
        " This absolute same problem is present with the ERC4626 logic in LoanVault, as it is a common vulnerability related to vault shares calculations. OpenZeppelin has introduced a way for mitigation in version 4.8.0 which is the used version by this protocol."
    ],
    "Recommendations": [
        "",
        "UniswapV2 fixed this with two types of protection:",
        "First, on the first mint it actually mints the first 1000 shares to the zero-address",
        "Second, it requires that the minted shares are not 0",
        "Implementing them both will resolve this vulnerability."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-chainlink-price-feeds-input-is-not-properly-validated-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(, int256 exchangeRate, , , ) = fundingTokenChainLinkFeeds[fundingToken].latestRoundData();\n\nif (exchangeRate == 0) {\n    revert Errors.ZeroExchangeRate();\n}\n",
        "- (, int256 exchangeRate, , , ) = fundingTokenChainLinkFeeds[fundingToken].latestRoundData();\n+ (, int256 exchangeRate, , uint256 updatedAt , ) = fundingTokenChainLinkFeeds[fundingToken].latestRoundData();\n\n- if (exchangeRate == 0) {\n+ if (exchangeRate <= 0) {\n    revert Errors.ZeroExchangeRate();\n}\n\n+ if (updatedAt < block.timestamp - 60 * 60 /* 1 hour */) {\n+   pause();\n+}\n"
    ],
    "Impact": [
        "\nHigh, as it can result in the application working with an incorrect asset price"
    ],
    "Likelihood": [
        "\nLow, as Chainlink oracles are mostly reliable, but there has been occurrences of this issue before"
    ],
    "Description": [
        "",
        "The code in LoanVault::getFundingTokenExchangeRate uses a Chainlink price oracle in the following way:",
        "This has some validation but it does not check if the answer (or price) received was actually a stale one. Reasons for a price feed to stop updating are listed here. Using a stale price in the application can result in wrong calculations in the vault shares math which can lead to an exploit from a bad actor."
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:",
        "This way you will also check for negative price (as it is of type int256) and also for stale price. To implement the pausing mechanism I proposed some other changes will be needed as well, another option is to just revert there."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-user-exitclaim-methods-should-not-have-a-whennotpaused-modifier-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as user funds can be left stuck in the contract"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or a compromised owner"
    ],
    "Description": [
        "",
        "The unstake and claim methods in FlorinStaking have a whenNotPaused modifier and the same is true for the redeem and _withdraw methods in LoanVault. This opens up an attack vector, where the protocol owner can decide if the users are able to withdraw/claim any funds from it. There is also the possibility that an admin pauses the contracts and renounces ownership, which will leave the funds stuck in the contract forever."
    ],
    "Recommendations": [
        "",
        "Remove the whenNotPaused modifier from user exit/claim methods in the protocol or reconsider the Pausable integration in the protocol altogether."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-the-apr-and-fundingfee-percentage-values-are-not-constrained-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as this can result in the contract being in a state of DoS or in 0 rewards for users"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or a compromised owner, or a big mistake on the owner side"
    ],
    "Description": [
        "",
        "Neither the setApr nor the setFundingFee methods have input validations, checking if the percentage value arguments are too big or too small. A malicious/compromised owner, or one that does a \"fat-finger\", can input a huge number as those methods' argument, which will result in a state of DoS for the contract. Also the values of 0 or 100 (percentage) are valid as well, but shouldn't be - they will result in either 0 rewards for users or high fees (100% fees are not possible because of the slippage check in approveFundingAttempt)."
    ],
    "Recommendations": [
        "",
        "Add a min and max value checks in both the setApr and setFundingFee methods in LoanVault."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-multiple-centralization-attack-vectors-are-present-in-the-protocol-pashov-none-florence-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can result in a rug from the protocol owner"
    ],
    "Likelihood": [
        "\nLow, as it requires a compromised or a malicious owner"
    ],
    "Description": [
        "",
        "The protocol owner has privileges to control the funds in the protocol or the flow of them.",
        "The mint function in FlorinToken is callable by the contract owner, which is FlorinTreasury, but FloriNTreasury has the transferFlorinTokenOwnership method. This makes it possible that the FlorinTreasury deployer to mint as many FlorinToken tokens to himself as he wants, on demand.",
        "The withdraw method in FlorinStaking works so that the owner can move all of the staked florinToken tokens to any wallet, including his.",
        "The setMDCperFLRperSecond method in FlorinStaking works so that the owner can stop the rewards at any time or unintentionally distribute them in an instant.",
        "The method setFundingTokenChainLinkFeed allows the owner to set any address as the new Chainlink feed, so he can use an address that he controls and returns different prices based on rules he decided."
    ],
    "Recommendations": [
        "",
        "Consider removing some owner privileges or put them behind a Timelock contract or governance."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-revoke-mechanics-are-not-compatible-with-tokens-that-implement-a-block-list-feature-pashov-none-moleculevesting-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as important functionality in the protocol won't work"
    ],
    "Likelihood": [
        "\nLow, as a special type of ERC20 token has to be used as well as the attacker's address has to be in a block list"
    ],
    "Description": [
        "",
        "Some tokens, for example USDC and USDT implement an admin controlled address block list. All transfers to a blocked address will revert. Since the revoke functionality forcefully transfers the claimable vested tokens to an address with a vestingSchedule, all calls to revoke will revert if such an address has claimable balance and is in the token's block list."
    ],
    "Recommendations": [
        "",
        "Use the Pull over Push pattern to send tokens out of the contract in a revoke scenario."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-insufficient-input-validation-in-function-createvestingschedule-pashov-none-moleculevesting-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can lead to users never vesting their tokens"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious/compromised admin or an error on his side"
    ],
    "Description": [
        "",
        "The input arguments of the createVestingSchedule function are not sufficiently validated. Here are some problematic scenarios:"
    ],
    "Recommendations": [
        "",
        "Add sensible lower and upper bounds for all arguments of the createVestingSchedule method."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-contract-can-receive-eth-but-has-no-withdraw-function-for-it-pashov-none-moleculevesting-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as value can be stuck forever"
    ],
    "Likelihood": [
        "\nLow, as it should be an error that someone sends ETH to the contract"
    ],
    "Description": [
        "",
        "The TokenVesting contract has receive and fallback functions that are payable. If someone sends a transaction with msg.value != 0 then the ETH will be stuck in the contract forever without a way for anyone to withdraw it."
    ],
    "Recommendations": [
        "",
        "Remove the receive and fallback functions since the ETH balance is not used in the contract anyway."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-users-wont-be-able-to-claim-vested-tokens-when-contract-is-paused-pashov-none-moleculevesting-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as owner has the power to make it so that users can't claim any vested tokens"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious or a compromised owner"
    ],
    "Description": [
        "",
        "The owner can currently execute the following attack:",
        "This is a common centralization problem which means the contract owner can \"rug\" users."
    ],
    "Recommendations": [
        "",
        "Remove the whenNotPaused modifier from releaseAvailableTokensForHolder, so users can claim vested tokens even if admin pauses the contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-anyone-can-steal-all-honeyjar-nfts-in-honeyjarportal-and-exploit-its-allowances-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _debitFrom(address _from, uint16, bytes memory, uint _tokenId) internal override {\n    honeyJar.safeTransferFrom(_from, address(this), _tokenId); // Performs the owner & approval checks\n}\n"
    ],
    "Impact": [
        "\nHigh, as it is a value loss for users"
    ],
    "Likelihood": [
        "\nHigh, as it is a common vulnerability and requires no preconditions"
    ],
    "Description": [
        "",
        "The _debitFrom function in HoneyJarPortal is exploitable, as it looks like this:",
        "Since there is no check for the _from argument, anyone can call the function (through the sendFrom method in ONFT721Core) and pass the address of HoneyJarPortal as the _from argument and his address as the _toAddress argument in the sendFrom method and essentially steal every NFT that is owned by the HoneyJarPortal. It can also steal NFTs that HoneyJarPortal does not own, but is an approved spender of, since the safeTransferFrom method will complete successfully."
    ],
    "Recommendations": [
        "",
        "In _debitFrom check that the owner of the _tokenId NFT is the msg.sender."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-reentrancy-allows-any-user-allowed-even-one-free-honeyjar-mint-to-mint-the-max-supply-for-himself-for-free-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "_canMintHoneyJar(bundleId_, numClaim); // Validating here because numClaims can change\n\n// If for some reason this fails, GG no honeyJar for you\n_mintHoneyJarForBear(msg.sender, bundleId_, numClaim);\n\nclaimed[bundleId_] += numClaim;\n// Can be combined with \"claim\" call above, but keeping separate to separate view + modification on gatekeeper\ngatekeeper.addClaimed(bundleId_, gateId, numClaim, proof);\n"
    ],
    "Impact": [
        "\nHigh, as the user will steal all HoneyJar NFTs, paying nothing"
    ],
    "Likelihood": [
        "\nHigh, as reentrancy is a very common attack vector and easily exploitable"
    ],
    "Description": [
        "",
        "The claim method in HoneyBox (from its NatSpec) \"Allows a player to claim free HoneyJar based on eligibility\". Let's look at this part of its code:",
        "Where you update the claimed mapping and account for the claim in the Gatekeeper contract after you actually do the minting itself. The problem is that the _mintHoneyJarForBear method calls honeyJar::batchMint, that uses safeMint, which does an unsafe external call to the mint recipient. This call can reenter the claim method while the claimed accounting was still not done and actually claim all of the HoneyJar NFTs until mintConfig.maxHoneyJar is hit, which will most likely make him the winner of the game so he will get all of the NFTs in it as well, paying nothing.",
        "What makes it worse as well is that even though the claim method has protection because it accepts a gateId argument, and the gates themselves have a maxClaimable property, this is also broken since the gatekeeper::addClaimed call is also done after the unsafe external call, so multiple invariants can be broken here."
    ],
    "Recommendations": [
        "",
        "Make sure the claim method is following the Checks-Effects-Interactions pattern or add a nonReentrant modifier to it."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-03-anyone-can-mint-all-nfts-through-the-public-mint-before-it-has-even-started-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (slumberParties[bundleId_].publicMintTime > block.timestamp) revert GeneralMintNotOpen(bundleId_);\n"
    ],
    "Impact": [
        "\nHigh, as it breaks an important protocol invariant and the way the protocol should work overall"
    ],
    "Likelihood": [
        "\nHigh, as it does not need any preconditions, can be executed easily at the deployment of HoneyBox"
    ],
    "Description": [
        "",
        "Both the mekHoneyJarWithERC20 and mekHoneyJarWithETH methods are ways for the players to mint HoneyJar NFTs, but they should work only when general mint is open, as shown in this check that is present in both methods:",
        "The problem is that anyone can call both methods anytime before the first bundle was added. If there were no bundles, this means that if a user supplied bundleId_ == 0 to either method, all of the values in the slumberParties[bundleId_] mapping will have a default value, passing all of the checks in the methods and in the _canMintHoneyJar method. This essentially means anyone can front-run the games and mint the maximum available HoneyJar configured in the mintConfig."
    ],
    "Recommendations": [
        "",
        "In _canMintHoneyJar, revert if slumberParties[bundleId_].publicMintTime == 0, this means that this bundle is not initialized yet. This will cover this attack vector and any other bundleId == 0 attack as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-04-re-requesting-randomness-from-vrf-is-a-security-anti-pattern-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Re-requesting randomness is easily detectable on-chain and should be avoided for use cases that want to be considered as using VRFv2 correctly.\n"
    ],
    "Impact": [
        "\nHigh, as the VRF service provider has control over who wins the game"
    ],
    "Likelihood": [
        "\nHigh, as there is an incentive for a VRF provider to exploit this and it is not hard to do from his side"
    ],
    "Description": [
        "",
        "The forceHoneyJarSearch method is used to \"kick off another VRF request\", as mentioned in its NatSpec. This goes against the security standards in using VRF, as stated in the docs:",
        "Basically, the service provider can withhold a VRF fulfillment until a new request that is favorable for them comes."
    ],
    "Recommendations": [
        "",
        "Remove the forceHoneyJarSearch method as it is exploitable."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-mint-function-mekhoneyjarwitheth-will-revert-every-time-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "-    function mekHoneyJarWithETH(uint8 bundleId_, uint256 amount_) external returns (uint256) {\n+    function mekHoneyJarWithETH(uint8 bundleId_, uint256 amount_) external payable returns (uint256) {\n"
    ],
    "Impact": [
        "\nMedium, as there is an option to mint with ERC20 tokens too"
    ],
    "Likelihood": [
        "\nHigh, as the function will just revert every time"
    ],
    "Description": [
        "",
        "The HoneyBox contract exposes a way for users to mint HoneyJar NFTs with ETH in a public sale by the mekHoneyJarWithETH method. The problem is that the method uses msg.value to calculate the expected price, as the name suggest, that would have been paid with ETH, but the method is missing the payable keyword. Every call with msg.value != 0 to the method will revert."
    ],
    "Recommendations": [
        ""
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-admin-account-has-a-lot-of-power-in-the-protocol-and-multiple-ways-to-denysteal-users-rewards-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as the admin can steal funds from users(players)"
    ],
    "Likelihood": [
        "\nMedium, as it requires a malicious or a compromised admin, but the incentives are high"
    ],
    "Description": [
        "",
        "There are multiple centralization flaws and attack vectors in the protocol:"
    ],
    "Recommendations": [
        "",
        "Redesign all methods that can be used as rug pulls and possibly make the admin in the protocol a Timelock contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-possible-overflow-will-break-the-logic-in-honeybox-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        uint8 bundleId = uint8(slumberPartyList.length); // Will fail if we have >255 bundles\n"
    ],
    "Impact": [
        "\nHigh, as bundles storage variables will be overwritten"
    ],
    "Likelihood": [
        "\nLow, as it is not expected to add more than 255 bundles"
    ],
    "Description": [
        "",
        "In HoneyBox::addBundle we have the following code:",
        "The comment is wrong, as it assumes that the cast is safe and will revert if slumberPartyList.length > 255 but this is not the case as it will just overflow. This will be a big problem as then already existing bundleId values will be overwritten in the slumberParties mapping, which will break the logic of the contract."
    ],
    "Recommendations": [
        "",
        "Use a SafeCast library or revert if slumberPartyList.length > 255."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-multiple-flaws-in-the-gate-reset-logic-in-gatekeeper-pashov-none-bearcave-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, as no value will be lost but the contract state will be incorrect"
    ],
    "Likelihood": [
        "\nMedium, as it is not expected to happen every time, but there are multiple attack paths here"
    ],
    "Description": [
        "",
        "The resetAllGates method is iterating over unbounded arrays - both tokenToGates[tokenId] and consumedProofsList[gateId] arrays are unbounded. This might result in a state of DoS for the resetAllGates method, since it might take too much gas to iterate over the arrays (more than the block gas limit).",
        "Another, bigger problem in the method, is that it does not do delete on tokenToGates[tokenId] - even though it sets claimedCount to 0, it does not set claimed to false for example, so methods that check this will still think that claimed == true (for example validateProof checks it)."
    ],
    "Recommendations": [
        "",
        "Make sure to add an upper bound to both tokenToGates[tokenId] and consumedProofsList[gateId] arrays size, in the addGate and addClaimed methods respectively. Make sure to call delete on tokenGates[i] in the first for loop in resetAllGates and also emit an GateReset event for each reset gate in the resetAllGates method."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-anyone-can-make-new-bids-always-revert-after-a-window-expires-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (hasExpired) {\n    window = _window[auctionId][windowExpiration(auctionId)];\n}\n",
        "if (window.processed) {\n    revert WindowFulfilled();\n}\n"
    ],
    "Impact": [
        "\nHigh, as all new bidding will revert until auction ends"
    ],
    "Likelihood": [
        "\nHigh, as anyone can execute the attack without rare preconditions"
    ],
    "Description": [
        "",
        "The fulfillWindow method is a public method that is also called internally. It sets window.processed to true, which makes it callable only once for a single windowId. The problem is that the commitBid function has the following logic:",
        "Where windowExpiration calls fulfillWindow with the latest windowId in itself. If any user manages to call fulfillWindow externally first, then the window.processed will be set to true, making the following check in fulfillWindow",
        "revert on every commitBid call from now on. This will result in inability for anyone to place more bids, so the auction will not sell anything more until the end of the auction period."
    ],
    "Recommendations": [
        "",
        "Make fulfillWindow to be internal and then add a new public method that calls it internally but also has the inactiveAuction modifier as well - this way anyone will be able to complete a window when an auction is finished even though no one can call commitBid."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-successful-bidders-can-lose-significant-value-due-to-division-rounding-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "_auctions[auctionId].reserves -= volume / price;\n_auctions[auctionId].proceeds += volume;\n\n_claims[bidder][auctionId] = abi.encode(refund - volume, claim + (volume / price));\n"
    ],
    "Impact": [
        "\nHigh, as possibly significant value will be lost"
    ],
    "Likelihood": [
        "\nHigh, as it will happen with most bids"
    ],
    "Description": [
        "",
        "The fulfillWindow method calculates the auction reserves and proceeds after a successful bid in a window. Here is how it accounts it in both the auctions and claims storage mappings:",
        "The problem is in the volume / price division and the way Solidity works - since it only has integers, in division the result is always rounded down. This would mean the bidder will have less claim tokens than expected, while the _auctions[auctionId].reserves will keep more tokens than it should have. Let's look at the following scenario:",
        "Every remainder of the volume / price division will result in a loss for the bidder."
    ],
    "Recommendations": [
        "",
        "Design the code so that the remainder of the volume / price division gets refunded to the bidder, for example adding it to the refund value."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-03-the-logic-in-elapsedtime-is-flawed-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as the method is used to calculate the price of the auction but will give out wrong results"
    ],
    "Likelihood": [
        "\nHigh, as the problems are present almost all of the time during an auction"
    ],
    "Description": [
        "",
        "There are multiple flaws with the elapsedTime method:",
        "The method has multiple flaws and works only in the happy-case scenario."
    ],
    "Recommendations": [
        "",
        "Remove the method altogether or extract two methods out of it, removing the timestamp parameter to simplify the logic. Also think about the edge case scenarios."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-users-are-likely-to-lose-their-bid-if-purchasetoken-is-a-low-decimals-token-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "_auctions[auctionId].reserves -= volume / price;\n_auctions[auctionId].proceeds += volume;\n\n_claims[bidder][auctionId] = abi.encode(refund - volume, claim + (volume / price));\n"
    ],
    "Impact": [
        "\nHigh, because users will lose their entire bid amount"
    ],
    "Likelihood": [
        "\nMedium, because it happens when purchaseToken is a low-decimals token, but those are commonly used"
    ],
    "Description": [
        "",
        "When a user calls commitBid he provides a volume parameter, which is the amount of purchaseToken he will bid, and a price parameter, which is the price in reserveToken. His bid is then cached and when window expires the fulfillWindow method is called, where we have this logic:",
        "The problem lies in the volume / price calculation. In the case that the reserveToken is a 18 decimal token (most common ones) but the purchaseToken has a low decimals count - USDC, USDT and WBTC have 6 to 8 decimals, then it's very likely that the volume / price calculation will result in rounding down to 0. This means that the auction owner would still get the whole bid amount, but the bidder will get 0 reserveTokens to claim, resulting in a total loss of his bid.",
        "The issue is also present when you are using same decimals tokens for both reserve and purchase tokens but the volume in a bid is less than the price. Again, the division will round down to zero, resulting in a 100% loss for the bidder."
    ],
    "Recommendations": [
        "",
        "In commitBid enforce that volume >= price and in createAuction enforce that the reserveToken decimals are equal to the purchaseToken decimals."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-missing-input-validation-on-createauction-function-parameters-can-lead-to-loss-of-value-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can lead to stuck funds"
    ],
    "Likelihood": [
        "\nLow, as it requires user error/misconfiguration"
    ],
    "Description": [
        "",
        "There are some problems with the input validation in createAuction, more specifically related to the timestamp values.",
        "Those possibilities should all be mitigated, as they can lead to the initial reserves and/or the bids being stuck in the protocol forever."
    ],
    "Recommendations": [
        "",
        "Use a minimal duration value, for example 1 day, as well as a max value, for example 20 days. Make sure auction does not start more than X days after it has been created as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-loss-of-precision-in-scalarprice-function-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 b_18 = 1e18;\nuint256 t_mod = t % (t_r - t);\nuint256 x = (t + t_mod) * b_18 / t_r;\nuint256 y = !isInitialised ? state.price : window.price;\n\nreturn y - (y * x) / b_18;\n"
    ],
    "Impact": [
        "\nMedium, as the price will not be very far from the expected one"
    ],
    "Likelihood": [
        "\nMedium, as it will not always result in big loss of precision"
    ],
    "Description": [
        "",
        "In scalarPrice there is this code:",
        "Here, when you calculate x you divide by t_r even though later you multiply x by y. To minimize loss of precision you should always do multiplications before divisions, since Solidity just rounds down when there is a remainder in the division operation."
    ],
    "Recommendations": [
        "",
        "Always do multiplications before divisions in Solidity, make sure to follow this throughout the whole scalarPrice method."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-protocol-wont-work-correctly-with-tokens-that-do-not-revert-on-failed-transfer-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can lead to a loss of value"
    ],
    "Likelihood": [
        "\nLow, as such tokens are not so common"
    ],
    "Description": [
        "",
        "Some tokens do not revert on failure in transfer or transferFrom but instead return false (example is ZRX). While such tokens are technically compliant with the standard it is a common issue to forget to check the return value of the transfer/transferFrom calls. With the current code, if such a call fails but does not revert it will result in inaccurate calculations or funds stuck in the protocol."
    ],
    "Recommendations": [
        "",
        "Use OpenZeppelin's SafeERC20 library and its safe methods for ERC20 transfers."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-auction-wont-work-correctly-with-fee-on-transfer-rebasing-tokens-pashov-none-rolling-dutch-auction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "IERC20(reserveToken).transferFrom(msg.sender, address(this), reserveAmount);\n...\n...\nstate.reserves = reserveAmount;\n"
    ],
    "Impact": [
        "\nHigh, as it can lead to a loss of value"
    ],
    "Likelihood": [
        "\nLow, as such tokens are not so common"
    ],
    "Description": [
        "",
        "The code in createAuction does the following:",
        "so it basically caches the expected transferred amount. This will not work if the reserveToken has a fee-on-transfer mechanism, since the actual received amount will be less because of the fee. It is also a problem if the token used had a rebasing mechanism, as this can mean that the contract will hold less balance than what it cached in state.reserves for the auction, or it will hold more, which will be stuck in the protocol."
    ],
    "Recommendations": [
        "",
        "You can either explicitly document that you do not support tokens with a fee-on-transfer or rebasing mechanism or you can do the following:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-contract-inherits-from-pausable-but-does-not-expose-pausingunpausing-functionality-pashov-none-parcel-payroll-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nLow, as methods do not have whenNotPaused modifier"
    ],
    "Likelihood": [
        "\nHigh, as it is certain that contract can't be paused at all"
    ],
    "Description": [
        "",
        "The Organizer smart contract inherits from OpenZeppelin's Pausable contract, but the _pause and _unpause methods are not exposed externally to be callable and also no method actually uses the whenNotPaused modifier. This shows that Pausable was used incorrectly and is possible to give out a false sense of security when actually contract is not pausable at all."
    ],
    "Recommendations": [
        "",
        "Either remove Pausable from the contract or add whenNotPaused modifier to the methods that you want to be safer and also expose the _pause and _unpause methods externally with access control."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-value-of-leaf-argument-when-calling-addreserve-is-hardcoded-incorrectly-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint128 reward = lp.addReserve(\n    0,\n    fullPayout - amount,\n    fullPayout - payout,\n    0\n    );\n"
    ],
    "Impact": [
        "\nHigh, because liquidity won't be returned to the LiquidityTree"
    ],
    "Likelihood": [
        "\nHigh, because the incorrect value is hardcoded and can't be changed"
    ],
    "Description": [
        "",
        "In BetExpress::resolvePayout we can see the following code:",
        "where the last argument is 0 sent as a value for the leaf parameter. Since the leafs counting begins at 1, this will always be wrong and the liquidity won't be returned to the LiquidityTree."
    ],
    "Recommendation": [
        "",
        "The value of leaf should be the leaf value of each condition in the bet. The current design of resolvePayout does not allow to work on each condition in isolation, so this would need a redesign where you handle each condition separately."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-protection-check-for-maxbetshare-can-be-gamed-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, because a protocol invariant can be broken and the code gives a false sense of security"
    ],
    "Likelihood": [
        "\nMedium, as it can easily be gamed but there is no incentive for an attacker"
    ],
    "Description": [
        "",
        "The lockLiquidity method tries to block a single bet from taking up too much of the LP's allowed liquidity limit, but this can be gamed by splitting a very large bet into a big number of smaller ones, so this LargeBet custom error check would give a false sense of security as it doesn't guarantee what it intended to."
    ],
    "Recommendations": [
        "",
        "Change the validation to be based on all bets made through BetExpress instead of on each bet in isolation."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-tokens-with-a-no-op-fallback-function-can-be-used-to-steal-the-eth-balance-of-lp-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (isNative) {\n    IWNative(token).withdraw(amount);\n    TransferHelper.safeTransferETH(account, amount);\n} else {\n    TransferHelper.safeTransfer(token, account, amount);\n}\n"
    ],
    "Impact": [
        "\nHigh, because it can lead to stolen funds from the protocol"
    ],
    "Likelihood": [
        "\nLow, as it requires a token with a fallback function but without a withdraw function"
    ],
    "Description": [
        "",
        "In LP::withdrawPayout we have the following code:",
        "Now imagine the following scenario:",
        "The attack is similar to this one and even though it requires a special token and the LP to hold liquidity it is still a potential attack vector."
    ],
    "Recommendations": [
        "",
        "You can implement team processes about adding specific token contracts to be used in LP, where you have a checklist that contains not including tokens with a fallback function that are missing a withdraw function. You can also check the balance of LP before and after the withdraw call so you see it changed accordingly."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-users-can-split-a-token-to-more-fractions-than-the-units-held-at-tokenid-pashov-none-hypercerts-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "-_mintBatch(_account, toIDs, amounts, \"\");\n-\n-tokenValues[_tokenID] = valueLeft;\n+tokenValues[_tokenID] = valueLeft;\n+\n+_mintBatch(_account, toIDs, amounts, \"\");\n"
    ],
    "Impact": [
        "\nHigh, as it breaks an important protocol invariant"
    ],
    "Likelihood": [
        "\nHigh, as those types of issues are common and are easily exploitable"
    ],
    "Description": [
        "",
        "The _splitValue method in SemiFungible1155 does not follow the Checks-Effects-Interactions pattern and it calls _mintBatch from the ERC1155 implementation of OpenZeppelin which will actually do a hook call to the recipient account as a safety check. This call is unsafe as it can reenter the _splitValue method and since tokenValues[_tokenID] hasn't been updated yet, it can once again split the tokens into more fractions and then repeat until a huge amount of tokens get minted."
    ],
    "Recommendation": [
        "",
        "Follow the Checks-Effects-Interactions pattern"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-calling-splitvalue-when-token-index-is-not-the-latest-will-overwrite-other-claims-storage-pashov-none-hypercerts-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 currentID = _tokenID;\n...\ntoIDs[i] = ++currentID;\n...\nfor (uint256 i; i < len; ) {\n    valueLeft -= values[i];\n\n    tokenValues[toIDs[i]] = values[i];\n\n    unchecked {\n        ++i;\n    }\n}\n...\n_mintBatch(_account, toIDs, amounts, \"\");\n",
        "- maxIndex[_typeID] += len;\n...\n- toIDs[i] = ++currentID;\n+ toIDs[i] = _typeID + ++maxIndex[typeID];\n"
    ],
    "Impact": [
        "\nHigh, as it can lead to loss of units for an account without any action on his side"
    ],
    "Likelihood": [
        "\nMedium, because it can happen only with a token that has a non-latest index"
    ],
    "Description": [
        "",
        "The logic in _splitValue is flawed here:",
        "Let's look at the following scenario:",
        "Now we will have tokenValues[toIDs[i]] = values[i] where toIDs[i] is ++currentID which is 2 and values[i] is 5, so now tokenValues[2] = 5 which is overwriting the tokenValues of Bob. Also, later _mintBatch is called with Bob's token ID as a token ID, which will make some of the split tokens be of the type of Bob's token."
    ],
    "Recommendations": [
        "",
        "Change the code the following way:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-unused-function-parameters-can-lead-to-false-assumptions-on-user-side-pashov-none-hypercerts-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nLow, because the caller still controls the minted token"
    ],
    "Likelihood": [
        "\nHigh, because users will provide values to those parameters and their assumptions about their usage will always be false"
    ],
    "Description": [
        "",
        "The units parameter in mintClaimWithFractions is used only in the event emission. This is misleading as actually fractions.length number of fractions will be minted. If units != fractions.length this can have unexpected consequences for a user. The same is the problem with the account parameter in both mintClaim and mintClaimWithFractions - it is not used in the method and actually msg.sender is the account to which tokens are minted and is set as the token creator. Again if account != msg.sender this is unexpected from a user standpoint and while in the best case scenario leads to a not so great UX, in the worst case it can lead to faulty assumptions for value received by the account address."
    ],
    "Recommendations": [
        "",
        "Remove the units parameter from mintClaimWithFractions and also use account instead of msg.sender in the _mintValue call in mintClaim and mintClaimWithFractions."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-input-data-validation-is-missing-or-incomplete-pashov-none-hypercerts-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, because in some cases this can lead to DoS and unexpected behaviour"
    ],
    "Likelihood": [
        "\nLow, as it requires malicious user or a big error on the user side"
    ],
    "Description": [
        "",
        "Multiple methods are missing input/data validation or it is incomplete."
    ],
    "Recommendations": [
        "",
        "Add the checks mentioned for all inputs and logic."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-its-impossible-for-a-user-to-claim-his-rewards-as-claimreward-will-never-send-out-usdc-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "USDc.transferFrom(msg.sender, address(this), claimableRewards);\n",
        "- USDc.transferFrom(msg.sender, address(this), claimableRewards);\n+ USDc.transfer(msg.sender, claimableRewards);\n"
    ],
    "Impact": [
        "\nHigh, because users will never receive rewards from the contract"
    ],
    "Likelihood": [
        "\nHigh, because the code just uses the ERC20 API incorrectly"
    ],
    "Description": [
        "",
        "The claimReward method should be used by a staker to receive USDC rewards for his locked NFTs. This won't ever work, as the transfer of the rewards is implemented with this code:",
        "This is wrong as it will transfer USDC from the staker to the staking contract instead of the other way around."
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:",
        "Make sure to always use the ERC20 API correctly and also to have complete code coverage with unit tests of the codebase prior to having an audit."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-calculation-for-owedamount-will-round-down-to-zero-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "owedAmount = (currentShareRaw / pool[_poolNumber].currentGlobalShare) * pool[_poolNumber].value;\n",
        "- owedAmount = (currentShareRaw / pool[_poolNumber].currentGlobalShare) * pool[_poolNumber].value;\n+ owedAmount = currentShareRaw * pool[_poolNumber].value / pool[_poolNumber].currentGlobalShare;\n"
    ],
    "Impact": [
        "\nHigh, as this will result in 0 claimable rewards for users when they should have been able to claim some"
    ],
    "Likelihood": [
        "\nHigh, as this will happen any time the user's share is smaller than the pool's cached global share, which is almost always"
    ],
    "Description": [
        "",
        "The claimCalculation method calculates the owedAmount that is about to be send to the user in the form of USDC rewards with the following calculation:",
        "This happens both if the _poolNumber == 1 and if it is a different value, but the code is present in both cases. The issue is that it does division before multiplication, where if the pool[_poolNumber].currentGlobalShare value is bigger than the currentShareRaw value, the division will round down to zero resulting in zero owedAmount. This will almost always happen as it is expected that the pool's cached currentGlobalShare will be bigger than a single user's raw share. This means that no matter how much a user waits he won't be able to claim his rewards for this pool, leaving them stuck in the contract forever.",
        "This issue was partly noticed by the developer mid-audit, where he fixed one of the places where owedAmount was calculated, but the other owedAmount calculation error one wasn't discovered."
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:",
        "So this way you do multiplication before division which will not round down to zero, as the pool's value is in USDC that has 6 decimals, but the shares have 18 decimals."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-users-will-forever-lose-their-accrued-rewards-if-they-call-withdrawstake-before-calling-claimreward-first-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as this will lead to a monetary loss for users"
    ],
    "Likelihood": [
        "\nMedium, as even though the front-end will enforce the right sequence of calls, the Gitbook docs falsely claims re-staking will re-gain user's access to their rewards"
    ],
    "Description": [
        "",
        "The contract is implemented so that if a user calls withdrawStake without first calling claimReward for each reward pool then the staker will lose all of his unclaimed rewards forever, they will be locked into the staking contract. While the front-end will enforce the right sequence of calls, the Gitbook docs state that When un-staked, a user will lose access to all their pending rewards and lose access to future rewards (unless they re-stake) which gives the impression that you can re-stake and then you will re-gain access to your unclaimed rewards, but this is not the case as the withdrawStake method removes the data needed for previous rewards calculation.",
        "Since the docs give a misleading information about they way this mechanism works and also users can interact directly with the smart contract in a bad way for them (when they are not malicious) this has a higher likelihood of happening and resulting a monetary value loss for users."
    ],
    "Recommendations": [
        "",
        "One possible solution is to enforce zero unclaimed rewards when a call to withdrawStake is made by reverting if there are any such unclaimed rewards. Another one is to just call claimReward in withdrawStake."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-wrong-check-in-claimcalculation-will-result-in-less-rewards-received-for-users-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "- if (_poolNumber == 1) {\n+ if (_poolNumber == 0) {\n"
    ],
    "Impact": [
        "\nHigh, as this will lead to a monetary loss for users"
    ],
    "Likelihood": [
        "\nMedium, as it happens only for the pool with an ID of 1"
    ],
    "Description": [
        "",
        "The first if statement in claimCalculation checks if (_poolNumber == 1) and does not factor in any inflation for that particular pool. The problem is that (it is also explained in the comment above the if statement) the intention was to check if there was only 1 pool (or if it was the first pool) then there is no need to do inflation calculations, which result in a higher reward. But when you have _poolNumber == 1 this means that you have at least 2 pools, as arrays start from an index of 0, so 1 is actually for the second pool in the pool array. This will result in all claimers of the rewards for staking in the pool with an ID of 1 missing out on their inflation rewards."
    ],
    "Recommendations": [
        "",
        "Change the code in the following way:"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-looping-over-unbounded-array-can-result-in-a-state-of-dos-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as the contract will be in a state of DoS, without a way for anyone to withdraw NFTs or claim rewards"
    ],
    "Likelihood": [
        "\nLow, as it requires a lot of pools added or a malicious owner"
    ],
    "Description": [
        "",
        "The claimCalculation and getCurrentShareRaw methods both loop over the pool array to do proper calculations. The problems is that there is no way to pop elements out of the array, but there is no upper bound on the length of the array. Each time the currentRewards are more than or equal to the minResetValue, the createPool method will be called, adding a new element to the pool array. If at some point there are now a large number of pools, iterating over them will become very costly and can result in a gas cost that is over the block gas limit. This will mean that a transaction cannot be executed anymore, leaving the contract's main functionalities (withdrawing the staked NFTs and claiming rewards) in a state of DoS."
    ],
    "Recommendations": [
        "",
        "Limit the number of pools that can be created, for example a maximum of 25 pools created."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-missing-constraint-on-the-setter-method-of-a-percentage-value-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it will result in wrong reward calculations"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious/compromised owner or a big error on his side"
    ],
    "Description": [
        "",
        "The setResetShareValue lacks a check that the _newShareResetValue argument is not more than 100%. Since it is expected that the value will be in percentages, setting a value that is bigger than 100 will mess with the important calculations in the contract, one of which is the rewards to claim calculation. This can make users receive a smaller reward than what they have earned since a bigger resetShareValue equals smaller rewards for users."
    ],
    "Recommendations": [
        "",
        "Add a check in setResetShareValue that the _newShareResetValue argument is not more than 100%."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-owner-has-the-power-to-zero-out-users-daily-interest-on-rewards-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as users can lose their right to claim accrued rewards"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious/compromised owner"
    ],
    "Description": [
        "",
        "The setDepositsActive method resets startTimestamp and lastGlobalUpdate. The owner can front-run each claimReward transaction and by resetting the startTimestamp this will result in 0 requiredRebases in calculateShareFromTime, so the user will lose on his daily interest. On the other side, by resetting lastGlobalUpdate this will make updateGlobalShares never do a rebase, which will never inflate the overallShare which also shouldn't be possible."
    ],
    "Recommendations": [
        "",
        "Make the setDepositsActive method callable only once after contract deployment."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-constraining-approvals-only-partially-limits-the-nfts-from-being-sold-pashov-none-lizardstarking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can lead to scams and bugs when integrating with other games/protocols"
    ],
    "Likelihood": [
        "\nLow, as such sales or integrations are not currently expected to happen and because information about this is present in the docs"
    ],
    "Description": [
        "",
        "Constraints on approvals (the onlyApprovedContracts modifier) were added so that the Locked Lizards NFTs can't be sold in marketplaces like OpenSea, Blur etc. This only partially limits selling the NFTs because users can always do OTC trades. Those trades will be scams though, since the original NFT owner can call retractLockedLizard anytime and re-gain ownership of the NFT. Not only sales will be problematic, but for example integrations with NFT games - the games are not expected to work properly with NFTs that can be retracted, as this opens up multiple attack-vectors."
    ],
    "Recommendations": [
        "",
        "Either remove the onlyApprovedContracts modifier and allow sales and integrations by removing the retractLockedLizard functionality, or just forbid the approve and transfer functionality altogether as otherwise they can result in problems."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-the-protection-check-for-maxrecordspertransaction-can-be-gamed-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, because a protocol invariant can be broken and the code gives a false sense of security"
    ],
    "Likelihood": [
        "\nMedium, because the attack is easy to do and we have seen such attacks in the past"
    ],
    "Description": [
        "",
        "Let's look at the following example scenario:",
        "Even though there was some kind of a protection against bots/snipers the result was still that only 1 account got to minting."
    ],
    "Recommendations": [
        "",
        "Document that the maxRecordsPerTransaction check does not protect the protocol from sniping attacks. To protect from them you can decide to use an off-chain process for pre-registrations of addresses that will be put into a Merkle tree and then validated on mint."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-insufficient-input-validation-opens-up-multiple-attack-vectors-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as it can overflow a balance and re-mint burned NFTs"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious/compromised owner account or an owner input error"
    ],
    "Description": [
        "",
        "The adminTransferFrom method does not validate that the from argument shouldn't have a value of address(0). Now if from == address(0) multiple attack vectors open:"
    ],
    "Recommendations": [
        "",
        "Add a check and assert that the from argument is not address(0)."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-owner-can-front-run-sequence-configurations-by-setting-fee-to-100-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "dropData.primarySaleFeeBps = primarySaleFeeBps;\n"
    ],
    "Impact": [
        "\nHigh, as if it goes unnoticed it can rug the revenueRecipient address"
    ],
    "Likelihood": [
        "\nLow, as it requires a malicious/compromised owner account"
    ],
    "Description": [
        "",
        "The setPrimarySaleFeeBps is callable at any time by the contract owner address and will update the fee variable immediately. Now if a user is trying to call configureSequence, the owner can front-run the user call, update the fee to 100% and since there is this code in configureSequence",
        "Now the whole mint payment for this sequence drop will go to the contract owner. He can also execute this attack and front-run each configureSequence call to get all mints' ETH value."
    ],
    "Recommendations": [
        "",
        "Since the user provides dropData.primarySaleFeeBps, check that he expected the same fee as the one that is currently set in DropEngineV2 and if the current one is bigger revert the transaction. Also it is generally recommended to not allow fee to go up to 100% - lower the upper limit to a sensible number."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-01-contract-is-missing-a-payable-function-which-makes-it-impossible-to-operate-with-native-assets-pashov-none-parcel-payroll-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as all transactions that use native assets will revert"
    ],
    "Likelihood": [
        "\nHigh, as it is well expected that native assets will be used as a paymentToken often"
    ],
    "Description": [
        "",
        "The PayrollManager does not have a receive function that is marked as payable neither any payable function at all. This will make it impossible for the contract to work with native assets because all transfers from the Gnosis Safe multisig to him will revert."
    ],
    "Recommendations": [
        "",
        "Add a payable fallback or receive function in PayrollManager to allow for native assets transfers."
    ]
}
----End JSON----

https://solodit.xyz/issues/c-02-contract-fails-to-handle-address0-as-a-native-asset-for-its-zero-balance-left-invariant-pashov-none-parcel-payroll-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Check if the contract has any tokens left\nfor (uint256 i = 0; i < paymentTokens.length; i++) {\n    IERC20 erc20 = IERC20(paymentTokens[i]);\n    if (erc20.balanceOf(address(this)) > 0) {\n        // Revert if the contract has any tokens left\n        revert(\"CS018\");\n    }\n}\n",
        "if (tokenAddress[i] == address(0)) {\n    // Transfer ether\n    payable(to[i]).transfer(amount[i]);\n    packPayoutNonce(true, payoutNonce[i]);\n}\n"
    ],
    "Impact": [
        "\nHigh, as all transactions that use native assets will revert"
    ],
    "Likelihood": [
        "\nHigh, as it is well expected that native assets will be used as a paymentToken often"
    ],
    "Description": [
        "",
        "The executePayroll method has the following code at the end of it:",
        "A few lines above the code looks like this:",
        "Which shows us that address(0) is used to handle native assets transfers. The problem is that the formerly mentioned code does not handle this address(0) token correctly, so if the paymentTokens array contains it the whole transaction will revert."
    ],
    "Recommendations": [
        "",
        "Check separately for the native asset balance of the contract in the end of executePayroll and ignore address(0) when calling ERC20::balanceOf for the paymentTokens array values."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-using-the-transfer-function-of-address-payable-is-discouraged-pashov-none-parcel-payroll-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, as payroll will revert and Merkle Trees & approvals would have to be done again"
    ],
    "Likelihood": [
        "\nMedium, as it happens any time the recipient is a smart contract or a multisig wallet that has a receive function taking up more than 2300 gas"
    ],
    "Description": [
        "",
        "The executePayroll function uses the transfer method of address payable to transfer native asset funds to a recipient address. This address is set by the caller but is also encoded in the leaf of a Merkle Tree that is created off-chain. It is possible that this recipient is a smart contract that has a receive or fallback function that takes up more than the 2300 gas which is the limit of transfer. Examples are some smart contract wallets or multi-sig wallets, so usage of transfer is discouraged."
    ],
    "Recommendations": [
        "",
        "Use a call with value instead of transfer. The function already has a nonReentrant modifier so reentrancy is not a problem here."
    ]
}
----End JSON----

https://solodit.xyz/issues/02-usage-of-non-standard-erc20-tokens-might-lead-to-stuck-funds-pashov-none-parcel-payroll-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, because tokens will be left stuck in PayrollManager"
    ],
    "Likelihood": [
        "\nLow, because there aren't many such ERC20 tokens"
    ],
    "Description": [
        "",
        "The executePayroll method uses the transfer method of ERC20, but does not check if the returned bool value is true. This is problematic, because there are tokens on the blockchain which actually do not revert on failure but instead return false (example is ZRX). If such a token is used and a transfer fails, the tokens will be stuck in the PayrollManager smart contract forever."
    ],
    "Recommendations": [
        "",
        "Use the SafeERC20 library from OpenZeppelin and change the transfer call to a safeTransfer call instead."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-insufficient-input-data-validation-for-configuresequence-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as some of those can result in a DoS or too big of a royalty payment"
    ],
    "Likelihood": [
        "\nLow, as it requires a configuration error or a malicious actor"
    ],
    "Description": [
        "",
        "An authorized address for a node can call Collection::configureSequence where most of the input is not validated properly. The _sequence parameter of the method is of type SequenceData which fields are not validated. Missing checks are the following:",
        "Also in DropEngine::configureSequence the royaltyBps is not validated that it is not more than 100% (a value of 10000). I suggest you add a lower royaltyBps upper bound."
    ],
    "Recommendations": [
        "",
        "Add sensible constraints and validations for all user input mentioned above."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-using-the-transfer-function-of-address-payable-is-discouraged-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nMedium, as sequence won't be usable as mints will revert"
    ],
    "Likelihood": [
        "\nMedium, as it happens any time the recipient is a smart contract or a multisig wallet that has a receive function taking up more than 2300 gas"
    ],
    "Description": [
        "",
        "The mint function in DropEngine uses the transfer method of address payable to transfer native asset funds to an address. This address is set by a node owner and is possible to be a smart contract that has a receive or fallback function that takes up more than the 2300 gas which is the limit of transfer. Examples are some smart contract wallets or multi-sig wallets, so usage of transfer is discouraged."
    ],
    "Recommendations": [
        "",
        "Use a call with value instead of transfer. There is no risk from reentrancy in the mint method as it has a check for the caller to be an EOA. When this is done you can remove the payable keyword from the revenueRecipient variable."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-role-transfer-actions-done-in-a-single-step-manner-are-dangerous-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as important protocol functionality would become unusable"
    ],
    "Likelihood": [
        "\nLow, as it requires an admin/owner error"
    ],
    "Description": [
        "",
        "This is a common problem where transferring a role or admin rights to a different address can go wrong if this address is wrong and not actually controlled by any user. This is taken into consideration in NodeRegistry where the node ownership transfer is a two-step operation. Not the same approach is used in AccountRegistry though, where the contract inherits from Owned which has a single-step ownership transfer pattern and also the transferAccount logic in it is also using a single-step pattern."
    ],
    "Recommendations": [
        "",
        "Use a two-step ownership/rights transfer pattern in both the AccountRegistry ownership and in the transferAccount method, you can reuse the approach you used in NodeRegistry."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-records-minted-to-an-address-that-is-a-smart-contract-that-cant-handle-erc721-tokens-will-be-stuck-forever-pashov-none-metalabel-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Impact": [
        "\nHigh, as records will be stuck forever"
    ],
    "Likelihood": [
        "\nLow, as it requires the engine to allow smart contracts as minters and that contracts should not support handling of ERC721 tokens"
    ],
    "Description": [
        "",
        "Both mintRecord methods in Collection use the _mint method of ERC721 which is missing a check if the recipient is a smart contract that can actually handle ERC721 tokens. If the case is that the recipient can't handle ERC721 tokens then they will be stuck forever. For this particular problem the safe methods were added to the ERC721 standard and Solmate has added the _safeMint method to check handle this problem in a minting context. This is actually not a problem in DropEngine because it allows only EOAs to mint, but since users can freely implement Engines then this is a valid problem."
    ],
    "Recommendations": [
        "",
        "Prefer using _safeMint over _mint for ERC721 tokens, but do this very carefully, because this opens up a reentrancy attack vector. It's best to add a nonReentrant modifier in the method that is calling _safeMint because of this."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-anyone-can-use-or-steal-arbitrumswaps-native-asset-balance-pashov-none-mugen-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nHigh, because this can easily be noticed and exploited"
    ],
    "Impact": [
        "\nMedium, because value can be stolen, but it should be limited to gas refunds"
    ],
    "Description": [
        "",
        "An attacker can steal the ArbitrumSwaps native asset balance by doing a call to the arbitrumSwaps method with steps WETH_DEPOSIT and WETH_WITHDRAW - this will send over the whole contract balance to a caller-supplied address. This shouldn't be a problem, because the contract is a \"swap router\" and is not expected to hold any native asset balance at any time. Well this assumption does not hold, because in the stargateSwap method the _refundAddress argument of the swap method call to the stargateRouter is address(this). This means that all of the native asset that is refunded will be held by the ArbitrumSwaps contract and an attacker can back-run this refund and steal the balance."
    ],
    "Recommendations": [
        "",
        "The refund address should be msg.sender and not address(this). This way the protocol won't be expected to receive native assets, so they can be stolen only if someone mistakenly sends them to the ArbitrumSwaps contract which is an expected risk."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-malicious-user-can-easily-make-the-protocol-revert-on-every-usdt-swap-on-uniswap-pashov-none-mugen-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        TransferHelper.safeApprove(\n            swapParams.token1, address(swapRouter), IERC20(swapParams.token1).balanceOf(address(this))\n        );\n"
    ],
    "Likelihood": [
        "\nHigh, attack can easily be done and it exploits a well-known attack vector of USDT"
    ],
    "Impact": [
        "\nMedium, because the protocol will not work with only one ERC20 token, but it is a widely used one"
    ],
    "Description": [
        "",
        "A malicious user can get the ArbitrumSwaps contract to revert on each USDT swap on Uniswap, because of a well-known attack vector of the token implementation. The problem is in the following code from UniswapAdapter.sol and is present in both swapExactInputSingle and swapExactInputMultihop",
        "Here is how the attack can be done:"
    ],
    "Recommendation": [
        "",
        "Instead of using the IERC20(multiParams.token1).balanceOf(address(this)) as the approved allowance, use the amountIn parameter."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-use-quotelayerzerofee-instead-of-sending-all-native-asset-balance-as-gas-fee-for-swap-call-pashov-none-mugen-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nHigh, because the wrong value will be sent always"
    ],
    "Impact": [
        "\nLow, because the swap function has a gas refund mechanism"
    ],
    "Description": [
        "",
        "Currently in StargateArbitrum::stargateSwap when doing a call to the swap method of stargateRouter, all of the contract's native asset balance is sent to it so it can be used to pay the gas fee. The Stargate docs show that there is a proper way to calculate the fee and it is by utilizing the quoteLayerZeroFee method of stargateRouter."
    ],
    "Recommendations": [
        "",
        "Follow the documentation to calculate the fee correctly instead of always sending the whole contract's balance as a fee, even though there is a refund mechanism."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-there-is-no-way-to-withdraw-the-eth-paid-by-minters-pashov-none-arcana-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function withdrawBalance() external onlyOwner {\n    (bool success, ) = msg.sender.call{value: address(this).balance}(\"\");\n    require(success);\n  }\n"
    ],
    "Proof of Concept": [
        "",
        "There is currently no possible way for the contract deployer/owner to withdraw the ETH that was paid by miners. This means that value will be stuck & lost forever.\nThis is also the case for the ERC721A standard, which this project actually extends as well, but it was verified in a conversation with the developer that the ArcanaPrime contract is expected to be used as-is, without a need for inheritance/extension."
    ],
    "Impact": [
        "",
        "This will mean hundreds of thousands of dollars (since MAX_SUPPLY = 10_000 and MINT_PRICE = 0.08 ether) will be irretrievable, essentially drying the runway of the NFT project, so it is High severity."
    ],
    "Recommendation": [
        "",
        "Add a method to withdraw the value in the contract, for example"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-if-address-is-a-smart-contract-that-cant-handle-erc721-tokens-they-will-be-stuck-after-a-whitelisted-mint-pashov-none-arcana-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (tx.origin != msg.sender) revert ContractsNotAllowed();\n"
    ],
    "Proof of Concept": [
        "",
        "The mintPublic method has a check that allows only EOAs to call it",
        "but it is missing in the whitelisted mint methods (mintArcanaList, mintAspirantList, mintAllianceList). This means that if the address that is whitelisted is a contract and it calls those functions but it can't handle ERC721 tokens correctly, they will be stuck. This problem is usually handled by using _safeMint instead of _mint but all mint functionality in ArcanaPrime uses _mint."
    ],
    "Impact": [
        "",
        "This can result in a user losing his newly minted tokens forever, which is a potential values loss. It requires the user to be using a smart contract that does not handle ERC721 properly, so it is Medium severity."
    ],
    "Recommendation": [
        "",
        "In mintArcanaList, mintAspirantList and mintAllianceList change the _mint call to _safeMint. Keep in mind this adds a reentrancy possibility, so it is best to add a nonReentrant modifier as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-claimtimeout-is-not-checked-for-first-claim-by-an-account-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if ((block.timestamp - reward.claimedAt) < claimTimeout)\n    revert ClaimTimeout(reward.claimedAt + claimTimeout);\n"
    ],
    "Likelihood": [
        "\nHigh, because it will happen for each account's first claim"
    ],
    "Impact": [
        "\nLow, because there is no loss of funds, but code is not working as intended"
    ],
    "Description": [
        "",
        "In claimRewards in LP.sol there is the following check",
        "which basically forces an account that claims his rewards to wait for at least claimTimeout amount of time. The problem is, in addReserve the reward amount is set, but reward.claimedAt is not set to block.timestamp. This means that reward.claimedAt will be 0 the first time claimRewards is called for an address, so the claimTimeout check will pass even though the time might have not passed yet."
    ],
    "Recommendations": [
        "",
        "When setting the reward amount in addReserve also set reward.claimedAt = block.timestamp"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-protocol-cant-use-smaller-decimals-tokens-as-bet-tokens-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nMedium, because such tokens are widely used and accepted"
    ],
    "Impact": [
        "\nMedium, because it limits the functionality of the protocol"
    ],
    "Description": [
        "",
        "The current implementation of the protocol allows it to only use higher (for example 18) decimals tokens like DAI for betting and liquidity provision. This is enforced by the minDepo property in LP.sol which can't be less than 1e12 for adding liquidity, as well as the check for amount in putBet in Core.sol where amount should be >1e12. If a smaller decimals tokens is to be used (for example USDT, USDC, wBTC) then the users and LPs will need to have a very high amount of capital to interact with the platform."
    ],
    "Recommendations": [
        "",
        "Revisit the validations for minDepo and amount, one possible approach is to calculate those based on the token's decimals"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-missing-admin-input-sanitization-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires a malicious/compromised admin or an error on admin side"
    ],
    "Impact": [
        "\nHigh, because important protocol functionality can be bricked"
    ],
    "Description": [
        "",
        "It is not checked that the claimTimeout property in LP.sol both in its setter function and in initialize does not have a very big value. Same thing for the setter function of withdrawTimeout. Also, the checkFee method in LP.sol has a loose validation - the max sum of all fees should be much lower than 100%. Finally the startsAt argument of shiftGame in LP.sol is not validated that it is not after the current timestamp."
    ],
    "Recommendations": [
        "",
        "Add an upper cap for claimTimeout & withdrawTimeout. Make the max sum of all fees to be lower - for example 20%. In shiftGame check that startsAt >= blockTimestamp."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-ownableupgradeable-uses-single-step-ownership-transfer-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires an error on the admin side"
    ],
    "Impact": [
        "\nHigh, because important protocol functionality will be bricked"
    ],
    "Description": [
        "",
        "Single-step ownership transfer means that if a wrong address was passed when transferring ownership or admin rights it can mean that role is lost forever. The ownership pattern implementation for the protocol is in OwnableUpgradeable.sol where a single-step transfer is implemented.This can be a problem for all methods marked in onlyOwner throughout the protocol, some of which are core protocol functionality."
    ],
    "Recommendations": [
        "",
        "It is a best practice to use two-step ownership transfer pattern, meaning ownership transfer gets to a \"pending\" state and the new owner should claim his new rights, otherwise the old owner still has control of the contract. Consider using OpenZeppelin's Ownable2Step contract"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-admin-privileges-are-dangerous-pashov-none-azuro-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires a malicious/compromised admin"
    ],
    "Impact": [
        "\nHigh, because a rug pull can be executed"
    ],
    "Description": [
        "",
        "A malicious or a compromised admin can execute a 100% rug pull in the following way:",
        "Same thing applies to withdrawPayout."
    ],
    "Recommendations": [
        "",
        "Make the process of adding a new coreType or calling plugCore to be safer. One possible approach is by adding a time delay before a core is added to the LP, up until which the request will be pending."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-hardcoding-gas-costs-should-be-avoided-pashov-none-cadmos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nMedium, because changes to gas costs have happened before, but it is not certain that there will be changes that affect the protocol."
    ],
    "Impact": [
        "\nLow, because even though calculations will be wrong they can still be done off-chain"
    ],
    "Description": [
        "",
        "The modifier markCost in SimpleAdministrator has some hard coded gas cost values like for example 21000 (the base cost of an EVM transaction). We have seen previous EVM forks changing the gas cost of some key things, for example the SSTORE opcode. This can happen again and in this case the hardcoded values in markCost might not be correct anymore which will lead to wrong accounting for incurred gas costs. Also if the project is deployed on a different EVM-compatible chain, the gas costs there might be different."
    ],
    "Recommendations": [
        "",
        "Initialize the expected gas costs in the initialize method and add setter functions to be able to update them in case of an EVM fork"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-transfererc20totreasury-wont-work-as-intended-if-assettoken-is-a-multiple-address-token-pashov-none-cadmos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(tokenAddress != _assetTokenAddress, \"IP: Asset transfer\");\n"
    ],
    "Likelihood": [
        "\nLow, because it requires using a multiple-address token and a malicious/compromised admin"
    ],
    "Impact": [
        "\nHigh, because users can use 100% of their deposits"
    ],
    "Description": [
        "",
        "Some ERC20 tokens on the blockchain are deployed behind a proxy, so they have at least 2 entry points (the proxy and the implementation) for their functionality. Example is Synthetix\u2019s ProxyERC20 contract from where you can interact with sUSD, sBTC etc). If such a token was used as the assetTokentoken in an InvestmentPool, then the admin will be able to rug all depositors with thetransferERC20ToTreasury` method, even though it has the following check",
        "Since the tokens have multiple addresses the admin can give another address and pass those checks."
    ],
    "Recommendations": [
        "",
        "Instead of checking the address of the transferred token, it is a better approach to check the balance of it before and after the transfer and to verify it is the same."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-front-running-risk-in-key-admin-actions-pashov-none-cadmos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nMedium, because it requires the malicious user to have a script that monitors the public mempool"
    ],
    "Impact": [
        "\nMedium, because key admin functionality will revert"
    ],
    "Description": [
        "",
        "The methods forceTransfer, whitelistAccount and freezeAccount from InvestmentPoolCore and Whitelist can be monitored for transactions and front-ran. Imagine the following scenario:",
        "The same logic applies for the whitelistAccount and forceTransfer functionalities."
    ],
    "Recommendations": [
        "",
        "Always execute transactions to the mentioned functions through a private mempool or redesign them so they are not front-runnable."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-an-important-flow-of-admin-actions-is-not-enforced-just-documented-pashov-none-cadmos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    /// @notice call batchSettlement(id) beforehand, otherwise it will rug the old pool tokenholders\n"
    ],
    "Likelihood": [
        "\nLow, because it requires either a malicious/compromised admin or the admin to forget it has to do the correct flow of operations"
    ],
    "Impact": [
        "\nHigh, because users will lose their funds"
    ],
    "Description": [
        "",
        "The NatSpec of InvestmentPoolCore::setInflowOutflowPool contains the following comment:",
        "This can easily be forgotten or missed when executing a call to the method. This way of ensuring proper flow of operations is used is error-prone."
    ],
    "Recommendations": [
        "",
        "Ensure that batchSettlement(id) was called beforehand by using a flag or some storage variable to be certain that users won't be rugged."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-single-step-ownership-transfer-can-be-dangerous-pashov-none-cadmos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires an error on the admin side"
    ],
    "Impact": [
        "\nHigh, because protocol will be bricked"
    ],
    "Description": [
        "",
        "Single-step ownership transfer means that if a wrong address was passed when transferring ownership or admin rights it can mean that role is lost forever. This can be detrimental in the context of InvestmentPoolCore, where if transferAdminRole method was called with a wrong newAdmin address, then the InvestmentPoolCore contract will be bricked, since it relies heavily on admin-only methods."
    ],
    "Recommendations": [
        "",
        "It is a best practice to use two-step ownership transfer pattern, meaning ownership transfer gets to a \"pending\" state and the new owner should claim his new rights, otherwise the old owner still has control of the contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-hardcoded-handling-of-non-18-decimal-token-pools-limits-the-interoperability-of-the-protocol-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nMedium, because even though at this point no such pools are added, it is possible that they are in the future"
    ],
    "Impact": [
        "\nMedium, because it limits the functionality of the protocol"
    ],
    "Description": [
        "",
        "The enter method implements specific handling for USDC and wBTC tokens, because they have decimals that are not equal to 18. This should be done for all such pools tokens, but since it is hardcoded it is not extensible - for example USDT pool can't be added."
    ],
    "Recommendations": [
        "",
        "Redesign the approach with the decimals that is hardcoded or implement it in an extensible-friendly way for new non-18 decimal token pools."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-as-protocol-relies-heavily-on-admin-actions-single-step-ownership-transfer-pattern-is-dangerous-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires admin error when transferring ownership"
    ],
    "Impact": [
        "\nHigh, because it bricks core protocol functionality"
    ],
    "Description": [
        "",
        "Inheriting from OpenZeppelin's Ownable contract means you are using a single-step ownership transfer pattern. If an admin provides an incorrect address for the new owner this will result in none of the onlyOwner marked methods being callable again. The better way to do this is to use a two-step ownership transfer approach, where the new owner should first claim its new rights before they are transferred."
    ],
    "Recommendations": [
        "",
        "Use OpenZeppelin's Ownable2Step instead of Ownable"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-if-addpool-is-called-too-many-times-it-can-brick-core-functionality-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires a malicious admin or a big admin error"
    ],
    "Impact": [
        "\nHigh, because it bricks core protocol functionality"
    ],
    "Description": [
        "",
        "The addPool method pushes an entry to the poolInfo array. Methods like swapGLPout and recoverTreasuryTokensFromGLP have internal calls (GLPbackingNeeded) that iterate over the whole array. If too many pools are added then all calls to those methods will need too much gas to iterate over the array and if this cost is over the block gas limit it will lead to a DoS situation of core functionality."
    ],
    "Recommendations": [
        "",
        "Limit the number of pools that can be added, for example to 50."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-call-to-updatepoolrate-is-missing-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nMedium, because it happens only for a paused and then resumed pool"
    ],
    "Impact": [
        "\nMedium, because it can hardly lead to big losses"
    ],
    "Description": [
        "",
        "Every time the totalStaked amount of a pool is updated, the updatePoolRate method is called to update the EarnRateSec. This is not true for the pauseReward method, which calls updatePool that changes the totalStaked amount. Now if a pool is paused, when it gets resumed again and updatePool is called it will calculate less rewards than it should had, because EarnRateSec was not updated."
    ],
    "Recommendations": [
        "",
        "Call updatePoolRate after the updatePool call in pauseReward"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-admin-privilege-actions-can-be-risky-for-users-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nLow, because it requires a malicious/compromised admin"
    ],
    "Impact": [
        "\nHigh, because it can brick the protocol"
    ],
    "Description": [
        "",
        "The methods updateOracle, updateRouter and updateRewardRouter are admin controllable and callable anytime. Same for the withdrawable property of PoolInfo. A malicious/compromised admin can either provide non-existing addresses or set the withdrawable property to false for all pools, leading to a DoS for users of the protocol."
    ],
    "Recommendations": [
        "",
        "Consider using an role-based access control approach instead of a single admin role as well as a timelock for important admin actions."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-token-approvals-allowances-management-is-flawed-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Likelihood": [
        "\nMedium, because it will be problematic only with special type of tokens"
    ],
    "Impact": [
        "\nMedium, because it can lead to a limited loss of funds"
    ],
    "Description": [
        "",
        "There are a few problems related to approvals & allowances in the contract. One is that the swaptoGLP method approves another contract to spend tokens, but some tokens (like USDT) have approval race condition protection, which requires the allowance before a call to approve to already be either 0 or UINT_MAX. If this is not the case, the call reverts, which can lead to a DoS situation with swaptoGLP. It looks like there was an idea to mitigate this, because at all places (apart from in convertDust) after calling the swaptoGLP method there is an approve call for 0 allowance, but it is done to the wrong address. swaptoGLP always approves poolGLP but the 0 allowance approve call is always to the _GLPRouter when the _GLPRouter should never have allowance."
    ],
    "Recommendations": [
        "",
        "Set allowance to zero after each swaptoGLP call for the poolGLP address"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-inverted-slippage-protection-approach-can-lead-to-problems-pashov-none-gmd-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 percentage = 100000 - slippage;\nuint256 glpPrice = priceFeed.getGLPprice().mul(percentage).div(100000);\nuint256 glpOut = amountOut.mul(10**12).mul(tokenPrice).div(glpPrice).div(10**30);\n"
    ],
    "Likelihood": [
        "\nLow, because it needs more than one special condition simultaneously"
    ],
    "Impact": [
        "\nMedium, because it can lead to limited amount of funds lost from the protocol"
    ],
    "Description": [
        "",
        "Both the leaveETH and leave methods use the slippage storage variable to implement slippage protection for the users leaving the vault. The problem is that the slippage protection is done in an unusual approach which can result in problems. Both methods call the swapGLPto method which has the min_receive parameter that is passed to the unstakeAndRedeemGlp method in GLPRouter. The usual approach to slippage protection is to calculate how much tokens you expect to receive after a swap, let's say 100 $TKN, and then apply some slippage tolerance percentage to it - if the tolerance is 5% then the minimum expected tokens received is 95 $TKN. The protocol implemented a different approach, instead of providing a smaller expected received value it actually inflates the value to be sent for the swap.",
        "As you see, the way it works is \"expecting\" a lower price of $GLP which means the protocol always sends more $GLP than needed to swap. Now if the slippage protection is bigger than the deposit fee this can be used as a griefing attack vector by depositing and then withdrawing from a vault multiple times to drain the pool's $GLP balance."
    ],
    "Recommendations": [
        "",
        "Think about redesigning the leave methods so that you make the user pay the slippage cost instead of the protocol."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-incorrect-user-accounting-in-withdraw-method-pashov-none-yield-ninja-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "user.amount = user.amount - _shares;\n",
        "- user.amount = user.amount - _shares;\n+ user.amount = user.amount - r;\n"
    ],
    "Proof of Concept": [
        "",
        "The withdraw method in NYProfitTakingVaultBaseV1 does incorrect user accounting in the following line:",
        "In the deposit method we use the user.amount to store the amount of underlying tokens deposited, but in withdraw instead of subtracting the underlying tokens the code subtracts the shares burned."
    ],
    "Impact": [
        "",
        "Since shares are not 1:1 with underlying this will completely mess up the user accounting on each withdraw. It is possible to be in two directions - if _shares was less than the amount withdrawn, then the user will be able to withdraw more than he deposited, essentially a possibility to deplete the vault to zero. If _shares was more than the amount withdrawn, then the user will be able to withdraw less than he deposited, essentially a loss of value for users."
    ],
    "Recommendation": [
        "",
        "Make the following change:"
    ]
}
----End JSON----

https://solodit.xyz/issues/h-02-first-vault-depositor-can-steal-subsequent-depositors-tokens-pashov-none-yield-ninja-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Proof of Concept": [
        "",
        "Imagine the following scenario:",
        "This can be replayed multiple times until the depositors notice the problem."
    ],
    "Impact": [
        "",
        "The result of this is 100% value loss for all subsequent depositors."
    ],
    "Recommendation": [
        "",
        "UniswapV2 fixed this with two types of protection:",
        "First, on the first mint it actually mints the first 1000 shares to the zero-address",
        "Second, it requires that the minted shares are not 0",
        "Implementing them both will resolve this vulnerability."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-mev-can-sandwich-every-harvest-due-to-missing-slippage-tolerance-value-pashov-none-yield-ninja-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "IUniswapV2Router02(SPOOKY_ROUTER).swapExactTokensForTokensSupportingFeeOnTransferTokens(\n      booBalance,\n      0,\n      booToUsdcPath,\n      address(this),\n      block.timestamp\n    );\n"
    ],
    "Proof of Concept": [
        "",
        "In NyPtvFantomWftmBooSpookyV2StrategyToUsdc each time the _harvestCore method is called (on each harvest) it will call the _swapFarmEmissionTokens method which itself has the following code:",
        "The \u201c0\u201d here is the value of the amountOutMin argument which is used for slippage tolerance. 0 value here essentially means 100% slippage tolerance. This is a very easy target for MEV and bots to do a flash loan sandwich attack on each of the strategy\u2019s swaps, resulting in very big slippage on each trade."
    ],
    "Impact": [
        "",
        "100% slippage tolerance can be exploited in a way that the strategy (so the vault and the users) receive much less value than it should had. This can be done on every trade if the trade transaction goes through a public mempool."
    ],
    "Recommendation": [
        "",
        "The best solution here is to make the harvest method of the vault be callable only by a list of trusted addresses which will send the transaction through a private mempool. This, combined with an on-chain calculation for an amountOutMin that is off from the expected amountOut by a slippage tolerance percentage (that might be configurable through a setter in the strategy) should be good enough to protect you from MEV sandwich attacks."
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-hardcoded-swap-path-might-not-be-the-most-optimalliquid-one-pashov-none-yield-ninja-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Proof of Concept": [
        "",
        "Currently in NyPtvFantomWftmBooSpookyV2StrategyToUsdc the value of the booToUsdcPath trade path is not configurable and is basically hardcoded to be [BOO, USDC]. It is the same for the swap router, as it is currently hardcoded to point to the SpookySwap router. The problem is that the BOO/USDC pool on SpookySwap might not be the most optimal and liquid one, and maybe instead it would be better to go BOO/USDT and then USDT/USDC. If the BOO/USDC pair for example loses most of its liquidity (maybe LPs are not incentivised as much or they decided to move elsewhere) then the strategy will still be forced to do its swaps on harvest through the illiquid/non-optimal BOO/USDC pair on SpookySwap."
    ],
    "Impact": [
        "",
        "This can result in a loss of value for vault users, as if a more liquid pool was used for swaps it could have resulted in less slippage so a bigger reward."
    ],
    "Recommendation": [
        "",
        "Add setter functions for both the trade router and the trade path - make them configurable. One possible option is to hardcode the 3 most liquid Fantom exchanges and 3 possible trade paths and switch through them via the setter."
    ]
}
----End JSON----

https://solodit.xyz/issues/h-01-the-unlockexponent-does-not-work-as-intended-when-it-is-1-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 factor = deltaTimeNormalized ** unlockExponent;\n\nif (factor > precision) {\n         factor = precision;\n}\n",
        "uint256 deltaTimeNormalized = (deltaTimeDelayed * precision) / unlockPeriodSec;\n\nuint256 factor = deltaTimeNormalized ** unlockExponent;\n\nif (factor > precision) {\n      factor = precision;\n}\nuint256 totalUnlockedAmount = (record.totalAmount * factor) / precision;\n"
    ],
    "Proof of Concept": [
        "",
        "The documentation and the chart in README.md shows that it is expected that when unlockExponent == 0 then immediately after funds unlockDelaySec the user can claim his whole locked amount. This is actually not working as intended, let\u2019s look at the _getWithdrawableAmount function:",
        "The expected unlocked amount was equal to record.totalAmount but instead we got record.totalAmount / precision which is incorrect. Now every subsequent time the _getWithdrawableAmount function is called, the math will be the same and the code will basically think there is no newly unlocked amount. This means that no user that has locked funds in Zerem will be able to withdraw more than totalLockedAmount / 1e8 ever, all of the other tokens will be stuck.",
        "There is also a problem when unlockExponent > 1 , because the computed factor can easily be >= precision which will result in 100% of funds being unlocked too early.",
        "Here is the important math:",
        "and let\u2019s look at example scenario:"
    ],
    "Impact": [
        "",
        "The protocol does not work as expected in its core functionality and can also result in stuck tokens (value loss) for users or tokens unlocked too early, so it is High severity."
    ],
    "Recommendation": [
        "",
        "Redesign the unlockExponent logic or just hardcode it to always be linear (a value of 1)"
    ],
    "Client response": [
        "",
        "Fixed by removing the unlockExponent logic"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-01-unsafe-call-to-erc20transfer-can-result-in-stuck-funds-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "IERC20(underlyingToken).transfer(receiver, amount);\n"
    ],
    "Proof of Concept": [
        "",
        "In the _sendFunds method we have the following code for transferring ERC20 tokens",
        "The problem is that the transfer function from ERC20 returns a bool to indicate if the transfer was a success or not. As there are some tokens that do not revert on failure but instead return false (one such example is ZRX) and also Zerem should work with all types of ERC20 tokens since it might be integrated with a protocol that does that, not checking the return value can result in tokens getting stuck. Let\u2019s look at the following scenario:"
    ],
    "Impact": [
        "",
        "If an ERC20::transfer call fails it will lead to stuck funds for a user. This only happens with a special class of ERC20 tokens though, so it is Medium severity."
    ],
    "Recommendation": [
        "",
        "Use OpenZeppelin\u2019s SafeERC20 library and change transfer to safeTransfer"
    ],
    "Client response": [
        "",
        "Fixed by adding SafeERC20"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-02-gas-stipend-for-external-call-might-be-insufficient-and-lead-to-stuck-eth-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "payable(receiver).call{gas: 3000, value: amount}(hex\"\")\n"
    ],
    "Proof of Concept": [
        "",
        "The way the Zerem protocol transfers out ETH looks like this",
        "As you see, there is a gas stipend of 3000, but this might not be enough in some cases as some smart contract recipients need more than 3000 gas to receive ETH.",
        "Examples of problematic recipients:",
        "Additionally, using higher than 3000 gas might be mandatory for some multi-sig wallets."
    ],
    "Impact": [
        "",
        "Some recipients will lose access to all of their claimable ETH from protocols that are integrated with Zerem. This requires a special type of recipient, so it is Medium severity."
    ],
    "Recommendation": [
        "",
        "At least doubling down the gas stipend should help in most scenarios, but maybe think about dynamic configuration options for it as well"
    ],
    "Client response": [
        "",
        "Fixed by doubling the gas stipend"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-03-gas-griefingtheft-is-possible-on-unsafe-external-call-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(bool success,) = payable(receiver).call{gas: 3000, value: amount}(hex\"\");\n",
        "bool success;\nassembly {\n    success := call(3000, receiver, amount, 0, 0, 0, 0)\n}\n"
    ],
    "Proof of Concept": [
        "",
        "This comment // TODO: send relayer fees here in the unlockFor method and its design show that it is possible that unlockFor is usually called by relayers. This opens up a new attack-vector in the contract and it is gas griefing on the ETH transfer",
        "Now (bool success, ) is actually the same as writing (bool success, bytes memory data) which basically means that even though the data is omitted it doesn\u2019t mean that the contract does not handle it. Actually, the way it works is the bytes data that was returned from the receiver will be copied to memory. Memory allocation becomes very costly if the payload is big, so this means that if a receiver implements a fallback function that returns a huge payload, then the msg.sender of the transaction, in our case the relayer, will have to pay a huge amount of gas for copying this payload to memory."
    ],
    "Impact": [
        "",
        "Malicious actor can launch a gas griefing attack on a relayer. Since griefing attacks have no economic incentive for the attacker and it also requires relayers it should be Medium severity."
    ],
    "Recommendation": [
        "",
        "Use a low-level assembly call since it does not automatically copy return data to memory"
    ],
    "Client response": [
        "",
        "Fixed by using a low-level assembly call"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-04-centralisation-risk-with-liquidationresolver-as-it-can-steal-100-of-locked-funds-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Proof of Concept": [
        "",
        "Currently the liquidationResolver has the power to steal 100% of locked funds in the following way:",
        "This can happen if the liquidationResolver becomes malicious or is compromised."
    ],
    "Impact": [
        "",
        "Centralisation vulnerabilities usually require a malicious or a compromised account and are of Medium severity"
    ],
    "Recommendation": [
        "",
        "Reconsider if the freeze/liquidate funds is a mandatory mechanism for the protocol"
    ],
    "Client response": [
        "",
        "Acknowledged"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-05-missing-configuration-validations-constraints-can-lead-to-stuck-funds-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (deltaTime < unlockDelaySec) {\n     return 0;\n}\n"
    ],
    "Proof of Concept": [
        "",
        "If a protocol integrates with Zerem it needs to deploy different instances of Zerem.sol for each underlyingToken. In the constructor there are some configurations being set but the inputs are not validated at all. Now if the deployer did not configure them correctly, or fat-fingered the deployment or if the deployment scripts were incorrect, it is possible to misconfigure the protocol in such a way that it is not obvious but leads to all locked funds getting stuck forever.",
        "Let\u2019s look at the following scenario:",
        "This means the user will need to wait a huge amount (might be infinite) of time to be able to unlock his funds, and they won\u2019t be unlockable even with the liquidateFunds functionality"
    ],
    "Impact": [
        "",
        "This can possibly lead to user funds being stuck in Zerem, but this requires misconfiguration in deployment, so it is Medium severity"
    ],
    "Recommendation": [
        "",
        "Add sensible constraints for the valid values of unlockDelaySec and unlockPeriodSec in the constructor of Zerem.sol"
    ],
    "Client response": [
        "",
        "Fixed by adding constraints in the constructor"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-06-erc20-tokens-that-have-a-fee-on-transfer-mechanism-require-special-handling-pashov-none-zerem-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Proof of Concept": [
        "",
        "Some tokens take a transfer fee (STA, PAXG) and there are some that currently do not but might do so in the future (USDT, USDC). Since Zerem might be integrated with a protocol that works with all types of ERC20 tokens, and Zerem should too, this can lead to problems.",
        "Let\u2019s look at the following scenario:",
        "If this happens this means that all of users balances of such tokens won\u2019t be claimable and stuck forever."
    ],
    "Impact": [
        "",
        "If a token with a fee-on-transfer mechanism is used and not properly handled on both the integration protocol and Zerem\u2019s side, it can result in 100% stuck balances of this token of users. Since this happens only with a special type of ERC20 it is Medium severity."
    ],
    "Recommendation": [
        "",
        "Integration of such tokens will require special handling on the integrating protocol side (pre-calculating the fee, so the amount argument passed has the correct value) and possibly on Zerem\u2019s side. Consider either better documentation for those or advise integrating protocols to not transfer such tokens through Zerem."
    ],
    "Client response": [
        "",
        "Added a warning comment in the code"
    ]
}
----End JSON----

https://solodit.xyz/issues/m-07-protocol-does-not-work-with-erc20-tokens-that-have-a-mechanism-for-balance-modifications-outside-of-transfers-pashov-none-zerem-markdown--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Proof of Concept": [
        "",
        "Some tokens may make arbitrary balance modifications outside of transfers. One example are Ampleforth-style rebasing tokens and there are other tokens with airdrop or mint/burn mechanisms. The Zerem system caches the locked balances for users and if such an arbitrary modification has happened this can mean that the protocol is operating with outdated information. Let\u2019s look at the following scenario:",
        "Also if the rebasing of the tokens actually increased the protocol balance, then those excess tokens will be stuck in it."
    ],
    "Impact": [
        "",
        "Funds can be stuck in Zerem, but it requires a special type of ERC20 token, so it is Medium severity."
    ],
    "Recommendation": [
        "",
        "Allow partial unlock of funds or document that the protocol does not support such tokens, so integrating protocols do not transfer them through Zerem. Also you can add functionality to rescue excess funds out of the Zerem protocol."
    ],
    "Client response": [
        "",
        "Acknowledged"
    ]
}
----End JSON----
