
https://solodit.xyz/issues/lack-of-origin-check-on-rpc-requests-fixed-consensys-none-tezoro-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export const onRpcRequest: OnRpcRequestHandler = async ({ request }) => {\n switch (request.method) {\n case 'requestAccounts': {\n const data = await ethereum.request({\n method: 'eth\\_requestAccounts',\n\n",
        "case 'getToken': {\n const state = await snap.request({\n\n",
        "case 'saveToken': {\n const result = await snap.request({\n\n"
    ],
    "Resolution": [
        "Addressed by tezoroproject/metamask-snap#41"
    ],
    "Description": [
        "The Snap does not validate the origin of RPC requests, allowing any arbitrary dApp to connect to the Snap and initiate arbitrary RPC requests. Specifically, any dApp can access the privileged getToken and deleteToken RPC endpoints. Consequently, a malicious dApp could potentially extract a user\u2019s Tezoro token from the Snap and impersonate the user in interactions with the Tezoro API. Depending on the permissions associated with this token, the implications could be critical."
    ],
    "Example": [
        "packages/snap/src/index.ts:L14-L18",
        "packages/snap/src/index.ts:L64-L65",
        "packages/snap/src/index.ts:L34-L35"
    ],
    "Recommendation": [
        "Validate the origin of all incoming RPC requests. Specifically, restrict access to the RPC endpoints to only the Tezoro management dApp. Additionally, consider removing any endpoints that are not essential for the Snap\u2019s functionality. For example, the getToken endpoint for extracting the API token might be unnecessary and could be removed to enhance security."
    ]
}
----End JSON----

https://solodit.xyz/issues/getpriceofassetquotedinusd-might-return-flawed-asset-prices-fixed-consensys-none-tezoro-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (assetName.startsWith('W')) {\n // Assume this is a wrapped token\n assetName = assetName.slice(1); // remove W\n}\ntry {\n\n",
        "const response = await fetch(\n `https://api.binance.com/api/v3/ticker/price?symbol=${assetName.toUpperCase()}USDT`,\n);\nconst json = await response.json();\n\n"
    ],
    "Resolution": [
        "Addressed by tezoroproject/metamask-snap#42"
    ],
    "Description": [
        "First, the function getPriceOfAssetQuotedInUSD() operates under the assumption that stablecoins\u2014specifically \u2018USDT\u2019, \u2018USDC\u2019, \u2018DAI\u2019, \u2018USDP\u2019, and \u2018TUSD\u2019\u2014always maintain a 1:1 price ratio with the USD. Although this is generally expected to be the case, there have been instances where some stablecoins failed to uphold their peg to the USD. In such scenarios, this assumption no longer holds true, resulting in the return of inaccurate balances. Furthermore, it\u2019s important to note that the prices returned by this function are quoted in USDT, despite the function\u2019s name suggesting that prices are returned in USD. This could lead to discrepancies if \u2018USDT\u2019 diverges from its fiat counterpart.",
        "Second, The function getPriceOfAssetQuotedInUSD() assumes that every token name that starts with \u2018W\u2019 is a wrapped token. Thus, the initial \u2018W\u2019 is removed from the token name before fetching the prices from Binance API. As a result, the subsequent API request made to get the price of the unwrapped token could potentially fail or return an incorrect price, if the token name starts with a \u2018W\u2019 but the token is not a wrapped token. For instance, the \u201cWOO\u201d token is present in the list of tokens supported by the Snap. In that case, the price API will error as it will try to fetch the price of theOOUSDT pair instead of WOOUSDT.",
        "Finally, relying on an hardcoded external APIs is sub-optimal. Indeed, it may be that the API may fail, start returning incorrect data, or simply become outdated and stop working."
    ],
    "Example": [
        "packages/snap/src/external/get-price-of-asset-quoted-in-usd.ts:L15-L19",
        "packages/snap/src/external/get-price-of-asset-quoted-in-usd.ts:L20-L23"
    ],
    "Recommendation": [
        "To mitigate this issue, one should avoid making assumptions about token names. Instead, one would ideally fetch token metadata from a trusted source to determine whether a token is wrapped or not, hardcode this information in the token-list, or directly fetch the price of the wrapped token.",
        "Moreover, instead of hardcoding the price API, we would recommend setting up a custom API Gateway which provides a layer of abstraction between the Snap and the external APIs it uses. This would provide flexibility and allow quickly swapping for other external APIs in case they stop behaving properly."
    ]
}
----End JSON----

https://solodit.xyz/issues/inaccurate-return-value-in-checktokens-fixed-consensys-none-tezoro-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (!token) {\n return {\n isStatePresent: true,\n isTokenPresent: true,\n };\n}\n\n",
        "export const stateSchema = z.object({\n token: z.string().optional(),\n});\n\n"
    ],
    "Resolution": [
        "Addressed by tezoroproject/metamask-snap#43"
    ],
    "Description": [
        "The function checkTokens() checks if token exists in parsedState.data and returns {isStatePresent: true, isTokenPresent: true,} if it does not. This is incoherent as isTokenPresent should be false in that case."
    ],
    "Examples": [
        "packages/snap/src/check-tokens.ts:L41-L46",
        "packages/snap/src/schemas.ts:L35-L37"
    ],
    "Recommendation": [
        "Fix the return value. isTokenPresent should be false if the token is not present in the state. Alternatively, fix the zod stateSchema to ensure that token is not optional. In that case the safeParse function will fail and the function will return the correct value."
    ]
}
----End JSON----

https://solodit.xyz/issues/cronjob-checktokens-might-flood-user-notifications-fixed-consensys-none-tezoro-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "[...tokensList].map(async (token) => {\n await snap.request({\n method: 'snap\\_notify',\n params: {\n\n"
    ],
    "Resolution": [
        "Addressed by tezoroproject/metamask-snap#44. The snap now sends a single notification."
    ],
    "Description": [
        "The snap includes a cron job named checkToken that activates every 15 days to verify which user tokens are backed up and which are not. For each token identified as not backed up (listed in tokenList), the snap issues a notification to the user. If the list of unbacked tokens is extensive, the user will receive many notifications, potentially undermining the effectiveness of these alerts or causing the user to overlook other important notifications. To alleviate this concern, it is recommended to aggregate these notifications. Issuing a single notification, or capping the number of notifications when the size of tokenList surpasses a specific threshold (e.g., 5), could improve the user experience."
    ],
    "Examples": [
        "packages/snap/src/index.ts:L122-L125"
    ],
    "Recommendation": [
        "We would recommend to aggregate notifications, summarizing the status of unbacked tokens, at least when their number exceeds a certain reasonable threshold."
    ]
}
----End JSON----

https://solodit.xyz/issues/deletetoken-should-prompt-user-for-its-consent-fixed-consensys-none-tezoro-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "case 'deleteToken': {\n await snap.request({\n method: 'snap\\_manageState',\n\n params: {\n operation: ManageStateOperation.UpdateState,\n newState: {},\n encrypted: true,\n },\n });\n return true;\n}\n\n"
    ],
    "Resolution": [
        "Addressed by tezoroproject/metamask-snap#45"
    ],
    "Description": [
        "As a rule of thumb, every state-changing interaction with the Snap\u2019s state should require user confirmation, and the process should be aborted if the user does not consent. This principle is already applied to the saveToken RPC endpoint. To maintain consistency and ensure user control over their data, the deleteToken endpoint should also prompt the user for consent before proceeding to delete the token from the Snap\u2019s state."
    ],
    "Examples": [
        "packages/snap/src/index.ts:L85-L96"
    ],
    "Recommendation": [
        "Similarly to the saveToken RPC endpoint, the deleteToken endpoint should ask the user for its consent before deleting the token from the snap\u2019s state."
    ]
}
----End JSON----

https://solodit.xyz/issues/public-rpc-methods-and-consent-management-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function handleIdentitySign(bodyCBOR: string, origin: TOrigin): Promise<ArrayBuffer> {\n const body: IIdentitySignRequest = zodParse(ZIdentitySignRequest, fromCBOR(bodyCBOR));\n const manager = await StateManager.make();\n let session = (await manager.getOriginData(origin)).currentSession;\n\n if (session === undefined) {\n err(ErrorCode.UNAUTHORIZED, \"Log in first\");\n }\n\n const identity = await getSignIdentity(session.deriviationOrigin, session.identityId, body.salt);\n\n return await identity.sign(body.challenge);\n}\n\n"
    ],
    "Resolution": [
        "Addressed with the following changeset: fort-major/msq@7f9cde2."
    ],
    "Description": [
        "User consent may not consistently be enforced. Identities are bound to their origin (URL). Third-party origins are outside the scope of this Snap and are therefore in a lower trust zone where it is uncertain what security measures are in place to protect the dApp from impersonating the user\u2019s wallet identity. dApps may be hosted on integrity-protecting endpoints (ipfs/IC), however, this is not enforced. Additionally, even when hosted on integrity-protecting endpoints there are still risks of insider and external attacks on the deployed dApp (Insider changing code, External attacker gaining access to code, Injection, Web Attacks), BGP routing related attacks (typically expensive), and DNS related attacks.",
        "Allowing linked identities to sign with a main origin\u2019s identity extends the risk from one public origin to another.",
        "It should be noted that identities on public RPC methods are origin bound. There is no direct way for one public origin to sign with another origin\u2019s identity unless it is linked."
    ],
    "Examples": [
        "Example: signing",
        "The function handleIdentitySign is responsible for signing a payload with an identity. However, it has been observed that the function proceeds to sign the payload without seeking explicit user confirmation or displaying the payload in a human-readable format. This approach can significantly undermine the security and trust model of MetaMask Snaps by allowing potentially malicious operations to be executed without the user\u2019s informed consent.",
        "packages/snap/src/protocols/identity.ts:L268-L280"
    ],
    "Recommendation": [
        "When performing critical actions on behalf of the user, always ask for consent. The user must always be notified when a dApp acts on their behalf (especially signing). For API that provides less critical information it should be considered to implement a session based consent mechanism that trades security for convenience where, e.g., linked identities or the public key can only be extracted if the user at least once confirmed this for the current origin (caching the decision)."
    ]
}
----End JSON----

https://solodit.xyz/issues/keypairs-generated-by-dapps-might-be-unrecoverable-which-could-result-in-loss-of-funds-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " const body = zodParse(ZIdentityGetPublicKeyRequest, fromCBOR(bodyCBOR));\n const manager = await StateManager.make();\n let session = (await manager.getOriginData(origin)).currentSession;\n\n if (session === undefined) {\n err(ErrorCode.UNAUTHORIZED, \"Log in first\");\n }\n\n const identity = await getSignIdentity(session.deriviationOrigin, session.identityId, body.salt);\n\n return identity.getPublicKey().toRaw();\n}\n\n"
    ],
    "Resolution": [
        "The client acknowledged and mitigated this issue in commit\nfort-major/msq@59a0b88.\nNote that the companion dApp can still sign data with arbitrary salts, but external dApps cannot anymore."
    ],
    "Description": [
        "The current Snap implementation allows untrusted dapps to supply their own nonces for the generation of unique private keys tied to their identities. These nonces, which can be arbitrary and are not managed or stored by the Snap, introduce a risk. Specifically, if a dapp fails to securely store these nonces or ceases operation, users may irretrievably lose access to their accounts, potentially resulting in the loss of funds. This issue underscores a vulnerability in the system\u2019s design, where the reliance on external parties for the management of crucial security parameters compromises the safety and recoverability of user assets."
    ],
    "Examples": [
        "From the documentation:",
        "packages/snap/src/protocols/identity.ts:L298-L309"
    ],
    "Recommendation": [
        "To mitigate the risk of users losing access to their accounts and funds due to mismanaged or lost nonces by dapps, it is recommended to either:"
    ]
}
----End JSON----

https://solodit.xyz/issues/timestamp-logic-flaws-in-snaps-caching-mechanism-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " if (state == null) {\n const s = makeDefaultState();\n STATE = s;\n\n STATE\\_UPDATE\\_TIMESTAMP = Date.now();\n } else {\n STATE = zodParse(ZState, fromCBOR(state.data as string));\n }\n}\n\n",
        "async function persistStateLocal(): Promise<void> {\n if (LAST\\_STATE\\_PERSIST\\_TIMESTAMP >= STATE\\_UPDATE\\_TIMESTAMP) return;\n\n zodParse(ZState, STATE);\n\n LAST\\_STATE\\_PERSIST\\_TIMESTAMP = Date.now();\n\n await snap.request({\n method: \"snap\\_manageState\",\n params: {\n operation: \"update\",\n newState: { data: toCBOR(STATE) },\n\n"
    ],
    "Resolution": [
        "Addressed in commit 4d6b006f2870b8b560e068ae51821d9d962d129a"
    ],
    "Description": [
        "The Snap employs a custom wrapper around its storage, incorporating a caching mechanism to optimize performance by updating the Snap\u2019s storage only when necessary. This caching strategy uses a timestamp-based method, maintaining records of the last storage (LAST_STATE_PERSIST_TIMESTAMP) and state (STATE_UPDATE_TIMESTAMP) updates to decide on the need for persisting the updated state. However, two logical flaws were identified in this approach:",
        "packages/snap/src/state.ts:L464-L472",
        "packages/snap/src/state.ts:L527-L538"
    ],
    "Recommendation": [
        "Adjust the timestamp update logic as follows:"
    ]
}
----End JSON----

https://solodit.xyz/issues/protected-administrative-origin-rpc-methods-and-consent-management-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Resolution": [
        "Addressed with the following changesets: fort-major/msq@7f9cde2 and fort-major/msq@0b9f8d1 (removing whitelisted method names, only allowing  icrc1_transfer)",
        "The client provided the following statement:"
    ],
    "Description": [
        "Identities are bound to their origin (URL). Third-party origins are outside the scope of this Snap and are therefore in a lower trust zone where it is unsure what security measures are in place to protect the dApp from impersonating the users\u2019 wallet identity. dApps may be hosted on integrity protecting endpoints (ipfs/IC), however, this is not enforced.",
        "Protected RPC functions can only be invoked by the MSQ administrative origin. User consent may not consistently be enforced on the administrative origin.",
        "The administrative origin is identified by the origin URL. According to the client the dApp is hosted on an integrity protecting endpoint (IC). This already protects from direct manipulation of the deployed code, however, it may still be problematic as the Snap and Management dApp are in different trust zones with the dApp being exposed to many external factors that make it more prone to web related attacks. That said, even when hosted on integrity protecting endpoins there are still risks of insider and external attacks on the deployed dApp (Insider changing code, External attacker gaining access to code, Injection, Web Attacks), BGP routing related attacks (typically expensive), and DNS related attacks. In the worst case, an insider/external attacker gaining control of the trusted origin may be able to perform actions on many users behalf\u2019s without them knowing (given that the user accesses the management origin)."
    ],
    "Examples": [],
    "Recommendation": [
        "When performing critical actions on behalf of the user, always ask for consent. The user must always be notified when a dApp acts on their behalf (especially signing). For API that provides less critical information it should be considered to implement a lazy session based consent mechanism that trades security for convenience where, i.e., data can only be extracted from the snap if the user at least once confirmed this for the current session."
    ]
}
----End JSON----

https://solodit.xyz/issues/protected_handleidentitylogin-unchecked-withidentityid-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function protected\\_handleIdentityLogin(bodyCBOR: string): Promise<true> {\n const body: IIdentityLoginRequest = zodParse(ZIdentityLoginRequest, fromCBOR(bodyCBOR));\n const manager = await StateManager.make();\n\n if (body.withLinkedOrigin !== undefined && body.withLinkedOrigin !== body.toOrigin) {\n if (!manager.linkExists(body.withLinkedOrigin, body.toOrigin))\n err(ErrorCode.UNAUTHORIZED, \"Unable to login without a link\");\n }\n\n const originData = await manager.getOriginData(body.toOrigin);\n if (Object.keys(originData.masks).length === 0) {\n unreacheable(\"login - no origin data found\");\n }\n\n const timestamp = new Date().getTime();\n originData.currentSession = {\n deriviationOrigin: body.withLinkedOrigin ?? body.toOrigin,\n identityId: body.withIdentityId,\n timestampMs: timestamp,\n };\n\n manager.setOriginData(body.toOrigin, originData);\n manager.incrementStats({ login: 1 });\n\n return true;\n}\n\n"
    ],
    "Resolution": [
        "Addressed with the following changeset enforcing that a valid identityId was supplied: fort-major/msq@59a0b88"
    ],
    "Description": [
        "protected_handleIdentityLogin is used to create a new session and logs in to a particular origin (e.g., a website). At a certain point, a new session object is created, where identityId: body.withIdentityId is set. The withIdentityId is an unchecked request parameter, which could potentially lead to an inconsistency where the origin set\u2019s an invalid ID."
    ],
    "Examples": [
        "packages/snap/src/protocols/identity.ts:L76-L101"
    ],
    "Recommendation": [
        "withIdentityId is an id relative to the origins masks, hence, it should be validated against the number of existing masks.",
        "The client validated the issue providing more context:"
    ]
}
----End JSON----

https://solodit.xyz/issues/protected_handleaddassetaccount-should-verify-name-symbol-matches-assetid-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function protected\\_handleAddAssetAccount(bodyCBOR: string): Promise<string | null> {\n const body = zodParse(ZICRC1AddAssetAccountRequest, fromCBOR(bodyCBOR));\n const manager = await StateManager.make();\n\n const agreed = await snap.request({\n method: \"snap\\_dialog\",\n params: {\n type: \"confirmation\",\n content: panel([\n heading(`\ud83d\udd12 Confirm New ${body.symbol} Account \ud83d\udd12`),\n text(`Are you sure you want to create a new \\*\\*${body.name}\\*\\* (\\*\\*${body.symbol}\\*\\*) token account?`),\n text(`This will allow you to send and receive \\*\\*${body.symbol}\\*\\* tokens.`),\n divider(),\n text(\"\\*\\*Confirm?\\*\\* \ud83d\ude80\"),\n ]),\n },\n });\n\n if (!agreed) return null;\n\n const accountName = manager.addAssetAccount(body.assetId);\n\n return accountName;\n}\n\n"
    ],
    "Resolution": [
        "Addressed with the following changeset, escaping and validating asset data more strictly, verifying that the assetId is valid and displaying symbol and name from it\u2019s internal data: fort-major/msq@59a0b88"
    ],
    "Description": [
        "The function protected_handleAddAssetAccount adds an account to an existing asset. It takes the asset name/symbol and assetId as inputs and then adds an account to the assetId if the user approves.",
        "The dialog shown to the user displays the target assets symbol and name. However, this information comes from the dApp and it only used within the dialog. There is no check if the assetId matches the name and symbol which might allow the dApp to mislead the user into accepting the addition of an account for an asset that does not match the displayed name and symbol."
    ],
    "Examples": [
        "packages/snap/src/protocols/icrc1.ts:L90-L113"
    ],
    "Recommendation": [
        "The function should take an assetId as input parameter only. Then check if the assetId has accounts registered. If that\u2019s the case, display the name, symbol that corresponds to the assetId and add an account upon user confirmation."
    ]
}
----End JSON----

https://solodit.xyz/issues/entropy-signature-handling-hardening-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function getSignIdentity(\n origin: TOrigin,\n identityId: TIdentityId,\n salt: Uint8Array,\n): Promise<Secp256k1KeyIdentity> {\n // the MSQ site has constant origin\n // this will allow us to change the domain name without users losing their funds and accounts\n const orig = isMsq(origin) ? \"https://msq.tech\" : origin;\n\n // shared prefix may be used in following updates\n const entropy = await getEntropy(orig, identityId, \"identity-sign\\nshared\", salt);\n\n return Secp256k1KeyIdentity.fromSecretKey(entropy);\n}\n\n",
        "async function getBaseEntropy(origin: TOrigin, identityId: TIdentityId, internalSalt: string): Promise<Uint8Array> {\n const generated: string = await snap.request({\n method: \"snap\\_getEntropy\",\n params: {\n version: 1,\n salt: `\\x0amsq-snap\\n${origin}\\n${identityId}\\n${internalSalt}`,\n },\n });\n\n return hexToBytes(generated.slice(2));\n}\n\n"
    ],
    "Resolution": [
        "The following changeset is addressing this issue by being more strict on type and input validation: fort-major/msq@26a0eec"
    ],
    "Description": [
        "The functions getBaseEntropy and getSignIdentity lack validation for the correct type of arguments or the presence of control characters that may allow context breaks (newline).",
        "For example, in the SNAP_METHODS.public.identity.requestLink method handler, the body.withOrigin is unsanitized and concatenated directly for the resulting salt. withOrigin is a user provided value and may include \\n which breaks the context of the salt structure."
    ],
    "Examples": [
        "packages/snap/src/utils.ts:L75-L89",
        "packages/snap/src/utils.ts:L105-L115"
    ],
    "Recommendation": [
        "To address this, enforcing that identityId is a positive number, valid id and origin is a valid URL (free from control characters) would mitigate misuse of this functionality."
    ]
}
----End JSON----

https://solodit.xyz/issues/makeavatarsvgcustom-potential-svg-html-injection-react-innerhtml-fixed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* Generates a custom avatar SVG string based on provided parameters including body color, body angle,\n \\* face expression, and optional background and eye colors. This function allows for the creation of a\n \\* personalized avatar with specific characteristics defined by the input parameters. The SVG is constructed\n \\* with various elements such as circles for the body and eyes, and a custom path for the face expression.\n \\* Additional details like eye pupils and mouth are also included, with positions adjusted based on the body angle.\n \\*\n \\* @param {string} id - A unique identifier used to generate clip paths for the eyes, ensuring they are unique within the SVG.\n \\* @param {string} bodyColor - The fill color for the avatar's body.\n \\* @param {IAngle} bodyAngle - An object containing the center coordinates for the body and face, used to position elements.\n \\* @param {string} faceExpression - A string representing the SVG path for the face expression.\n \\* @param {string} [bgColor=\"#1E1F28\"] - Optional background color of the SVG. Defaults to a dark gray if not specified.\n \\* @param {string} [eyeWhiteColor=\"white\"] - Optional color for the whites of the eyes. Defaults to white if not specified.\n \\* @returns {string} A string representation of the SVG for the custom avatar.\n \\*/\nexport function makeAvatarSvgCustom(\n id: string,\n bodyColor: string,\n bodyAngle: IAngle,\n faceExpression: string,\n bgColor: string = \"#1E1F28\",\n eyeWhiteColor: string = \"white\",\n): string {\n const { bodyCx, bodyCy, faceX, faceY } = bodyAngle;\n\n const eyeWhite1Cx = faceX + EYE\\_WHITE\\_1\\_CX;\n const eyeWhite1Cy = faceY + EYE\\_WHITE\\_1\\_CY;\n const eyePupil1Cx = faceX + EYE\\_PUPIL\\_1\\_CX;\n const eyePupil1Cy = faceY + EYE\\_PUPIL\\_1\\_CY;\n\n const eyeWhite2Cx = faceX + EYE\\_WHITE\\_2\\_CX;\n const eyeWhite2Cy = faceY + EYE\\_WHITE\\_2\\_CY;\n const eyePupil2Cx = faceX + EYE\\_PUPIL\\_2\\_CX;\n const eyePupil2Cy = faceY + EYE\\_PUPIL\\_2\\_CY;\n\n const mouthX = faceX + MOUTH\\_X;\n const mouthY = faceY + MOUTH\\_Y;\n\n return `\n <svg xmlns=\"http://www.w3.org/2000/svg\" width=\"100\" height=\"100\" style=\"position:relative;width:100%;height:100%;\" viewBox=\"0 0 100 100\" fill=\"none\">\n <defs>\n <clipPath id=\"clip-eye-1-${id}\">\n <circle cx=\"${eyeWhite1Cx}\" cy=\"${eyeWhite1Cy}\" r=\"6\" />\n </clipPath>\n <clipPath id=\"clip-eye-2-${id}\">\n <circle cx=\"${eyeWhite2Cx}\" cy=\"${eyeWhite2Cy}\" r=\"6\" />\n </clipPath>\n </defs>\n\n <rect id=\"bg\" x=\"0\" y=\"0\" width=\"100\" height=\"100\" fill=\"${bgColor}\"/>\n\n <g id=\"body-group\">\n <circle id=\"body\" cx=\"${bodyCx}\" cy=\"${bodyCy}\" r=\"50\" fill=\"${bodyColor}\" />\n\n <circle id=\"eye-white-1\" cx=\"${eyeWhite1Cx}\" cy=\"${eyeWhite1Cy}\" r=\"6\" fill=\"${eyeWhiteColor}\" />\n <circle id=\"eye-pupil-1\" cx=\"${eyePupil1Cx}\" cy=\"${eyePupil1Cy}\" r=\"5\" fill=\"#0A0B15\" clip-path=\"url(#clip-eye-1-${id})\" />\n\n <circle id=\"eye-white-2\" cx=\"${eyeWhite2Cx}\" cy=\"${eyeWhite2Cy}\" r=\"6\" fill=\"${eyeWhiteColor}\" />\n <circle id=\"eye-pupil-1\" cx=\"${eyePupil2Cx}\" cy=\"${eyePupil2Cy}\" r=\"5\" fill=\"#0A0B15\" clip-path=\"url(#clip-eye-2-${id})\" />\n\n <g transform=\"translate(${mouthX}, ${mouthY})\" id=\"mouth\">\n ${faceExpression}\n </g>\n </g>\n </svg>\n `;\n}\n\n",
        "export function CustomBoopAvatar(props: ICustomBoopAvatarProps) {\n return (\n <BoopAvatarWrapper\n classList={props.classList}\n size={props.size}\n ref={(r) => {\n r.innerHTML = makeAvatarSvgCustom(\n props.id,\n props.bodyColor,\n props.angle,\n FACE\\_EXPRESSIONS[props.faceExpression - 1],\n props.bgColor,\n props.eyeWhiteColor,\n );\n }}\n />\n );\n}\n\n",
        "/\\*\\*\n \\* ## Returns user's avatar for current MSQ identity\n \\*\n \\* This avatar is an auto-generated SVG image\n \\* and should be treated as an easy way to render avatars for users without profiles.\n \\*\n \\* @param {string | undefined} bgColor\n \\* @returns {Promise<string>} avatar SVG src string as \"data:image/svg+xml...\"\n \\*/\ngetAvatarSrc(bgColor?: string): Promise<string> {\n const principal = this.getPrincipal();\n const svg = btoa(makeAvatarSvg(principal, bgColor));\n\n return Promise.resolve(`data:image/svg+xml;base64,${svg}`);\n}\n\n",
        "const profile: IProfile = {\n pseudonym: await identity.getPseudonym(),\n avatarSrc: await identity.getAvatarSrc(),\n};\n\n",
        "export function BoopAvatar(props: IBoopAvatarProps) {\n return (\n <BoopAvatarWrapper\n size={props.size}\n ref={(r) => {\n r.innerHTML = makeAvatarSvg(props.principal);\n }}\n />\n );\n}\n\n"
    ],
    "Resolution": [
        "Addressed with fort-major/msq@26a0eec by adding dompurify to the manually generated SVG-XML, still using innerHTML but sanitized for XSS, escaping bgcolor (incomplete: see below) and turning makeAvatarSvgCustom into an internal function with makeAvatarSvg being the external interface where most params cannot be directly controlled.",
        "Additional fix addressing shortcomings of the previous solution as escapeHtml cannot be used for HTML-Attrib sanitization, adding regex checks for html color arguments for makeAvatarSvgCustom: fort-major/msq@59a0b88"
    ],
    "Description": [
        "The function makeAvatarSvgCustom inserts the given arguments directly into a string that represents an XML SVG image. Since the arguments are not sanitized, there is a potential risk for XML-SVG injection, which could include malicious scripts.",
        "Please note that this affects all arguments provided to the function, especially bgColor, but also the ones that are calculating cx,cy because the addition turns into a string concatenation if face[xy] is a string.",
        "The severity rating is based on the current exploitability which is comparable low with the demo implementations of the front-end."
    ],
    "Examples": [
        "packages/shared/src/avatar.ts:L23-L89",
        "used in:",
        "apps/site/src/frontend/components/boop-avatar/index.tsx:L37-L54",
        "packages/client/src/identity.ts:L69-L83",
        "apps/demo/src/frontend/pages/index/index.tsx:L73-L76",
        "used with innerHTML",
        "apps/site/src/frontend/components/boop-avatar/index.tsx:L15-L24"
    ],
    "Recommendation": [
        "Runtime typecheck provided values (numbers vs. strings). Sanitize and validate arguments before embedding then with HTML or use a templating language to build the SVG (recommended)"
    ]
}
----End JSON----

https://solodit.xyz/issues/ctrlcharmarkdown-injection-partially-addressed-consensys-none-msq-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function protected\\_handleAddAssetAccount(bodyCBOR: string): Promise<string | null> {\n const body = zodParse(ZICRC1AddAssetAccountRequest, fromCBOR(bodyCBOR));\n const manager = await StateManager.make();\n\n const agreed = await snap.request({\n method: \"snap\\_dialog\",\n params: {\n type: \"confirmation\",\n content: panel([\n heading(`\ud83d\udd12 Confirm New ${body.symbol} Account \ud83d\udd12`),\n text(`Are you sure you want to create a new \\*\\*${body.name}\\*\\* (\\*\\*${body.symbol}\\*\\*) token account?`),\n text(`This will allow you to send and receive \\*\\*${body.symbol}\\*\\* tokens.`),\n divider(),\n text(\"\\*\\*Confirm?\\*\\* \ud83d\ude80\"),\n ]),\n },\n });\n\n",
        "export async function protected\\_handleAddAsset(bodyCBOR: string): Promise<IAssetDataExternal[] | null> {\n const body = zodParse(ZICRC1AddAssetRequest, fromCBOR(bodyCBOR));\n const manager = await StateManager.make();\n\n const assetNames = body.assets.filter((it) => it.name && it.symbol).map((it) => `${it.name} (${it.symbol})`);\n\n if (assetNames.length > 0) {\n const agreed = await snap.request({\n method: \"snap\\_dialog\",\n params: {\n type: \"confirmation\",\n content: panel([\n heading(`\ud83d\udd12 Confirm New Assets \ud83d\udd12`),\n text(`Are you sure you want to add the following tokens to your managed assets list?`),\n ...assetNames.map((it) => text(` - \\*\\*${it}\\*\\*`)),\n divider(),\n text(\"\\*\\*Confirm?\\*\\* \ud83d\ude80\"),\n ]),\n },\n });\n\n",
        "export async function protected\\_handleShowICRC1TransferConfirm(bodyCBOR: string): Promise<boolean> {\n const body = zodParse(ZShowICRC1TransferConfirmRequest, fromCBOR(bodyCBOR));\n\n const agreed = await snap.request({\n method: \"snap\\_dialog\",\n params: {\n type: \"confirmation\",\n content: panel([\n heading(`\ud83d\udcb3 Confirm ${body.ticker} Transfer \ud83d\udcb3`),\n text(\"\\*\\*Protocol:\\*\\*\"),\n text(\"ICRC-1\"),\n text(\"\\*\\*Initiator:\\*\\*\"),\n text(`\ud83c\udf10 ${originToHostname(body.requestOrigin)}`),\n text(\"\\*\\*From:\\*\\*\"),\n text(body.from),\n text(\"\\*\\*To principal ID:\\*\\*\"),\n text(body.to.owner),\n text(\"\\*\\*To subaccount ID:\\*\\*\"),\n text(body.to.subaccount !== undefined ? bytesToHex(body.to.subaccount) : \"Default subaccount ID\"),\n text(\"\\*\\*Total amount:\\*\\*\"),\n heading(`${body.totalAmountStr} ${body.ticker}`),\n divider(),\n heading(\"\ud83d\udea8 BE CAREFUL! \ud83d\udea8\"),\n text(\"This action is irreversible. You won't be able to recover your funds!\"),\n divider(),\n text(\"\\*\\*Confirm?\\*\\* \ud83d\ude80\"),\n ]),\n },\n });\n\n return Boolean(agreed);\n}\n\n",
        "/\\*\\*\n \\* Create a {@link Text} node.\n \\*\n \\* @param args - The node arguments. This can be either a string\n \\* and a boolean, or an object with a `value` property\n \\* and an optional `markdown` property.\n \\* @param args.value - The text content of the node.\n \\* @param args.markdown - An optional flag to enable or disable markdown. This\n \\* is enabled by default.\n \\* @returns The text node as object.\n \\* @example\n \\* const node = text({ value: 'Hello, world!' });\n \\* const node = text('Hello, world!');\n \\* const node = text({ value: 'Hello, world!', markdown: false });\n \\* const node = text('Hello, world!', false);\n \\*/\nexport const text = createBuilder(NodeType.Text, TextStruct, [\n 'value',\n 'markdown',\n]);\n\n",
        "const node = text({ value: 'Hello, world!', markdown: false });\n\n"
    ],
    "Resolution": [
        "Addressed with the following changeset, wrapping the Snap native UI Text element (accepts Markdown), escaping control characters. Note that the client chose to allow Markdown *_ style elements which is not ideal, as it gives some control over the presentation of data inside the Snap context to the calling dApp.",
        "Changeset: fort-major/msq@2704c68"
    ],
    "Description": [
        "On certain occasions, the snap may need to present a dialog to the user to request confirmation for an action or data verification. This step is crucial as dapps are not always trusted, and it\u2019s essential to prevent scenarios where they can silently sign data or perform critical operations using the user\u2019s keys without explicit permission. To create custom user-facing dialogs, MetaMask provides the Snaps UI package, equipped with style-specific components. However, some of these components have been found to have potentially unintended side-effects.",
        "For instance, the text() component can render Markdown or allow for control character injections. Specifically this poses a concern because users trust information displayed by the Snap.",
        "In the code snippet provided below, please note that the variable body is provided by the dApp. It may contain Markdown renderable strings or Control Characters that can disrupt the context of the user-displayed message. It appears that only protected methods (admin origin) are affected by this, which is reflected in the severity rating of this finding."
    ],
    "Examples": [
        "packages/snap/src/protocols/icrc1.ts:L90-L107",
        "packages/snap/src/protocols/icrc1.ts:L59-L78",
        "packages/snap/src/protocols/icrc1.ts:L26-L57"
    ],
    "Recommendation": [
        "Validate inputs. Encode data in a safe way to be displayed to the user (markdown, control chars). Show the original data provided within a pre-text or code block (copyable). Consider setting markdown: false for text ui components that do not render text.",
        "../packages/snaps-sdk/src/ui/components/text.ts:L34-L53"
    ]
}
----End JSON----

https://solodit.xyz/issues/no-limit-for-minting-amount-fixed-consensys-none-trillion-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function mint(address to, uint256 amount) public onlyRole(MINTER\\_ROLE) {\n \\_mint(to, amount);\n}\n\n"
    ],
    "Description": [
        "In token contract FiatTokenV1, there is no limit set for amount of tokens can be minted, as a result, the minter can mint unlimited tokens, disrupting the token supply and value."
    ],
    "Examples": [
        "../src/v1/FiatTokenV1.sol:L77-L79"
    ],
    "Recommendation": [
        "Add a limit for the number of tokens the minter can mint."
    ]
}
----End JSON----

https://solodit.xyz/issues/private-key-is-exposed-in-the-deployment-and-upgrade-script-fixed-consensys-none-trillion-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 deployerPrivateKey = vm.envUint(\"PRIVATE\\_KEY\");\n\n",
        "uint256 deployerPrivateKey = vm.envUint(\"PRIVATE\\_KEY\");\nvm.startBroadcast(deployerPrivateKey);\n\n"
    ],
    "Description": [
        "In the contract deploying and upgrading script, private key is used to broadcast the transaction, this would expose private key of the deployer and upgrader account on the machine running the script, therefore compromising these accounts."
    ],
    "Examples": [
        "../script/DeployFiatToken.s.sol:L12",
        "../script/UpgradeFiatToken.s.sol:L13-L14"
    ],
    "Recommendation": [
        "Have Forge sending a raw transaction to the cold wallet of the account, the wallet signs the transaction then return the signed transactions to Forge and broadcaster. Alternatively use different wallet for deployment and upgrade and stop using the wallet after the script is complete"
    ]
}
----End JSON----

https://solodit.xyz/issues/critical-functions-are-public-and-without-access-control-fixed-consensys-none-trillion-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function rescue(IERC20 token, address to, uint256 amount) public virtual {\n\n",
        "function blacklist(address account) public virtual {\n \\_blacklisted[account] = true;\n emit Blacklisted(account);\n}\n\n/\\*\\*\n \\* @dev Removes account from blacklist\n \\* @param account The address to remove from the blacklist\n \\*/\nfunction unBlacklist(address account) public virtual {\n \\_blacklisted[account] = false;\n emit UnBlacklisted(account);\n}\n\n"
    ],
    "Description": [
        "Critical functions in RescuableV1(rescue) and BlacklistableV1 (blacklist,unblacklist) are public and unauthenticated, any one can call these function to steal funds and blacklist other accounts. Although the child contract FiatTokenV1 has authenticated the overridden functions and protected them from public access, other contracts inheriting RescuableV1 and BlacklistableV1 might have risks from the unauthenticated public functions"
    ],
    "Examples": [
        "../src/v1/RescuableV1.sol:L30",
        "../src/v1/BlacklistableV1.sol:L51-L63"
    ],
    "Recommendation": [
        "Make these functions internal and in the child contract add correspondent public function with authentication to call the inherited functions"
    ]
}
----End JSON----

https://solodit.xyz/issues/lack-of-fee-limits-for-v3-transactions-fixed-consensys-none-argent-account-argent-multisig-starknet-transaction-v3-updates-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// Limits fee in escapes\nconst MAX\\_ESCAPE\\_MAX\\_FEE: u128 = 50000000000000000; // 0.05 ETH\n\n",
        "} else if tx\\_info.version == TX\\_V1 || tx\\_info.version == TX\\_V1\\_ESTIMATE {\n // other fields not available on V1\n assert(tx\\_info.max\\_fee <= MAX\\_ESCAPE\\_MAX\\_FEE, 'argent/max-fee-too-high');\n\n",
        "/// Limits tip in escapes\nconst MAX\\_ESCAPE\\_TIP: u128 = 1\\_000000000000000000; // 1 STRK\n\n",
        "// Limit the maximum tip while escaping (max\\_fee returns 0 on TX\\_V3)\nlet max\\_l2\\_gas: u64 = loop {\n match tx\\_info.resource\\_bounds.pop\\_front() {\n Option::Some(r) => { if \\*r.resource == 'L2\\_GAS' {\n break \\*r.max\\_amount;\n } },\n Option::None => {\n // L2\\_GAS not found\n break 0;\n }\n };\n};\nlet max\\_tip = tx\\_info.tip \\* max\\_l2\\_gas.into();\nassert(max\\_tip <= MAX\\_ESCAPE\\_TIP, 'argent/tip-too-high');\n\n"
    ],
    "Resolution": [
        "Fixed in PR-266 by introducing limits on the v3 transaction fees through two separate maximums:"
    ],
    "Description": [
        "Starknet transactions have fields to specify the maximum amount of fees the sequencer may take. For v1 transactions, this is just one field with the name max_fee and unit WEI (i.e., 10^{-18} ETH). For the newly introduced v3 transactions, the situation is a bit more complicated. First of all, there are two types of fees: L1_GAS and L2_GAS. The former is needed to cover the gas costs on L1 that the transaction produces, the second is supposed to cover the L2 costs and will be utilized in the upcoming fee market. For each of these two fee types, a transaction specifies the max_amount and the max_price_per_unit. In addition to that, there is also a tip field to help facilitate the market. It is noteworthy that the max_price_per_unit fields \u2013 even for L1_GAS \u2013 and the tip will be specified in 10^{-18} STRK/gas. Another point worth highlighting is that, as Starknet has built-in account abstraction, the fee for a transaction is paid by the account.",
        "Currently, the only sequencer is operated by StarkWare and charges a fair price for the L1 costs. (And L2 fees are not being collected yet.) Hence, even if a transaction specifies a very high fee limit, the sequencer takes only what is really needed and not everything that the transaction limit(s) would allow. For the sake of brevity, let us call such a sequencer \u201cnice\u201d. In a more decentralized Starknet future, there will probably be more sequencers, and they may not necessarily be nice, meaning they may take more in fees than what the L1 costs demand of them. Also, it is not impossible that the rules for the StarkWare sequencer change at some point in the future (although it seems reasonable to assume that this would be properly announced). But \u2013 to summarize this discussion \u2013 currently there is only sequencer, and it is nice. The attack we describe below requires a \u201cnon-nice\u201d sequencer \u2013 and, as we will explain shortly, a malicious Guardian \u2013 and is therefore, at the time of writing this report, not feasible, even assuming the Guardian acts with malice.",
        "As explained in more detail in the System Overview of our previous report, there is an escape mechanism which (1) allows users to reclaim control of their account if the Guardian fails to cooperate and (2) allows Guardians to assign a new owner if the original owner lost access to their key. Crucially and unlike other account activities, escape-related actions require only a single signer. Hence, a general attack scenario that the account should implement protective measures against is a malicious Guardian trying to drain the account by signing an escape transaction with an excessive fee limit. A similar situation arises if, instead of the Guardian being malicious, a third party comes into possession of the owner\u2019s private key, but to keep the discussion more concise, we\u2019ll consider this subsumed under \u201cmalicious Guardian.\u201d As mentioned above, such an attack is not possible with a nice sequencer, but \u2013 ideally \u2013 the account contract should not rely on that.",
        "Examining the relevant code, we see that the fee restriction logic for v1 transactions \u2013 which is known from earlier versions of the contract \u2013 is still present:",
        "src/account/argent_account.cairo:L47-L48",
        "src/account/argent_account.cairo:L772-L774",
        "And there is a limit on the total tip, i.e., tip * L2_GAS.max_amount, for v3 transactions:",
        "src/account/argent_account.cairo:L49-L50",
        "src/account/argent_account.cairo:L758-L771",
        "However, no limit is imposed on the amount of STRK for L1_GAS or L2_GAS. Regarding L1_GAS, this means that a malicious Guardian could specify an excessive max_price_per_unit in an escape transaction and \u2013 with the help of a non-nice sequencer \u2013 drain the account\u2019s entire STRK balance. Since the sequencer can pocket the difference between max_price_per_unit and what is really needed on L1, it is also conceivable that the two parties collude for an attack.",
        "For L2_GAS, the situation is more difficult to assess because the fee market has not been implemented yet. It is very well possible that the \u201cbase fee\u201d will be set by the network \u2013 similar to the base fee on Ethereum, see EIP-1559. In this case, constraining only the tip, as is currently the case, would be sufficient to prevent the L2_GAS part of this kind of attack, as long as one is comfortable with risking to pay any fee the market demands. Nevertheless, as the details of the L2 fee mechanism have not yet been specified, we advise caution."
    ],
    "Recommendation": [
        "For both L1_GAS and L2_GAS, the amount of STRK that can be spent on fees should be limited, similar to the limit on max_fee for v1 transactions. There are several different \u2013 and equally viable \u2013 ways to do this: separately for L1_GAS and L2_GAS or together; including the tip in a (higher) limit or handling it separately.",
        "One aspect of the L2 fees that has, to the best of our knowledge, not been decided yet is whether the tip will be considered part of the max_price_per_unit (similar to EIP-1559) or if it can be on top of that. Hence, to be on the safe side, the latter should be considered possible, and the tip should not be left unconstrained."
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-final-block-number-can-be-finalized-fixed-consensys-none-linea-contracts-update-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "currentL2BlockNumber = \\_finalizationData.finalBlockNumber;\n\n",
        "if (stateRootHashes[currentL2BlockNumber] != \\_finalizationData.parentStateRootHash) {\n revert StartingRootHashDoesNotMatch();\n}\n\n"
    ],
    "Resolution": [
        "fixed by adding a recommended check of finalBlockNumber matching the last block number of the submitted data in _finalizeCompressedBlocks and a check in the prover and adding finalBlockNumber and lastFinalizedBlockNumber in the public input of the verifier in the finalization in PR-24"
    ],
    "Description": [
        "In the data finalization function finalizeCompressedBlocksWithProof, finalizationData.finalBlockNumber is the final block number of the compressed block data to be finalized. However, there is no check in the contract or the prover to ensure finalBlockNumber is correct when there is no new data submitted in the finalization, i.e., submissionDataLength == 0 . The prover can submit an incorrect final block number and, as a result, the finalized block number (currentL2BlockNumber) would be incorrect. Consequently, the prover can skip block data in the finalization."
    ],
    "Examples": [
        "contracts/LineaRollup.sol:L347",
        "contracts/LineaRollup.sol:L199-L201"
    ],
    "Recommendation": [
        "In _finalizeCompressedBlocks, check if finalBlockNumber is equal to the last block number (finalBlockInData) of the last item of submitted block data. Another solution is to have the prover show that finalBlockNumberis correct in the proof by providing the last finalized block number (lastFinalizedBlockNumber) and verify it by adding finalBlockNumber and lastFinalizedBlockNumber in the public input of the verifier in the finalization."
    ]
}
----End JSON----

https://solodit.xyz/issues/finalization-fails-for-the-first-batch-of-data-submitted-after-migration-to-the-updated-contract-fixed-consensys-none-linea-contracts-update-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (startingParentFinalStateRootHash != _finalizationData.parentStateRootHash) {\r\n          revert FinalStateRootHashDoesNotMatch(\r\n            startingParentFinalStateRootHash,\r\n            _finalizationData.parentStateRootHash\r\n          );\r\n }\n\n",
        "if (stateRootHashes[currentL2BlockNumber] != \\_finalizationData.parentStateRootHash) {\n revert StartingRootHashDoesNotMatch();\n}\n\n",
        "if (finalizationDataDataHashesLength != 0) {\n bytes32 startingDataParentHash = dataParents[\\_finalizationData.dataHashes[0]];\n\n if (startingDataParentHash != \\_finalizationData.dataParentHash) {\n revert ParentHashesDoesNotMatch(startingDataParentHash, \\_finalizationData.dataParentHash);\n }\n\n bytes32 startingParentFinalStateRootHash = dataFinalStateRootHashes[startingDataParentHash];\n\n if (startingParentFinalStateRootHash != \\_finalizationData.parentStateRootHash) {\n revert FinalStateRootHashDoesNotMatch(startingParentFinalStateRootHash, \\_finalizationData.parentStateRootHash);\n }\n\n"
    ],
    "Resolution": [
        "Linea responded:",
        "The issue is fixed in PR-24 by wrapping the check",
        "with if (startingDataParentHash != EMPTY_HASH) { to allow it go through the first time after migration, subsequent finalization will be checked."
    ],
    "Description": [
        "When submitting the initial batch of compressed block data after the contract update, the finalization will fail.",
        "In function _finalizeCompressedBlocks, startingDataParentHash = dataParents[_finalizationData.dataHashes[0]] will be empty and, therefore, startingParentFinalStateRootHash = dataFinalStateRootHashes[startingDataParentHash] will be empty too. The check _finalizationData.parentStateRootHash == stateRootHashes[currentL2BlockNumber] requires _finalizationData.parentStateRootHash == _initialStateRootHash, which is not empty, so the condition startingParentFinalStateRootHash != _finalizationData.parentStateRootHash is true, and we revert with the error FinalStateRootHashDoesNotMatch:",
        "contracts/LineaRollup.sol:L199-L201",
        "contracts/LineaRollup.sol:L283-L294"
    ],
    "Recommendation": [
        "Set the correct initial value for dataFinalStateRootHashes for the initial batch of compressed block data."
    ]
}
----End JSON----

https://solodit.xyz/issues/prover-can-censor-l2-l1-messages-partially-addressed-consensys-none-linea-contracts-update-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_addL2MerkleRoots(\\_finalizationData.l2MerkleRoots, \\_finalizationData.l2MerkleTreesDepth);\n\\_anchorL2MessagingBlocks(\\_finalizationData.l2MessagingBlocksOffsets, lastFinalizedBlock);\n\n"
    ],
    "Resolution": [
        "Linea responded that the prover enforces all messages are included in the circuit, however with the circuit code is not opensourced yet, this still need to be verified"
    ],
    "Description": [
        "In L2 \u2192 L1 messaging, messages are grouped and added to a Merkle tree by the prover. During finalization, the operator (coordinator) submits the Merkle root to L1, and the user SDK rebuilds the tree to which the message is added and generates a Merkle proof to claim against the root finalized on L1. However, the prover can skip messages when building the tree. Consequently, the user cannot claim the skipped message, which might result in frozen funds.",
        "Currently, the prover is a single entity owned by Linea. Hence, this would require malice or negligence on Linea\u2019s part."
    ],
    "Examples": [
        "contracts/LineaRollup.sol:L314-L315"
    ],
    "Recommendation": [
        "Decentralize the prover, so messages can be included by different provers."
    ]
}
----End JSON----

https://solodit.xyz/issues/malicious-operator-might-finalize-data-from-a-forked-linea-chain-fixed-consensys-none-linea-contracts-update-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 publicInput = uint256(\n keccak256(\n abi.encode(\n shnarf,\n \\_finalizationData.parentStateRootHash,\n \\_finalizationData.lastFinalizedTimestamp,\n \\_finalizationData.finalBlockNumber,\n \\_finalizationData.finalTimestamp,\n \\_finalizationData.l1RollingHash,\n \\_finalizationData.l1RollingHashMessageNumber,\n keccak256(abi.encodePacked(\\_finalizationData.l2MerkleRoots))\n )\n\n",
        "\\_addL2MerkleRoots(\\_finalizationData.l2MerkleRoots, \\_finalizationData.l2MerkleTreesDepth);\n\n"
    ],
    "Resolution": [
        "Linea team responded that chainId is hard coded in the prover\u2019s circuit, the verifier key (verifier contract) would be different for different chainId, the proof won\u2019t pass the verification unless the forked Linea chain has the same chainId as the canonical chain"
    ],
    "Description": [
        "A malicious operator (prover) can add and finalize block data from a forked Linea chain, so transactions on the forked chain can be finalized, causing a loss of funds from the L1.",
        "For example, a malicious operator forks the canonical chain, then the attacker sends the forked chain Ether to L1 with sendMessage from the forked L2. The operator then submits the block data to L1 and finalizes it with finalizeCompressedBlocksWithProof, using the finalization data and proof from the forked chain. (Note that the malicious prover sets the forked chain chainId in its circuit as a constant.) The L1 contract (LineaRollup) doesn\u2019t know whether the data and the proof are from the canonical L2 or the forked one. The finalization succeeds, and the attacker can claim the bridged forked chain Ether and steal funds from L1.",
        "As there is currently only one operator and it is owned by the Linea team, this kind of attack is unlikely to happen. However, when the operator and the coordinator are decentralized, the likelihood of this attack increases."
    ],
    "Examples": [
        "contracts/LineaRollup.sol:L211-L222",
        "contracts/LineaRollup.sol:L314"
    ],
    "Recommendation": [
        "Add chainId in the FinalizationData as a public input of the verifier function _verifyProof, so the proof from the forked Linea chain will not pass the verification because the chainId won\u2019t match."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-compressed-block-data-is-not-verified-against-data-in-the-prover-during-data-submission-acknowledged-consensys-none-linea-contracts-update-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "shnarf = keccak256(\r\n      abi.encode(\r\n        shnarf,\r\n        _submissionData.snarkHash,\r\n        _submissionData.finalStateRootHash,\r\n        compressedDataComputedX,\r\n        _calculateY(_submissionData.compressedData, compressedDataComputedX)\r\n      )\r\n );     \n\n",
        "function \\_submitData(SubmissionData calldata \\_submissionData) internal returns (bytes32 shnarf) {\n shnarf = dataShnarfHashes[\\_submissionData.dataParentHash];\n\n bytes32 parentFinalStateRootHash = dataFinalStateRootHashes[\\_submissionData.dataParentHash];\n uint256 lastFinalizedBlock = currentL2BlockNumber;\n\n if (\\_submissionData.firstBlockInData <= lastFinalizedBlock) {\n revert FirstBlockLessThanOrEqualToLastFinalizedBlock(\\_submissionData.firstBlockInData, lastFinalizedBlock);\n }\n\n if (\\_submissionData.firstBlockInData > \\_submissionData.finalBlockInData) {\n revert FirstBlockGreaterThanFinalBlock(\\_submissionData.firstBlockInData, \\_submissionData.finalBlockInData);\n }\n\n if (\\_submissionData.parentStateRootHash != parentFinalStateRootHash) {\n revert StateRootHashInvalid(parentFinalStateRootHash, \\_submissionData.parentStateRootHash);\n }\n\n bytes32 currentDataHash = keccak256(\\_submissionData.compressedData);\n\n if (dataFinalStateRootHashes[currentDataHash] != EMPTY\\_HASH) {\n revert DataAlreadySubmitted(currentDataHash);\n }\n\n dataParents[currentDataHash] = \\_submissionData.dataParentHash;\n dataFinalStateRootHashes[currentDataHash] = \\_submissionData.finalStateRootHash;\n\n bytes32 compressedDataComputedX = keccak256(abi.encode(\\_submissionData.snarkHash, currentDataHash));\n\n shnarf = keccak256(\n abi.encode(\n shnarf,\n \\_submissionData.snarkHash,\n \\_submissionData.finalStateRootHash,\n compressedDataComputedX,\n \\_calculateY(\\_submissionData.compressedData, compressedDataComputedX)\n )\n );\n\n dataShnarfHashes[currentDataHash] = shnarf;\n\n emit DataSubmitted(currentDataHash, \\_submissionData.firstBlockInData, \\_submissionData.finalBlockInData);\n}\n\n",
        "function \\_calculateY(\n bytes calldata \\_data,\n bytes32 \\_compressedDataComputedX\n) internal pure returns (bytes32 compressedDataComputedY) {\n if (\\_data.length % 0x20 != 0) {\n revert BytesLengthNotMultipleOf32();\n }\n\n bytes4 errorSelector = ILineaRollup.FirstByteIsNotZero.selector;\n assembly {\n for {\n let i := \\_data.length\n } gt(i, 0) {\n\n } {\n i := sub(i, 0x20)\n let chunk := calldataload(add(\\_data.offset, i))\n if iszero(iszero(and(chunk, 0xFF00000000000000000000000000000000000000000000000000000000000000))) {\n let ptr := mload(0x40)\n mstore(ptr, errorSelector)\n revert(ptr, 0x4)\n }\n compressedDataComputedY := addmod(\n mulmod(compressedDataComputedY, \\_compressedDataComputedX, Y\\_MODULUS),\n chunk,\n Y\\_MODULUS\n )\n }\n }\n}\n\n"
    ],
    "Resolution": [
        "Linea has acknowledged this issue and will implement the recommended check with the EIP-4844 upgrade using the KZG precompile"
    ],
    "Description": [
        "When the sequencer submits the batched block data with the submitData function, it\u2019s expected to check that the submitted commitment of the compressed block data keccak(_submissionData.compressedData) and the commitment of the block data used in the prover (snarkHash) commit to the same data. This is done by proof of equivalence; the x is calculated by hashing keccak(_submissionData.compressedData) and snarkHash, and y is provided by the prover. Then it\u2019s verified that P(x) = y, where P is a polynomial that encodes the compressed data (_submissionData.compressedData). However, in the submitData function, y is evaluated by _calculateY  but it is not checked against the y provided by the prover. In fact, the prover doesn\u2019t provide y to the function; instead x and y are provided to the prover who would evaluate y' and compare it with y from the contract, then x and y are included in the public input for the proof verification in the finalization.",
        "The only difference is if the two commitments don\u2019t commit to the same block data (meaning the data submitted doesn\u2019t match the data used in the prover), submitData would fail \u2013 while in the current implementation, it would fail in the proof verification during the finalization. As a result, if the data submitted doesn\u2019t match the data in the prover in the finalization, the operator has to submit the correct data again in order to finalize it. Linea stated they will verify it in the data submission, once EIP-4844 is implemented."
    ],
    "Examples": [
        "contracts/LineaRollup.sol:L131-L173",
        "contracts/LineaRollup.sol:L384-L413"
    ],
    "Recommendation": [
        "Add the compressed block data verification in the submitData function."
    ]
}
----End JSON----

https://solodit.xyz/issues/empty-compressed-data-allowed-in-data-submission-fixed-consensys-none-linea-contracts-update-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function submitData(\n SubmissionData calldata \\_submissionData\n)\n external\n whenTypeNotPaused(PROVING\\_SYSTEM\\_PAUSE\\_TYPE)\n whenTypeNotPaused(GENERAL\\_PAUSE\\_TYPE)\n onlyRole(OPERATOR\\_ROLE)\n{\n \\_submitData(\\_submissionData);\n}\n\n"
    ],
    "Resolution": [
        "fixed by adding a recommended check in PR-20"
    ],
    "Description": [
        "In submitData, the coordinator can submit data with empty compressedData in _submissionData, which is not a desired purpose of this function and may cause undefined system behavior."
    ],
    "Examples": [
        "contracts/LineaRollup.sol:L115-L124"
    ],
    "Recommendation": [
        "Add a check to disallow data submission with empty compressedData."
    ]
}
----End JSON----

https://solodit.xyz/issues/limiting-the-price-in-the-buy-and-ontokentransfer-functions-fixed-consensys-none-tokenize-it-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function buy(uint256 \\_amount, address \\_tokenReceiver) public whenNotPaused nonReentrant {\n // rounding up to the next whole number. Investor is charged up to one currency bit more in case of a fractional currency bit.\n uint256 currencyAmount = Math.ceilDiv(\\_amount \\* getPrice(), 10 \\*\\* token.decimals());\n\n"
    ],
    "Resolution": [
        "Fixed here for the buy function by adding a _maxCurrencyAmount variable check.\nIt is also mitigated in the onTokenTransfer function. But since you cannot add an extra argument to this function, the minimal token amount is optionally added to the _data parameter. This parameter became a bit complicated and remains optional. So, the result of the direct token transfer with an empty _data can theoretically be manipulated by the owner."
    ],
    "Description": [
        "When an investor tries to buy the tokens in the Crowdinvesting contract, the buy function does not allow to limit the amount of tokens that can be spent during this particular transaction:",
        "contracts/Crowdinvesting.sol:L277-L279",
        "The owner of the price oracle can front-run the transaction and twist the price.",
        "Of course, the buyer can try to regulate that limit with the token allowance, but there may be some exceptions. Sometimes, users want to give more allowance and buy in multiple transactions over time. Or even give an infinite allowance (not recommended) out of convenience.",
        "The same issue can be found in the onTokenTransfer function. This function works differently because the amount of currency is fixed, and the amount of tokens minted is undefined. Because of that, limiting the allowance won\u2019t help, so the user doesn\u2019t know how many tokens can be bought."
    ],
    "Recommendation": [
        "It\u2019s recommended to explicitly limit the amount of tokens that can be transferred from the buyer for the buy function. And allow users to define a minimal amount of tokens bought in the onTokenTransfer function."
    ]
}
----End JSON----

https://solodit.xyz/issues/an-attacker-can-flood-the-support-by-creating-many-tickets-for-arbitrary-addresses-fixed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function create\\_ticket(req\\_address: string, title: any, description: any, apikey: any) {\n\n const address\\_key = SHA256(req\\_address, { outputLength: 32 }).toString();\n\n try{\n const requester = \"[[email\u00a0protected]](/cdn-cgi/l/email-protection)\";\n const ticketData = {ticket: {\n subject: title,\n requester: requester,\n tags: 'anon\\_' + address\\_key,\n comment:{body: description }\n }};\n const url = 'https://71z6182pq3.execute-api.eu-west-1.amazonaws.com/default/tickets?create=true';\n fetch(url, {\n\n"
    ],
    "Resolution": [
        "The client remediated to this issue and provided the following statement: \u201cThe create_ticket function has been removed from both the site and snap. The create tickets handler has also been disabled in the backend, it is not used for now. When the time comes we\u2019ll take care of the DoS protection and authorization\u201d."
    ],
    "Description": [
        "The POST endpoint called by the create_ticket function does not implement any access control mechanism nor does not seem to implement any kind of DoS protection. An attacker can create tickets for any arbitrary address by providing the corresponding address_key, even if he does not own the corresponding private key. That is made possible because the backend does not check whether the API key is authorized for the address key that is submitted."
    ],
    "Examples": [
        "packages/snap/utils/backend_functions.ts:L5-L18"
    ],
    "Recommendation": [
        "When new tickets are submitted, the backend must check that the API key is authorized to create new tickets for that particular address key. Additionally, one should consider implementing proper rate limiting or equivalent DoS protection to prevent the mass creation of tickets by a single user or address, mitigating the risk of support flooding."
    ]
}
----End JSON----

https://solodit.xyz/issues/broken-authorization-scheme-fixed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function create\\_ticket(req\\_address: string, title: any, description: any, apikey: any) {\n\n const address\\_key = SHA256(req\\_address, { outputLength: 32 }).toString();\n\n try{\n const requester = \"[[email\u00a0protected]](/cdn-cgi/l/email-protection)\";\n const ticketData = {ticket: {\n subject: title,\n requester: requester,\n tags: 'anon\\_' + address\\_key,\n comment:{body: description }\n }};\n const url = 'https://71z6182pq3.execute-api.eu-west-1.amazonaws.com/default/tickets?create=true';\n\n",
        "const address\\_key = SHA256(req\\_address, { outputLength: 32 }).toString();\n\ntry{\n const url = 'https://71z6182pq3.execute-api.eu-west-1.amazonaws.com/default/tickets';\n const final\\_url = url + '?address=' + address\\_key;\n\n",
        "export async function get\\_ticket\\_comments(ticket\\_id : any, req\\_address: any, apikey: any){\n let json\\_ticket\\_comments = null;\n const address\\_key = SHA256(req\\_address, { outputLength: 32 }).toString();\n\n try{\n const url = 'https://71z6182pq3.execute-api.eu-west-1.amazonaws.com/default/tickets?ticketId=' + ticket\\_id;\n\n",
        "export async function update\\_ticket(ticket\\_id: any, input\\_data: any, req\\_address: any, apikey: any) {\n console.log(`Updating ticket ${ticket\\_id} with comment: `, input\\_data);\n const address\\_key = SHA256(req\\_address, { outputLength: 32 }).toString();\n\n try {\n const url = 'https://71z6182pq3.execute-api.eu-west-1.amazonaws.com/default/tickets?ticketId='\n + ticket\\_id + '&create=false' + '&from\\_snap';\n\n"
    ],
    "Resolution": [
        "The client fixed this issue by implementing a proper authorisation mechanism on the backend, enforcing that API keys can only access objects they own."
    ],
    "Description": [
        "Anyone can enumerate all tickets belonging to any wallet address by providing the corresponding address key (SHA256 of the address) to the right API endpoint. Users can also create tickets on behalf of other users by sending a POST request to the API with the corresponding address key. Finally, any user can view and post updates to tickets belonging to other users by injecting arbitrary ticket IDs in GET/POST requests sent to the API. The root cause is that the ticket IDs and address keys are not authenticated against a particular user ID/access token. Thus, it allows unauthorized access to potentially sensitive ticket information and the ability to impersonate users and create tickets and post comments to tickets belonging to other users. This is a critical flaw which must be fixed."
    ],
    "Examples": [
        "packages/snap/utils/backend_functions.ts:L5-L17",
        "packages/snap/utils/backend_functions.ts:L38-L42",
        "packages/snap/utils/backend_functions.ts:L67-L72",
        "packages/snap/utils/backend_functions.ts:L94-L100"
    ],
    "Recommendation": [
        "Implement strict validation and proper access control mechanisms to ensure that users can only create, view and modify tickets they are authorized to access. This could involve verifying user permissions against the ticket ID and address key before granting access or allowing modifications."
    ]
}
----End JSON----

https://solodit.xyz/issues/any-website-connected-to-the-snap-can-access-the-address-and-api-key-and-impersonate-the-user-fixed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export const onRpcRequest: OnRpcRequestHandler = async ({ request }) => {\n \n switch (request.method) {\n \n case 'set\\_snap\\_state':\n let allTicketCommentsCount: any = [];\n\n"
    ],
    "Resolution": [
        "The client removed the get_snap_state RPC endpoint, and implemented origin validation in the Snap. Note that the whitelisted origin will still have to be updated to the production domain."
    ],
    "Description": [
        "Currently, there is no validation of the origin for RPC calls made to the Snap. Thus, any dapp connected to the Snap can call any RPC endpoint, which allows an attacker crafting a malicious dapp to access a user\u2019s tickets and impersonate the user to support services. The vulnerability arises because the RPC call handler onRpcRequest() can be invoked by any dapp as it does not validate the origin of the call. This enables any connected dapp to call get_snap_state, exposing critical user information like its userID, API token, and ticket details."
    ],
    "Examples": [
        "packages/snap/src/index.ts:L242-L247"
    ],
    "Recommendation": [
        "Implement strict origin validation in the onRpcRequest() handler to ensure that only authorized and intended domains can invoke the Snap. Additionally, consider removing the get_snap_state RPC endpoint if it is not strictly needed."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-notifications-in-case-multiple-tickets-are-updated-partially-addressed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for(let i = 1; i < ticket\\_ids\\_and\\_comment\\_count.length; i += 3){\n if(ticket\\_ids\\_and\\_comment\\_count[i] > allTicketCommentsCount[i]){\n if(ticket\\_ids\\_and\\_comment\\_count[i+1] == 'agent'){\n if (ticket\\_ids\\_and\\_comment\\_count[i - 1] == allTicketCommentsCount[i - 1]) {\n fireAlerts = true;\n updatedTicketId = ticket\\_ids\\_and\\_comment\\_count[i - 1];\n console.log(\"There is an update on ticket ID: \", updatedTicketId);\n console.log('Firing notifications...');\n setSnapState(apiKey, address, allTicketCommentsCount, dialog);\n\n"
    ],
    "Resolution": [
        "The client fixed the issue in commit 7ef2853d21049986beefaec4f2405814319f7cfb and provided the following statement: \u201cIf multiple tickets are updated, all of them are sent as a notification to the user, so they don\u2019t miss any updates.\nIn the future, we should also check if there are too many updates and redirect the user to the dashboard instead of showing 5 notifications, for example. At the moment this is not a concern, since the average user statistically has about 1.1 tickets in their lifetime.\u201d"
    ],
    "Description": [
        "Currently, if multiple tickets are updated (have new comments), the Snap will only trigger a notification for the last updated ticket. The fetchAllTicketCommentsCount function only triggers a notification for the last updated ticket, as the variable updatedTicketId gets overridden in each iteration of the loop by the last updated ticket id. Consequently, updates to other tickets are not notified. This issue is problematic for users who have multiple tickets opened concurrently, as when there are multiple tickets with new comments, all except the last updated ticket go unnoticed."
    ],
    "Examples": [
        "packages/snap/src/index.ts:L83-L91"
    ],
    "Recommendation": [
        "Revise the notification logic to ensure that the user is notified in case multiple tickets are updated. One could accumulate all updated ticket IDs in an array and then iterate over this array to fire alerts for each updated ticket. In case there are many updated tickets, one should probably notify the user and redirect him to the dapp to read the new messages."
    ]
}
----End JSON----

https://solodit.xyz/issues/general-design-and-performance-considerations-data-fetchingcaching-and-state-update-partially-addressed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "setSnapState(apiKey, address, allTicketCommentsCount, dialog);\n\n",
        "setSnapState(apiKey, address, allTicketCommentsCount, dialog);\n\n"
    ],
    "Resolution": [
        "The client partly addressed this issue in commit 7ef2853d21049986beefaec4f2405814319f7cfb and provided the following statement: \u201cAll of the user\u2019s tickets (list of ticket ids and other data, not whole tickets) and only the tickets that have had updates are fetched every 30 seconds. We determine if a ticket has been updated if the id of the last comment of a ticket has changed.\u201d."
    ],
    "Description": [
        "The Snap\u2019s current design, which pulls all user tickets and comments from the server every second, poses significant performance and efficiency issues. This constant fetching process occurs for every user who has installed the Snap, leading to concerns, particularly for users with numerous tickets and comments. The Snaps has to re-process the same data repeatedly, despite having a local cache. This approach not only renders the local caching inefficient, as data is re-fetched in every cycle, but also places an unnecessary load on the backend and results in the same data being transmitted many times.",
        "Additionally, it can also be highlighted that the snaps contain unnecessary state updates: every key in the Snap\u2019s state is updated every time, even if it hasn\u2019t changed. For instance, but not exclusively, here:",
        "packages/snap/src/index.ts:L91",
        "packages/snap/src/index.ts:L103"
    ],
    "Recommendation": [
        "We recommend redesigning the data fetching mechanism to enhance efficiency and performance. One should aim to fetch only new or updated comments, potentially by cleverly leveraging ticket and comment IDs/timestamps. This would reduce the load on both the client and the server and minimize unneeded computing and data transfer. If tickets can be updated, one also needs to consider this case.\nIn general, one should also avoid unnecessary Snap state updates by updating only the modified keys."
    ]
}
----End JSON----

https://solodit.xyz/issues/markdown-injection-in-snaps-ui-components-acknowledged-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (let i = 0; i < json.length; i++){\n const comment = json[i]['body'];\n const sender = json[i]['via']['channel'] == 'api' ? '\\*\\*You\\*\\*' : '\\*\\*Agent\\*\\*'\n formatted\\_comments += `${sender}: ${comment}\\n\\n\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\_\\n\\n`;\n\n"
    ],
    "Resolution": [
        "The client acknowledged this issue and has decided not to fix it yet: \u201cThis has not been tackled yet. Since this could only be exploited by our own agents, we decided to focus on fixing the other issues first.\u201d"
    ],
    "Description": [
        "Snaps UI components are prone to markdown and control character injections. In this case, one of the risk is the potential for operators to mislead users. For example, an operator could create a comment that falsely appears as if another person has joined the discussion. This is achieved by formatting a comment with a reply followed by a separator and then falsely attributing a message to someone else, as in <officialReply>\\n\\n______________________\\n\\n<OtherPerson>: <OtherComment>.",
        "Considering users should only be able to see their own and the operator\u2019s comments, and operators are assumed non-malicious, this vulnerability should not pose significant security concerns.\nHowever, one should keep that in mind in case security assumptions evolve."
    ],
    "Examples": [
        "packages/snap/src/index.ts:L120-L123"
    ],
    "Recommendation": [
        "As a mitigation, one could implement comprehensive content sanitization and strict validation for markdown rendered in UI components to prevent such misleading representations. Alternatively, one could investigate rendering comments in distinct UI components."
    ]
}
----End JSON----

https://solodit.xyz/issues/fetchallticketcommentscount-is-unoptimized-overly-complex-and-lacks-untrusted-input-validation-fixed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const fetchAllTicketCommentsCount = async () => {\n\n let allTicketCommentsCount : any = [];\n let fireAlerts = false;\n let updatedTicketId = null;\n\n const state = await getSnapState();\n const address = state?.address as string\n\n",
        "await get\\_user\\_tickets(address, apiKey)\n .then( async (json : any) => {\n const ticket\\_count = json['count'];\n if (ticket\\_count > 0)\n for(let i = 0; i < ticket\\_count; i++){\n const ticket\\_id = json['rows'][i]['ticket']['id'];\n await get\\_ticket\\_comments(ticket\\_id, address, apiKey).then( (json : any) => {\n if(json.length > 0){\n const last\\_comment\\_source = json[json.length-1]['via']['channel'];\n ticket\\_ids\\_and\\_comment\\_count.push(ticket\\_id);\n ticket\\_ids\\_and\\_comment\\_count.push(json.length);\n if(last\\_comment\\_source == 'api')\n ticket\\_ids\\_and\\_comment\\_count.push('user');\n else if (last\\_comment\\_source == 'web')\n ticket\\_ids\\_and\\_comment\\_count.push('agent');\n }\n })\n }\n })\n .then(() => {\n // console.log(ticket\\_ids\\_and\\_comment\\_count);\n // console.log(allTicketCommentsCount);\n if(allTicketCommentsCount.length == 0){\n console.log('Notification process started.');\n }\n\n",
        " if (ticket\\_ids\\_and\\_comment\\_count[i - 1] == allTicketCommentsCount[i - 1]) {\n fireAlerts = true;\n updatedTicketId = ticket\\_ids\\_and\\_comment\\_count[i - 1];\n console.log(\"There is an update on ticket ID: \", updatedTicketId);\n console.log('Firing notifications...');\n setSnapState(apiKey, address, allTicketCommentsCount, dialog);\n }\n }\n }\n }\n }\n }\n}).then(() =>{\n // console.log(ticket\\_ids\\_and\\_comment\\_count);\n\n"
    ],
    "Resolution": [
        "The client addressed this issue in commit 7ef2853d21049986beefaec4f2405814319f7cfb. Additionally, they provided the following statement:",
        "\u201cThe fetchAllTicketCommentsCount() method has been deleted and rebuilt from scratch. Its new name is checkTicketUpdates and the following improvements were added:"
    ],
    "Description": [
        "The current fetchAllTicketCommentsCount() function is overly complex and poorly optimized. For instance, the function unnecessarily exhibits a sequence of \u201cthen\u201d promises, which could be avoided. Moreover, the function fetches ticket comments sequentially, whereas a parallel approach would be more efficient. It also parses ticket_count from the received JSON data and uses it to iterate over that data, yet it fails to validate that ticket_count is less than the length of the received data. These examples illustrate that it would be a good idea to refactor and optimize the function to increase the readability and robustness of its code.",
        "We would suggest optimizing the function and simplifying its code to improve readability and robustness. More precisely, one could make the following changes:",
        "packages/snap/src/index.ts:L35-L42",
        "packages/snap/src/index.ts:L53-L77",
        "packages/snap/src/index.ts:L86-L99"
    ],
    "Recommendation": [
        "We recommend completely refactoring the fetchAllTicketCommentsCount() function in line with these suggestions. This refactoring will not only make the code more readable and maintainable but also improve its performance.",
        "As a future improvement, one should also investigate more optimized mechanisms to fetch tickets, such as server-side push instead of client-side pull or smarter algorithms to fetch only new comments. This would significantly improve user performance with many tickets/comments and reduce both server and client-side load. (see issue 4.5 )"
    ]
}
----End JSON----

https://solodit.xyz/issues/improper-paramater-sanitization-in-fetchallticketcommentscount-updateticket-and-parseticketcomments-fixed-consensys-none-web3-tickets-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const fetchAllTicketCommentsCount = async () => {\n\n let allTicketCommentsCount : any = [];\n let fireAlerts = false;\n let updatedTicketId = null;\n\n const state = await getSnapState();\n const address = state?.address as string\n const apiKey = state?.apiKey as string\n const dialog = state?.dialog as string\n\n",
        "async function updateTicket(ticketId: any, user\\_comment: any) {\n // need a function here as getSnapState() doesn't seem to work in cron\n const state = await getSnapState();\n const address = state?.address as string\n const apiKey = state?.apiKey as string\n\n const update\\_result = await update\\_ticket(ticketId, user\\_comment, address, apiKey);\n\n",
        "async function parseTicketComments(ticketId: any) {\n const state = await getSnapState();\n const address = state?.address as string\n const apiKey = state?.apiKey as string\n let formatted\\_comments = `Login to https://web3tickets.metamask.io to see your personal dashboard with all tickets open for your ethereum account address. \\n\\n`;\n\n"
    ],
    "Resolution": [
        "The client addressed this issue in commit 7ef2853d21049986beefaec4f2405814319f7cfb: \u201cAll of the methods now have an early if statement causing them to exit if the needed variables are not present at the moment of their calling.\u201d"
    ],
    "Description": [
        "Currently, if the Snap\u2019s state is empty or undefined, fetchAllTicketCommentsCount() tries to fetch tickets for the key corresponding to the hash of the empty string \"\". This occurs when the snap is installed and the state has not yet been initialized by the dapp, for instance. This leads to unnecessary processing on the server and could also result in more severe issues. In general, functions should validate and sanitize any input parameters, especially if they are not trusted.\nIn this case, fetchAllTicketCommentsCount(), updateTicket(), and parseTicketComments() should exit early if any of their parameters or values retrieved from the state, such as apiKey, address, or ticketID are not defined."
    ],
    "Examples": [
        "packages/snap/src/index.ts:L35-L44",
        "packages/snap/src/index.ts:L133-L139",
        "packages/snap/src/index.ts:L113-L117"
    ],
    "Recommendation": [
        "Modify fetchAllTicketCommentsCount(), updateTicket(), and parseTicketComments() to include early exit conditions. These functions should immediately return or exit if essential parameters such as apiKey, address, or ticketID are not defined. Implementing these checks will prevent the functions from executing with incomplete or invalid data."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-events-on-important-state-changes-fixed-consensys-none-rocket-pool-houston-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function bootstrapMember(string memory _id, string memory _url, address _nodeAddress) override external onlyGuardian onlyBootstrapMode onlyRegisteredNode(_nodeAddress) onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\n    // Ok good to go, lets add them\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalInvite(_id, _url, _nodeAddress);\n}\n\n\n// Bootstrap mode - Uint Setting\nfunction bootstrapSettingUint(string memory _settingContractName, string memory _settingPath, uint256 _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\n    // Ok good to go, lets update the settings\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalSettingUint(_settingContractName, _settingPath, _value);\n}\n\n// Bootstrap mode - Bool Setting\nfunction bootstrapSettingBool(string memory _settingContractName, string memory _settingPath, bool _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\n    // Ok good to go, lets update the settings\n    RocketDAONodeTrustedProposalsInterface(getContractAddress(\"rocketDAONodeTrustedProposals\")).proposalSettingBool(_settingContractName, _settingPath, _value);\n}\n\n",
        "function bootstrapSettingMulti(string[] memory _settingContractNames, string[] memory _settingPaths, SettingType[] memory _types, bytes[] memory _values) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\n  // Ok good to go, lets update the settings\n  RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalSettingMulti(_settingContractNames, _settingPaths, _types, _values);\n}\n\n/// @notice Bootstrap mode - Uint Setting\nfunction bootstrapSettingUint(string memory _settingContractName, string memory _settingPath, uint256 _value) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\n    // Ok good to go, lets update the settings\n    RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalSettingUint(_settingContractName, _settingPath, _value);\n}\n\n",
        "function bootstrapTreasuryNewContract(string memory _contractName, address _recipientAddress, uint256 _amountPerPeriod, uint256 _periodLength, uint256 _startTime, uint256 _numPeriods) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\n    RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalTreasuryNewContract(_contractName, _recipientAddress, _amountPerPeriod, _periodLength, _startTime, _numPeriods);\n}\n\n",
        "function bootstrapDisable(bool _confirmDisableBootstrapMode) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\n    require(_confirmDisableBootstrapMode == true, \"You must confirm disabling bootstrap mode, it can only be done once!\");\n    setBool(keccak256(abi.encodePacked(daoNameSpace, \"bootstrapmode.disabled\")), true);\n}\n\n",
        "function bootstrapSpendTreasury(string memory _invoiceID, address _recipientAddress, uint256 _amount) override external onlyGuardian onlyBootstrapMode onlyLatestContract(\"rocketDAOProtocol\", address(this)) {\n    RocketDAOProtocolProposalsInterface(getContractAddress(\"rocketDAOProtocolProposals\")).proposalTreasuryOneTimeSpend(_invoiceID, _recipientAddress, _amount);\n}\n\n",
        "function setDelegate(address _newDelegate) external override onlyRegisteredNode(msg.sender) {\n\n",
        "function proposalSettingUint(string memory _settingNameSpace, string memory _settingPath, uint256 _value) override public onlyExecutingContracts() onlyValidSetting(_settingNameSpace, _settingPath) {\n    bytes32 namespace = keccak256(abi.encodePacked(protocolDaoSettingNamespace, _settingNameSpace));\n\n",
        "function proposalSettingBool(string memory _settingNameSpace, string memory _settingPath, bool _value) override public onlyExecutingContracts() onlyValidSetting(_settingNameSpace, _settingPath) {\n    bytes32 namespace = keccak256(abi.encodePacked(protocolDaoSettingNamespace, _settingNameSpace));\n\n",
        "function proposalSettingAddress(string memory _settingNameSpace, string memory _settingPath, address _value) override public onlyExecutingContracts() onlyValidSetting(_settingNameSpace, _settingPath) {\n    bytes32 namespace = keccak256(abi.encodePacked(protocolDaoSettingNamespace, _settingNameSpace));\n\n",
        "function proposalInvite(string calldata _id, address _memberAddress) override public onlyLatestContract(\"rocketDAOProtocolProposals\", msg.sender) {\n    // Their proposal executed, record the block\n\n",
        "function setMaxPenaltyRate(uint256 _rate) external override onlyGuardian {\n    // Update rate\n    maxPenaltyRate = _rate;\n    // Emit event\n    emit MaxPenaltyRateUpdated(_rate, block.timestamp);\n}\n\n"
    ],
    "Resolution": [
        "The client implemented a fix in commit 1be41a88a40125baf58d8904770cd9eb9e0732bb and provided the following statement:"
    ],
    "Description": [
        "Throughout the code base, various important settings-related state changes are not surfaced by events.",
        "In RocketDAONodeTrusted:",
        "contracts/contract/dao/node/RocketDAONodeTrusted.sol:L149-L165",
        "In RocketDAOProtocol:",
        "contracts/contract/dao/protocol/RocketDAOProtocol.sol:L42-L51",
        "Treasury address setter:",
        "contracts/contract/dao/protocol/RocketDAOProtocol.sol:L77-L79",
        "Bootstrap mode management:",
        "contracts/contract/dao/protocol/RocketDAOProtocol.sol:L97-L100",
        "One-time treasury spends:",
        "contracts/contract/dao/protocol/RocketDAOProtocol.sol:L72-L74",
        "In RocketNetworkVoting.sol:",
        "contracts/contract/network/RocketNetworkVoting.sol:L122",
        "In RocketDAOSecurityProposals.sol:",
        "contracts/contract/dao/security/RocketDAOSecurityProposals.sol:L98-L99",
        "contracts/contract/dao/security/RocketDAOSecurityProposals.sol:L107-L108",
        "contracts/contract/dao/security/RocketDAOSecurityProposals.sol:L116-L117",
        "contracts/contract/dao/security/RocketDAOSecurityProposals.sol:L126-L127"
    ],
    "Recommendation": [
        "We recommend emitting events on state changes, particularly when these are performed by an authorized party. The implementation of the recommendation should be analogous to the handling of events on state changes in the rest of the system, such as in the RocketMinipoolPenalty contract:",
        "contracts/contract/minipool/RocketMinipoolPenalty.sol:L28-L33"
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaoprotocolproposal_propose-should-revert-if-_blocknumber-blocknumber-fixed-consensys-none-rocket-pool-houston-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function _propose(string memory _proposalMessage, uint256 _blockNumber, uint256 _totalVotingPower, bytes calldata _payload) internal returns (uint256) {\n\n"
    ],
    "Resolution": [
        "The client fixed this issue in commit c60c1d292a81eb83c4c766425303f31c1d74901e"
    ],
    "Description": [
        "Currently, the RocketDAOProtocolProposal._propose() function does not account for scenarios where _blockNumber is greater than block.number. This is a critical oversight, as voting power cannot be determined for future block numbers.",
        "contracts/contract/dao/protocol/RocketDAOProtocolProposal.sol:L351"
    ],
    "Recommendation": [
        "We recommend updating the function to revert on transactions where _blockNumber exceeds block.number. This will prevent the creation of proposals with undefined voting power and maintain the integrity of the voting process."
    ]
}
----End JSON----

https://solodit.xyz/issues/fetchallticketcommentscount-is-unoptimized-overly-complex-and-lacks-untrusted-input-validation-fixed-consensys-none-web3-tickets-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const fetchAllTicketCommentsCount = async () => {\n\n  let allTicketCommentsCount : any = [];\n  let fireAlerts = false;\n  let updatedTicketId = null;\n\n  const state = await getSnapState();\n  const address = state?.address as string\n\n",
        "await get_user_tickets(address, apiKey)\n .then( async (json : any) => {\n   const ticket_count = json['count'];\n   if (ticket_count > 0)\n     for(let i = 0; i < ticket_count; i++){\n       const ticket_id = json['rows'][i]['ticket']['id'];\n       await get_ticket_comments(ticket_id, address, apiKey).then( (json : any) => {\n         if(json.length > 0){\n           const last_comment_source = json[json.length-1]['via']['channel'];\n           ticket_ids_and_comment_count.push(ticket_id);\n           ticket_ids_and_comment_count.push(json.length);\n           if(last_comment_source == 'api')\n             ticket_ids_and_comment_count.push('user');\n           else if (last_comment_source == 'web')\n             ticket_ids_and_comment_count.push('agent');\n         }\n       })\n     }\n })\n .then(() => {\n   // console.log(ticket_ids_and_comment_count);\n   // console.log(allTicketCommentsCount);\n     if(allTicketCommentsCount.length == 0){\n     console.log('Notification process started.');\n   }\n\n",
        "            if (ticket_ids_and_comment_count[i - 1] == allTicketCommentsCount[i - 1]) {\n              fireAlerts = true;\n              updatedTicketId = ticket_ids_and_comment_count[i - 1];\n              console.log(\"There is an update on ticket ID: \", updatedTicketId);\n              console.log('Firing notifications...');\n              setSnapState(apiKey, address, allTicketCommentsCount, dialog);\n            }\n          }\n        }\n      }\n    }\n  }\n}).then(() =>{\n  // console.log(ticket_ids_and_comment_count);\n\n"
    ],
    "Resolution": [
        "The client addressed this issue in commit 7ef2853d21049986beefaec4f2405814319f7cfb. Additionally, they provided the following statement:",
        "\u201cThe fetchAllTicketCommentsCount() method has been deleted and rebuilt from scratch. Its new name is checkTicketUpdates and the following improvements were added:"
    ],
    "Description": [
        "The current fetchAllTicketCommentsCount() function is overly complex and poorly optimized. For instance, the function unnecessarily exhibits a sequence of \u201cthen\u201d promises, which could be avoided. Moreover, the function fetches ticket comments sequentially, whereas a parallel approach would be more efficient. It also parses ticket_count from the received JSON data and uses it to iterate over that data, yet it fails to validate that ticket_count is less than the length of the received data. These examples illustrate that it would be a good idea to refactor and optimize the function to increase the readability and robustness of its code.",
        "We would suggest optimizing the function and simplifying its code to improve readability and robustness. More precisely, one could make the following changes:",
        "packages/snap/src/index.ts:L35-L42",
        "packages/snap/src/index.ts:L53-L77",
        "packages/snap/src/index.ts:L86-L99"
    ],
    "Recommendation": [
        "We recommend completely refactoring the fetchAllTicketCommentsCount() function in line with these suggestions. This refactoring will not only make the code more readable and maintainable but also improve its performance.",
        "As a future improvement, one should also investigate more optimized mechanisms to fetch tickets, such as server-side push instead of client-side pull or smarter algorithms to fetch only new comments. This would significantly improve user performance with many tickets/comments and reduce both server and client-side load. (see issue 4.5 )"
    ]
}
----End JSON----

https://solodit.xyz/issues/no-protection-of-uninitialized-implementation-contracts-from-attacker-consensys-none-leequid-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "contract Rewards is IRewards, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\n\n",
        "contract Pool is IPool, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\n\n",
        "contract StakedLyxToken is OwnablePausableUpgradeable, LSP4DigitalAssetMetadataInitAbstract, IStakedLyxToken, ReentrancyGuardUpgradeable {\n\n",
        "Pool\r\nPoolValidators\r\nFeeEscrow\r\nReward\r\nStakeLyxTokem\r\nOracles \r\nMerkleDistributor\n\n"
    ],
    "Description": [
        "In the contracts implement Openzeppelin\u2019s UUPS model, uninitialized implementation contract can be taken over by an attacker with initialize function, it\u2019s recommended to invoke the _disableInitializers function in the constructor to prevent the implementation contract from being used by the attacker. However all the contracts which implements OwnablePausableUpgradeable do not call _disableInitializers in the constructors"
    ],
    "Examples": [
        "contracts/tokens/Rewards.sol:L25",
        "contracts/pool/Pool.sol:L20",
        "contracts/tokens/StakedLyxToken.sol:L46",
        "etc."
    ],
    "Recommendation": [
        "Invoke _disableInitializers in the constructors of contracts which implement OwnablePausableUpgradeable including following:"
    ]
}
----End JSON----

https://solodit.xyz/issues/no-protection-of-uninitialized-implementation-contracts-from-attacker-fixed-consensys-none-leequid-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "contract Rewards is IRewards, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\n\n",
        "contract Pool is IPool, OwnablePausableUpgradeable, ReentrancyGuardUpgradeable {\n\n",
        "contract StakedLyxToken is OwnablePausableUpgradeable, LSP4DigitalAssetMetadataInitAbstract, IStakedLyxToken, ReentrancyGuardUpgradeable {\n\n",
        "Pool\r\nPoolValidators\r\nFeeEscrow\r\nReward\r\nStakeLyxTokem\r\nOracles \r\nMerkleDistributor\n\n"
    ],
    "Description": [
        "In the contracts implement Openzeppelin\u2019s UUPS model, uninitialized implementation contract can be taken over by an attacker with initialize function, it\u2019s recommended to invoke the _disableInitializers function in the constructor to prevent the implementation contract from being used by the attacker. However all the contracts which implements OwnablePausableUpgradeable do not call _disableInitializers in the constructors"
    ],
    "Examples": [
        "contracts/tokens/Rewards.sol:L25",
        "contracts/pool/Pool.sol:L20",
        "contracts/tokens/StakedLyxToken.sol:L46",
        "etc."
    ],
    "Recommendation": [
        "Invoke _disableInitializers in the constructors of contracts which implement OwnablePausableUpgradeable including following:"
    ]
}
----End JSON----

https://solodit.xyz/issues/re-entrancy-risks-associated-with-external-calls-with-other-liquid-staking-systems-fixed-consensys-none-lybra-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "contract LybraWstETHVault is LybraPeUSDVaultBase {\n Ilido immutable lido;\n //WstETH = 0x7f39C581F595B53c5cb19bD0b3f8dA6c935E2Ca0;\n //Lido = 0xae7ab96520DE3A18E5e111B5EaAb095312D7fE84;\n constructor(address \\_lido, address \\_asset, address \\_oracle, address \\_config) LybraPeUSDVaultBase(\\_asset, \\_oracle, \\_config) {\n lido = Ilido(\\_lido);\n }\n\n function depositEtherToMint(uint256 mintAmount) external payable override {\n require(msg.value >= 1 ether, \"DNL\");\n uint256 sharesAmount = lido.submit{value: msg.value}(address(configurator));\n require(sharesAmount != 0, \"ZERO\\_DEPOSIT\");\n lido.approve(address(collateralAsset), msg.value);\n uint256 wstETHAmount = IWstETH(address(collateralAsset)).wrap(msg.value);\n depositedAsset[msg.sender] += wstETHAmount;\n if (mintAmount > 0) {\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\n }\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,wstETHAmount, block.timestamp);\n }\n\n",
        "contract LybraWBETHVault is LybraPeUSDVaultBase {\n //WBETH = 0xa2e3356610840701bdf5611a53974510ae27e2e1\n constructor(address \\_asset, address \\_oracle, address \\_config)\n LybraPeUSDVaultBase(\\_asset, \\_oracle, \\_config) {}\n\n function depositEtherToMint(uint256 mintAmount) external payable override {\n require(msg.value >= 1 ether, \"DNL\");\n uint256 preBalance = collateralAsset.balanceOf(address(this));\n IWBETH(address(collateralAsset)).deposit{value: msg.value}(address(configurator));\n uint256 balance = collateralAsset.balanceOf(address(this));\n depositedAsset[msg.sender] += balance - preBalance;\n\n if (mintAmount > 0) {\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\n }\n\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,balance - preBalance, block.timestamp);\n }\n\n",
        "constructor(address \\_rocketStorageAddress, address \\_rETH, address \\_oracle, address \\_config)\n LybraPeUSDVaultBase(\\_rETH, \\_oracle, \\_config) {\n rocketStorage = IRocketStorageInterface(\\_rocketStorageAddress);\n}\n\nfunction depositEtherToMint(uint256 mintAmount) external payable override {\n require(msg.value >= 1 ether, \"DNL\");\n uint256 preBalance = collateralAsset.balanceOf(address(this));\n IRocketDepositPool(rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \"rocketDepositPool\")))).deposit{value: msg.value}();\n uint256 balance = collateralAsset.balanceOf(address(this));\n depositedAsset[msg.sender] += balance - preBalance;\n\n if (mintAmount > 0) {\n \\_mintPeUSD(msg.sender, msg.sender, mintAmount, getAssetPrice());\n }\n\n emit DepositEther(msg.sender, address(collateralAsset), msg.value,balance - preBalance, block.timestamp);\n}\n\n"
    ],
    "Resolution": [
        "Fixed in commit f43b7cd5135872143cc35f40cae95870446d0413 by introducing reentrancy guards."
    ],
    "Description": [
        "As part of the strategy to integrate with Liquid Staking tokens for Ethereum staking, the Lybra Protocol vaults are required to make external calls to Liquid Staking systems.",
        "For example, the depositEtherToMint function in the vaults makes external calls to deposit Ether and receive the LSD tokens back. While external calls to untrusted third-party contracts may be dangerous, in this case, the Lybra Protocol already extends trust assumptions to these third parties simply through the act of accepting their tokens as collateral. Indeed, in some cases the contract addresses are even hardcoded into the contract and called directly instead of relying on some registry:",
        "contracts/lybra/pools/LybraWstETHVault.sol:L21-L40",
        "In that case, depending on the contract, it may be known what contract is being called, and the risk may be assessed as far as what logic may be executed.",
        "However, in the cases of BETH and rETH, the calls are being made into a proxy and a contract registry of a DAO (RocketPool\u2019s DAO) respectively.",
        "contracts/lybra/pools/LybraWbETHVault.sol:L15-L32",
        "contracts/lybra/pools/LybraRETHVault.sol:L25-L42",
        "As a result, it is impossible to make any guarantees for what logic will be executed during the external calls. Namely, reentrancy risks can\u2019t be ruled out, and the damage could be critical to the system. While the trust in these parties isn\u2019t in question, it would be best practice to avoid any additional reentrancy risks by placing reentrancy guards. Indeed, in the LybraRETHVault and LybraWbETHVault contracts, one can see the possible damage as the calls are surrounded in a preBalance <-> balance pattern.",
        "The whole of third party Liquid Staking systems\u2019 operations need not be compromised, only these particular parts would be enough to cause critical damage to the Lybra Protocol."
    ],
    "Recommendation": [
        "After conversations with the Lybra Finance team, it has been assessed that reentrancy guards are appropriate in this scenario to avoid any potential reentrancy risk, which is exactly the recommendation this audit team would provide."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-deployer-of-governancetimelock-gets-privileged-access-to-the-system-fixed-consensys-none-lybra-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function checkRole(bytes32 role, address \\_sender) public view returns(bool){\n return hasRole(role, \\_sender) || hasRole(DAO, \\_sender);\n}\n\nfunction checkOnlyRole(bytes32 role, address \\_sender) public view returns(bool){\n return hasRole(role, \\_sender);\n}\n\n",
        "constructor(uint256 minDelay, address[] memory proposers, address[] memory executors, address admin) TimelockController(minDelay, proposers, executors, admin) {\n \n \\_setRoleAdmin(DAO, GOV);\n \\_setRoleAdmin(TIMELOCK, GOV);\n \\_setRoleAdmin(ADMIN, GOV);\n \\_grantRole(DAO, address(this));\n \\_grantRole(DAO, msg.sender);\n \\_grantRole(GOV, msg.sender);\n}\n\n"
    ],
    "Resolution": [
        "As per discussions with the Lybra Finance team, this has been acknowledged as a temporary measure to configure anything before the launch of V2. Following the discussions, the Lybra Finance team has revoked the deployer\u2019s permissions in transaction 0x12c95eec095f7e24abc6a127f378f9f0fb3a0021aeac82b487c11afa01b793af and updated the GovernanceTimelock code in commit 77e8bc3664fb1b195fd718c2ce1d49af8530f981 to instead introduce a multisig address that will have the ADMIN role whose only permission within the configurator contract is to pause the minting function in emergency situations."
    ],
    "Description": [
        "The GovernanceTimelock contract is responsible for Roles Based Access Control management and checks in the Lybra Protocol. It offers two functions specifically that check if an address has the required role - checkRole and checkOnlyRole:",
        "contracts/lybra/governance/GovernanceTimelock.sol:L24-L30",
        "In checkRole, the contract also lets an address with the role DAO bypass the check altogether, making it a powerful role.",
        "For initial role management, when the GovernanceTimelock contract gets deployed, its constructor logic initializes a few roles, assigns relevant admin roles, and, notably, assigns the DAO role to the contract, and the DAO and the GOV role to the deployer.",
        "contracts/lybra/governance/GovernanceTimelock.sol:L14-L23",
        "The assignment of such powerful roles to a single private key with the deployer has inherent risks. Specifically in our case, the DAO role alone as we saw may bypass many checks within the Lybra Protocol, and the GOV role even has role management privileges.",
        "However, it does make sense to assign such roles at the beginning of the deployment to finish initialization and assign the rest of the roles. One could argue that having access to the DAO role in the early stages of the system\u2019s life could allow for quick disaster recovery in the event of incidents as well. Though, it is still dangerous to hold privileges for such a system in a single address as we have seen over the last years in security incidents that have to do with compromised keys."
    ],
    "Recommendation": [
        "While redesigning the deployment process to account for a lesser-privileged deployer would be ideal, the Lybra Finance team should at least transfer ownership as soon as the deployment is complete to minimize compromised private key risk."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-configuratorgeteusdmaxlocked-condition-can-be-bypassed-during-a-flashloan-fixed-consensys-none-lybra-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function convertToPeUSD(address user, uint256 eusdAmount) public {\n require(\\_msgSender() == user || \\_msgSender() == address(this), \"MDM\");\n require(eusdAmount != 0, \"ZA\");\n require(EUSD.balanceOf(address(this)) + eusdAmount <= configurator.getEUSDMaxLocked(),\"ESL\");\n\n"
    ],
    "Resolution": [
        "Fixed in f6c3afb5e48355c180417b192bd24ba294f77797 by checking eUSD amount after flash loan."
    ],
    "Description": [
        "When converting EUSD tokens to peUSD, there is a check that limits the total amount of EUSD that can be converted:",
        "contracts/lybra/token/PeUSDMainnet.sol:L74-L77",
        "The issue is that there is a way to bypass this restriction. An attacker can get a flash loan (in EUSD) from this contract, essentially reducing the visible amount of locked tokens (EUSD.balanceOf(address(this)))."
    ],
    "Recommendation": [
        "Multiple approaches can solve this issue. One would be adding reentrancy protection. Another one could be keeping track of the borrowed amount for a flashloan."
    ]
}
----End JSON----

https://solodit.xyz/issues/liquidation-keepers-automatically-become-eusd-debt-providers-for-other-liquidations-fixed-consensys-none-lybra-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function liquidation(address provider, address onBehalfOf, uint256 assetAmount) external virtual {\n uint256 assetPrice = getAssetPrice();\n uint256 onBehalfOfCollateralRatio = (depositedAsset[onBehalfOf] \\* assetPrice \\* 100) / borrowed[onBehalfOf];\n require(onBehalfOfCollateralRatio < badCollateralRatio, \"Borrowers collateral ratio should below badCollateralRatio\");\n\n require(assetAmount \\* 2 <= depositedAsset[onBehalfOf], \"a max of 50% collateral can be liquidated\");\n require(EUSD.allowance(provider, address(this)) != 0, \"provider should authorize to provide liquidation EUSD\");\n uint256 eusdAmount = (assetAmount \\* assetPrice) / 1e18;\n\n \\_repay(provider, onBehalfOf, eusdAmount);\n uint256 reducedAsset = assetAmount \\* 11 / 10;\n totalDepositedAsset -= reducedAsset;\n depositedAsset[onBehalfOf] -= reducedAsset;\n uint256 reward2keeper;\n if (provider == msg.sender) {\n collateralAsset.safeTransfer(msg.sender, reducedAsset);\n } else {\n reward2keeper = (reducedAsset \\* configurator.vaultKeeperRatio(address(this))) / 110;\n collateralAsset.safeTransfer(provider, reducedAsset - reward2keeper);\n collateralAsset.safeTransfer(msg.sender, reward2keeper);\n }\n emit LiquidationRecord(provider, msg.sender, onBehalfOf, eusdAmount, reducedAsset, reward2keeper, false, block.timestamp);\n}\n\n",
        "require(EUSD.allowance(provider, address(this)) != 0, \"provider should authorize to provide liquidation EUSD\");\n\n",
        "require(EUSD.allowance(provider, address(this)) >= eusdAmount, \"provider should authorize to provide liquidation EUSD\");\n\n",
        "if (provider == msg.sender) {\n collateralAsset.safeTransfer(msg.sender, reducedAsset);\n} else {\n reward2keeper = (reducedAsset \\* configurator.vaultKeeperRatio(address(this))) / 110;\n collateralAsset.safeTransfer(provider, reducedAsset - reward2keeper);\n collateralAsset.safeTransfer(msg.sender, reward2keeper);\n}\n\n"
    ],
    "Resolution": [
        "Fixed in commit bbcf1867ef66cfdcd4b4fd26df39518048fbde1f by adding an alternative check to the allowance flag to see if msg.sender == provider, thus removing the danger for solo liquidators that don\u2019t use another provider."
    ],
    "Description": [
        "One of the most important mechanisms in the Lybra Protocol is the liquidation of poorly collateralized vaults. For example, if a vault is found to have a collateralization ratio that is too small, a liquidator may provide debt tokens to the protocol and retrieve the vault collateral at a discount:",
        "contracts/lybra/pools/base/LybraEUSDVaultBase.sol:L148-L170",
        "To liquidate the vault, the liquidator needs to transfer debt tokens from the provider address, which in turn needs to have had approved allowance of the token for the vault:",
        "contracts/lybra/pools/base/LybraEUSDVaultBase.sol:L154",
        "The allowance doesn\u2019t need to be large, it only needs to be non-zero. While it is true that in the superLiquidation function the allowance check is for eusdAmount, which is the amount associated with assetAmount (the requested amount of collateral to be liquidated), the liquidator could simply call the maximum of the allowance the provider has given to the vault and then repeat the liquidation process. The allowance does not actually decrease throughout the liquidation process.",
        "contracts/lybra/pools/base/LybraEUSDVaultBase.sol:L191",
        "Notably, this address doesn\u2019t have to be the same one as the liquidator. In fact, there are no checks on whether the liquidator has an agreement or allowance from the provider to use their tokens in this particular vault\u2019s liquidation. The contract only checks to see if the provider has EUSD allowance for the vault, and how to split the rewards if the provider is different from the liquidator:",
        "contracts/lybra/pools/base/LybraEUSDVaultBase.sol:L162-L168",
        "In fact, this is a design choice of the system to treat the allowance to the vault as an agreement to become a public provider of debt tokens for the liquidation process. It is important to note that there are incentives associated with being a provider as they get the collateral asset at a discount.",
        "However, it is not obvious from documentation at the time of the audit nor the code that an address having a non-zero\nEUSD allowance for the vault automatically allows other users to use that address as a provider. Indeed, many general-purpose liquidator bots use their tokens during liquidations, using the same address for both the liquidator and the provider. As a result, this would put that address at the behest of any other user who would want to utilize these tokens in liquidations. The user might not be comfortable doing this trade in any case, even at a discount.",
        "In fact, due to this mechanism, even during consciously initiated liquidations MEV bots could spot this opportunity and front-run the liquidator\u2019s transaction. A frontrunner could put themselves as the keeper and the original user as the provider, grabbing the reward2keeper fee and leaving the original address with fewer rewards and failed gas after the liquidation."
    ],
    "Recommendation": [
        "While the mechanism is understood to be done for convenience and access to liquidity as a design decision, this could put unaware users in unfortunate situations of having performed a trade without explicit consent. Specifically, the MEV attack vector could be executed and repeated without fail by a capable actor monitoring the mempool. Consider having a separate, explicit flag for allowing others to use a user\u2019s tokens during liquidation, thus also accommodating solo liquidators by removing the MEV attack vector. Consider explicitly mentioning these mechanisms in the documentation as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/dapp-may-force-a-sign-approval-dialog-without-showing-the-message-to-be-signed-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        " text(host),\n ...(simulationResultItems.length > 0 || displayMessage ? [divider()] : []),\n ...simulationResultItems,\n ...(displayMessage ? [copyable(message)] : [])\n ])\n}\n\n"
    ],
    "Description": [
        "With the request.params.displayMessage parameter in requests to signTransaction and signAllTransactions the dapp controls if the message to be signed is displayed to the user or not. Allowing the dapp to control if the data to be signed is displayed to the user is dangerous as the dapp may silently ask for a signature to sign data the user did not intend to sign. This has potential to undermine security controls and procedures implemented by MetaMask which generally enforce clarity of what data the user is requested to sign.",
        "Note that the snap as an extension to the MetaMask trust module should not have to trust the dapp that is requesting signature."
    ],
    "Examples": [
        "Affects all snaps under review.",
        "../aptos-snap/src/index.js:L39-L51",
        "../aptos-snap/src/ui.js:L28-L33"
    ],
    "Recommendation": [
        "In accordance with how MetaMask signing works, it is highly recommended to remove the displayMessage toggle and consistently enforce the message to be signed to be displayed. Else, there is no way for the user to verify if they are signing the correct data/transaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/ctrlcharmarkdown-injection-in-rendersigntransaction-rendersignalltransactions-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        "export function renderSignTransaction(host, message, simulationResult, displayMessage = true) {\n const simulationResultItems = simulationResult.map((item) => text(item));\n\n return snap.request({\n method: 'snap\\_dialog',\n params: {\n type: 'confirmation',\n content: panel([\n heading('Sign transaction'),\n text(host),\n ...(simulationResultItems.length > 0 || displayMessage ? [divider()] : []),\n ...simulationResultItems,\n ...(displayMessage ? [copyable(message)] : [])\n ])\n }\n });\n}\n\n",
        "\nsimulationResults[i].forEach((item) => uiElements.push(text(item)));\nif (displayMessage) {\n uiElements.push(copyable(messages[i]));\n}\n\n",
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        "const { derivationPath, messages, simulationResults = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(messages);\nassertIsArray(messages);\nassertInput(messages.length);\nassertAllStrings(messages);\nassertIsArray(simulationResults);\nassertInput(messages.length === simulationResults.length);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignAllTransactions(dappHost, messages, simulationResults, displayMessage);\nassertConfirmation(accepted);\n\n",
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        "const { derivationPath, messages, simulationResults = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(messages);\nassertIsArray(messages);\nassertInput(messages.length);\nassertAllStrings(messages);\nassertIsArray(simulationResults);\nassertInput(messages.length === simulationResults.length);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignAllTransactions(dappHost, messages, simulationResults, displayMessage);\nassertConfirmation(accepted);\n\n"
    ],
    "Description": [
        "On certain occasions, the snap may need to present a dialog to the user to request confirmation for an action or data verification. This step is crucial as dapps are not always trusted, and it\u2019s essential to prevent scenarios where they can silently sign data or perform critical operations using the user\u2019s keys without explicit permission. To create custom user-facing dialogs, MetaMask provides the Snaps UI package, equipped with style-specific components. However, some of these components have been found to have unintended side-effects.",
        "For instance, the text() component can render Markdown or allow for control character injections.",
        "In the code snippet provided below, please note that request.params is considered untrusted. For example, request.params.simulationResult[] may contain Markdown renderable strings or Control Characters that can disrupt the context of the user-displayed message.",
        "Please also note that the user might decide whether to sign or reject the transaction based on the simulation that is being displayed. This simulation result, however, is directly provided by the dapp which is less trusted than the metamask security module/snap. This might lead to users signing data based on potentially false information if the dapp provides malicious information. It should, therefore, be considered to generate the simulation information within the snap itself!"
    ],
    "Examples": [
        "This affects all snaps under review.",
        "../solflare-snap/src/index.js:L41-L53",
        "../solflare-snap/src/ui.js:L19-L35",
        "../solflare-snap/src/ui.js:L51-L55",
        "../sui-snap/src/index.js:L41-L52",
        "../sui-snap/src/index.js:L64-L77",
        "../aptos-snap/src/index.js:L39-L50",
        "../aptos-snap/src/index.js:L62-L75"
    ],
    "Recommendation": [
        "Validate inputs. Encode data in a safe way to be displayed to the user. Show the original data provided within a pre-text or code block (copyable). Show derived or decoded information (token recipient) as additional information to the user. If possible, generate a trusted simulation result within the snap."
    ]
}
----End JSON----

https://solodit.xyz/issues/insufficient-input-validation-derivekeypair-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "case 'getPublicKey': {\n const { derivationPath, confirm = false } = request.params || {};\n\n assertInput(derivationPath);\n assertIsString(derivationPath);\n assertIsBoolean(confirm);\n\n const keyPair = await deriveKeyPair(derivationPath);\n\n",
        "const segments = path.split('/').slice(3).filter(Boolean);\n\n"
    ],
    "Description": [
        "path is checked for correct type: string",
        "../solflare-snap/src/index.js:L23-L30",
        "but is not checked for valid key derivation path format which may lead to unexpected outcomes or unhandled exceptions.",
        "../solflare-snap/src/privateKey.js:L20-L20",
        "For example, the function allows non alpha-num 0-9+', slip:x prefixes, or empty elements (\"m/44'/784'\".split(\"/\").slice(3).filter(Boolean) => []).",
        "Affects all snaps under review."
    ],
    "Recommendation": [
        "In general, the API design should be re-designed with the RPC functions receiving and validating only the last part of the key part, enforcing the format to be valid for the use case."
    ]
}
----End JSON----

https://solodit.xyz/issues/dapp-may-suppress-user-confirmation-on-request-to-extract-pubkey-may-extract-any-net-key-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "case 'getPublicKey': {\n const { derivationPath, confirm = false } = request.params || {};\n\n assertInput(derivationPath);\n assertIsString(derivationPath);\n assertIsBoolean(confirm);\n\n const keyPair = await deriveKeyPair(derivationPath);\n const pubkey = bs58.encode(keyPair.publicKey);\n\n if (confirm) {\n const accepted = await renderGetPublicKey(dappHost, pubkey);\n assertConfirmation(accepted);\n }\n\n"
    ],
    "Description": [
        "With the request.params.confirm parameter in requests to signTransaction and signAllTransactions the dapp controls if the user is requested confirmation to return the public key. If the dapp sets confirm=false the user will not be informed that the dapp accessed their pubkey information (any account). Allowing the dapp to control if the user is asked to extract certain (derived) information from the snap is intransparent and may leak sensitive information. Especially in a setting where the snap is gatekeeping access to user specific information."
    ],
    "Examples": [
        "Affects all snaps under review.",
        "../solflare-snap/src/index.js:L23-L36"
    ],
    "Recommendation": [
        "The snap should strictly enforce user confirmation on the first time the pubkey is requested from an origin. A potentially untrusted dapp (even though origin restricted; a dapp might turn malicious and should therefore be treated as untrusted) should never be able to silently dictate what security measures be enabled with a snap request."
    ]
}
----End JSON----

https://solodit.xyz/issues/production-builds-allow-development-and-localhost-origins-snap-does-not-enforce-transport-security-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "module.exports.onRpcRequest = async ({ origin, request }) => {\n if (\n !origin ||\n (\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.com$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.dev$/)\n )\n ) {\n throw new Error('Invalid origin');\n }\n\n",
        "module.exports.onRpcRequest = async ({ origin, request }) => {\n if (\n !origin ||\n (\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?risewallet\\.dev$/)\n )\n ) {\n throw new Error('Invalid origin');\n }\n\n",
        "module.exports.onRpcRequest = async ({ origin, request }) => {\n if (\n !origin ||\n (\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?elliwallet\\.dev$/)\n )\n ) {\n throw new Error('Invalid origin');\n }\n\n"
    ],
    "Description": [
        "The snaps RPC access is restricted to certain origins only. However, there is no logic that disables development/test domains from origin checks in production builds.",
        "This means, that, any localhost app is allowed to connect to snap (any port, not hardcoded to snap id; should not allow dev domain). The origin enforcing regex allows non-transport security-enabled connections, i.e. http://wallet.solflare.com is allowed while it should be enforced as https://wallet.solflare.com. Furthermore, the origin check allows potentially insecure subdomains, i.e. https://beta.test.solflare.com. Additionally, invalid domains are allowed as well, i.e. http://..solflare.com"
    ],
    "Examples": [
        "../solflare-snap/src/index.js:L7-L17",
        "../aptos-snap/src/index.js:L6-L15",
        "../sui-snap/src/index.js:L8-L17"
    ],
    "Recommendation": [
        "Implement logic that removes development/localhost origin from the allow list for production builds. Employ strict checks on the format of provided origin. Do not by default allow all subdomains."
    ]
}
----End JSON----

https://solodit.xyz/issues/dapp-may-force-a-sign-approval-dialog-without-showing-the-message-to-be-signed-fixed-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        " text(host),\n ...(simulationResultItems.length > 0 || displayMessage ? [divider()] : []),\n ...simulationResultItems,\n ...(displayMessage ? [copyable(message)] : [])\n ])\n}\n\n"
    ],
    "Resolution": [
        "Addressed by always displaying the raw message to be signed to the user. This allows them to independently verify that this is indeed what they want to sign off on. Additionally, the client provided the following statement and changesets addressing the finding:",
        "Changesets:"
    ],
    "Description": [
        "With the request.params.displayMessage parameter in requests to signTransaction and signAllTransactions the dapp controls if the message to be signed is displayed to the user or not. Allowing the dapp to control if the data to be signed is displayed to the user is dangerous as the dapp may silently ask for a signature to sign data the user did not intend to sign. This has potential to undermine security controls and procedures implemented by MetaMask which generally enforce clarity of what data the user is requested to sign.",
        "Note that the snap as an extension to the MetaMask trust module should not have to trust the dapp that is requesting signature."
    ],
    "Examples": [
        "Affects all snaps under review.",
        "../aptos-snap/src/index.js:L39-L51",
        "../aptos-snap/src/ui.js:L28-L33"
    ],
    "Recommendation": [
        "In accordance with how MetaMask signing works, it is highly recommended to remove the displayMessage toggle and consistently enforce the message to be signed to be displayed. Else, there is no way for the user to verify if they are signing the correct data/transaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/ctrlcharmarkdown-injection-in-rendersigntransaction-rendersignalltransactions-fixed-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        "export function renderSignTransaction(host, message, simulationResult, displayMessage = true) {\n const simulationResultItems = simulationResult.map((item) => text(item));\n\n return snap.request({\n method: 'snap\\_dialog',\n params: {\n type: 'confirmation',\n content: panel([\n heading('Sign transaction'),\n text(host),\n ...(simulationResultItems.length > 0 || displayMessage ? [divider()] : []),\n ...simulationResultItems,\n ...(displayMessage ? [copyable(message)] : [])\n ])\n }\n });\n}\n\n",
        "\nsimulationResults[i].forEach((item) => uiElements.push(text(item)));\nif (displayMessage) {\n uiElements.push(copyable(messages[i]));\n}\n\n",
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        "const { derivationPath, messages, simulationResults = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(messages);\nassertIsArray(messages);\nassertInput(messages.length);\nassertAllStrings(messages);\nassertIsArray(simulationResults);\nassertInput(messages.length === simulationResults.length);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignAllTransactions(dappHost, messages, simulationResults, displayMessage);\nassertConfirmation(accepted);\n\n",
        "const { derivationPath, message, simulationResult = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(message);\nassertIsString(message);\nassertIsArray(simulationResult);\nassertAllStrings(simulationResult);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignTransaction(dappHost, message, simulationResult, displayMessage);\nassertConfirmation(accepted);\n\n",
        "const { derivationPath, messages, simulationResults = [], displayMessage = true } = request.params || {};\n\nassertInput(derivationPath);\nassertIsString(derivationPath);\nassertInput(messages);\nassertIsArray(messages);\nassertInput(messages.length);\nassertAllStrings(messages);\nassertIsArray(simulationResults);\nassertInput(messages.length === simulationResults.length);\nassertIsBoolean(displayMessage);\n\nconst accepted = await renderSignAllTransactions(dappHost, messages, simulationResults, displayMessage);\nassertConfirmation(accepted);\n\n"
    ],
    "Resolution": [
        "The identified vulnerability has been remedied by excluding the simulation result from the dialog. It is essential to emphasize that the extension should ideally generate the simulation result as a validated source of information. The transmission of this information from a less trustworthy entity (even though it pertains to the dapp linked to the snap) to be displayed within the secure context of a snap, influencing users to endorse raw data based on this simulation result, may inherently introduce security risks. Eliminating the simulation result parameter from the RPC request effectively mitigates this specific injection opportunity. Additionally, the client has furnished the subsequent statement and alterations to address the aforementioned issue:",
        "Changesets:"
    ],
    "Description": [
        "On certain occasions, the snap may need to present a dialog to the user to request confirmation for an action or data verification. This step is crucial as dapps are not always trusted, and it\u2019s essential to prevent scenarios where they can silently sign data or perform critical operations using the user\u2019s keys without explicit permission. To create custom user-facing dialogs, MetaMask provides the Snaps UI package, equipped with style-specific components. However, some of these components have been found to have unintended side-effects.",
        "For instance, the text() component can render Markdown or allow for control character injections.",
        "In the code snippet provided below, please note that request.params is considered untrusted. For example, request.params.simulationResult[] may contain Markdown renderable strings or Control Characters that can disrupt the context of the user-displayed message.",
        "Please also note that the user might decide whether to sign or reject the transaction based on the simulation that is being displayed. This simulation result, however, is directly provided by the dapp which is less trusted than the metamask security module/snap. This might lead to users signing data based on potentially false information if the dapp provides malicious information. It should, therefore, be considered to generate the simulation information within the snap itself!"
    ],
    "Examples": [
        "This affects all snaps under review.",
        "../solflare-snap/src/index.js:L41-L53",
        "../solflare-snap/src/ui.js:L19-L35",
        "../solflare-snap/src/ui.js:L51-L55",
        "../sui-snap/src/index.js:L41-L52",
        "../sui-snap/src/index.js:L64-L77",
        "../aptos-snap/src/index.js:L39-L50",
        "../aptos-snap/src/index.js:L62-L75"
    ],
    "Recommendation": [
        "Validate inputs. Encode data in a safe way to be displayed to the user. Show the original data provided within a pre-text or code block (copyable). Show derived or decoded information (token recipient) as additional information to the user. If possible, generate a trusted simulation result within the snap."
    ]
}
----End JSON----

https://solodit.xyz/issues/production-builds-allow-development-and-localhost-origins-snap-does-not-enforce-transport-security-partially-addressed-consensys-none-solflare-metamask-snaps-solflare-sui-aptos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "module.exports.onRpcRequest = async ({ origin, request }) => {\n if (\n !origin ||\n (\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.com$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?solflare\\.dev$/)\n )\n ) {\n throw new Error('Invalid origin');\n }\n\n",
        "module.exports.onRpcRequest = async ({ origin, request }) => {\n if (\n !origin ||\n (\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?risewallet\\.dev$/)\n )\n ) {\n throw new Error('Invalid origin');\n }\n\n",
        "module.exports.onRpcRequest = async ({ origin, request }) => {\n if (\n !origin ||\n (\n !origin.match(/^https?:\\/\\/localhost:[0-9]{1,4}$/) &&\n !origin.match(/^https?:\\/\\/(?:\\S+\\.)?elliwallet\\.dev$/)\n )\n ) {\n throw new Error('Invalid origin');\n }\n\n"
    ],
    "Resolution": [
        "The client has issued the following statement:",
        "Changesets:",
        "Statement from the Assessment Team:",
        "The core tenet here is a robust defense-in-depth strategy that operates on the premise of making no assumptions. We must underscore the criticality of this principle in the context of trust module code. The same level of scrutiny should apply to wildcard origins. The rationale is rooted in the potential vulnerabilities associated with subdomain takeover scenarios, such as Azure instance compromise or DNS hijacking, among others. If an attacker can manipulate a subdomain, leading users to visit a site like malicious.solflare.com, there is a substantial risk of successfully conducting phishing attacks, potentially tricking users into permitting dapp actions on the snap. This not only jeopardizes user funds but also poses a severe threat to your organization\u2019s reputation. It falls squarely on your shoulders to ensure that such scenarios do not materialize through robust security controls.",
        "Recommendation: To mitigate these risks, it is imperative to maintain a curated list of official production hosts and validate requests against these origins. For development builds of the extension, you may consider allowing dev and wildcard hosts. However, when introducing new subdomains, it is crucial to manage them meticulously and refrain from merely deploying new subdomain websites, as this approach can become challenging to control. Ultimately, the decision rests with your organization regarding the level of risk tolerance. Based on experience, we would strongly advise against taking unnecessary risks in this regard."
    ],
    "Description": [
        "The snaps RPC access is restricted to certain origins only. However, there is no logic that disables development/test domains from origin checks in production builds.",
        "This means, that, any localhost app is allowed to connect to snap (any port, not hardcoded to snap id; should not allow dev domain). The origin enforcing regex allows non-transport security-enabled connections, i.e. http://wallet.solflare.com is allowed while it should be enforced as https://wallet.solflare.com. Furthermore, the origin check allows potentially insecure subdomains, i.e. https://beta.test.solflare.com. Additionally, invalid domains are allowed as well, i.e. http://..solflare.com"
    ],
    "Examples": [
        "../solflare-snap/src/index.js:L7-L17",
        "../aptos-snap/src/index.js:L6-L15",
        "../sui-snap/src/index.js:L8-L17"
    ],
    "Recommendation": [
        "Implement logic that removes development/localhost origin from the allow list for production builds. Employ strict checks on the format of provided origin. Do not by default allow all subdomains."
    ]
}
----End JSON----

https://solodit.xyz/issues/markdown-and-control-character-injection-fixed-consensys-none-metamaskpartner-snaps-filsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const conf = await snapDialog(ctx.snap, {\n type: 'confirmation',\n content: panel([\n heading(`Send ${Token.fromAttoFIL(message.value).toFIL().toString()} to`),\n copyable(message.to),\n divider(),\n heading('Details'),\n text(\n `Gas \\_(estimated)\\_: \\*\\*${gas.toFIL().toFormat({\n decimalPlaces: ctx.config.unit?.decimals,\n suffix: ` ${ctx.config.unit?.symbol}`,\n })}\\*\\*`\n ),\n text(\n `Total \\_(amount + gas)\\_: \\*\\*${total.toFIL().toFormat({\n decimalPlaces: ctx.config.unit?.decimals,\n suffix: ` ${ctx.config.unit?.symbol}`,\n })}\\*\\*`\n ),\n ]),\n})\n\n"
    ],
    "Resolution": [
        "Configuration values reflected in the confirmation prompt are implicitly validated by getting user consent on config changes through the fil_configure RPC call. Furthermore, confirmation dialogue values have been (mostly) displayed using the copyable function, resulting in escaped output.",
        "This issue has been addressed in revision 1a8715f42cfc9f721e8faab8a7a2610f53592f94."
    ],
    "Description": [
        "The snap uses MetaMask\u2019s Snaps UI package to present dialogs to users for data verification and action confirmations. While these dialogs ensure dapps don\u2019t silently execute operations without user consent, some UI components have vulnerabilities. For instance, the text() component can render Markdown or be susceptible to control character injections. Specifically, in FilSnap\u2019s context, when users are prompted to sign a message showing a gas cost estimate if the message contains Markdown-renderable text, the user might unintentionally sign an inaccurate message. It\u2019s critical to note that the variable ctx.config in the provided code snippet could contain untrusted data, potentially altering the context of the displayed message. Malicious manipulation of the snap context is outlined in issue 4.3.",
        "packages/snap/src/rpc/sign-message.ts:L68-L89"
    ],
    "Recommendation": [
        "Prioritize input validation. Encode data securely when presenting it to users. Display original data within an escaped pre-text or code block that prevents rendering non-standard characters or Markdown. Subsequently, add any derived or decoded data to offer users a comprehensive understanding."
    ]
}
----End JSON----

https://solodit.xyz/issues/directly-exposed-private-key-export-fixed-consensys-none-metamaskpartner-snaps-filsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export async function exportPrivateKey(\n ctx: SnapContext\n): Promise<ExportPrivateKeyResponse> {\n const conf = await snapDialog(ctx.snap, {\n type: 'confirmation',\n content: panel([heading(`Do you want to export your private key?`)]),\n })\n\n if (conf) {\n return {\n result: base64pad.encode(ctx.account.privateKey),\n error: null,\n }\n }\n return serializeError('User denied private key export')\n}\n\n"
    ],
    "Resolution": [
        "While the exportPrivateKey function is still present and exposed via the fil_exportPrivateKey RPC call, it now displays a warning and only surfaces the user\u2019s private key in a secured dialogue. This is analogous to MetaMask\u2019s approach and will make users consider their actions carefully. Automated attacks without user intervention are no longer possible since users must copy-paste their keys.",
        "This issue has been addressed in commit c88a9ee1359e9a35735ce5d7b18b4cfcd2de0326."
    ],
    "Description": [
        "The snap can access the BIP44 entropy for Filecoin\u2019s private keys, granting it considerable power over MetaMask\u2019s private keys. Specifically, the fil_exportPrivateKey command lets dapps obtain the private key programmatically, pending user consent. However, there\u2019s a heightened risk of users indiscriminately granting this permission. To maintain MetaMask\u2019s security integrity, the snap should mirror the same rigorous security standards to mitigate the effect of phishing attacks and malicious dapps.",
        "packages/snap/src/rpc/export-private-key.ts:L19-L34"
    ],
    "Recommendation": [
        "The development team should reconsider providing such a sensitive functionality. Instead of programmatically exposing the private key, use a dialog that prompts users to copy the private key manually. This approach, consistent with MetaMask\u2019s default, encourages users to deliberate their actions more thoroughly."
    ]
}
----End JSON----

https://solodit.xyz/issues/fil_configure-allows-anyone-to-change-the-snaps-configuration-partially-addressed-consensys-none-metamaskpartner-snaps-filsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "type ConfigureParams = {\n derivationPath?: string | undefined;\n rpc?: {\n url: string;\n token: string;\n } | undefined;\n network?: \"mainnet\" | \"testnet\" | undefined;\n unit?: {\n symbol: string;\n decimals: number;\n image?: string | undefined;\n customViewUrl?: string | undefined;\n } | undefined;\n}\n\n"
    ],
    "Resolution": [
        "This issue has been partially addressed and practically fixed. While it is still possible for any site to change the snap\u2019s configuration, its values are now maintained under the origin site\u2019s namespace. Furthermore, when connecting to a site, the user must manually confirm the proposed configuration values.",
        "This issue has been fixed in 1a8715f42cfc9f721e8faab8a7a2610f53592f94."
    ],
    "Description": [
        "The fil_configure command, accessible by any dapp, accepts parameters of type ConfigureParams. This allows for modifying key configuration details like the derivation path, RPC details, network state, and unit data:",
        "An attacker exploiting this open access can manipulate elements such as the network state or RPC URL, which could mislead users when signing messages. Furthermore, given the shared instance nature of the snap across multiple pages, a malicious dapp can influence the behavior of the snap in other dapps.",
        "The MetaMask Snaps team has responded to this particular issue by stating that they will soon add a mutex to the SDKs state object to mitigate the problem partially. Nonetheless, even with a mutex in place, it\u2019s important to remember that business logic can still execute in an outdated state."
    ],
    "Recommendation": [
        "Evaluate the necessity of exposing specific configuration options through fil_configure. If it doesn\u2019t offer significant utility, consider removing it entirely, favoring a hardcoded configuration approach. This would ensure that critical token data and RPC URLs are modifiable only through controlled snap updates."
    ]
}
----End JSON----

https://solodit.xyz/issues/lack-of-signature-dialog-context-and-rpc-origin-fixed-consensys-none-metamaskpartner-snaps-filsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const conf = await snapDialog(ctx.snap, {\n type: 'confirmation',\n content: panel([\n heading(`Send ${Token.fromAttoFIL(message.value).toFIL().toString()} to`),\n copyable(message.to),\n divider(),\n heading('Details'),\n text(\n `Gas \\_(estimated)\\_: \\*\\*${gas.toFIL().toFormat({\n decimalPlaces: ctx.config.unit?.decimals,\n suffix: ` ${ctx.config.unit?.symbol}`,\n })}\\*\\*`\n ),\n text(\n `Total \\_(amount + gas)\\_: \\*\\*${total.toFIL().toFormat({\n decimalPlaces: ctx.config.unit?.decimals,\n suffix: ` ${ctx.config.unit?.symbol}`,\n })}\\*\\*`\n ),\n ]),\n})\n\n"
    ],
    "Resolution": [
        "The signature UI dialogue now displays the user account used for signing and the origin site that triggered the process. Furthermore, details such as the RPC URL and the network name are displayed. This issue has been fully addressed in 1a8715f42cfc9f721e8faab8a7a2610f53592f94 and 6ddb227738ed3aa041c18131eee65a98e17acdf4."
    ],
    "Description": [
        "The FilSnap signing dialog doesn\u2019t indicate which user account is used for signing. This omission can be exploited by malicious dapps, leading users to believe they\u2019re signing with one account when in fact, another is being used. Such transparency gaps, especially in an environment integrating multiple dapps and accounts, can mislead users into providing unintended signatures.",
        "For reference, MetaMask displays these details during its signing requests, a practice FilSnap should adopt.",
        "packages/snap/src/rpc/sign-message.ts:L68-L88"
    ],
    "Recommendation": [
        "Display the user account used for signing and the origin domain of the RPC call during the signing dialog, ensuring users have full context before confirming any transactions."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-address-protection-fixed-consensys-none-metamaskpartner-snaps-filsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Resolution": [
        "Address protection has been introduced with commit 1a8715f42cfc9f721e8faab8a7a2610f53592f94. Before an origin site can access the snap\u2019s RPC calls, it has to call the fil_configure RPC call, which requires manual user confirmation of the connection."
    ],
    "Description": [
        "While MetaMask hides wallet addresses by default, requiring users to expose them to dapps manually, the snap\u2019s fil_getAddress and fil_getAccountInfo RPC endpoints always disclose the current address to any connected dapp, even if that address has not been connected to the page. This allows potentially untrusted dapps to silently retrieve all user addresses, bypassing MetaMask\u2019s intentional security design."
    ],
    "Recommendation": [
        "Adopt security protocols similar to MetaMask\u2019s main wallet. Let users select which addresses they share with dapps and prevent automatic exposure of non-allowlisted wallet addresses without explicit user permission."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-timeout-in-rpccall-fixed-consensys-none-metamaskpartner-snaps-filsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const res = await this.fetch(this.api, {\n method: 'POST',\n headers: this.headers,\n body: JSON.stringify({\n jsonrpc: '2.0',\n method,\n params,\n id: 1,\n }),\n})\n\n"
    ],
    "Resolution": [
        "A timeout option has been added to the iso-filecoin dependency in e1908f9ea05e309c7f1d260ecc18584503155cb4 addressing this issue."
    ],
    "Description": [
        "Within the dependency iso-filecoin, there\u2019s an oversight in the RPC class. Specifically, the call method lacks a timeout parameter. Due to this missing timeout, the snap execution can experience delays, which could lead to an aborted request. The code excerpt provided shows the missing timeout in the fetch call."
    ],
    "Recommendation": [
        "To mitigate potential delays and ensure smoother operation, it\u2019s recommended to introduce a timeout to this call method. Implementing a timeout can prevent prolonged waits and enhance the resilience of the method against unexpected delays."
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-priviliges-setoperatoraddresses-acknowledged-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setOperatorAddresses(\n uint256 \\_operatorIndex,\n address \\_operatorAddress,\n address \\_feeRecipientAddress\n) external onlyActiveOperatorFeeRecipient(\\_operatorIndex) {\n \\_checkAddress(\\_operatorAddress);\n \\_checkAddress(\\_feeRecipientAddress);\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n\n operators.value[\\_operatorIndex].operator = \\_operatorAddress;\n operators.value[\\_operatorIndex].feeRecipient = \\_feeRecipientAddress;\n emit ChangedOperatorAddresses(\\_operatorIndex, \\_operatorAddress, \\_feeRecipientAddress);\n}\n\n"
    ],
    "Description": [
        "The function setOperatorAddresses instead of allowing the Operator to update its own, as well as the Fee Recipient address, incorrectly provides the privileges to the Fee Recipient. As a result, the Fee Recipient can modify the operator address as and when needed, to DoS the operator and exploit the system. Additionally, upon reviewing the documentation, we found that there are no administrative rights defined for the Fee Recipient, hence highlighting the incorrect privilege allocation.",
        "src/contracts/StakingContract.sol:L412-L424"
    ],
    "Recommendation": [
        "The modifier should be onlyActiveOperatorOrAdmin allowing only the operator itself or admin of the system, to update the necessary addresses.",
        "Also, for transferring crucial privileges from one address to another, the operator\u2019s address should follow a 2-step approach like transferring ownership."
    ]
}
----End JSON----

https://solodit.xyz/issues/unconstrained-snapshot-while-setting-operator-limit-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\n operators.value[\\_operatorIndex].limit < \\_limit &&\n StakingContractStorageLib.getLastValidatorEdit() > \\_snapshot\n) {\n revert LastEditAfterSnapshot();\n}\n\n"
    ],
    "Description": [
        "Function setOperatorLimit as the name says, allows the SYS_ADMIN to set/update the staking limit for an operator. The function ensures that if the limit is being increased, the _snapshot must be ahead of the last validator edit(block.number at which the last validator edit occurred). However, the parameter _snapshot is unconstrained and can be any number. Also, the functions addValidators and removeValidators update the block.number signifying the last validator edit, but never constrain the new edits with it. Since there are no publicly available functions to access this value, makes the functionality even more confusing and may be unnecessary.",
        "src/contracts/StakingContract.sol:L468-L473"
    ],
    "Recommendation": [
        "If the functionality is not needed, consider removing it. Otherwise, add some necessary logic to either constrain the last validator edit or add public functions for the users to access it."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-input-validation-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n StakingContractStorageLib.OperatorInfo memory newOperator;\n\n if (operators.value.length == 1) {\n revert MaximumOperatorCountAlreadyReached();\n }\n newOperator.operator = \\_operatorAddress;\n newOperator.feeRecipient = \\_feeRecipientAddress;\n operators.value.push(newOperator);\n uint256 operatorIndex = operators.value.length - 1;\n emit NewOperator(\\_operatorAddress, \\_feeRecipientAddress, operatorIndex);\n return operatorIndex;\n}\n\n",
        "function setTreasury(address \\_newTreasury) external onlyAdmin {\n emit ChangedTreasury(\\_newTreasury);\n StakingContractStorageLib.setTreasury(\\_newTreasury);\n}\n\n",
        "/// @notice Deactivates an operator and changes the fee recipient address and the staking limit\n/// @param \\_operatorIndex Operator Index\n/// @param \\_temporaryFeeRecipient Temporary address to receive funds decided by the system admin\nfunction deactivateOperator(uint256 \\_operatorIndex, address \\_temporaryFeeRecipient) external onlyAdmin {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n operators.value[\\_operatorIndex].limit = 0;\n emit ChangedOperatorLimit(\\_operatorIndex, 0);\n operators.value[\\_operatorIndex].deactivated = true;\n emit DeactivatedOperator(\\_operatorIndex);\n operators.value[\\_operatorIndex].feeRecipient = \\_temporaryFeeRecipient;\n emit ChangedOperatorAddresses(\\_operatorIndex, operators.value[\\_operatorIndex].operator, \\_temporaryFeeRecipient);\n \\_updateAvailableValidatorCount(\\_operatorIndex);\n}\n\n/// @notice Activates an operator, without changing its 0 staking limit\n/// @param \\_operatorIndex Operator Index\n/// @param \\_newFeeRecipient Sets the fee recipient address\nfunction activateOperator(uint256 \\_operatorIndex, address \\_newFeeRecipient) external onlyAdmin {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n operators.value[\\_operatorIndex].deactivated = false;\n emit ActivatedOperator(\\_operatorIndex);\n operators.value[\\_operatorIndex].feeRecipient = \\_newFeeRecipient;\n emit ChangedOperatorAddresses(\\_operatorIndex, operators.value[\\_operatorIndex].operator, \\_newFeeRecipient);\n}\n\n"
    ],
    "Description": [
        "src/contracts/StakingContract.sol:L392-L405",
        "src/contracts/StakingContract.sol:L214-L217",
        "src/contracts/StakingContract.sol:L479-L502"
    ]
}
----End JSON----

https://solodit.xyz/issues/hardcoded-operator-limit-logic-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n StakingContractStorageLib.OperatorInfo memory newOperator;\n\n if (operators.value.length == 1) {\n revert MaximumOperatorCountAlreadyReached();\n }\n\n",
        "function \\_depositOnOneOperator(uint256 \\_depositCount, uint256 \\_totalAvailableValidators) internal {\n StakingContractStorageLib.setTotalAvailableValidators(\\_totalAvailableValidators - \\_depositCount);\n \\_depositValidatorsOfOperator(0, \\_depositCount);\n}\n\n"
    ],
    "Description": [
        "The contract defines some hardcoded limits which is not the right approach for upgradeable contracts and opens doors for accidental mistakes, if not handled with care.",
        "The operators for the current version are limited to 1. If the auditee team decides to open the system to work with more operators but fails to change the limit while upgrading, the upgraded contract will have no effect, and will still disallow any more operators to be added.",
        "src/contracts/StakingContract.sol:L392-L398",
        "Also, the function _depositOnOneOperator hardcodes the operator Index as 0 since the contract only supports one operator.",
        "src/contracts/StakingContract.sol:L893-L896"
    ],
    "Recommendation": [
        "A better approach could be to constrain the limit of operators that can be added with a storage variable or constant, provided at the time of contract initialization. The contract should also consider supporting dynamic operator deposits for future versions instead of the default hardcoded index."
    ]
}
----End JSON----

https://solodit.xyz/issues/stakingcontract-pubkey-length-checks-not-always-enforced-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addValidators(\n uint256 \\_operatorIndex,\n uint256 \\_keyCount,\n bytes calldata \\_publicKeys,\n bytes calldata \\_signatures\n) external onlyActiveOperator(\\_operatorIndex) {\n if (\\_keyCount == 0) {\n revert InvalidArgument();\n }\n\n if (\\_publicKeys.length % PUBLIC\\_KEY\\_LENGTH != 0 || \\_publicKeys.length / PUBLIC\\_KEY\\_LENGTH != \\_keyCount) {\n revert InvalidPublicKeys();\n }\n\n",
        "/// @notice Set withdrawer for public key\n/// @dev Only callable by current public key withdrawer\n/// @param \\_publicKey Public key to change withdrawer\n/// @param \\_newWithdrawer New withdrawer address\nfunction setWithdrawer(bytes calldata \\_publicKey, address \\_newWithdrawer) external {\n if (!StakingContractStorageLib.getWithdrawerCustomizationEnabled()) {\n revert Forbidden();\n }\n \\_checkAddress(\\_newWithdrawer);\n bytes32 pubkeyRoot = \\_getPubKeyRoot(\\_publicKey);\n StakingContractStorageLib.WithdrawersSlot storage withdrawers = StakingContractStorageLib.getWithdrawers();\n\n if (withdrawers.value[pubkeyRoot] != msg.sender) {\n revert Unauthorized();\n }\n\n emit ChangedWithdrawer(\\_publicKey, \\_newWithdrawer);\n\n withdrawers.value[pubkeyRoot] = \\_newWithdrawer;\n}\n\n",
        "function \\_getPubKeyRoot(bytes memory \\_publicKey) internal pure returns (bytes32) {\n return sha256(abi.encodePacked(\\_publicKey, bytes16(0)));\n}\n\n",
        "/// @notice Withdraw the Execution Layer Fee for a given validator public key\n/// @dev Funds are sent to the withdrawer account\n/// @param \\_publicKey Validator to withdraw Execution Layer Fees from\nfunction withdrawELFee(bytes calldata \\_publicKey) external {\n \\_onlyWithdrawerOrAdmin(\\_publicKey);\n \\_deployAndWithdraw(\\_publicKey, EXECUTION\\_LAYER\\_SALT\\_PREFIX, StakingContractStorageLib.getELDispatcher());\n}\n\n"
    ],
    "Description": [
        "addValidators checks that the provided bytes pubKey is a multiple of the expected pubkey length while functions like setWithdrawer do not enforce similar length checks. This is an inconsistency that should be avoided.",
        "src/contracts/StakingContract.sol:L530-L542",
        "src/contracts/StakingContract.sol:L426-L445",
        "src/contracts/StakingContract.sol:L775-L777",
        "src/contracts/StakingContract.sol:L696-L702",
        "Nevertheless, the methods should be hardened so as not to give a malicious actor the freedom to use an unexpected input size for the pubKey argument."
    ],
    "Recommendation": [
        "Enforce pubkey length checks when accepting a single pubkey as bytes similar to the batch functions that check for a multiple of \u00b4PUBLIC_KEY_LENGTH\u00b4. Alternatively, declare the function argument as bytes48 (however, in this case inputs may be auto-padded to fit the expected length, pot. covering situations that otherwise would throw an error)"
    ]
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-due-to-admin-front-running-or-general-bad-timing-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Change the Operator fee\n/// @param \\_operatorFee Fee in Basis Point\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\n revert InvalidFee();\n }\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\n emit ChangedOperatorFee(\\_operatorFee);\n}\n\n",
        "\n/// @notice Change the Global fee\n/// @param \\_globalFee Fee in Basis Point\nfunction setGlobalFee(uint256 \\_globalFee) external onlyAdmin {\n if (\\_globalFee > StakingContractStorageLib.getGlobalCommissionLimit()) {\n revert InvalidFee();\n }\n StakingContractStorageLib.setGlobalFee(\\_globalFee);\n emit ChangedGlobalFee(\\_globalFee);\n}\n\n"
    ],
    "Description": [
        "In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.",
        "Some instances of this are more important than others, but in general, users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "src/contracts/StakingContract.sol:L504-L512",
        "src/contracts/StakingContract.sol:L513-L522"
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period."
    ]
}
----End JSON----

https://solodit.xyz/issues/potentially-uninitialized-implementations-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize\\_1(\n address \\_admin,\n address \\_treasury,\n address \\_depositContract,\n address \\_elDispatcher,\n address \\_clDispatcher,\n address \\_feeRecipientImplementation,\n uint256 \\_globalFee,\n uint256 \\_operatorFee,\n uint256 globalCommissionLimitBPS,\n uint256 operatorCommissionLimitBPS\n) external init(1) {\n\n",
        "/// @notice Initializes the receiver\n/// @param \\_dispatcher Address that will handle the fee dispatching\n/// @param \\_publicKeyRoot Public Key root assigned to this receiver\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\n if (initialized) {\n revert AlreadyInitialized();\n }\n initialized = true;\n dispatcher = IFeeDispatcher(\\_dispatcher);\n publicKeyRoot = \\_publicKeyRoot;\n stakingContract = msg.sender; // The staking contract always calls init\n}\n\n",
        "/// @param \\_publicKeyRoot Public Key root assigned to this receiver\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\n if (initialized) {\n revert AlreadyInitialized();\n }\n initialized = true;\n dispatcher = IFeeDispatcher(\\_dispatcher);\n publicKeyRoot = \\_publicKeyRoot;\n}\n\n"
    ],
    "Description": [
        "Most contracts in the system are meant to be used with a proxy pattern. First, the implementations are deployed, and then proxies are deployed that delegatecall into the respective implementations following an initialization call (hardhat, with same transaction). However, the implementations are initialized explicitly nor are they protected from other actors claiming/initializing them. This allows anyone to call initialization functions on implementations for use with phishing attacks (i.e. contract implementation addresses are typically listed on the official project website as valid contracts) which may affect the reputation of the system.",
        "None of the implementations allow unprotected delegatecalls or selfdesturcts. lowering the severity of this finding."
    ],
    "Examples": [
        "src/contracts/StakingContract.sol:L151-L162",
        "src/contracts/AuthorizedFeeRecipient.sol:L21-L32",
        "src/contracts/FeeRecipient.sol:L18-L27"
    ],
    "Recommendation": [
        "Petrify contracts in the constructor and disallow other actors from claiming/initializing the implementations."
    ]
}
----End JSON----

https://solodit.xyz/issues/operator-may-dos-the-withdrawal-or-make-it-more-expensive-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (operatorFee > 0) {\n (status, data) = operator.call{value: operatorFee}(\"\");\n if (status == false) {\n revert FeeRecipientReceiveError(data);\n }\n}\n\n"
    ],
    "Description": [
        "While collecting fees, the operator may:",
        "src/contracts/ConsensusLayerFeeDispatcher.sol:L105-L110"
    ],
    "Recommendation": [
        "A possible solution could be to make a low-level call in an inline assembly block, restricting the returndata to a couple of bytes, and instead of reverting on the failed call, emit an event, flagging the call that failed."
    ]
}
----End JSON----

https://solodit.xyz/issues/proxyadmin-may-cause-dos-for-sys_admin-consensys-none-kilnfi-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " if (msg.sender == \\_getAdmin()) {\n bytes memory ret;\n bytes4 selector = msg.sig;\n if (selector == ITransparentUpgradeableProxy.upgradeTo.selector) {\n ret = \\_dispatchUpgradeTo();\n } else if (selector == ITransparentUpgradeableProxy.upgradeToAndCall.selector) {\n ret = \\_dispatchUpgradeToAndCall();\n } else if (selector == ITransparentUpgradeableProxy.changeAdmin.selector) {\n ret = \\_dispatchChangeAdmin();\n } else if (selector == ITransparentUpgradeableProxy.admin.selector) {\n ret = \\_dispatchAdmin();\n } else if (selector == ITransparentUpgradeableProxy.implementation.selector) {\n ret = \\_dispatchImplementation();\n } else {\n revert(\"TransparentUpgradeableProxy: admin cannot fallback to proxy target\");\n }\n assembly {\n return(add(ret, 0x20), mload(ret))\n }\n\n",
        "function \\_beforeFallback() internal override {\n if (StorageSlot.getBooleanSlot(\\_PAUSE\\_SLOT).value == false || msg.sender == stakingContract.getAdmin() || msg.sender == address(0)) {\n\n super.\\_beforeFallback();\n }\n\n"
    ],
    "Description": [
        "As the TransparentUpgradeableProxy doesn\u2019t allow the ProxyAdmin to delegate calls to the implementation, it means the SYS_ADMIN can\u2019t be the same as ProxyAdmin. Now, talking about the design, the proxy defines a system-wide feature to pause or unpause. If the proxyAdmin pauses the staking contract, it implies no one can interact with it, not even the SYS_ADMIN, which might not be what the auditee team wants. There may be multiple scenarios where the auditee team wants to intervene manually in the system even if the system is paused, for instance, withdrawing funds while restricting the withdrawer."
    ],
    "Recommendation": [
        "The system-wide pause feature should allow the SYS_ADMIN to call the staking functions if the system is paused. Something like:"
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-priviliges-setoperatoraddresses-acknowledged-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setOperatorAddresses(\n uint256 \\_operatorIndex,\n address \\_operatorAddress,\n address \\_feeRecipientAddress\n) external onlyActiveOperatorFeeRecipient(\\_operatorIndex) {\n \\_checkAddress(\\_operatorAddress);\n \\_checkAddress(\\_feeRecipientAddress);\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n\n operators.value[\\_operatorIndex].operator = \\_operatorAddress;\n operators.value[\\_operatorIndex].feeRecipient = \\_feeRecipientAddress;\n emit ChangedOperatorAddresses(\\_operatorIndex, \\_operatorAddress, \\_feeRecipientAddress);\n}\n\n"
    ],
    "Description": [
        "The function setOperatorAddresses instead of allowing the Operator to update its own, as well as the Fee Recipient address, incorrectly provides the privileges to the Fee Recipient. As a result, the Fee Recipient can modify the operator address as and when needed, to DoS the operator and exploit the system. Additionally, upon reviewing the documentation, we found that there are no administrative rights defined for the Fee Recipient, hence highlighting the incorrect privilege allocation.",
        "src/contracts/StakingContract.sol:L412-L424"
    ],
    "Recommendation": [
        "The modifier should be onlyActiveOperatorOrAdmin allowing only the operator itself or admin of the system, to update the necessary addresses.",
        "Also, for transferring crucial privileges from one address to another, the operator\u2019s address should follow a 2-step approach like transferring ownership."
    ]
}
----End JSON----

https://solodit.xyz/issues/unconstrained-snapshot-while-setting-operator-limit-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\n operators.value[\\_operatorIndex].limit < \\_limit &&\n StakingContractStorageLib.getLastValidatorEdit() > \\_snapshot\n) {\n revert LastEditAfterSnapshot();\n}\n\n"
    ],
    "Description": [
        "Function setOperatorLimit as the name says, allows the SYS_ADMIN to set/update the staking limit for an operator. The function ensures that if the limit is being increased, the _snapshot must be ahead of the last validator edit(block.number at which the last validator edit occurred). However, the parameter _snapshot is unconstrained and can be any number. Also, the functions addValidators and removeValidators update the block.number signifying the last validator edit, but never constrain the new edits with it. Since there are no publicly available functions to access this value, makes the functionality even more confusing and may be unnecessary.",
        "src/contracts/StakingContract.sol:L468-L473"
    ],
    "Recommendation": [
        "If the functionality is not needed, consider removing it. Otherwise, add some necessary logic to either constrain the last validator edit or add public functions for the users to access it."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-input-validation-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n StakingContractStorageLib.OperatorInfo memory newOperator;\n\n if (operators.value.length == 1) {\n revert MaximumOperatorCountAlreadyReached();\n }\n newOperator.operator = \\_operatorAddress;\n newOperator.feeRecipient = \\_feeRecipientAddress;\n operators.value.push(newOperator);\n uint256 operatorIndex = operators.value.length - 1;\n emit NewOperator(\\_operatorAddress, \\_feeRecipientAddress, operatorIndex);\n return operatorIndex;\n}\n\n",
        "function setTreasury(address \\_newTreasury) external onlyAdmin {\n emit ChangedTreasury(\\_newTreasury);\n StakingContractStorageLib.setTreasury(\\_newTreasury);\n}\n\n",
        "/// @notice Deactivates an operator and changes the fee recipient address and the staking limit\n/// @param \\_operatorIndex Operator Index\n/// @param \\_temporaryFeeRecipient Temporary address to receive funds decided by the system admin\nfunction deactivateOperator(uint256 \\_operatorIndex, address \\_temporaryFeeRecipient) external onlyAdmin {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n operators.value[\\_operatorIndex].limit = 0;\n emit ChangedOperatorLimit(\\_operatorIndex, 0);\n operators.value[\\_operatorIndex].deactivated = true;\n emit DeactivatedOperator(\\_operatorIndex);\n operators.value[\\_operatorIndex].feeRecipient = \\_temporaryFeeRecipient;\n emit ChangedOperatorAddresses(\\_operatorIndex, operators.value[\\_operatorIndex].operator, \\_temporaryFeeRecipient);\n \\_updateAvailableValidatorCount(\\_operatorIndex);\n}\n\n/// @notice Activates an operator, without changing its 0 staking limit\n/// @param \\_operatorIndex Operator Index\n/// @param \\_newFeeRecipient Sets the fee recipient address\nfunction activateOperator(uint256 \\_operatorIndex, address \\_newFeeRecipient) external onlyAdmin {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n operators.value[\\_operatorIndex].deactivated = false;\n emit ActivatedOperator(\\_operatorIndex);\n operators.value[\\_operatorIndex].feeRecipient = \\_newFeeRecipient;\n emit ChangedOperatorAddresses(\\_operatorIndex, operators.value[\\_operatorIndex].operator, \\_newFeeRecipient);\n}\n\n"
    ],
    "Description": [
        "src/contracts/StakingContract.sol:L392-L405",
        "src/contracts/StakingContract.sol:L214-L217",
        "src/contracts/StakingContract.sol:L479-L502"
    ]
}
----End JSON----

https://solodit.xyz/issues/hardcoded-operator-limit-logic-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addOperator(address \\_operatorAddress, address \\_feeRecipientAddress) external onlyAdmin returns (uint256) {\n StakingContractStorageLib.OperatorsSlot storage operators = StakingContractStorageLib.getOperators();\n StakingContractStorageLib.OperatorInfo memory newOperator;\n\n if (operators.value.length == 1) {\n revert MaximumOperatorCountAlreadyReached();\n }\n\n",
        "function \\_depositOnOneOperator(uint256 \\_depositCount, uint256 \\_totalAvailableValidators) internal {\n StakingContractStorageLib.setTotalAvailableValidators(\\_totalAvailableValidators - \\_depositCount);\n \\_depositValidatorsOfOperator(0, \\_depositCount);\n}\n\n"
    ],
    "Description": [
        "The contract defines some hardcoded limits which is not the right approach for upgradeable contracts and opens doors for accidental mistakes, if not handled with care.",
        "The operators for the current version are limited to 1. If the auditee team decides to open the system to work with more operators but fails to change the limit while upgrading, the upgraded contract will have no effect, and will still disallow any more operators to be added.",
        "src/contracts/StakingContract.sol:L392-L398",
        "Also, the function _depositOnOneOperator hardcodes the operator Index as 0 since the contract only supports one operator.",
        "src/contracts/StakingContract.sol:L893-L896"
    ],
    "Recommendation": [
        "A better approach could be to constrain the limit of operators that can be added with a storage variable or constant, provided at the time of contract initialization. The contract should also consider supporting dynamic operator deposits for future versions instead of the default hardcoded index."
    ]
}
----End JSON----

https://solodit.xyz/issues/stakingcontract-pubkey-length-checks-not-always-enforced-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addValidators(\n uint256 \\_operatorIndex,\n uint256 \\_keyCount,\n bytes calldata \\_publicKeys,\n bytes calldata \\_signatures\n) external onlyActiveOperator(\\_operatorIndex) {\n if (\\_keyCount == 0) {\n revert InvalidArgument();\n }\n\n if (\\_publicKeys.length % PUBLIC\\_KEY\\_LENGTH != 0 || \\_publicKeys.length / PUBLIC\\_KEY\\_LENGTH != \\_keyCount) {\n revert InvalidPublicKeys();\n }\n\n",
        "/// @notice Set withdrawer for public key\n/// @dev Only callable by current public key withdrawer\n/// @param \\_publicKey Public key to change withdrawer\n/// @param \\_newWithdrawer New withdrawer address\nfunction setWithdrawer(bytes calldata \\_publicKey, address \\_newWithdrawer) external {\n if (!StakingContractStorageLib.getWithdrawerCustomizationEnabled()) {\n revert Forbidden();\n }\n \\_checkAddress(\\_newWithdrawer);\n bytes32 pubkeyRoot = \\_getPubKeyRoot(\\_publicKey);\n StakingContractStorageLib.WithdrawersSlot storage withdrawers = StakingContractStorageLib.getWithdrawers();\n\n if (withdrawers.value[pubkeyRoot] != msg.sender) {\n revert Unauthorized();\n }\n\n emit ChangedWithdrawer(\\_publicKey, \\_newWithdrawer);\n\n withdrawers.value[pubkeyRoot] = \\_newWithdrawer;\n}\n\n",
        "function \\_getPubKeyRoot(bytes memory \\_publicKey) internal pure returns (bytes32) {\n return sha256(abi.encodePacked(\\_publicKey, bytes16(0)));\n}\n\n",
        "/// @notice Withdraw the Execution Layer Fee for a given validator public key\n/// @dev Funds are sent to the withdrawer account\n/// @param \\_publicKey Validator to withdraw Execution Layer Fees from\nfunction withdrawELFee(bytes calldata \\_publicKey) external {\n \\_onlyWithdrawerOrAdmin(\\_publicKey);\n \\_deployAndWithdraw(\\_publicKey, EXECUTION\\_LAYER\\_SALT\\_PREFIX, StakingContractStorageLib.getELDispatcher());\n}\n\n"
    ],
    "Description": [
        "addValidators checks that the provided bytes pubKey is a multiple of the expected pubkey length while functions like setWithdrawer do not enforce similar length checks. This is an inconsistency that should be avoided.",
        "src/contracts/StakingContract.sol:L530-L542",
        "src/contracts/StakingContract.sol:L426-L445",
        "src/contracts/StakingContract.sol:L775-L777",
        "src/contracts/StakingContract.sol:L696-L702",
        "Nevertheless, the methods should be hardened so as not to give a malicious actor the freedom to use an unexpected input size for the pubKey argument."
    ],
    "Recommendation": [
        "Enforce pubkey length checks when accepting a single pubkey as bytes similar to the batch functions that check for a multiple of \u00b4PUBLIC_KEY_LENGTH\u00b4. Alternatively, declare the function argument as bytes48 (however, in this case inputs may be auto-padded to fit the expected length, pot. covering situations that otherwise would throw an error)"
    ]
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-due-to-admin-front-running-or-general-bad-timing-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Change the Operator fee\n/// @param \\_operatorFee Fee in Basis Point\nfunction setOperatorFee(uint256 \\_operatorFee) external onlyAdmin {\n if (\\_operatorFee > StakingContractStorageLib.getOperatorCommissionLimit()) {\n revert InvalidFee();\n }\n StakingContractStorageLib.setOperatorFee(\\_operatorFee);\n emit ChangedOperatorFee(\\_operatorFee);\n}\n\n",
        "\n/// @notice Change the Global fee\n/// @param \\_globalFee Fee in Basis Point\nfunction setGlobalFee(uint256 \\_globalFee) external onlyAdmin {\n if (\\_globalFee > StakingContractStorageLib.getGlobalCommissionLimit()) {\n revert InvalidFee();\n }\n StakingContractStorageLib.setGlobalFee(\\_globalFee);\n emit ChangedGlobalFee(\\_globalFee);\n}\n\n"
    ],
    "Description": [
        "In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.",
        "Some instances of this are more important than others, but in general, users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "src/contracts/StakingContract.sol:L504-L512",
        "src/contracts/StakingContract.sol:L513-L522"
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period."
    ]
}
----End JSON----

https://solodit.xyz/issues/potentially-uninitialized-implementations-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize\\_1(\n address \\_admin,\n address \\_treasury,\n address \\_depositContract,\n address \\_elDispatcher,\n address \\_clDispatcher,\n address \\_feeRecipientImplementation,\n uint256 \\_globalFee,\n uint256 \\_operatorFee,\n uint256 globalCommissionLimitBPS,\n uint256 operatorCommissionLimitBPS\n) external init(1) {\n\n",
        "/// @notice Initializes the receiver\n/// @param \\_dispatcher Address that will handle the fee dispatching\n/// @param \\_publicKeyRoot Public Key root assigned to this receiver\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\n if (initialized) {\n revert AlreadyInitialized();\n }\n initialized = true;\n dispatcher = IFeeDispatcher(\\_dispatcher);\n publicKeyRoot = \\_publicKeyRoot;\n stakingContract = msg.sender; // The staking contract always calls init\n}\n\n",
        "/// @param \\_publicKeyRoot Public Key root assigned to this receiver\nfunction init(address \\_dispatcher, bytes32 \\_publicKeyRoot) external {\n if (initialized) {\n revert AlreadyInitialized();\n }\n initialized = true;\n dispatcher = IFeeDispatcher(\\_dispatcher);\n publicKeyRoot = \\_publicKeyRoot;\n}\n\n"
    ],
    "Description": [
        "Most contracts in the system are meant to be used with a proxy pattern. First, the implementations are deployed, and then proxies are deployed that delegatecall into the respective implementations following an initialization call (hardhat, with same transaction). However, the implementations are initialized explicitly nor are they protected from other actors claiming/initializing them. This allows anyone to call initialization functions on implementations for use with phishing attacks (i.e. contract implementation addresses are typically listed on the official project website as valid contracts) which may affect the reputation of the system.",
        "None of the implementations allow unprotected delegatecalls or selfdesturcts. lowering the severity of this finding."
    ],
    "Examples": [
        "src/contracts/StakingContract.sol:L151-L162",
        "src/contracts/AuthorizedFeeRecipient.sol:L21-L32",
        "src/contracts/FeeRecipient.sol:L18-L27"
    ],
    "Recommendation": [
        "Petrify contracts in the constructor and disallow other actors from claiming/initializing the implementations."
    ]
}
----End JSON----

https://solodit.xyz/issues/operator-may-dos-the-withdrawal-or-make-it-more-expensive-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (operatorFee > 0) {\n (status, data) = operator.call{value: operatorFee}(\"\");\n if (status == false) {\n revert FeeRecipientReceiveError(data);\n }\n}\n\n"
    ],
    "Description": [
        "While collecting fees, the operator may:",
        "src/contracts/ConsensusLayerFeeDispatcher.sol:L105-L110"
    ],
    "Recommendation": [
        "A possible solution could be to make a low-level call in an inline assembly block, restricting the returndata to a couple of bytes, and instead of reverting on the failed call, emit an event, flagging the call that failed."
    ]
}
----End JSON----

https://solodit.xyz/issues/proxyadmin-may-cause-dos-for-sys_admin-consensys-none-kilnfi-staking-consensys-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " if (msg.sender == \\_getAdmin()) {\n bytes memory ret;\n bytes4 selector = msg.sig;\n if (selector == ITransparentUpgradeableProxy.upgradeTo.selector) {\n ret = \\_dispatchUpgradeTo();\n } else if (selector == ITransparentUpgradeableProxy.upgradeToAndCall.selector) {\n ret = \\_dispatchUpgradeToAndCall();\n } else if (selector == ITransparentUpgradeableProxy.changeAdmin.selector) {\n ret = \\_dispatchChangeAdmin();\n } else if (selector == ITransparentUpgradeableProxy.admin.selector) {\n ret = \\_dispatchAdmin();\n } else if (selector == ITransparentUpgradeableProxy.implementation.selector) {\n ret = \\_dispatchImplementation();\n } else {\n revert(\"TransparentUpgradeableProxy: admin cannot fallback to proxy target\");\n }\n assembly {\n return(add(ret, 0x20), mload(ret))\n }\n\n",
        "function \\_beforeFallback() internal override {\n if (StorageSlot.getBooleanSlot(\\_PAUSE\\_SLOT).value == false || msg.sender == stakingContract.getAdmin() || msg.sender == address(0)) {\n\n super.\\_beforeFallback();\n }\n\n"
    ],
    "Description": [
        "As the TransparentUpgradeableProxy doesn\u2019t allow the ProxyAdmin to delegate calls to the implementation, it means the SYS_ADMIN can\u2019t be the same as ProxyAdmin. Now, talking about the design, the proxy defines a system-wide feature to pause or unpause. If the proxyAdmin pauses the staking contract, it implies no one can interact with it, not even the SYS_ADMIN, which might not be what the auditee team wants. There may be multiple scenarios where the auditee team wants to intervene manually in the system even if the system is paused, for instance, withdrawing funds while restricting the withdrawer."
    ],
    "Recommendation": [
        "The system-wide pause feature should allow the SYS_ADMIN to call the staking functions if the system is paused. Something like:"
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-input-validation-for-walletaddress-fixed-consensys-none-wallet-guard-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\n request.method === RpcRequestMethods.UpdateAccount &&\n 'walletAddress' in request.params &&\n typeof request.params.walletAddress === 'string'\n) {\n const { walletAddress } = request.params;\n\n if (!walletAddress) {\n throw new Error('no wallet address provided');\n }\n\n updateWalletAddress(walletAddress);\n\n"
    ],
    "Resolution": [
        "The client acknowledged the issue and fixed it by implementing a regex validation in PR#25 here - Snap shasum YzN/+ty8xOTEacH19iYGw1a9+MBCgL7PUkU9d/Rf51E=.\nNote that the fix does not validate the address checksum, which is not critical considering the application."
    ],
    "Description": [
        "The snap prompts users to input the wallet address to be monitored. Users can set wallet addreses that do not adhere to the common Ethereum address format. The user input is not sanitized. This could lead to various injection vulnerabilities such as markdown or control character injections that could break other components.\nIn particular, the address is sent to the API as a URL query parameter. A malicious attacker could try using that to mount URL injection attacks.",
        "packages/snap/src/index.ts:L50-L61"
    ],
    "Recommendation": [
        "Sanitize the address string input by the user and reject all addresses that do not adhere to the Ethereum address format."
    ]
}
----End JSON----

https://solodit.xyz/issues/server-should-not-rely-on-clients-randomness-fixed-consensys-none-wallet-guard-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const simulateRequest: SimulateRequestParams = {\n id: crypto.randomUUID(),\n chainID: mappedChainId,\n signer: transaction.from as string,\n origin: transactionOrigin as string,\n method: transaction.method as string,\n transaction,\n source: 'SNAP',\n};\n\n"
    ],
    "Resolution": [
        "Severity decreased: Major \u2013> Medium: The client acknowledged the issue, and let us know that the ID is only used for analytics purposes, to be compatible with the existing API. A future release of the API will improve UID handling."
    ],
    "Description": [
        "The snap code sends a request to the Wallet Guard API with a random UUID crypto.randomUUID() generated by the client.\nWe would like to underline that the API should never trust clients\u2019 randomness nor assume any property about it.\nRelying on client-generated randomness for the API could lead to many vulnerabilities, such as replay attacks or collision issues due to the inability to ensure uniqueness. The varying algorithms used by clients may be subpar or even compromised.\nAs this id is not used anywhere else in the snap code, we assume that it might be used on the API side. Because the API is not in scope for this review, we don\u2019t have access to the code and cannot tell whether this pseudo-random UUID is used in a safe way.",
        "packages/snap/src/http/fetchTransaction.ts:L32-L40"
    ],
    "Recommendation": [
        "Don\u2019t rely on clients\u2019 randomness on the API. Instead, the server should assign a unique ID to every incoming request."
    ]
}
----End JSON----

https://solodit.xyz/issues/properties-of-the-transaction-object-might-be-undefined-consensys-none-wallet-guard-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const simulateRequest: SimulateRequestParams = {\n id: crypto.randomUUID(),\n chainID: mappedChainId,\n signer: transaction.from as string,\n origin: transactionOrigin as string,\n method: transaction.method as string,\n transaction,\n source: 'SNAP',\n};\n\n"
    ],
    "Description": [
        "The Metamask Snaps API does not guarantee that the properties from and method of the transaction object are defined. Depending on the transaction type, it could happen that these properties are not defined. This would result in a runtime error when undefined is casted to string.",
        "packages/snap/src/http/fetchTransaction.ts:L32-L40"
    ],
    "Recommendation": [
        "One should check whether properties from, and method are defined, before explicitly casting them to a string. This could be done by introducing a hasProperty utility function for instance."
    ]
}
----End JSON----

https://solodit.xyz/issues/assetchangecomponent-displays-a-change-with-value-0-if-fiatvalue-0005-consensys-none-wallet-guard-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const fiatValue = Number(stateChange.fiatValue).toFixed(2);\n\n"
    ],
    "Description": [
        "The toFixed(2) method rounds the transaction value string to 2 decimals. For transactions with fiatValue < 0.005, the function returns 0, meaning the component will display a transaction with zero value to the user, even if the transaction has a small yet non-zero value. This is not a good idea as it might trick the user.\nIn that case, it would be better to default to the smallest value that can represented (i.e. 0.01) instead of 0.",
        "packages/snap/src/components/stateChanges/AssetChangeComponent.ts:L18"
    ],
    "Recommendation": [
        "If fiatValue < 0.005, consider displaying a value of 0.01 to the user, instead of 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/superfluous-permission-endowmentethereum-provider-fixed-consensys-none-push-protocol-snap-for-metamask-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\"endowment:ethereum-provider\": {}\n\n"
    ],
    "Resolution": [
        "fixed in ethereum-push-notification-service/push-protocol-snaps@1a6a32ef760088ca59f73e555f41b5b5d871f761 by removing the ethereum provider permission from the manifest."
    ],
    "Description": [
        "The snap requests permission endowment:ethereum-provider but window.ethereum is never accessed from within the snap\u2019s context.",
        "snap/snap.manifest.json:L39"
    ],
    "Recommendation": [
        "Remove superfluous permissions."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-trusted-website-can-add-any-address-to-the-snaps-address-storage-no-control-over-added-addresses-confirmation-is-a-notification-fixed-consensys-none-push-protocol-snap-for-metamask-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "await window.ethereum?.request({\n method: \"wallet\\_invokeSnap\",\n params: {\n snapId: \"local:http://localhost:8080\",\n request: { method: 'hello', params: { address: \"\\nhi\\nho\" } },\n }})\n\n",
        "export default function ConfirmButton() {\n const { address, isConnecting, isDisconnected } = useAccount();\n const defaultSnapOrigin = `local:http://localhost:8080`;\n\n const sendHello = async (address: string) => {\n await window.ethereum?.request({\n method: \"wallet\\_invokeSnap\",\n params: {\n snapId: defaultSnapOrigin,\n request: { method: 'hello', params: { address: address } },\n },\n });\n };\n\n const { data, isError, isLoading, isSuccess, signMessage } = useSignMessage({\n message:\n `Confirm your Address ${address}, \\n this will be added to MetaMask for sending notifications`,\n });\n\n function sleep(ms: number) {\n return new Promise((resolve) => setTimeout(resolve, ms));\n }\n\n const confirmAddition=async()=>{\n signMessage();\n if(isSuccess){\n await sleep(5000);\n await sendHello(String(address));\n }\n }\n\n"
    ],
    "Resolution": [
        "partially addressed in ethereum-push-notification-service/push-protocol-snaps@1a6a32ef760088ca59f73e555f41b5b5d871f761 by only allowing trusted origins to interact with the snap.",
        "Update: user confirmation for address management (add/remove current account) added with ethereum-push-notification-service/push-protocol-snaps@7ee018947303014e8c14e9413a5edd9fd29f9829"
    ],
    "Description": [
        "Trusted websites can add addresses to the list of addresses the user wants to receive notifications for. However, the user has no control over the addresses, and even though the code suggests that the snap user must confirm new address addition, this confirmation is merely a notification that the address has been added.",
        "The lack of address management may lead to a self-DoS when too many addresses are added to the extension.",
        "push-snap-site/components/buttons/ConfirmButton.tsx:L6-L35",
        "The same is true for configuration settings. Any connected dap may set togglepopup. This may be problematic in multi-dapp scenarios where multiple dapps request to set togglepopup."
    ],
    "Recommendation": [
        "Note that dapps are not necessarily completely trusted. They can be modified, or malicious behavior may be added later by the dapp deployer (unless used locally or via IPFS). Therefore, the snap should always notify the wallet owner of important state changes and allow them to reject them or, in this case, manage addresses that\u2019ve been added previously.",
        "Consider checking the origin in onRPC if this dapp is only meant to be called from a specific dapp address. Otherwise, any connected dapp may change configuration settings."
    ]
}
----End JSON----

https://solodit.xyz/issues/lax-input-validation-control-char-uri-and-markdown-injection-fixed-consensys-none-push-protocol-snap-for-metamask-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "await addAddress(request.params.address || \"0x0\");\n\n",
        "await window.ethereum?.request({\n method: \"wallet\\_invokeSnap\",\n params: {\n snapId: \"local:http://localhost:8080\",\n request: { method: 'hello', params: { address: \"Hi \ud83d\ude4c\\n\\n \ud83d\udd38 \\*\\*boom\\*\\*\" } },\n }})\n\n",
        "export const getNotifications=async(address:string)=>{\n const url = `https://backend-prod.epns.io/apis/v1/users/eip155:5:${address}/feeds`;\n const response = await fetch(url, {\n method: 'get',\n headers: {\n 'Content-Type': 'application/json',\n },\n });\n const data = await response.json();\n return data;\n }\n\n",
        "export const popupHelper = (notifs: String[]) => {\n let msg = [];\n if (notifs.length > 0) {\n notifs.forEach((notif) => {\n let str = `\\n\ud83d\udd14` + notif + \"\\n\";\n msg.push(str);\n });\n }\n return msg;\n};\n\n",
        "const data = persistedData.addresses;\nconst popup = persistedData.popuptoggle;\nlet msg='';\nfor(let i = 0; i < data!.length; i++){\n msg = msg + '\ud83d\udd39' + data![i] + '\\n';\n}\nreturn snap.request({\n method: 'snap\\_dialog',\n\n"
    ],
    "Resolution": [
        "addressed in ethereum-push-notification-service/push-protocol-snaps@1a6a32ef760088ca59f73e555f41b5b5d871f761 validating the address with ethers.utils.isAddress.",
        "Update 1:",
        "Update 2:",
        "Markdown Injection in Confirmation Dialogue fixed with ethereum-push-notification-service/push-protocol-snaps@b40e141243c77bfd7ec109408b326607b19314c8"
    ],
    "Description": [
        "There is no input validation on the address to be added. The input may be an ethereum address but can be anything, potentially breaking security assumptions in the code and leading to unwanted side effects.",
        "snap/src/index.ts:L18"
    ],
    "Example": [
        "",
        "snap/src/utils/fetchnotifs.ts:L3-L13",
        "snap/src/utils/popupHelper.ts:L3-L12",
        "snap/src/utils/fetchAddress.ts:L45-L52",
        "Also, note that the currently rendered markdown that lists addresses appears wrong, as markdown newlines require \\n\\n instead of \\n."
    ],
    "Recommendation": [
        "Strictly validate inputs from external origins. Ensure that the provided address is a valid ethereum address. Optionally check the addresses checksum to detect typos. Ensure that inputs may not lead to renderable markdown. Fix the rendered list of addresses to properly display as a newline\u2019d list. Ensure untrusted inputs cannot inject context-sensitive information into fetch urls."
    ]
}
----End JSON----

https://solodit.xyz/issues/persisteddata-race-where-snap_managestateget-returnsnull-fixed-consensys-none-push-protocol-snap-for-metamask-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Oops! Something went wrong.\r\nSnap Error: 'Cannot read properties of null (reading 'addresses')'. Error Code: '-32603'\n\n",
        "export const addAddress = async (address:string) => {\n\n const persistedData = await snap.request({\n method: 'snap\\_manageState',\n params: { operation: 'get' },\n });\n\n if(persistedData == null){\n const data = {\n addresses: [address],\n popuptoggle: 0,\n };\n await snap.request({\n method: 'snap\\_manageState',\n params: { operation: 'update', newState:data },\n });\n\n",
        "export const onRpcRequest: OnRpcRequestHandler = async ({\n origin,\n request,\n}) => {\n switch (request.method) {\n case \"hello\": {\n await addAddress(request.params.address || \"0x0\");\n await confirmAddress();\n break;\n }\n\n",
        "let persistedData = await snap.request({\n method: 'snap\\_manageState',\n params: { operation: 'get' },\n});\n\nlet popuptoggle = notifcount;\n\nconst data = {\n addresses: persistedData.addresses,\n popuptoggle: popuptoggle,\n};\n\n"
    ],
    "Resolution": [
        "addressed with ethereum-push-notification-service/push-protocol-snaps@7ee018947303014e8c14e9413a5edd9fd29f9829 by introducing a wrapper function that ensures that snapstate returns sane defaults. This function is not used everywhere, but in places where it is not, custom checks are employed."
    ],
    "Description": [
        "Metamask Error:",
        "snap.request(, {method: 'snap_manageState', params: {operation: 'get'}}) may return null. Snap state is only initialized on rpc request method hello via addAddress().",
        "This is the only method that checks if the retrieved state is null:",
        "snap/src/utils/fetchAddress.ts:L5-L20",
        "snap/src/index.ts:L12-L21",
        "If the state was never initialized or there was a race where rpc-hello() was not called first, then the snap may run into a null deref exception (here rpc-togglepopup):",
        "snap/src/utils/toggleHelper.ts:L2-L12"
    ],
    "Recommendation": [
        "Wrap snap_manageState with a function that always falls back to safe defaults if the snap state was never set. This also obsoleted the future need to check if persistedData is null as the new method ensures safe non-null defaults.",
        "This should also silence some of the type errors reported by tslint that warn that attributes of persistentdata are read while it might be null (see issue 5.6 )."
    ]
}
----End JSON----

https://solodit.xyz/issues/user-flow-request-to-sign-message-does-not-provide-security-guarantee-fixed-consensys-none-push-protocol-snap-for-metamask-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const { data, isError, isLoading, isSuccess, signMessage } = useSignMessage({\n message:\n `Confirm your Address ${address}, \\n this will be added to MetaMask for sending notifications`,\n});\n\n"
    ],
    "Resolution": [
        "obsolete, removed with ethereum-push-notification-service/push-protocol-snaps@7ee018947303014e8c14e9413a5edd9fd29f9829."
    ],
    "Description": [
        "A connected dapp can add any address to the snap via the RPC method hello. There is no added security by requesting the user to sign with their address as the backend API gives access to any address notification (they are not private) and the dapps request is a front-end-only solution. A user may add any other address by creating their dapp which allows custom addresses.",
        "In light of this, the front-end (dapp) security check requiring the user to prove that they are in possession of the private key appears not to add any security guarantees to the snap. Instead, the snap may want to enumerate wallet account addresses internally instead and remove the hello API altogether, or, allow any address to be added without requiring a proof of ownership of an address."
    ],
    "Examples": [
        "push-snap-site/components/buttons/ConfirmButton.tsx:L20-L23"
    ],
    "Recommendation": [
        "Remove the signature check, and add linked accounts from within the snaps context. Be transparent that notification texts are not private, and anyone can subscribe to the back-end API. If notifications are private to the recipient, we suggest encrypting them for the target account and adding logic in the snap to allow the recipient to decrypt them within the context of the snap."
    ]
}
----End JSON----

https://solodit.xyz/issues/typescript-errors-fixed-consensys-none-push-protocol-snap-for-metamask-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Type '{ addresses: Json; popuptoggle: Number; }' is not assignable to type 'Record<string, Json>'.\n Property 'popuptoggle' is incompatible with index signature.\n Type 'Number' is not assignable to type 'Json'.\n Type 'Number' is not assignable to type '{ [prop: string]: Json; }'.\n Index signature for type 'string' is missing in type 'Number'.ts(2322)\n\n",
        "let popuptoggle = notifcount;\n\nconst data = {\n addresses: persistedData.addresses,\n popuptoggle: popuptoggle,\n};\nawait snap.request({\n method: 'snap\\_manageState',\n params: { operation: 'update', newState:data },\n});\n\n",
        "Variable 'msg' implicitly has an 'any[]' type.ts(7005)\n\n",
        "export const fetchAllAddrNotifs = async () => {\n const addresses = await fetchAddress();\n let notifs:String[] = [];\n for(let i = 0; i < addresses.length; i++){\n\n",
        "let persistedData = await snap.request({\n method: \"snap\\_manageState\",\n params: { operation: \"get\" },\n});\n\nlet popuptoggle = Number(persistedData.popuptoggle) + msgs.length;\n\n"
    ],
    "Resolution": [
        "partially addressed in ethereum-push-notification-service/push-protocol-snaps@1a6a32ef760088ca59f73e555f41b5b5d871f761:",
        "Update: toggleHelper and persistedData addressed with the snap data check wrapper function in ethereum-push-notification-service/push-protocol-snaps@7ee018947303014e8c14e9413a5edd9fd29f9829"
    ],
    "Description": [
        "persistedData should be checked for null and default to a sane initial config. notifcount:Number should be notifcount:number.",
        "snap/src/utils/toggleHelper.ts:L7-L16",
        "let msg = [] should be let msg = [] as String[];",
        "snap/src/utils/fetchnotifs.ts:L34-L37",
        "snap/src/index.ts:L63-L68"
    ],
    "Recommendation": [
        "Fix the typescript configuration (see issue 5.13 ). Fix all reported ts-lint errors. Avoid using any types and use safe types instead."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-eth_signmessage-allows-linked-dapps-to-sign-messages-with-any-wallet-account-and-wo-explicit-user-consent-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nasync signMessage({ message }: SignMessageParamsType<T>): Promise<SignMessageResponseType<T>> {\n try {\n return (await this.signer.ethSignMessage(\n message as SignerSignMessageType<T>,\n )) as SignMessageResponseType<T>\n } catch (error) {\n this.logger.error(message, { fn: 'ethSignMessage' }, error)\n return Promise.reject(error)\n }\n}\n\n",
        "export const avalancheSignMessage = async (\n params: AvalancheSignMessageParams,\n): Promise<AvalancheSignMessageResponse> => {\n try {\n const avalancheSigner = new AvalancheSigner()\n await avalancheSigner.initialize()\n return await avalancheSigner.signMessage(params)\n } catch (error) {\n moduleLogger.error({ fn: 'avalancheSignMessage' }, error)\n return Promise.reject(error)\n }\n}\n\n",
        "await window.ethereum.request({\n method: 'wallet\\_invokeSnap',\n params: {\n snapId: \"local:http://localhost:9000\",\n request: { method: 'eth\\_signMessage', params: {message: {addressNList: [0x80000000 + 44, 0x80000000 + 60, 0x80000000 + 0, 0, 1], message:\"hi\"}, snapId: \"local:http://localhost:9000\" }},\n }});\n{address: '0xBaB66CfA59757200c90c79BC6e2aEe4bFBe382Be', signature: '0x5c04bcc1ca73e9f9d4bf3642150407c01c189d784dd90349\u2026e03ca8ec026ec6062b3d708c5fedbca0f2427282620be8c1b'}\n\n"
    ],
    "Description": [
        "When a normal dapp requests MetaMask to sign an arbitrary message, the message is displayed to the user for confirmation before signing it. Requiring explicit user consent and displaying the message to be signed is crucial to ensure that the user has full control over what messages are signed on their behalf.",
        "The shapeshift snap exposes an RPC endpoint for ethereum (and an undocumented one for AVAX) that allows bypassing user consent. When invoking the shapeshift snap with the eth_signMessage RPC method, the snap signs the message right away, silently, without requiring consent from the wallet owner or notifying them of the fact that the dapp is signing with a HD wallet account on their behalf. This severely undermines security restrictions by the MetaMask that ensure that the end-user has full control over what is being signed, giving them the option to reject signing.",
        "For comparison, eth_signTransaction ask for user confirmation while eth_signMessage does not a.",
        "The relevant code can be found here:",
        "packages/snap/src/rpc/evm/common/EVMSigner.ts:L37-L47",
        "It also affects the avax implementation:",
        "packages/snap/src/rpc/evm/avalanche/handlers.ts:L34-L45"
    ],
    "Examples": [
        "A dapp can invoke eth_signMessage which will not require user confirmation and silently return a message that is signed with any of the users HD wallet accounts."
    ],
    "Recommendation": [
        "Follow exactly the same flow MetaMask already implemented when signing arbitrary messages. Log signing requests, surface them to the user, ask for confirmation, and reject them by default (timeout). Display the origin on signing request dialogues and present the data to be signed and the account in a human-readable, understandable way while showing the original data to be signed, too."
    ]
}
----End JSON----

https://solodit.xyz/issues/shapeshift-manages-metamasks-ethereum-private-keys-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "As the Snap Outline in this report mentions, the ShapeShift snap requests access to the BIP32 entropy for the Ethereum private keys. This effectively allows the ShapeShift snap to manage MetaMasks Ethereum keys directly, which comes with great responsibility. To avoid undermining established security controls put in place by the MetaMask team, the snap would have to replicate the same security functionality not to degrade the security posture of MetaMask altogether.",
        "For reference, please take a look at issue 4.4, issue 4.1 , issue 4.9 ."
    ],
    "Recommendation": [
        "We recommend using the Metamask provider exposed via the endowment:ethereum-provider RPC endpoint to perform Ethereum operations instead of managing the Ethereum keys and low-level operations directly. This avoids bypassing MetaMask security controls but falling back to proven and battle-tested user confirmation dialogs instead.",
        "Moreover, we also asked the MM team to provide a more robust account management API that is not based on giving full low-level account access to Snaps. This would enable Snaps to perform signing operations with control over cryptographic parameters (e.g., BIP-44 derivation path) without accessing the root entropy. This will significantly decrease the risks for the end-user."
    ]
}
----End JSON----

https://solodit.xyz/issues/superfluous-permission-endowmentnetwork-access-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\"endowment:network-access\": {},\n\n"
    ],
    "Description": [
        "The snap requests permission endowment:network-access to interact with external entities over HTTP/fetch. While the sandbox/demo dapp may use the fetch API in its context as a web app, the requested permission is only relevant for the snap and the snap never calls the fetch() API. Hence, the permission is requested but never used.",
        "Requesting more permissions than necessary should always be avoided following the principle of least privilege."
    ],
    "Examples": [
        "packages/snap/snap.manifest.json:L69"
    ],
    "Recommendation": [
        "Remove superfluous permissions."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-eth_getaddress-undermines-metamask-security-features-by-exposing-all-accounts-wo-explicit-user-consent-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "await window.ethereum.request({ method: 'eth\\_requestAccounts' })\n['0x3d0c4e58b3ff2516455f79c1147eb95f125d56ae']\n\n",
        "await window.ethereum.request({ method: 'eth\\_requestAccounts' })\n['0x3d0c4e58b3ff2516455f79c1147eb95f125d56ae']\n\n",
        "await window.ethereum.request({\n method: 'wallet\\_invokeSnap',\n params: {\n snapId: \"local:http://localhost:9000\",\n request: { method: 'eth\\_getAddress', params: {addressParams:{addressNList: [0x80000000 + 44, 0x80000000 + 60, 0x80000000 + 0, 0, 0]}, snapId: \"local:http://localhost:9000\" }},\n }});\n'0x3D0C4e58b3fF2516455f79c1147eB95F125d56aE'\n\n",
        "await window.ethereum.request({\n method: 'wallet\\_invokeSnap',\n params: {\n snapId: \"local:http://localhost:9000\",\n request: { method: 'eth\\_getAddress', params: {addressParams:{addressNList: [0x80000000 + 44, 0x80000000 + 60, 0x80000000 + 0, 0, 1]}, snapId: \"local:http://localhost:9000\" }},\n }});\n'0xBaB66CfA59757200c90c79BC6e2aEe4bFBe382Be'\n\n"
    ],
    "Description": [
        "Metamask by default protects wallet addresses from being exposed to connected websites. A user wishing to expose a wallet address to a dapp must explicitly connect that address with the dapp website. Here is an example of MetaMask Flask with a random test wallet managing 2 accounts. Account 1 is connected to metamask, test2 is not.",
        "\nThe dapp can query for connected addresses via the MetaMask injected provider RPC method eth_requestAccounts. Other non-connected addresses will not be returned:",
        "In contrast, the shapeshift snap requests low-level access for the ethereum root key. The snap exposes a similar RPC endpoint named eth_getAddress that returns all ethereum addresses. Any connected dapp can query the snap to retrieve ethereum addresses. The dapp - not necessarily trusted - can even silently interact with the snap to enumerate all ethereum addresses, whether they\u2019re \u2018connected\u2019 to the dapp or not. This effectively bypasses MetaMask security measures where the user defines the addresses to expose.",
        "Via the ShapeShift snap eth_getAddress RPC endpoint, the dapp can effectively enumerate all addresses even though they\u2019re not connected via the main wallet. This circumvents MetaMask security measures undermining established security principles of the wallet.",
        "Note that all *_getAddress RPC endpoints exhibit this problem."
    ],
    "Examples": [],
    "Recommendation": [
        "Ensure that the implemented security measures match those of the main wallet. Allow users to choose which addresses they want to expose to the dapp. Do not give low-level access to all wallet addresses without user consent."
    ]
}
----End JSON----

https://solodit.xyz/issues/signing-request-fails-to-display-origin-and-user-account-on-confirmation-message-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "The signing request message does not display the user account used to sign the message. A malicious dapp may pretend to sign a message with one account while issuing an RPC call for a different account.",
        "ShapeShift snap signing requests should implement similar security measures to how MetaMask signing requests work. Being fully transparent on \u201cwho signs what\u201d, and displaying the origin of the request. This is especially important on multi-dapp snaps to avoid users being tricked into signing transactions they did not intend to sign (wrong signer; dapp race condition).",
        "Please note that we have also reported to the MM Snaps team that dialogs do not, by default, hint at the origin of the action. We hope this will be addressed commonly for all snaps in the future."
    ],
    "Recommendation": [
        "Display the signing account in a human-readable and expected format on the signing request. Also, display the origin of the RPC call."
    ]
}
----End JSON----

https://solodit.xyz/issues/control-character-and-markdown-injection-in-snap_dialog-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "await window.ethereum.request({\n method: 'wallet\\_invokeSnap',\n params: {\n snapId: \"local:http://localhost:9000\",\n request: { method: 'binance\\_signTransaction', params: {transaction:{\"hi \\*\\*bold\\*\\*\\n\\nnextline \\*\\*test\\*\\*\":1}}},\n }});\n\n",
        "export const userConfirm = async (params: userConfirmParam): Promise<boolean> => {\n try {\n /\\* eslint-disable-next-line no-undef \\*/\n const ret = await snap.request({\n method: 'snap\\_dialog',\n params: {\n type: 'confirmation',\n content: panel([\n heading(`${params.prompt}: ${params.description}`),\n text(params.textAreaContent),\n ]),\n },\n })\n if (!ret) {\n return false\n }\n } catch (error) {\n moduleLogger.error(error, { fn: 'userConfirm' }, 'Could not display confirmation dialog')\n return false\n }\n return true\n}\n\n",
        "protected async confirmTransaction(transaction: any): Promise<boolean> {\n return await userConfirm({\n prompt: `Sign ${this.coin} Transaction?`,\n description: 'Please verify the transaction data below',\n textAreaContent: JSON.stringify(transaction, null, 2),\n })\n}\n\n",
        "/\\*\\*\n \\* TODO: This is a snap-native call - a handler must be added to the snap onRpcRequest() method to support this.\n \\*/\nexport const snapDialog = async ({\n prompt,\n description,\n textAreaContent,\n}: {\n prompt: string\n description: string\n textAreaContent: string\n}): Promise<boolean> => {\n const provider = await getMetaMaskProvider()\n if (provider === undefined) {\n throw new Error('Could not get MetaMask provider')\n }\n if (provider.request === undefined) {\n throw new Error('MetaMask provider does not define a .request() method')\n }\n try {\n const ret = await provider.request({\n method: 'snap\\_dialog',\n params: {\n type: 'confirmation',\n content: panel([heading(`${prompt}: ${description}`), text(textAreaContent)]),\n },\n })\n\n"
    ],
    "Description": [
        "On certain occasions, the snap may need to present a dialog to the user to request confirmation for an action or data verification. This step is crucial as dapps are not always trusted, and it\u2019s essential to prevent scenarios where they can silently sign data or perform critical operations using the user\u2019s keys without explicit permission. To create custom user-facing dialogs, MetaMask provides the Snaps UI package, equipped with style-specific components. However, some of these components have been found to have unintended side-effects.",
        "For instance, the text() component can render Markdown or allow for control character injections. Specifically for the ShapeShift snap, this poses a concern because when the snap asks the user to sign structured data, that data might be mistakenly interpreted as Markdown. As a result, the user could inadvertently sign something they did not intend to sign. This means that if the message-to-be-signed contains Markdown renderable text, the displayed message for user approval will be inaccurate.",
        "In the code snippet provided below, please note that the variable params is considered potentially untrusted. It may contain Markdown renderable strings or Control Characters that can disrupt the context of the user-displayed message."
    ],
    "Examples": [
        "\npackages/snap/src/rpc/common/utils.ts:L89-L110",
        "packages/snap/src/rpc/common/BaseSigner.ts:L54-L60",
        "packages/adapter/src/metamask/metamask.ts:L114-L140",
        "Please note that we have also reported the need for plaintext UI elements to the MM Snaps team. We hope this will be addressed commonly for all snaps in the future."
    ],
    "Recommendation": [
        "Validate inputs. Encode data in a safe way to be displayed to the user. Show the original data provided within a pre-text or code block. Show derived or decoded information (token recipient) as additional information to the user."
    ]
}
----End JSON----

https://solodit.xyz/issues/lack-of-high-level-and-inline-documentation-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "The codebase currently lacks inline documentation, and the repository is missing high-level documentation explaining the Snap capabilities and features. This absence of documentation poses several concerns for future maintenance and transparency.\nWithout inline documentation, as the codebase grows, understanding the code\u2019s logic and functionality can be more challenging for developers, making maintenance and bug fixes more time-consuming and error-prone. Additionally, the absence of high-level documentation makes grasping the Snap\u2019s intended functionality and capabilities hard for end-users."
    ],
    "Recommendation": [
        "We recommend adding inline documentation throughout the codebase to facilitate comprehension of the code\u2019s behavior and contribute to its maintainability. We also recommend adding comprehensive high-level documentation in the repository, detailing the Snap\u2019s capabilities, features, and intended usage. This will offer insights to developers and end-users, promoting transparency for all parties."
    ]
}
----End JSON----

https://solodit.xyz/issues/notify-on-chain-switches-and-allow-users-to-restrict-access-to-chain-specific-functionality-and-data-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "MetaMask core is set to Ethereum as the default network. When switching to BNB or other Networks, Metamask asks the user to confirm the switch. This ensures that, at any point, the user is fully aware of the network they are currently operating on.",
        "ShapeShift Snap exports multi-chain functionality, making it available to connected dapps via the MetaMask RPC. Connected dapps can request operations on various chains without requiring the users to confirm a chain switch. This deviates from the MetaMask security principles of always keeping the user informed about chain switches. Furthermore, the user does not have fine-grained control over what chain functionality is exposed to the dapp.",
        "For example, since there is no origin check in the RPC handler onRpcRequest(), any connected dapp may access ShapeShift snap functionality. Some dapps may only require access to Avalanche or Thorchain-related functionality, while others may request access to functionality for several chains. Following the principle of least privilege, the user should be able to choose the chains dapps can access instead of granting access to every chain as soon as the dapp is connected to the snap. Indeed, this behavior poses a substantial phishing risk."
    ],
    "Recommendation": [
        "We recommend keeping an internal state of the last chain used. When a dapp requests to access functionality for a different chain, ask the user to confirm the chain switch. Give users control over what chains they want to expose to the dapp and keep a record of their choice. For example, the first time a dapp access Avalanche-specific features, the user should be able to accept or reject the dapp from accessing the network. Incorporate MetaMask\u2019s security measures without compromising or weakening them in any way."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-_signtransaction-endpoints-should-display-human-readable-transaction-data-consensys-none-metamaskpartner-snaps-shapeshift-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "The transaction signing process lacks essential information to make sense of the transaction data object. The addressNList is assumed to be a BIP-32 path without proper explanation, and the contained information is presented in a non-human-readable format. As a result, the user cannot easily identify critical information, such as the signer\u2019s address. This leads to a non-user-friendly experience, which also poses security concerns.",
        ""
    ],
    "Recommendation": [
        "Provide some means for the user to understand what they are signing. Display the signing request origin (multi-dapp usage). Additionally, show the raw data they\u2019re actually signing. Decode the BIP-32 key path to a user-readable address."
    ]
}
----End JSON----

https://solodit.xyz/issues/assetchangecomponent-displays-a-change-with-value-0-if-fiatvalue-0005-consensys-none-wallet-guard-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const fiatValue = Number(stateChange.fiatValue).toFixed(2);\n\n"
    ],
    "Description": [
        "The toFixed(2) method rounds the transaction value string to 2 decimals. For transactions with fiatValue < 0.005, the function returns 0, meaning the component will display a transaction with zero value to the user, even if the transaction has a small yet non-zero value. This is not a good idea as it might trick the user.\nIn that case, it would be better to default to the smallest value that can represented (i.e. 0.01) instead of 0.",
        "packages/snap/src/components/stateChanges/AssetChangeComponent.ts:L18"
    ],
    "Recommendation": [
        "If fiatValue < 0.005, consider displaying a value of 0.01 to the user, instead of 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/allowing-program-execution-even-after-a-failed-step-may-lead-to-unnecessary-wastage-of-gas-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "The Verifier stores the result of computations obtained in different steps of Verifier algorithm. The result is stored at a designated memory location state_success by doing bitwise & with the previous result, and if the final result at the end of all the steps comes out to be 1 or true, it verifies the proof.",
        "However, it makes no sense to continue with the rest of the operations, if any step results into a failure, as the proof verification will be failing anyways. But, it will result into wastage of more gas for the zkEVM Operator.",
        "The functions which update the state_success state are:"
    ],
    "Recommendation": [
        "It would be best to revert, the moment any step fails."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-starknet_sendtransaction-the-user-displayed-message-generated-with-getsigningtxntext-is-prone-to-markdowncontrol-chars-injection-from-contractcalldata-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export function getSigningTxnText(\n state: SnapState,\n contractAddress: string,\n contractFuncName: string,\n contractCallData: string[],\n senderAddress: string,\n maxFee: number.BigNumberish,\n network: Network,\n): string {\n // Retrieve the ERC-20 token from snap state for confirmation display purpose\n const token = getErc20Token(state, contractAddress, network.chainId);\n let tokenTransferStr = '';\n if (token && contractFuncName === 'transfer') {\n try {\n let amount = '';\n if ([3, 6, 9, 12, 15, 18].includes(token.decimals)) {\n amount = convert(contractCallData[1], -1 \\* token.decimals, 'ether');\n } else {\n amount = (Number(contractCallData[1]) \\* Math.pow(10, -1 \\* token.decimals)).toFixed(token.decimals);\n }\n tokenTransferStr = `\\n\\nSender Address: ${senderAddress}\\n\\nRecipient Address: ${contractCallData[0]}\\n\\nAmount(${token.symbol}): ${amount}`;\n } catch (err) {\n console.error(`getSigningTxnText: error found in amount conversion: ${err}`);\n }\n }\n return (\n `Contract: ${contractAddress}\\n\\nCall Data: [${contractCallData.join(', ')}]\\n\\nEstimated Gas Fee(ETH): ${convert(\n maxFee,\n 'wei',\n 'ether',\n )}\\n\\nNetwork: ${network.name}` + tokenTransferStr\n );\n}\n\n",
        "const signingTxnText = getSigningTxnText(\n state,\n contractAddress,\n contractFuncName,\n contractCallData,\n senderAddress,\n maxFee,\n network,\n);\n\nconst response = await wallet.request({\n method: 'snap\\_dialog',\n params: {\n type: DialogType.Confirmation,\n content: panel([\n heading('Do you want to sign this transaction ?'),\n text(`It will be signed with address: ${senderAddress}`),\n text(signingTxnText),\n ]),\n },\n});\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by rendering untrusted user input with the copyable UI component, preventing markdown injection. Additionally, the client provided the following statement:"
    ],
    "Description": [
        "In the code snippet below, contractCallData is potentially untrusted and may contain Markdown renderable strings or strings containing Control Characters that break the context of the message displayed to the user. This can lead to misrepresenting the transaction data to be signed, which should be avoided.",
        "packages/starknet-snap/src/utils/snapUtils.ts:L163-L195",
        "packages/starknet-snap/src/sendTransaction.ts:L60-L80",
        "Please note that we have also reported to the MM Snaps team, that dialogues do not by default hint the origin of the action. We hope this will be addressed in a common way for all snaps in the future,"
    ],
    "Recommendation": [
        "Validate inputs. Encode data in a safe way to be displayed to the user. Show the original data provided within a pre-text or code-block. Show derived or decoded information (token recipient) as additional information to the user."
    ]
}
----End JSON----

https://solodit.xyz/issues/lax-validation-usingstarknetvalidateandparseaddress-allows-short-addresses-and-does-not-verify-checksums-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "try {\n validateAndParseAddress(requestParamsObj.tokenAddress);\n} catch (err) {\n throw new Error(`The given token address is invalid: ${requestParamsObj.tokenAddress}`);\n}\ntry {\n validateAndParseAddress(requestParamsObj.userAddress);\n} catch (err) {\n throw new Error(`The given user address is invalid: ${requestParamsObj.userAddress}`);\n}\n\n",
        "export function validateAndParseAddress(address: BigNumberish): string {\n assertInRange(address, ZERO, MASK\\_251, 'Starknet Address');\n\n const result = addAddressPadding(address);\n\n if (!result.match(/^(0x)?[0-9a-fA-F]{64}$/)) {\n throw new Error('Invalid Address Format');\n }\n\n return result;\n}\n\n",
        "export function validateAndParseAddress(address: BigNumberish): string {\n assertInRange(address, ZERO, MASK\\_251, 'Starknet Address');\n\n const result = addAddressPadding(address);\n\n if (!result.match(/^(0x)?[0-9a-fA-F]{64}$/)) {\n throw new Error('Invalid Address Format');\n }\n\n return result;\n}\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by wrapping validateAndParseAddress() with an implicit length check. Additionally, the client provided the following statement:",
        "As per the client\u2019s decision, checksummed addresses are not enforced."
    ],
    "Description": [
        "Address inputs in RPC calls are validated using @starknet::validateAndParseAddress().",
        "packages/starknet-snap/src/getErc20TokenBalance.ts:L19-L28",
        "While the message validates the general structure for valid addresses, it does not strictly enforce address length and may silently add padding to the inputs before validation. This can be problematic as it may hide user input errors when a user provides an address that is too short and silently gets left-padded with zeroes. This may unintentionally cause a user to request action on the wrong address without them recognizing it.",
        "../src/utils/address.ts:L14-L24"
    ],
    "Recommendation": [
        "The exposed Snap API should strictly validate inputs. User input must be provided in a safe canonical form (exact address length, checksum) by the dapp."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-starknet_signmessage-fails-to-display-the-user-account-that-is-used-for-signing-the-message-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nconst response = await wallet.request({\n method: 'snap\\_dialog',\n params: {\n type: DialogType.Confirmation,\n content: panel([heading('Do you want to sign this message ?'), text(JSON.stringify(typedDataMessage))]),\n },\n});\nif (!response) return false;\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by displaying the signing accounts address with the dialog. All user-provided fields are copyable, preventing any markdown injection. Additionally, the client provided the following statement:",
        "We want to note that the origin of the RPC call is not visible in the dialog. However, we recommend addressing this with the MM Snap SDK by generically showing the origin of MM popups with the dialog."
    ],
    "Description": [
        "The signing request dialogue does not display the user account that is being used to sign the message. A malicious dapp may pretend to sign a message with one account while issuing an RPC call for a different account.",
        "Note that StarkNet signing requests should implement similar security measures to how MetaMask signing requests work. Being fully transparent on \u201cwho signs what\u201d, also displaying the origin of the request. This is especially important on multi-dapp snaps to avoid users being tricked into signing transactions they did not intend to sign (wrong signer).",
        "packages/starknet-snap/src/signMessage.ts:L34-L42"
    ],
    "Examples": [
        "UI does not show the signing accounts address. Hence, the user cannot be sure what account is used to sign the message.",
        ""
    ],
    "Recommendation": [
        "Show what account is requested to sign a message. Display the origin of the RPC call."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-starknet_signmessage-inconsistency-when-previewing-the-signed-message-markdown-injection-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const response = await wallet.request({\n method: 'snap\\_dialog',\n params: {\n type: DialogType.Confirmation,\n content: panel([heading('Do you want to sign this message ?'), text(JSON.stringify(typedDataMessage))]),\n },\n});\n\n",
        "{\"a \\*\\*mykey\\*\\*\":\"this should not render \\*\\*markdown\\*\\* <pre>test</pre><b>bbb</b><strong>strongstrong</strong>[visit oststrom](https://oststrom.com) \\_ital\\_\"}\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by rendering user-provided information with the copyable UI component. Additionally, the client provided the following statement:"
    ],
    "Description": [
        "The snap displays an dialogue to the user requesting them to confirm that they want to sign a message when a dapp performs a request to starkNet_signMessage. However, the MetaMask Snaps UI text() component will render Markdown. This means that the message-to-be-signed displayed to the user for approval will be inaccurate if it contains Markdown renderable text.",
        "packages/starknet-snap/src/signMessage.ts:L35-L41"
    ],
    "Examples": [
        ""
    ],
    "Recommendation": [
        "Render signed message contents in a code block or preformatted text blocks.",
        "Note: we\u2019ve also reported this to the MetaMask Snaps team to provide further guidance."
    ]
}
----End JSON----

https://solodit.xyz/issues/uialertview-unnecessary-use-of-dangerouslysetinnerhtml-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nexport function AlertView({ text, variant, ...otherProps }: Props) {\n const paragraph = useRef<HTMLParagraphElement | null>(null);\n const [isMultiline, setIsMultiline] = useState(false);\n useEffect(() => {\n if (paragraph.current) {\n const height = paragraph.current.offsetHeight;\n setIsMultiline(height > 20);\n }\n }, []);\n return (\n <Wrapper isMultiline={isMultiline} variant={variant} {...otherProps}>\n <>\n {variant === VariantOptions.SUCCESS && <LeftIcon icon={['fas', 'check-circle']} />}\n {variant === VariantOptions.INFO && <LeftIcon icon={['fas', 'info-circle']} color={theme.palette.info.dark} />}\n {variant === VariantOptions.ERROR && (\n <LeftIcon icon={['fas', 'exclamation-circle']} color={theme.palette.error.main} />\n )}\n {variant === VariantOptions.WARNING && (\n <LeftIcon icon={['fas', 'exclamation-triangle']} color={theme.palette.warning.main} />\n )}\n <Parag ref={paragraph} color={variant} dangerouslySetInnerHTML={{ \\_\\_html: text }} />\n </>\n </Wrapper>\n );\n}\n\n",
        "export const NoFlaskModalView = () => {\n return (\n <Wrapper>\n <StarknetLogo />\n <Title>You don't have the MetaMask Flask extension</Title>\n <DescriptionCentered>\n You need to install MetaMask Flask extension in order to use the StarkNet Snap.\n <br />\n <br />\n <AlertView\n text=\"Please make sure that the regular MetaMask extension is disabled or use a different browser profile\"\n variant=\"warning\"\n />\n </DescriptionCentered>\n <a href=\"https://metamask.io/flask\" target=\"\\_blank\" rel=\"noreferrer noopener\">\n <ConnectButton customIconLeft={<FlaskIcon />} onClick={() => {}}>\n Download MetaMask Flask\n </ConnectButton>\n </a>\n </Wrapper>\n );\n};\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by not using dangerouslySetInnerHTML. Additionally, the client provided the following statement:"
    ],
    "Description": [
        "AlertView is populated by setting innerHTML instead of the component\u2019s value, which would be auto-escaped. This only makes sense if the component is supposed to render HTML. However, the component is never used with HTML as input, and the attribute name text is misleading.",
        "packages/wallet-ui/src/components/ui/atom/Alert/Alert.view.tsx:L11-L36",
        "packages/wallet-ui/src/components/ui/organism/NoFlaskModal/NoFlaskModal.view.tsx:L4-L25",
        "Setting HTML from code is risky because it\u2019s easy to inadvertently expose users to a cross-site scripting (XSS) attack."
    ],
    "Recommendation": [
        "Do not use dangerouslySetInnerHTML unless there is a specific requirement that passed in HTML be rendered. If so, rename the attribute name to html instead of text to set clear expectations regarding how the input is treated. Nevertheless, since the component is not used with HTML input, we recommend removing dangerouslySetInnerHTML altogether."
    ]
}
----End JSON----

https://solodit.xyz/issues/rpc-starknet_adderc20token-should-ask-for-user-confirmation-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " validateAddErc20TokenParams(requestParamsObj, network);\n\n const erc20Token: Erc20Token = {\n address: tokenAddress,\n name: tokenName,\n symbol: tokenSymbol,\n decimals: tokenDecimals,\n chainId: network.chainId,\n };\n\n await upsertErc20Token(erc20Token, wallet, saveMutex);\n\n console.log(`addErc20Token:\\nerc20Token: ${JSON.stringify(erc20Token)}`);\n return erc20Token;\n} catch (err) {\n console.error(`Problem found: ${err}`);\n throw err;\n}\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by requesting user confirmation for adding new ERC20 Tokens. Additionally, the client provided the following statement:"
    ],
    "Description": [
        "The RPC method upserts ERC20 tokens received via RPC without asking the user for confirmation. This would allow a connected dapp to insert/change ERC20 token information anytime. This can even be more problematic when multiple dapps are connected to the StarkNet-Snap (race conditions).",
        "packages/starknet-snap/src/addErc20Token.ts:L30-L47"
    ],
    "Recommendation": [
        "Ask the user for confirmation when changing the snaps state."
    ]
}
----End JSON----

https://solodit.xyz/issues/getkeysfromaddress-possible-unchecked-null-dereference-when-looking-up-private-key-fixed-consensys-none-metamaskpartner-snaps-starknetsnap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " }\n return null;\n};\n\n",
        "const { privateKey: signerPrivateKey } = await getKeysFromAddress(keyDeriver, network, state, signerAddress);\nconst signerKeyPair = getKeyPairFromPrivateKey(signerPrivateKey);\nconst typedDataSignature = getTypedDataMessageSignature(signerKeyPair, typedDataMessage, signerAddress);\n\n",
        "const { privateKey: userPrivateKey } = await getKeysFromAddress(keyDeriver, network, state, userAddress);\n\n",
        "const { publicKey } = await getKeysFromAddress(keyDeriver, network, state, userAddress);\nuserPublicKey = publicKey;\n\n",
        "const {\n privateKey: senderPrivateKey,\n publicKey,\n addressIndex,\n} = await getKeysFromAddress(keyDeriver, network, state, senderAddress);\n\n",
        "const { privateKey: signerPrivateKey } = await getKeysFromAddress(keyDeriver, network, state, signerAddress);\nconst signerKeyPair = getKeyPairFromPrivateKey(signerPrivateKey);\n\n",
        "const { privateKey: signerPrivateKey } = await getKeysFromAddress(keyDeriver, network, state, verifySignerAddress);\n\n",
        "const { privateKey: senderPrivateKey, publicKey } = await getKeysFromAddress(\n keyDeriver,\n network,\n state,\n senderAddress,\n);\n\n"
    ],
    "Resolution": [
        "Fixed with Consensys/starknet-snap@7231bb7fa4671283b2e7b4cbf5a519d56a57697a by throwing an exception on error. Additionally, the client provided the following statement:"
    ],
    "Description": [
        "getKeysFromAddress() may return null if an invalid address was provided but most callers of the function do not check for the null condition and blindly dereference or unpack the return value causing an exception.",
        "packages/starknet-snap/src/utils/starknetUtils.ts:L453-L455"
    ],
    "Examples": [
        "packages/starknet-snap/src/signMessage.ts:L44-L46",
        "packages/starknet-snap/src/extractPrivateKey.ts:L37",
        "packages/starknet-snap/src/extractPublicKey.ts:L31-L32",
        "packages/starknet-snap/src/sendTransaction.ts:L48-L52",
        "packages/starknet-snap/src/signMessage.ts:L44-L45",
        "packages/starknet-snap/src/verifySignedMessage.ts:L38",
        "packages/starknet-snap/src/estimateFee.ts:L48-L53"
    ],
    "Recommendation": [
        "Explicitly check for the null or {} case. Consider returning {} to not allow unpacking followed by an explicit null check."
    ]
}
----End JSON----

https://solodit.xyz/issues/inconsistency-between-actual-iaccount-interface-and-published-interface-id-fixed-consensys-none-argent-account-multisig-for-starknet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "fn supports\\_interface(self: @ContractState, interface\\_id: felt252) -> bool {\n if interface\\_id == ERC165\\_IERC165\\_INTERFACE\\_ID {\n true\n } else if interface\\_id == ERC165\\_ACCOUNT\\_INTERFACE\\_ID {\n true\n } else if interface\\_id == ERC165\\_OUTSIDE\\_EXECUTION\\_INTERFACE\\_ID {\n true\n } else if interface\\_id == ERC165\\_IERC165\\_INTERFACE\\_ID\\_OLD {\n true\n } else if interface\\_id == ERC165\\_ACCOUNT\\_INTERFACE\\_ID\\_OLD\\_1 {\n true\n } else if interface\\_id == ERC165\\_ACCOUNT\\_INTERFACE\\_ID\\_OLD\\_2 {\n true\n } else {\n false\n }\n}\n\n",
        "const ERC165\\_ACCOUNT\\_INTERFACE\\_ID: felt252 =\n 0x32a450d0828523e159d5faa1f8bc3c94c05c819aeb09ec5527cd8795b5b5067;\n\n",
        " fn \\_\\_validate\\_\\_(Array<Call>) -> felt252;\n fn \\_\\_execute\\_\\_(Array<Call>) -> Array<Span<felt252>>;\n fn is\\_valid\\_signature(felt252, Array<felt252>) -> bool;\n\n",
        "// InterfaceID: 0x32a450d0828523e159d5faa1f8bc3c94c05c819aeb09ec5527cd8795b5b5067\ntrait IAccount<TContractState> {\n fn \\_\\_validate\\_\\_(ref self: TContractState, calls: Array<Call>) -> felt252;\n fn \\_\\_execute\\_\\_(ref self: TContractState, calls: Array<Call>) -> Array<Span<felt252>>;\n fn is\\_valid\\_signature(\n self: @TContractState, hash: felt252, signatures: Array<felt252>\n ) -> felt252;\n}\n\n",
        "fn is\\_valid\\_signature(\n self: @ContractState, hash: felt252, signatures: Array<felt252>\n) -> felt252 {\n if self.is\\_valid\\_span\\_signature(hash, signatures.span()) {\n ERC1271\\_VALIDATED\n } else {\n 0\n }\n}\n\n",
        "const ERC1271\\_VALIDATED: felt252 = 0x1626ba7e;\n\n"
    ],
    "Resolution": [
        "After the official end of this engagement, the community has come to the decision that is_valid_signature should return the StarkNet constant VALIDATED (which is a felt252 that represents the string 'VALID') in the affirmative case and 0 otherwise. Therefore, the interface ID to be returned is now set to be 0x2ceccef7f994940b3962a6c67e0ba4fcd37df7d131417c604f91e03caecc1cd. The Argent team has changed the implementation accordingly and provided us with the updated commit hash. We have reviewed the changes and updated the final commit hash of the report to this new version."
    ],
    "Description": [
        "As an analog to Ethereum Improvement Proposals (EIPs), there are StarkNet Improvement Proposals (SNIPs), and SNIP-5 \u2013 similar in intention and technique to ERC-165 \u2013 defines how to publish and detect what interfaces a smart contract implements. As in ERC-165, this is achieved with the help of an interface identifier.",
        "Specifically, this ID is defined as the XOR of the \u201cextended function selectors\u201d in the interface. While not going into all the details here, a function\u2019s extended selector is the starknet_keccak hash of its signature, where some special rules define how to deal with the different data types. The details can be found in the proposal. Compliant contracts implement a supports_interface function that takes a felt252 and returns true if the contract implements the interface with this ID and false otherwise. For example, argent_account.cairo defines the following supports_interface function:",
        "contracts/account/src/argent_account.cairo:L506-L522",
        "In this issue, we\u2019re interested in ERC165_ACCOUNT_INTERFACE_ID, which is defined as follows:",
        "contracts/lib/src/account.cairo:L3-L4",
        "This ID corresponds to an interface with the following function signatures:",
        "Note that is_valid_signature returns a bool. However, in the actual IAccount interface, this function returns a felt252:",
        "contracts/lib/src/account.cairo:L10-L17",
        "If we check out the implementation of is_valid_signature, we see that it returns the magic value 0x1626ba7e known from ERC-1271 if the signature is valid and 0 otherwise:",
        "contracts/account/src/argent_account.cairo:L214-L222",
        "contracts/lib/src/account.cairo:L8",
        "The ID for this interface would be 0x2ceccef7f994940b3962a6c67e0ba4fcd37df7d131417c604f91e03caecc1cd. Note that, unlike in ERC-165, in SNIP-5, the return type of a function does matter for the interface identifier. Hence, the actual IAccount interface defined and implemented and the published interface ID do not match."
    ],
    "Recommendation": [
        "At the end of this engagement, the community has not come to a decision yet whether is_valid_signature should return a bool or a felt252 (i.e., the magic value 0x1626ba7e in the affirmative case and 0 otherwise). Depending on the outcome, either the actual interface and its implementation or the published interface ID must be changed to achieve consistency between the two."
    ],
    "Remark": [
        "SNIP-5 is not very clear on how to deal with the new Cairo syntax introduced in v2.0.0 of the compiler. Specifically, with this new syntax, interface traits have a generic parameter TContractState, and all non-static functions in the interface have a first parameter self of type TContractState or @TContractState for view functions. How to deal with this parameter in the derivation of the interface identifier is not (yet) explicitly specified in the proposal, but the Argent team has assured us that the understanding in the community is to ignore this parameter for the extended function selectors and hence the interface ID."
    ]
}
----End JSON----

https://solodit.xyz/issues/wrong-id-for-outsideexecution-interface-fixed-consensys-none-argent-account-multisig-for-starknet-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// Interface ID: 0x3a8eb057036a72671e68e4bad061bbf5740d19351298b5e2960d72d76d34cb9\n// get\\_outside\\_execution\\_message\\_hash is not part of the standard interface\n#[starknet::interface]\ntrait IOutsideExecution<TContractState> {\n /// @notice This method allows anyone to submit a transaction on behalf of the account as long as they have the relevant signatures\n /// @param outside\\_execution The parameters of the transaction to execute\n /// @param signature A valid signature on the Eip712 message encoding of `outside\\_execution`\n /// @notice This method allows reentrancy. A call to `\\_\\_execute\\_\\_` or `execute\\_from\\_outside` can trigger another nested transaction to `execute\\_from\\_outside`.\n fn execute\\_from\\_outside(\n ref self: TContractState, outside\\_execution: OutsideExecution, signature: Array<felt252>\n ) -> Array<Span<felt252>>;\n\n /// Get the status of a given nonce, true if the nonce is available to use\n fn is\\_valid\\_outside\\_execution\\_nonce(self: @TContractState, nonce: felt252) -> bool;\n\n /// Get the message hash for some `OutsideExecution` following Eip712. Can be used to know what needs to be signed\n fn get\\_outside\\_execution\\_message\\_hash(\n self: @TContractState, outside\\_execution: OutsideExecution\n ) -> felt252;\n}\n\n",
        "const ERC165\\_OUTSIDE\\_EXECUTION\\_INTERFACE\\_ID: felt252 =\n 0x3a8eb057036a72671e68e4bad061bbf5740d19351298b5e2960d72d76d34cb9;\n\n",
        "starknet_keccak(\r\n    'execute_from_outside(\r\n        (ContractAddress,felt252,u64,u64,(@Array<(ContractAddress,felt252,Array<felt252>)>)),\r\n        Array<felt252>\r\n     )->Array<(@Array<felt252>)>'\r\n) = 0x3c6e798a947887809ab7c506818dac2e3632acafa20cb51d2fff56b3577dc75\n\n"
    ],
    "Description": [
        "While not standardized across the community, the Argent team has decided to isolate the \u201coutside execution\u201d functionality in a separate interface, so other teams in the ecosystem can choose to implement that interface as well.",
        "contracts/lib/src/outside_execution.cairo:L10-L29",
        "SNIP-5 \u2013 as already mentioned in issue 5.1 \u2013 is a StarkNet Improvement Proposal that describes how to publish and detect what interfaces a contract implements. To briefly summarize, the interface ID is defined as the XOR of the extended selectors of the functions in the interface, and a function\u2019s extended selector is the starknet_keccak hash of the function signature, where some special rules define how to deal with the different data types. Deriving the input for starknet_keccak can be done manually, but it is tedious, error-prone, and can even be somewhat involved, as it may require knowledge of some Cairo internals, depending on the types used in the function.",
        "When we tried to verify the ID for the OutsideExecution interface, we noticed a mismatch between the result of our own calculations and the ID the Argent team had arrived at:",
        "contracts/lib/src/outside_execution.cairo:L7-L8",
        "Together with the client, we were able to identify a mistake that was made in the manual derivation of the input to the hash function, leading to a wrong extended function selector and, therefore, an incorrect interface identifier.",
        "The correct extended function selector for execute_from_outside is:",
        "(The line breaks were only inserted for better readability in this document. The string does not contain any whitespace.)"
    ],
    "Recommendation": [
        "Together with the extended function selector for is_valid_outside_execution_nonce, 0x3ae284922d559e87220df9c5a51dae59c391ce8f3b4fabb572275e210299df4, the resulting interface ID for OutsideExecution is 0x68cfd18b92d1907b8ba3cc324900277f5a3622099431ea85dd8089255e4181, and the definition of ERC165_OUTSIDE_EXECUTION_INTERFACE_ID should be changed accordingly.",
        "Note that the Argent team has deliberately omitted get_outside_execution_message_hash from the interface (in the sense of SNIP-5)."
    ]
}
----End JSON----

https://solodit.xyz/issues/lockup-plans-are-not-well-suited-for-trading-on-traditional-otc-platforms-consensys-none-hedgey-token-lockup-and-vesting-plans-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "For most of the OTC trading platforms with RFQ style the maker or the taker creates an order that is valid for some time and is expecting a specific token ID. In case of a lockup period a trade participants can request to buy a specific plan ID and then give a fixed amount of time to fill that order, assuming that anything past that time that is unvested is guaranteed to go to them. In reality, the taker of such an order can batch two transactions in one block:",
        "People should be aware of such a possibility before attempting to purchase any lockup plans over OTC platforms."
    ],
    "Recommendation": [
        "One way to solve this is to assign both plans a new ID during the segmentation process."
    ]
}
----End JSON----

https://solodit.xyz/issues/bridge-token-would-be-locked-and-cannot-bridge-to-native-token-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (nativeMappingValue == NATIVE\\_STATUS) {\n // Token is native on the local chain\n IERC20(\\_nativeToken).safeTransfer(\\_recipient, \\_amount);\n} else {\n bridgedToken = nativeMappingValue;\n if (nativeMappingValue == EMPTY) {\n // New token\n bridgedToken = deployBridgedToken(\\_nativeToken, \\_tokenMetadata);\n bridgedToNativeToken[bridgedToken] = \\_nativeToken;\n nativeToBridgedToken[\\_nativeToken] = bridgedToken;\n }\n BridgedToken(bridgedToken).mint(\\_recipient, \\_amount);\n}\n\n",
        "function setDeployed(address[] memory \\_nativeTokens) external onlyMessagingService fromRemoteTokenBridge {\n address nativeToken;\n for (uint256 i; i < \\_nativeTokens.length; i++) {\n nativeToken = \\_nativeTokens[i];\n nativeToBridgedToken[\\_nativeTokens[i]] = DEPLOYED\\_STATUS;\n emit TokenDeployed(\\_nativeTokens[i]);\n }\n}\n\n",
        "if (nativeMappingValue == NATIVE_STATUS || nativeMappingValue == DEPLOYED_STATUS) {\r\n   IERC20(_nativeToken).safeTransfer(_recipient, _amount);\n\n"
    ],
    "Resolution": [
        "The recommendations are implemented by the Linea team in the pull request 66 with the final commit hash as 8f8ee32cf3ad24ec669b62910d3d6eb1da9cc78e"
    ],
    "Description": [
        "If the bridge token B of a native token A is already deployed and confirmDeployment is called on the other layer and setDeployed sets A\u2019s nativeToBridgedToken value to DEPLOYED_STATUS. The bridge token B cannot bridge to native token A in completeBridging function, because A\u2019s nativeToBridgedToken value is not NATIVE_STATUS, as a result the native token won\u2019t be transferred to the receiver. User\u2019s bridge token will be locked in the original layer"
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L217-L229",
        "contracts/TokenBridge.sol:L272-L279"
    ],
    "Recommendation": [
        "Add an condition nativeMappingValue = DEPLOYED_STATUS for native token transfer in confirmDeployment"
    ]
}
----End JSON----

https://solodit.xyz/issues/user-cannot-withdraw-funds-if-bridging-failed-or-delayed-wont-fix-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setCustomContract(\n address \\_nativeToken,\n address \\_targetContract\n) external onlyOwner isNewToken(\\_nativeToken) {\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\n}\n\n"
    ],
    "Description": [
        "If the bridging failed due to the single coordinator is down, censoring the message, or bridge token contract is set to a bad or wrong contract address by setCustomContract, user\u2019s funds will stuck in the TokenBridge contract until coordinator is online or stop censoring, there is no way to withdraw the deposited funds"
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L341-L348"
    ],
    "Recommendation": [
        "Add withdraw functionality to let user withdraw the funds under above circumstances or at least add withdraw functionality for Admin (admin can send the funds to the user manually), ultimately decentralize coordinator and sequencer to reduce bridging failure risk."
    ]
}
----End JSON----

https://solodit.xyz/issues/bridges-dont-support-multiple-native-tokens-which-may-lead-to-incorrect-bridging-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  mapping(address => address) public nativeToBridgedToken;\r\n  mapping(address => address) public bridgedToNativeToken;\n\n",
        "function completeBridging(\n address \\_nativeToken,\n uint256 \\_amount,\n address \\_recipient,\n bytes calldata \\_tokenMetadata\n) external onlyMessagingService fromRemoteTokenBridge {\n address nativeMappingValue = nativeToBridgedToken[\\_nativeToken];\n address bridgedToken;\n\n if (nativeMappingValue == NATIVE\\_STATUS) {\n // Token is native on the local chain\n IERC20(\\_nativeToken).safeTransfer(\\_recipient, \\_amount);\n } else {\n\n"
    ],
    "Resolution": [
        "The recommendations are implemented by the Linea team in the pull request 65 with the final commit hash as 27c2e53c8da206d1d2e06abbdadee1e728219763.\nThe Bridges now support only one native token and revert, if attempted to bridge a native token with the same address on the other layer. The team mentions the reason for choosing this design is to support their specific use case, and for the cases where the users want to have same native tokens on both the layers, third-party liquidity bridges would be a better option.",
        "Note:- Although, the introduced check adds a scenario, where if the owner adds a bridge for a native token on the source layer via setCustomContract , the protocol will disallow any bridging from it. However, after having a discussion, the team concluded that the function setCustomContract  is intended to be called on the destination layer and the team will take the necessary precautions while dealing with it.",
        "Update: A related issue 4.7 with a similar root cause has also been identified and addressed with a fix that also correct this issue."
    ],
    "Description": [
        "Currently, the system design does not support the scenarios where native tokens with the same addresses (which is possible with the same deployer and nonce) on different layers can be bridged.",
        "For instance,\nLet\u2019s consider, there is a native token A on L1 which has already been bridged on L2. If anyone tries to bridge native token B on L2 with the same address as token A , instead of creating a new bridge on L1 and minting new tokens, the token bridge will transfer native token A on L1 to the _recipient which is incorrect.",
        "The reason is the mappings don\u2019t differentiate between the native tokens on two different Layers."
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L208-L220"
    ],
    "Recommendation": [
        "Redesign the approach to handle the same native tokens on different layers. One possible approach could be to define the set of mappings for each layer."
    ]
}
----End JSON----

https://solodit.xyz/issues/no-check-for-initializing-parameters-of-tokenbridge-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize(\n address \\_securityCouncil,\n address \\_messageService,\n address \\_tokenBeacon,\n address[] calldata \\_reservedTokens\n) external initializer {\n \\_\\_Pausable\\_init();\n \\_\\_Ownable\\_init();\n setMessageService(\\_messageService);\n tokenBeacon = \\_tokenBeacon;\n for (uint256 i = 0; i < \\_reservedTokens.length; i++) {\n setReserved(\\_reservedTokens[i]);\n }\n \\_transferOwnership(\\_securityCouncil);\n}\n\n"
    ],
    "Resolution": [
        "The recommendations are implemented by the Linea team in the pull request 68 with the final commit hash as 7a3764b461b70f3b06aa77b859349be7a918ac1d"
    ],
    "Description": [
        "In TokenBridge contract\u2019s initialize function, there is no check for initializing parameters including _securityCouncil, _messageService, _tokenBeacon and _reservedTokens. If any of these address is set to 0 or other invalid value, TokenBridge would not work, user may lose funds."
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L97-L111"
    ],
    "Recommendation": [
        "Add non-zero address check for _securityCouncil, _messageService, _tokenBeacon and _reservedTokens"
    ]
}
----End JSON----

https://solodit.xyz/issues/owner-can-update-arbitrary-status-for-new-native-token-without-confirmation-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setCustomContract(\n address \\_nativeToken,\n address \\_targetContract\n) external onlyOwner isNewToken(\\_nativeToken) {\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\n}\n\n"
    ],
    "Resolution": [
        "The recommendations are implemented by the Linea team in the pull request 67 with the final commit hash as e096523ec3fc34996a30fd517d6e97cfef3bcf8d.\nThe function now reverts, if the _targetContract  supplied is any of the reserved status codes."
    ],
    "Description": [
        "The function setCustomContract allows the owner to update arbitrary status for new native tokens without confirmation, bypassing the bridge protocol."
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L341-L348"
    ],
    "Recommendation": [
        "The function should not allow _targetContract to be any state code"
    ]
}
----End JSON----

https://solodit.xyz/issues/owner-may-exploit-bridged-tokens-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setCustomContract(\n address \\_nativeToken,\n address \\_targetContract\n) external onlyOwner isNewToken(\\_nativeToken) {\n nativeToBridgedToken[\\_nativeToken] = \\_targetContract;\n bridgedToNativeToken[\\_targetContract] = \\_nativeToken;\n emit CustomContractSet(\\_nativeToken, \\_targetContract);\n}\n\n",
        "} else {\n bridgedToken = nativeMappingValue;\n if (nativeMappingValue == EMPTY) {\n // New token\n bridgedToken = deployBridgedToken(\\_nativeToken, \\_tokenMetadata);\n bridgedToNativeToken[bridgedToken] = \\_nativeToken;\n nativeToBridgedToken[\\_nativeToken] = bridgedToken;\n }\n BridgedToken(bridgedToken).mint(\\_recipient, \\_amount);\n}\n\n"
    ],
    "Resolution": [
        "The recommendations are implemented by the Linea team in the pull request 67 with the final commit hash as e096523ec3fc34996a30fd517d6e97cfef3bcf8d.\nThe function now reverts, if the _targetContract  supplied has already been defined as a bridge to a native token."
    ],
    "Description": [
        "The function setCustomContract allows the owner, to define a custom ERC20 contract for the native token. However, it doesn\u2019t check whether the target contract has already been defined as a bridge to a native token or not. As a result, the owner\nmay take advantage of the design flaw and bridge another new native token that has not been bridged yet, to an already existing target(already a bridge for another native token).\nNow, if a user tries to bridge this native token, the token bridge on the source chain will take the user\u2019s tokens, and instead of deploying a new bridge on the destination chain, tokens will be minted to the _recipient on an existing bridge defined by the owner, or it can be any random EOA address to create a DoS.",
        "The owner can also try to front-run calls to completeBridging for new Native Tokens on the destination chain, by setting a different bridge via setCustomContract. Although, the team states that the role will be controlled by a multi-sig which makes frontrunning less likely to happen."
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L341-L348",
        "contracts/TokenBridge.sol:L220-L229"
    ],
    "Recommendation": [
        "Make sure, a native token should bridge to a single target contract. A possible approach could be to check whether the bridgedToNativeToken for a target is EMPTY or not. If it\u2019s not EMPTY, it means it\u2019s already a bridge for a native token and the function should revert. The same can be achieved by adding the modifier isNewToken(_targetContract).",
        "Note:- However, it doesn\u2019t resolve the issue of frontrunning, even if the likelihood is less."
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-bridging-due-to-address-collision-inconsistent-state-of-native-tokens-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    if (nativeMappingValue == NATIVE_STATUS || nativeMappingValue == DEPLOYED_STATUS) {\r\n      // Token is native on the local chain\r\n      IERC20Upgradeable(_nativeToken).safeTransfer(_recipient, _amount);\n\n",
        "    messageService.sendMessage{ value: msg.value }(\r\n      remoteSender,\r\n      msg.value, // fees\r\n      abi.encodeCall(ITokenBridge.completeBridging, (nativeToken, _amount, _recipient, _isNativeLayer, tokenMetadata))\r\n    );\n\n",
        "...\r\n    if (_isNativeLayer == false && (nativeMappingValue == NATIVE_STATUS || nativeMappingValue == DEPLOYED_STATUS)) {\r\n      // Token is native on the local chain\r\n      IERC20Upgradeable(_nativeToken).safeTransfer(_recipient, _amount);\r\n    }\r\n    else{\r\n    ...\r\n          if (\r\n        nativeMappingValue == EMPTY ||\r\n        (_isNativeLayer && (nativeMappingValue == NATIVE_STATUS || nativeMappingValue == DEPLOYED_STATUS))\r\n      ) {\r\n              // New token\r\n        bridgedToken = deployBridgedToken(_nativeToken, _tokenMetadata);\r\n        bridgedToNativeToken[bridgedToken] = _nativeToken;\r\n        nativeToBridgedToken[_nativeToken] = bridgedToken;\r\n      }\r\n      BridgedToken(bridgedToken).mint(_recipient, _amount);\r\n      ...\r\n    }\r\n   \n\n",
        "      BridgedToken(bridgedToken).mint(_recipient, _amount);\n\n"
    ],
    "Resolution": [
        "The Linea team has proposed another PR to fix the issues associated with token address collision during bridging. Namely, the chain ID associated with the token\u2019s native chain is now introduced as a key to the token address mapping, and the chain ID is added to the salt when deploying bridged token contracts, ensuring uniqueness. Consequently, this PR addresses the raised concerns though introduction of a more complex state to the bridge contract may raise the difficulty of upgrading the contract, thus redeployments are recommended in future for any changes."
    ],
    "Description": [
        "In the second round of the audit, we discovered an edge case that may exist because of an address collision of native tokens. In the first round, we found issue 4.3 explaining how the bridges only support a single native token on both layers and may cause incorrect bridging. In response to that, the Linea team implemented a change that reverts whenever there is an attempt to bridge a native token with the same address on the other layer.",
        "However, the issue still exists because of the inconsistent state of native tokens while bridging. The reason is, there could be an attempt to bridge a token with the same address on both layers at the same time, which could be done deliberately by an attacker by monitoring the bridging call at source layer and frontrunning them on the destination layer. As a consequence, both the tokens will get the NATIVE_STATUS on both layers, as the bridges can\u2019t check the state of a token on the other layer while bridging. Now, the bridging that was initiated for a native token on the source layer will be completed with the native token on the destination layer, as the bridging was initiated at the same time.",
        "For the issue, the Linea team came back with the solution in the PR 1041 with the final commit a875e67e0681ce387825127a08f1f924991a274c. The solution implemented adds a flag _isNativeLayer while sending the message to Message Service on source layer",
        "and is used to verify the state of native token on destination layer while calling completeBridging.",
        "The logic adds two conditional checks:\n1- If _isNativeLayer  is false, it means the token is not native on the source layer, and if for the same address the status is either Native or Deployed, then the native token of the destination layer should be bridged.\n2- If the flag is true, it means the token is native on the source layer, and if there exists a collision of the Native or Deployed status, then a new bridge token should be created.",
        "Minting Bad Tokens\nWe reviewed the PR and new integrations and found that it is still problematic. The reason is the bridging of a token with the same address, will create a bridgedToken on each layer. Now the nativeToBridgedToken status is no more Native or Deployed, but a bridge address.\nLet\u2019s call the native token A and bridgedToken be B and C on each layer respectively. Now if the bridgeToken B is tried to be bridged back to native token A, it\u2019ll be not possible, as while doing completeBridging both of the conditional checks will be unsatisfied. However, in any case, the bridge on the destination layer will still mint the bridgedTokens",
        "As an example, the B tokens can be bridged to mint C bridgedTokens and vice-versa as and when needed. So, now it is mandatory to call confirmDeployment in order to allow condition 1 to be satisfied for this bridging and avoid this kind of bad minting."
    ]
}
----End JSON----

https://solodit.xyz/issues/updating-message-service-does-not-emit-event-fixed-consensys-none-linea-canonical-token-bridge-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setMessageService(address \\_messageService) public onlyOwner {\n messageService = IMessageService(\\_messageService);\n}\n\n"
    ],
    "Resolution": [
        "The recommendations are implemented by the Linea team in the pull request 69 with the final commit hash as 1fdd5cfc51c421ad9aaf8b2fd2b3e2ed86ffa898"
    ],
    "Description": [
        "The function setMessageService allows the owner to update the message service address. However, it does not emit any event reflecting the change. As a result, in case the owner gets compromised, it can silently add a malicious message service, exploiting users\u2019 funds. Since, there was no event emitted, off-chain monitoring tools wouldn\u2019t be able to trigger alarms and users would continue using rogue message service until and unless tracked manually."
    ],
    "Examples": [
        "contracts/TokenBridge.sol:L237-L240"
    ],
    "Recommendation": [
        "Consider emitting an event reflecting the update from the old message service to the new one."
    ]
}
----End JSON----

https://solodit.xyz/issues/heavy-blocks-may-affect-block-finalization-if-the-gas-requirement-exceeds-block-gas-limit-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function finalizeBlocks(\n BlockData[] calldata \\_blocksData,\n bytes calldata \\_proof,\n uint256 \\_proofType,\n bytes32 \\_parentStateRootHash\n)\n\n"
    ],
    "Description": [
        "The sequencer takes care of finalizing blocks by submitting proof, blocks\u2019 data, proof type, and parent state root hash. The team mentions that the blocks are finalized every 12s, and under general scenarios, the system will work fine. However, in cases where there are blocks containing lots of transactions and event logs, the function may require gas more than the block gas limit. As a consequence, it may affect block finalization or lead to a potential DoS."
    ],
    "Examples": [
        "contracts/contracts/ZkEvmV2.sol:L110-L115"
    ],
    "Recommendation": [
        "We advise the team to benchmark the cost associated per block for the finalization and how many blocks can be finalized in one rollup and add the limits accordingly for the prover/sequencer."
    ]
}
----End JSON----

https://solodit.xyz/issues/postman-can-incorrectly-deliver-a-message-while-still-collecting-the-fees-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\nif (!success) {\n if (returnData.length > 0) {\n assembly {\n let data\\_size := mload(returnData)\n revert(add(32, returnData), data\\_size)\n }\n } else {\n revert MessageSendingFailed(\\_to);\n }\n}\n\n",
        "(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\nif (!success) {\n if (returnData.length > 0) {\n assembly {\n let data\\_size := mload(returnData)\n revert(add(32, returnData), data\\_size)\n }\n } else {\n revert MessageSendingFailed(\\_to);\n }\n}\n\n"
    ],
    "Description": [
        "The message service allows cross chain message delivery, where the user can define the parameters of the message as:",
        "from: Sender of the message\n_to: Receiver of the message\n_fee: The fees, the sender wants to pay to the postman to deliver the message\nvalueSent: The value in the native currency of the chain to be sent with the message\nmessageNumber: Nonce value which increments for every message\n_calldata: Calldata for the message to be executed on the destination chain",
        "The postman estimates the gas before claiming/delivering the message on the destination chain, thus avoiding scenarios where the fees sent are less than the cost of claiming the message.",
        "However, there is nothing that restricts the postman from sending the gas equal to the fees paid by the user. Although it contributes to the MEV, where the postman can select the messages with higher fees first and deliver them prior to others, it also opens up an opportunity where the postman can deliver a message incorrectly while still claiming the fees.",
        "One such scenario is, where the low-level call to target _to makes another sub-call to another address, let\u2019s say x. Let\u2019s assume, the _to address doesn\u2019t check, whether the call to address x was successful or not. Now, if the postman supplies a gas, which makes the top-level call succeed, but the low-level call to x fails silently, the postman will still be retrieving the fees of claiming the message, even though the message was not correctly delivered."
    ],
    "Examples": [
        "contracts/contracts/messageService/l1/L1MessageService.sol:L125-L135",
        "contracts/contracts/messageService/l2/L2MessageService.sol:L150-L160"
    ],
    "Recommendation": [
        "Another parameter can be added to the message construct giving the user the option to define the amount of gas required to complete a transaction entirely. Also, a check can be added while claiming the message, to make sure the gas supplied by the postman is sufficient enough compared to the gas defined/demanded by the user. The cases, where the user can demand a huge amount of gas, can be simply avoided by doing the gas estimation, and if the demanded gas is more than the supplied fees, the postman will simply opt not to deliver the message"
    ]
}
----End JSON----

https://solodit.xyz/issues/users-funds-would-stuck-if-the-message-claim-failed-on-the-destination-layer-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 messageNumber = nextMessageNumber;\nuint256 valueSent = msg.value - \\_fee;\n\nbytes32 messageHash = keccak256(abi.encode(msg.sender, \\_to, \\_fee, valueSent, messageNumber, \\_calldata));\n\n",
        "(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\nif (!success) {\n if (returnData.length > 0) {\n assembly {\n let data\\_size := mload(returnData)\n revert(add(32, returnData), data\\_size)\n }\n } else {\n revert MessageSendingFailed(\\_to);\n }\n}\n\n",
        "(bool success, bytes memory returnData) = \\_to.call{ value: \\_value }(\\_calldata);\nif (!success) {\n if (returnData.length > 0) {\n assembly {\n let data\\_size := mload(returnData)\n revert(add(32, returnData), data\\_size)\n }\n } else {\n revert MessageSendingFailed(\\_to);\n }\n}\n\n"
    ],
    "Description": [
        "When claiming the message on the destination layer, if the message failed to execute with various reasons (e.g. wrong target contract address, wrong contract logic, out of gas, malicious contract), the Ether sent with sendMessage on the original layer will be stuck, although the message can be retried later by the Postman or the user (could fail again)"
    ],
    "Examples": [
        "contracts/contracts/messageService/l1/L1MessageService.sol:L81-L84",
        "contracts/contracts/messageService/l2/L2MessageService.sol:L150-L160",
        "contracts/contracts/messageService/l1/L1MessageService.sol:L125-L135"
    ],
    "Recommendation": [
        "Add refund mechanism to refund users funds if the message failed to deliver on the destination layer"
    ]
}
----End JSON----

https://solodit.xyz/issues/front-running-finalizeblocks-when-sequencers-are-decentralized-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function finalizeBlocks(\n BlockData[] calldata \\_blocksData,\n bytes calldata \\_proof,\n uint256 \\_proofType,\n bytes32 \\_parentStateRootHash\n)\n external\n whenTypeNotPaused(PROVING\\_SYSTEM\\_PAUSE\\_TYPE)\n whenTypeNotPaused(GENERAL\\_PAUSE\\_TYPE)\n onlyRole(OPERATOR\\_ROLE)\n{\n if (stateRootHashes[currentL2BlockNumber] != \\_parentStateRootHash) {\n revert StartingRootHashDoesNotMatch();\n }\n\n \\_finalizeBlocks(\\_blocksData, \\_proof, \\_proofType, \\_parentStateRootHash, true);\n}\n\n",
        "function _finalizeBlocks(\r\n   BlockData[] calldata _blocksData,\r\n   bytes memory _proof,\r\n   uint256 _proofType,\r\n   bytes32 _parentStateRootHash,\r\n   bool _shouldProve,\r\n   address _sequencer\r\n )\n\n",
        "_verifyProof(\r\n        uint256(\r\n          keccak256(\r\n            abi.encode(\r\n              keccak256(abi.encodePacked(blockHashes)),\r\n              firstBlockNumber,\r\n              keccak256(abi.encodePacked(timestampHashes)),\r\n              keccak256(abi.encodePacked(hashOfRootHashes)),\r\n              keccak256(abi.encodePacked(_sequencer)\r\n            )\r\n          )\r\n        ) % MODULO_R,\r\n        _proofType,\r\n        _proof,\r\n        _parentStateRootHash\r\n      );\n\n"
    ],
    "Description": [
        "When sequencer is decentralized in the future, one sequencer could front run another sequencer\u2019s finalizeBlocks transaction, without doing the actual proving and sequencing, and steal the reward for sequencing if there is one. Once the frontrunner\u2019s finalizeBlocks is executed, the original sequencer\u2019s transaction would fail as currentL2BlockNumber would increment by one and state root hash won\u2019t match, as a result the original sequencer\u2019s sequencing and proving work will be wasted."
    ],
    "Examples": [
        "contracts/contracts/ZkEvmV2.sol:L110-L126"
    ],
    "Recommendation": [
        "Add the sequencer\u2019s address as one parameters in _finalizeBlocks function, and include the sequencer\u2019s address in the public input hash of the proof in verification function _verifyProof."
    ]
}
----End JSON----

https://solodit.xyz/issues/user-funds-would-stuck-if-the-single-coordinator-is-offline-or-censoring-messages-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 messageNumber = nextMessageNumber;\nuint256 valueSent = msg.value - \\_fee;\n\nbytes32 messageHash = keccak256(abi.encode(msg.sender, \\_to, \\_fee, valueSent, messageNumber, \\_calldata));\n\n",
        "function addL1L2MessageHashes(bytes32[] calldata \\_messageHashes) external onlyRole(L1\\_L2\\_MESSAGE\\_SETTER\\_ROLE) {\n uint256 messageHashesLength = \\_messageHashes.length;\n\n if (messageHashesLength > 100) {\n revert MessageHashesListLengthHigherThanOneHundred(messageHashesLength);\n }\n\n for (uint256 i; i < messageHashesLength; ) {\n bytes32 messageHash = \\_messageHashes[i];\n if (inboxL1L2MessageStatus[messageHash] == INBOX\\_STATUS\\_UNKNOWN) {\n inboxL1L2MessageStatus[messageHash] = INBOX\\_STATUS\\_RECEIVED;\n }\n unchecked {\n i++;\n }\n }\n\n emit L1L2MessageHashesAddedToInbox(\\_messageHashes);\n}\n\n"
    ],
    "Description": [
        "When user sends message from L1 to L2, the coordinator needs to post the messages to L2, this happens in the anchoring message(addL1L2MessageHashes) on L2, then the user or Postman can claim the message on L2.\nsince there is only a single coordinator, if the coordinator is down or censoring messages sent from L1 to L2, users funds can stuck in L1, until the coordinator come back online or stops censoring the message, as there is no message cancel feature or message expire feature. Although the operator can pause message sending on L1 once the coordinator is down, but if the message is sent and not posted to L2 before the pause it will still stuck."
    ],
    "Examples": [
        "contracts/contracts/messageService/l1/L1MessageService.sol:L81-L84",
        "contracts/contracts/messageService/l2/L2MessageManager.sol:L42-L60"
    ],
    "Recommendation": [
        "Decentralize coordinator and sequencer or enable user cancel or drop the message if message deadline has expired."
    ]
}
----End JSON----

https://solodit.xyz/issues/changing-verifier-address-doesnt-emit-event-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setVerifierAddress(address \\_newVerifierAddress, uint256 \\_proofType) external onlyRole(DEFAULT\\_ADMIN\\_ROLE) {\n if (\\_newVerifierAddress == address(0)) {\n revert ZeroAddressNotAllowed();\n }\n verifiers[\\_proofType] = \\_newVerifierAddress;\n}\n\n"
    ],
    "Description": [
        "In function setVerifierAddress, after the verifier address is changed, there is no event emitted, which means if the operator (security council) changes the verifier to a buggy verifier, or if the security council is compromised, the attacker can change the verifier to a malicious one, the unsuspecting user would still use the service, potentially lose funds due to the fraud transactions would be verified."
    ],
    "Examples": [
        "contracts/contracts/ZkEvmV2.sol:L83-L88"
    ],
    "Recommendation": [
        "Emits event after changing verifier address including old verifier address, new verifier address and the caller account"
    ]
}
----End JSON----

https://solodit.xyz/issues/l2-blocks-with-incorrect-timestamp-could-be-finalized-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (blockInfo.l2BlockTimestamp >= block.timestamp) {\n revert BlockTimestampError();\n}\n\n"
    ],
    "Description": [
        "In _finalizeBlocks of ZkEvmV2, the current block timestamp blockInfo.l2BlockTimestamp should be greater or equal than the last L2 block timestamp and less or equal than the L1 block timestamp when _finalizeBlocks is executed. However the first check is missing, blocks with incorrect timestamp could be finalized, causing unintended system behavior"
    ],
    "Examples": [
        "contracts/contracts/ZkEvmV2.sol:L158-L160"
    ],
    "Recommendation": [
        "Add the missing timestamp check"
    ]
}
----End JSON----

https://solodit.xyz/issues/rate-limiting-affecting-the-usability-and-users-funds-safety-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_addUsedAmount(\\_fee + \\_value);\n\n",
        "\\_addUsedAmount(msg.value);\n\n",
        "function \\_addUsedAmount(uint256 \\_usedAmount) internal {\n uint256 currentPeriodAmountTemp;\n\n if (currentPeriodEnd < block.timestamp) {\n // Update period before proceeding\n currentPeriodEnd = block.timestamp + periodInSeconds;\n currentPeriodAmountTemp = \\_usedAmount;\n } else {\n currentPeriodAmountTemp = currentPeriodAmountInWei + \\_usedAmount;\n }\n\n if (currentPeriodAmountTemp > limitInWei) {\n revert RateLimitExceeded();\n }\n\n currentPeriodAmountInWei = currentPeriodAmountTemp;\n}\n\n"
    ],
    "Description": [
        "In claimMessage of L1MessageService and sendMessage function of L1MessageService contract, function _addUsedAmount is used to rate limit the Ether amount (1000 Eth) sent from L2 to L1 in a time period (24 hours), this is problematic, usually user sends the funds to L1 when they need to exit from L2 to L1 especially when some security issues happened affecting their funds safety on L2, if there is a limit, the limit can be reached quickly by some whale sending large amount of Ether to L1, while other users cannot withdraw their funds to L1, putting their funds at risk. In addition, the limit can only be set and changed by the security council and security council can also pause message service at any time, blocking user withdraw funds from L2, this makes the L2->L1 message service more centralized."
    ],
    "Examples": [
        "contracts/contracts/messageService/l1/L1MessageService.sol:L121",
        "contracts/contracts/messageService/l2/L2MessageService.sol:L108",
        "contracts/contracts/messageService/lib/RateLimiter.sol:L53-L69"
    ],
    "Recommendation": [
        "Remove rate limiting for L2->L1 message service"
    ]
}
----End JSON----

https://solodit.xyz/issues/front-running-claimmessage-on-l1-and-l2-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\\_fee > 0) {\n address feeReceiver = \\_feeRecipient == address(0) ? msg.sender : \\_feeRecipient;\n (bool feePaymentSuccess, ) = feeReceiver.call{ value: \\_fee }(\"\");\n if (!feePaymentSuccess) {\n revert FeePaymentFailed(feeReceiver);\n }\n\n",
        "if (\\_fee > 0) {\n address feeReceiver = \\_feeRecipient == address(0) ? msg.sender : \\_feeRecipient;\n (bool feePaymentSuccess, ) = feeReceiver.call{ value: \\_fee }(\"\");\n if (!feePaymentSuccess) {\n revert FeePaymentFailed(feeReceiver);\n }\n}\n\n"
    ],
    "Description": [
        "The front-runner on L1 or L2 can front run the claimMessage transaction, as long as the fee is greater than the gas cost of the claiming the message and feeRecipient is not set, consequently the fee will be transferred to the message.sender(the front runner) once the message is claimed. As a result, postman would lose the incentive to deliver(claim) the message on the destination layer."
    ],
    "Examples": [
        "contracts/contracts/messageService/l1/L1MessageService.sol:L137-L142",
        "contracts/contracts/messageService/l2/L2MessageService.sol:L162-L168"
    ],
    "Recommendation": [
        "There are a few protections against front running including flashbots service. Another option to mitigate front running is to avoid using msg.sender and have user use the signed claimMessage transaction by the Postman to claim the message on the destination layer"
    ]
}
----End JSON----

https://solodit.xyz/issues/contracts-not-well-designed-for-upgrades-consensys-none-linea-message-service-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256[10] private \\_gap;\n\n",
        "uint256[10] private \\_gap;\n\n",
        "uint256[10] private \\_\\_base\\_gap;\n\n",
        "uint256[50] private \\_\\_gap\\_L2MessageService;\n\n",
        "function \\_\\_RateLimiter\\_init(uint256 \\_periodInSeconds, uint256 \\_limitInWei) internal {\n\n",
        "function \\_init\\_MessageServiceBase(address \\_messageService, address \\_remoteSender) internal {\n\n"
    ],
    "Description": [
        "The Contracts introduce some buffer space in the storage layout to cope with the scenarios where new storage variables can be added if a need exists to upgrade the contracts to a newer version. This helps in reducing the chances of potential storage collisions.\nHowever, the storage layout concerning the buffer space is inconsistent, and multiple variations have been observed.",
        "contracts/contracts/messageService/lib/PauseManager.sol:L22",
        "contracts/contracts/messageService/lib/RateLimiter.sol:L26",
        "contracts/contracts/messageService/MessageServiceBase.sol:L14",
        "contracts/contracts/messageService/l2/L2MessageService.sol:L16",
        "If there exists a need to inherit from this contract in the future, the derived contract has to define the buffer space first, similar to L2MessageService. If it doesn\u2019t, L2MessageService can\u2019t have more storage variables. If it adds them, it will collide with the derived contract\u2019s storage slots.",
        "2. RateLimiter and MessageServiceBase initializes values without the modifier onlyInitializing",
        "contracts/contracts/messageService/lib/RateLimiter.sol:L33",
        "contracts/contracts/messageService/MessageServiceBase.sol:L65",
        "The modifier onlyInitializing makes sure that the function should only be invoked by a function marked as initializer. However, it is absent here, which means these are normal internal functions that can be utilized in any other function, thus opening opportunities for errors."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/no-proper-trusted-setup-acknowledged-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 constant g2\\_srs\\_0\\_x\\_0 = 11559732032986387107991004021392285783925812861821192530917403151452391805634;\nuint256 constant g2\\_srs\\_0\\_x\\_1 = 10857046999023057135944570762232829481370756359578518086990519993285655852781;\nuint256 constant g2\\_srs\\_0\\_y\\_0 = 4082367875863433681332203403145435568316851327593401208105741076214120093531;\nuint256 constant g2\\_srs\\_0\\_y\\_1 = 8495653923123431417604973247489272438418190587263600148770280649306958101930;\n\nuint256 constant g2\\_srs\\_1\\_x\\_0 = 18469474764091300207969441002824674761417641526767908873143851616926597782709;\nuint256 constant g2\\_srs\\_1\\_x\\_1 = 17691709543839494245591259280773972507311536864513996659348773884770927133474;\nuint256 constant g2\\_srs\\_1\\_y\\_0 = 2799122126101651639961126614695310298819570600001757598712033559848160757380;\nuint256 constant g2\\_srs\\_1\\_y\\_1 = 3054480525781015242495808388429905877188466478626784485318957932446534030175;\n\n"
    ],
    "Description": [
        "Linea uses Plonk proof system, which needs a preprocessed CRS (Common Reference String) for proving and verification, the Plonk system security is based on the existence of a trusted setup ceremony to compute the CRS, the current verifier uses a CRS created by one single party, which requires fully trust of the party to delete the toxic waste (trapdoor) which can be used to generate forged proof, undermining the security of the entire system",
        "contracts/Verifier.sol:L29-L37"
    ],
    "Recommendation": [
        "Conduct a proper MPC to generate CRS like the Powers of Tau MPC or use a trustworthy CRS generated by an exisiting audited trusted setup like Aztec\u2019s ignition"
    ]
}
----End JSON----

https://solodit.xyz/issues/broken-lagrange-polynomial-evaluation-at-zeta-acknowledged-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "The Verifier calculates the Lagrange Polynomial at \u03b6 with an efficient scheme as:\nLj(\u03b6) = \u03c9i/n * (\u03b6n-1)/(\u03b6-\u03c9i)",
        "which has also been pointed out in the plonk paper. However, the computation ignores the fact that \u03b6 can also be a root of unity, which means \u03b6n - 1 will be 0 for any \u03b6 that is a root of unity.",
        "Thus, the formula will yield the Lagrange polynomial evaluation as 0, which is incorrect.\nBecause the property of the Lagrange polynomial is:\nLj(\u03b6) = 1, if i=j and 0 otherwise, where \u03b6 belongs to domain H = \u03c9i, \u2200 0<=i< n(n being the domain size)",
        "Another way of calculating the Lagrange polynomial at zeta is:\nLj(\u03b6) = yj * \u220f 0<= m <= k, m != j (\u03b6 - xm)/(xj-xm); (k being the degree of polynomial)",
        "If we consider the same evaluation for \u03b6 at the root of unity in the second formula, it will correctly satisfy the property of the Lagrange polynomial stated above.",
        "Hence, there is a need to fix the computation considering the case highlighted.",
        "The problematic instances can be found in functions:"
    ],
    "Recommendation": [
        "Consider adopting a strategy to use the second formula for the computation of Lagrange Polynomial evaluation at \u03b6 if \u03b6 is a root of unity."
    ]
}
----End JSON----

https://solodit.xyz/issues/broken-logic-for-modular-multiplicative-inverse-acknowledged-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "The multiplicate inverse of an element \u03b1 in a finite field Fpn can be calculated as \u03b1pn - 2. \u03b1 can be any field element except 0 or the point at infinity.",
        "This totally makes sense as there exists no field element x such that\n0 * x = 1 mod p",
        "However, it is allowed here and it is calculated like any other field element.\nIt doesn\u2019t revert, because 0 raised to any power modulo p will yield 0.",
        "Thus the calculation points to a broken logic that defines the modular multiplicative inverse of 0 as 0."
    ],
    "Recommendation": [
        "The point at infinity can bring many mathematical flaws to the system. Hence require the utmost attention to be fixed."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-verifying-paring-check-result-fixed-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "let l\\_success := staticcall(sub(gas(), 2000),8,mPtr,0x180,0x00,0x20)\n// l\\_success := true\nmstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\n\n"
    ],
    "Description": [
        "In function batch_verify_multi_points, the SNARK paring check is done by calling paring pre-compile\nlet l_success := staticcall(sub(gas(), 2000),8,mPtr,0x180,0x00,0x20)\nand the only the execution status is stored in the final success state (state_success), but the the paring check result which is stored in 0x00 is not stored and checked, which means if the paring check result is 0 (pairing check failed), the proof would still pass verification, e.g. invalid proof with incorrect proof element proof_openings_selector_commit_api_at_zeta would pass the paring check. As a result it breaks the SNARK paring verification."
    ],
    "Examples": [
        "contracts/Verifier.sol:L586-L588",
        "Another example is, if either of the following is sent as a point at infinity or (0,0) as (x,y) co-ordinate:",
        "The proof will still work, since the pairing result is not being checked."
    ],
    "Recommendation": [
        "Verify paring check result and store it in the final success state after calling the paring pre-compile"
    ]
}
----End JSON----

https://solodit.xyz/issues/gas-greifing-and-missing-return-status-check-for-staticcalls-may-lead-to-unexpected-outcomes-partially-addressed-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "pop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1b), size, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\n\n",
        "pop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1c), 0x24, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\n\n",
        "pop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1b), 0x65, mPtr, 0x20)) //0x1b -> 000..\"gamma\"\n\n",
        "pop(staticcall(sub(gas(), 2000), 0x2, add(mPtr, 0x1c), 0xe4, mPtr, 0x20))\n\n",
        "pop(staticcall(sub(gas(), 2000), 0x2, add(mPtr,start\\_input), size\\_input, add(state, state\\_gamma\\_kzg), 0x20))\n\n",
        "pop(staticcall(sub(gas(), 2000),0x05,mPtr,0xc0,0x00,0x20))\n\n",
        "pop(staticcall(sub(gas(), 2000),0x05,mPtr,0xc0,mPtr,0x20))\n\n",
        "pop(staticcall(sub(gas(), 2000),0x05,mPtr,0xc0,mPtr,0x20))\n\n",
        "pop(staticcall(sub(gas(), 2000),7,folded\\_evals\\_commit,0x60,folded\\_evals\\_commit,0x40))\n\n",
        "let l\\_success := staticcall(sub(gas(), 2000),6,mPtr,0x80,dst,0x40)\n\n",
        "let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,dst,0x40)\n\n",
        "let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,mPtr,0x40)\n\n",
        "l\\_success := and(l\\_success, staticcall(sub(gas(), 2000),6,mPtr,0x80,dst, 0x40))\n\n"
    ],
    "Description": [
        "The gas supplied to the staticcall(s), is calculated by subtracting 2000 from the remaining gas at this point in time. However, if not provided enough gas, the staticcall(s) may fail and there will be no return data, and the execution will continue with the stale data that was previously there at the memory location specified by the return offset with the staticcall(s).",
        "1- Predictable Derivation of Challenges",
        "The function derive_gamma_beta_alpha_zeta is used to derive the challenge values gamma, beta, alpha, zeta. These values are derived from the prover\u2019s transcript by hashing defined parameters and are supposed to be unpredictable by either the prover or the verifier. The hash is collected with the help of SHA2-256 precompile.\nThe values are considered unpredictable, due to the assumption that SHA2-256 acts as a random oracle and it would be computationally infeasible for an attacker to find the pre-image of gamma. However, the assumption might be wrong."
    ],
    "Examples": [
        "contracts/Verifier.sol:L261",
        "contracts/Verifier.sol:L269",
        "contracts/Verifier.sol:L279",
        "contracts/Verifier.sol:L293",
        "contracts/Verifier.sol:L694",
        "If the staticcall(s) fails, it will make the challenge values to be predictable and may help the prover in forging proofs and launching other adversarial attacks.",
        "2- Incorrect Exponentiation",
        "Functions compute_ith_lagrange_at_z, compute_pi, and verify compute modular exponentiation by making a staticcall to the precompile modexp as:",
        "contracts/Verifier.sol:L335",
        "contracts/Verifier.sol:L441",
        "contracts/Verifier.sol:L889",
        "However, if not supplied enough gas, the staticcall(s) will fail, thus returning no result and the execution will continue with the stale data.",
        "3. Incorrect Point Addition and Scalar Multiplication",
        "contracts/Verifier.sol:L555",
        "contracts/Verifier.sol:L847",
        "contracts/Verifier.sol:L858",
        "contracts/Verifier.sol:L868",
        "contracts/Verifier.sol:L871",
        "For the same reason, point_add, point_mul, and point_acc_mul will return incorrect results. Matter of fact, point_acc_mul will not revert even if the scalar multiplication fails in the first step. Because, the memory location specified for the return offset, will still be containing the old (x,y) coordinates of src, which are points on the curve. Hence, it will proceed by incorrectly adding (x,y) coordinates of dst with it.",
        "However, it will not be practically possible to conduct a gas griefing attack for staticcall(s) at the start of the top-level transaction. As it will require an attacker to pass a very low amount of gas to make the staticcall fail, but at the same time, that would not be enough to make the top-level transaction execute entirely and not run out of gas. But, this can still be conducted for the staticcall(s) that are executed at the near end of the top-level transaction."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/verifier-doesnt-support-zero-or-multiple-bsb22-commitments-acknowledged-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 constant vk\\_selector\\_commitments\\_commit\\_api\\_0\\_x = {{ (fpptr .Qcp.X).String }};\nuint256 constant vk\\_selector\\_commitments\\_commit\\_api\\_0\\_y = {{ (fpptr .Qcp.Y).String }};\n\n"
    ],
    "Description": [
        "The verifier currently supports single BSB22 commitment as Gnark only supports single Commit(..) call. If there is no or multiple BSB22 commitments/Commit calls, the verifier would fail in proof verification."
    ],
    "Examples": [
        "tmpl/template_verifier.go:L57-L58"
    ],
    "Recommendation": [
        "Add support for zero or multiple BSB22 commitments"
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-tests-for-edge-cases-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "There are no test cases for invalid proof and public input such as proof elements not on curve, proof element is points of infinity, all proof elements are zero, wrong proof element, proof scalar element bigger than scalar field modulus, proof scalar element wrapping around scalar field modulus, public input greater than scalar field modulus etc. and no or multiple BSB22 commitments. There is only test for valid proof and one BSB22 commitment. Tests for all edge cases are crucial to check proof soundness in SNARK, missing it may result in missing some critical bugs, e.g. issue issue 4.4 issue issue 4.6"
    ],
    "Recommendation": [
        "Add missing test cases"
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-scalar-field-range-check-in-scalar-multiplication-fixed-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function point\\_mul(dst,src,s, mPtr) {\n // let mPtr := add(mload(0x40), state\\_last\\_mem)\n let state := mload(0x40)\n mstore(mPtr,mload(src))\n mstore(add(mPtr,0x20),mload(add(src,0x20)))\n mstore(add(mPtr,0x40),s)\n let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,dst,0x40)\n mstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\n}\n\n// dst <- dst + [s]src (Elliptic curve)\nfunction point\\_acc\\_mul(dst,src,s, mPtr) {\n let state := mload(0x40)\n mstore(mPtr,mload(src))\n mstore(add(mPtr,0x20),mload(add(src,0x20)))\n mstore(add(mPtr,0x40),s)\n let l\\_success := staticcall(sub(gas(), 2000),7,mPtr,0x60,mPtr,0x40)\n mstore(add(mPtr,0x40),mload(dst))\n mstore(add(mPtr,0x60),mload(add(dst,0x20)))\n l\\_success := and(l\\_success, staticcall(sub(gas(), 2000),6,mPtr,0x80,dst, 0x40))\n mstore(add(state, state\\_success), and(l\\_success,mload(add(state, state\\_success))))\n}\n\n"
    ],
    "Description": [
        "There is no field element range check on scalar field proof elements e.g. proof_l_at_zeta, proof_r_at_zeta, proof_o_at_zeta, proof_s1_at_zeta,proof_s2_at_zeta, proof_grand_product_at_zeta_omega as mentioned in the step 2 of the verifier\u2019s algorithm in the Plonk paper.\nThe scalar multiplication functions point_mul and point_acc_mul call precompile ECMUL, according to EIP-169 , which would verify the point P is on curve and P.x and P.y is less than the base field modulus, however it doesn\u2019t check the scalar s is less than scalar field modulus, if s is greater than scalar field modulus r_mod, it would cause unintended behavior of the contract, specifically if the scalar field proof element e are replaced by e + r_mod, the proof would still pass verification. Although in Plonk\u2019s case, there is few attacker vectors could exists be based on this kind of proof malleability."
    ],
    "Examples": [
        "contracts/Verifier.sol:L852-L873"
    ],
    "Recommendation": [
        "Add scalar field range check on scalar multiplication functions point_mul and point_acc_mul or the scalar field proof elements."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-public-inputs-range-check-fixed-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function Verify(bytes memory proof, uint256[] memory public\\_inputs)\n\n",
        "sum\\_pi\\_wo\\_api\\_commit(add(public\\_inputs,0x20), mload(public\\_inputs), zeta)\npi := mload(mload(0x40))\n\nfunction sum\\_pi\\_wo\\_api\\_commit(ins, n, z) {\n let li := mload(0x40)\n batch\\_compute\\_lagranges\\_at\\_z(z, n, li)\n let res := 0\n let tmp := 0\n for {let i:=0} lt(i,n) {i:=add(i,1)}\n {\n tmp := mulmod(mload(li), mload(ins), r\\_mod)\n res := addmod(res, tmp, r\\_mod)\n li := add(li, 0x20)\n ins := add(ins, 0x20)\n }\n mstore(mload(0x40), res)\n}\n\n"
    ],
    "Description": [
        "The public input is an array of uint256 numbers, there is no check if each public input is less than SNARK scalar field modulus r_mod, as mentioned in the step 3 of the verifier\u2019s algorithm in the Plonk paper. Since public inputs are involved computation of Pi in the plonk gate which is in the SNARK scalar field, without the check, it might cause scalar field overflow and the verification contract would fail and revert. To prevent overflow and other unintended behavior there should be a range check for the public inputs."
    ],
    "Examples": [
        "contracts/Verifier.sol:L470",
        "contracts/Verifier.sol:L367-L383"
    ],
    "Recommendation": [
        "Add range check for the public inputs\nrequire(input[i] < r_mod, \"public inputs greater than snark scalar field\");"
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-field-element-check-and-on-curve-point-check-for-proof-elements-acknowledged-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "Description": [
        "There is no prime field element check and on curve point for proof elements proof_l_com_x, proof_l_com_y,proof_r_com_x,proof_r_com_y, proof_o_com_x, proof_o_com_y, proof_h_0_x, proof_h_0_y,proof_h_1_x, proof_h_1_y,proof_h_2_x, proof_h_2_y, proof_batch_opening_at_zeta, proof_opening_at_zeta_omega, proof_selector_commit_api_commitment, as mentioned in",
        "of the verifier\u2019s algorithm in the Plonk paper. Although there is field element check and curve point check in ECCADD, ECCMUL and ECCParing precompiles on those elements, in which the precompile would revert on failed check but it would consume gas on revert and there is no error information. It\u2019s better to check explicitly and revert on fail to prevent unintended behavior of the verification contract."
    ],
    "Recommendation": [
        "Add field element, group element and curve point check for proof elements and revert if the check fails.",
        "`"
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-length-check-for-proof-fixed-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function Verify(bytes memory proof, uint256[] memory public_inputs)\n\n"
    ],
    "Description": [
        "The Verify function has the following signature:",
        "Here, proof is a dynamically sized array of bytes (padded upto the nearest word). The function derive_gamma(aproof, pub_inputs) uses this array and makes some assumptions about its length. Specifically, that it is (vk_nb_commitments_commit_api * 3 * 0x20) + 0x360 bytes long (when including the initial length field of the bytes array). However, there is no check that the proof supplied in the calldata (which originates within ZkEvmV2 where it is loaded into memory) has the correct length. This could result in the proof and pub_inputs overlapping in memory, leading to unintended consequences.",
        "Also, if mistakenly appended extra bits to the proof, it will not affect the proof verification as the Verifier doesn\u2019t account for any extra bits after the y coordinate of the last commitment. But it will surely make the verification expensive, as it will still be copied down into memory."
    ],
    "Recommendation": [
        "Add an appropriate length check at some point in the pipeline to ensure this doesn\u2019t cause any unintended problems."
    ]
}
----End JSON----

https://solodit.xyz/issues/loading-arbitrary-data-as-wire-commitments-acknowledged-consensys-none-linea-plonk-verifier-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256[] memory wire\\_committed\\_commitments = new uint256[](2\\*vk\\_nb\\_commitments\\_commit\\_api);\nload\\_wire\\_commitments\\_commit\\_api(wire\\_committed\\_commitments, proof);\n\n",
        "for {let i:=0} lt(i, mul(vk\\_nb\\_commitments\\_commit\\_api,2)) {i:=add(i,1)}\n\n",
        "for {let i:=0} lt(i, mul(vk_nb_commitments_commit_api,2)) {i:=add(i,1)}\n\n",
        "for {let i:=0} lt(i, vk_nb_commitments_commit_api) {i:=add(i,1)}\n\n"
    ],
    "Description": [
        "Function load_wire_commitments_commit_api as the name suggests, loads wire commitments from the proof into the memory array wire_commitments. The array is made to hold 2 values per commitment or the size of the array is 2 * vk_nb_commitments_commit_api, which makes sense as these 2 values are the x & y co-ordinates of the commitments.",
        "contracts/Verifier.sol:L453-L454",
        "Coming back to the functionload_wire_commitments_commit_api, it extracts both the x & y coordinates of a commitment in a single iteration. However, the loop runs 2 * vk_nb_commitments_commit_api, or in other words, twice as many of the required iterations. For instance, if there is 1 commitment, it will run two times. The first iteration will pick up the actual coordinates and the second one can pick any arbitrary data from the proof(if passed) and load it into memory. Although, this data which has been loaded in an extra iteration seems harmless but still adds an overhead for the processing.",
        "contracts/Verifier.sol:L307"
    ],
    "Recommendation": [
        "The number of iterations should be equal to the size of commitments, i.e., vk_nb_commitments_commit_api.\nSo consider switching from:",
        "to:"
    ]
}
----End JSON----

https://solodit.xyz/issues/node-operators-can-stake-validators-that-were-not-proposed-by-them-consensys-none-geode-liquid-staking-markdown
--------------------------------------------------
----Start JSON----

https://solodit.xyz/issues/node-operators-can-stake-validators-that-were-not-proposed-by-them-consensys-none-geode-liquid-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function stake(\n PooledStaking storage self,\n DSML.IsolatedStorage storage DATASTORE,\n uint256 operatorId,\n bytes[] calldata pubkeys\n) external {\n \\_authenticate(DATASTORE, operatorId, false, true, [true, false]);\n\n require(\n (pubkeys.length > 0) && (pubkeys.length <= DCL.MAX\\_DEPOSITS\\_PER\\_CALL),\n \"SML:1 - 50 validators\"\n );\n\n {\n uint256 \\_verificationIndex = self.VERIFICATION\\_INDEX;\n for (uint256 j = 0; j < pubkeys.length; ) {\n require(\n \\_canStake(self, pubkeys[j], \\_verificationIndex),\n \"SML:NOT all pubkeys are stakeable\"\n );\n\n unchecked {\n j += 1;\n }\n }\n }\n\n {\n bytes32 activeValKey = DSML.getKey(operatorId, rks.activeValidators);\n bytes32 proposedValKey = DSML.getKey(operatorId, rks.proposedValidators);\n uint256 poolId = self.validators[pubkeys[0]].poolId;\n bytes memory withdrawalCredential = DATASTORE.readBytes(poolId, rks.withdrawalCredential);\n\n uint256 lastIdChange = 0;\n for (uint256 i = 0; i < pubkeys.length; ) {\n uint256 newPoolId = self.validators[pubkeys[i]].poolId;\n if (poolId != newPoolId) {\n uint256 sinceLastIdChange;\n\n unchecked {\n sinceLastIdChange = i - lastIdChange;\n }\n\n DATASTORE.subUint(poolId, rks.secured, (DCL.DEPOSIT\\_AMOUNT \\* (sinceLastIdChange)));\n DATASTORE.subUint(poolId, proposedValKey, (sinceLastIdChange));\n DATASTORE.addUint(poolId, activeValKey, (sinceLastIdChange));\n\n lastIdChange = i;\n poolId = newPoolId;\n withdrawalCredential = DATASTORE.readBytes(poolId, rks.withdrawalCredential);\n }\n\n DCL.depositValidator(\n pubkeys[i],\n withdrawalCredential,\n self.validators[pubkeys[i]].signature31,\n (DCL.DEPOSIT\\_AMOUNT - DCL.DEPOSIT\\_AMOUNT\\_PRESTAKE)\n );\n\n self.validators[pubkeys[i]].state = VALIDATOR\\_STATE.ACTIVE;\n\n unchecked {\n i += 1;\n }\n }\n {\n uint256 sinceLastIdChange;\n unchecked {\n sinceLastIdChange = pubkeys.length - lastIdChange;\n }\n if (sinceLastIdChange > 0) {\n DATASTORE.subUint(poolId, rks.secured, DCL.DEPOSIT\\_AMOUNT \\* (sinceLastIdChange));\n DATASTORE.subUint(poolId, proposedValKey, (sinceLastIdChange));\n DATASTORE.addUint(poolId, activeValKey, (sinceLastIdChange));\n }\n }\n\n \\_increaseWalletBalance(DATASTORE, operatorId, DCL.DEPOSIT\\_AMOUNT\\_PRESTAKE \\* pubkeys.length);\n\n emit Stake(pubkeys);\n }\n\n"
    ],
    "preamble": [
        "In GeodeFi system node operators are meant to add the new validators in two steps:",
        "The issue itself stems from the fact that node operators are allowed to stake the validators of the other node operators. In the stake() function there is no check of the validator\u2019s operatorId against the operator performing the stake. Meaning that node operator A can stake validators of node operator B.",
        "contracts/Portal/modules/StakeModule/libs/StakeModuleLib.sol:L1478-L1558",
        "This issue can later be escalated to a point where funds can be stolen. Consider the following case:",
        "This way an attacker could profit 10ETH.",
        "This can be prevented by making sure that validator\u2019s operatorId is checked on the stake() function call."
    ]
}
----End JSON----

https://solodit.xyz/issues/cannot-blame-operator-for-proposed-validator-consensys-none-geode-liquid-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function blameOperator(\n PooledStaking storage self,\n DSML.IsolatedStorage storage DATASTORE,\n bytes calldata pk\n) external {\n require(\n self.validators[pk].state == VALIDATOR\\_STATE.ACTIVE,\n \"SML:validator is never activated\"\n );\n require(\n block.timestamp > self.validators[pk].createdAt + self.validators[pk].period,\n \"SML:validator is active\"\n );\n\n \\_imprison(DATASTORE, self.validators[pk].operatorId, pk);\n}\n\n"
    ],
    "preamble": [
        "In the current code, anyone can blame an operator who does not withdraw in time:",
        "contracts/Portal/modules/StakeModule/libs/StakeModuleLib.sol:L931-L946",
        "There is one more scenario where the operator should be blamed. When a validator is in the PROPOSED state, only the operator can call the stake function to actually stake the rest of the funds. Before that, the funds of the pool will be locked under the rks.secured variable. So the malicious operator can lock up 31 ETH of the pool indefinitely by locking up only 1 ETH of the attacker. There is currently no way to release these 31 ETH.",
        "We recommend introducing a mechanism that allows one to blame the operator for not staking for a long time after it was approved."
    ]
}
----End JSON----

https://solodit.xyz/issues/validators-array-length-has-to-be-updated-when-the-validator-is-alienated-consensys-none-geode-liquid-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_alienateValidator(\n SML.PooledStaking storage STAKE,\n DSML.IsolatedStorage storage DATASTORE,\n uint256 verificationIndex,\n bytes calldata \\_pk\n) internal {\n require(STAKE.validators[\\_pk].index <= verificationIndex, \"OEL:unexpected index\");\n require(\n STAKE.validators[\\_pk].state == VALIDATOR\\_STATE.PROPOSED,\n \"OEL:NOT all pubkeys are pending\"\n );\n\n uint256 operatorId = STAKE.validators[\\_pk].operatorId;\n SML.\\_imprison(DATASTORE, operatorId, \\_pk);\n\n uint256 poolId = STAKE.validators[\\_pk].poolId;\n DATASTORE.subUint(poolId, rks.secured, DCL.DEPOSIT\\_AMOUNT);\n DATASTORE.addUint(poolId, rks.surplus, DCL.DEPOSIT\\_AMOUNT);\n\n DATASTORE.subUint(poolId, DSML.getKey(operatorId, rks.proposedValidators), 1);\n DATASTORE.addUint(poolId, DSML.getKey(operatorId, rks.alienValidators), 1);\n\n STAKE.validators[\\_pk].state = VALIDATOR\\_STATE.ALIENATED;\n\n emit Alienated(\\_pk);\n}\n\n",
        "uint256 numOperatorValidators = DATASTORE.readUint(operatorId, rks.validators);\n\n",
        "uint256 numPoolValidators = DATASTORE.readUint(poolId, rks.validators);\n\n"
    ],
    "preamble": [
        "In GeodeFi when the node operator creates a validator with incorrect withdrawal credentials or signatures the Oracle has the ability to alienate this validator. In the process of alienation, the validator status is updated.",
        "contracts/Portal/modules/StakeModule/libs/OracleExtensionLib.sol:L111-L136",
        "An additional thing that has to be done during the alienation process is that the validator\u2019s count should be decreased in order for the monopoly threshold to be calculated correctly. That is because the length of the validators array is used twice in the OpeartorAllowance function:",
        "contracts/Portal/modules/StakeModule/libs/StakeModuleLib.sol:L975",
        "contracts/Portal/modules/StakeModule/libs/StakeModuleLib.sol:L988",
        "Without the update of the array length, the monopoly threshold as well as the time when the fallback operator will be able to participate is going to be computed incorrectly.",
        "It could be beneficial to not refer to rks.validators in the operator allowance function and instead use the rks.proposedValidators + rks.alienatedValidators + rks.activeValidators. This way allowance function can always rely on the most up to date data."
    ]
}
----End JSON----

https://solodit.xyz/issues/addpremium-a-back-runner-may-cause-an-insurance-holder-to-lose-their-refunds-by-calling-addpremium-right-after-the-original-call-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "refundMap[policyIndex\\_][week] = incomeMap[policyIndex\\_][week].mul(\n allCovered.sub(maximumToCover)).div(allCovered);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by returning with no-op in case\nincomeMap[policyIndex_][week] = 0, and by doing this eliminate the risk of loss of refunds."
    ],
    "Description": [
        "addPremium is a public function that can be called by anyone and that distributes the weekly premium payments to the pool manager and the rest of the pool share holders. If the collateral deposited is not enough to cover the total coverage offered to insurance holders for a given week, refunds are allocated pro rata for all insurance holders of that particular week and policy. However, in the current implementation, attackers can call addPremium right after the original call to addPremium but before the call to refund; this will cause the insurance holders to lose their refunds, which will be effectively locked forever in the contract (unless the contract is upgraded)."
    ],
    "Examples": [
        "code/contracts/Pool.sol:L313-L314"
    ],
    "Recommendation": [
        "addPremium should contain a validation check in the beginning of the function that reverts for the case of incomeMap[policyIndex_][week] = 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/refund-attacker-can-lock-insurance-holders-refunds-by-calling-refund-before-a-refund-was-allocated-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function refund(\n uint256 policyIndex\\_,\n uint256 week\\_,\n address who\\_\n) external noReenter {\n Coverage storage coverage = coverageMap[policyIndex\\_][week\\_][who\\_];\n\n require(!coverage.refunded, \"Already refunded\");\n\n uint256 allCovered = coveredMap[policyIndex\\_][week\\_];\n uint256 amountToRefund = refundMap[policyIndex\\_][week\\_].mul(\n coverage.amount).div(allCovered);\n coverage.amount = coverage.amount.mul(\n coverage.premium.sub(amountToRefund)).div(coverage.premium);\n coverage.refunded = true;\n\n IERC20(baseToken).safeTransfer(who\\_, amountToRefund);\n\n if (eventAggregator != address(0)) {\n IEventAggregator(eventAggregator).refund(\n policyIndex\\_,\n week\\_,\n who\\_,\n amountToRefund\n );\n }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "addPremium is used to determine the refund amount that an insurance holder is eligible to claim. The amount is stored in the refundMap mapping and can then later be claimed by anyone on behalf of an insurance holder by calling refund. The refund function can\u2019t be called more than once for a given combination of policyIndex_, week_, and who_, as it would revert with an \u201cAlready refunded\u201d error. This gives an attacker the opportunity to call refund on behalf of any insurance holder with value 0 inside the refundMap, causing any future refund allocated for that holder in a given week and for a given policy to be locked forever in the contract (unless the contract is upgraded)."
    ],
    "Examples": [
        "code/contracts/Pool.sol:L341-L367"
    ],
    "Recommendation": [
        "There should be a validation check at the beginning of the function that reverts if refundMap[policyIndex_][week_] == 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/addtidal-_updateusertidal-withdrawtidal-wrong-arithmetic-calculations-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "poolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\n amount\\_.mul(SHARE\\_UNITS)).div(poolInfo.totalShare);\n\n",
        "poolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\n amount\\_.mul(SHARE\\_UNITS).div(poolInfo.totalShare));\n\n",
        "poolInfo.accTidalPerShare += amount\\_ \\* SHARE\\_UNITS / poolInfo.totalShare;\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.add(\n userInfo.share).div(SHARE\\_UNITS);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.mul(\n userInfo.share).div(SHARE\\_UNITS);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.add(userInfo.share);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.mul(\n userInfo.share).div(SHARE\\_UNITS);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "To further incentivize sellers, anyone \u2013 although it will usually be the pool manager \u2013 can send an arbitrary amount of the Tidal token to a pool, which is then supposed to be distributed proportionally among the share owners. There are several flaws in the calculations that implement this mechanism:",
        "A. addTidal:",
        "code/contracts/Pool.sol:L543-L544",
        "This should be:",
        "Note the different parenthesization. Without SafeMath:",
        "B. _updateUserTidal:",
        "code/contracts/Pool.sol:L549-L550",
        "This should be:",
        "Note that add has been replaced with mul. Without SafeMath:",
        "C. withdrawTidal:",
        "code/contracts/Pool.sol:L568",
        "As in B, this should be:",
        "Note that add has been replaced with mul and that a division by SHARE_UNITS has been appended. Without SafeMath:",
        "As an additional minor point, the division in addTidal will revert with a panic (0x12) if the number of shares in the pool is zero. This case could be handled more gracefully."
    ],
    "Recommendation": [
        "Implement the fixes described above. The versions without SafeMath are easier to read and should be preferred; see https://github.com/ConsensysDiligence/tidal-audit-2023-04/issues/20."
    ]
}
----End JSON----

https://solodit.xyz/issues/claim-incomplete-and-lenient-implementation-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function claim(\n uint256 policyIndex\\_,\n uint256 amount\\_,\n address receipient\\_\n) external onlyPoolManager {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Acknowledged but not fixed in this version. The client provided the following message: \u201cNo fix for this version. This one is not a bug in the code but is a missing feature on product logic. The product is good for release without a fix. We may implement related functions in the future.\u201d"
    ],
    "Description": [
        "In the current version of the code, the claim function is lacking crucial input validation logic as well as required state changes. Most of the process is implemented in other contracts or off-chain at the moment and is therefore out of scope for this audit, but there might still be issues caused by potential errors in the process. Moreover, pool manager and committee together have unlimited ownership of the deposits and can essentially withdraw all collateral to any desired address."
    ],
    "Examples": [
        "code/contracts/Pool.sol:L588-L592"
    ],
    "Recommendation": [
        "To ensure a more secure claiming process, we propose adding the following logic to the claim function:"
    ]
}
----End JSON----

https://solodit.xyz/issues/buy-insurance-buyers-trying-to-increase-their-coverage-amount-will-lose-their-previous-coverage-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 w = fromWeek\\_; w < toWeek\\_; ++w) {\n incomeMap[policyIndex\\_][w] =\n incomeMap[policyIndex\\_][w].add(premium);\n coveredMap[policyIndex\\_][w] =\n coveredMap[policyIndex\\_][w].add(amount\\_);\n\n require(coveredMap[policyIndex\\_][w] <= maximumToCover,\n \"Not enough to buy\");\n\n coverageMap[policyIndex\\_][w][\\_msgSender()] = Coverage({\n amount: amount\\_,\n premium: premium,\n refunded: false\n });\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "When a user is willing to buy insurance, he is required to specify the desired amount (denoted as amount_) and to pay the entire premium upfront. In return, he receives the ownership over an entry inside the coverageMap mapping. If a user calls the buy function more than once for the same policy and time frame, his entry in the coverageMap will not represent the accumulated amount that he paid for but only the last coverage amount, which means previous coverage will be lost forever (unless the contract is upgraded)."
    ],
    "Examples": [
        "code/contracts/Pool.sol:L266-L280"
    ],
    "Recommendation": [
        "The coverage entry that represents the user\u2019s coverage should not be overwritten but should hold the accumulated amount of coverage instead."
    ]
}
----End JSON----

https://solodit.xyz/issues/several-issues-related-to-upgradeability-of-contracts-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Every Pool is a standalone smart contract. It is made upgradeable with OpenZeppelin\u2019s Proxy Upgrade Pattern.\n\n",
        "And there will be multiple proxies and one implementation of the Pools, and one proxy and one implementation of EventAggregator.\n\n",
        "import \"@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol\";\n\nimport \"@openzeppelin/contracts/utils/Context.sol\";\nimport \"@openzeppelin/contracts/utils/math/SafeMath.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Partially fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d as auditor\u2019s recommendations were implemented except from introducing __gap variables for NonReentrancy and EventAggregator."
    ],
    "Description": [
        "We did not find a proxy contract or factory in the repository, but the README contains the following information:",
        "code/README.md:L11",
        "code/README.md:L56",
        "There are several issues related to upgradeability or, generally, using the contracts as implementations for proxies. All recommendations in this report assume that it is not necessary to remain compatible with an existing deployment.",
        "A. The Pool.sol file imports Initializable.sol from OpenZeppelin\u2019s contracts-upgradeable and several other files from their \u201cregular\u201d contracts package.",
        "code/contracts/Pool.sol:L5-L10",
        "These two should not be mixed, and in an upgradeable context, all files should be imported from contracts-upgradeable. Note that the import of Ownable.sol in NonReentrancy.sol can be removed completely; see https://github.com/ConsensysDiligence/tidal-audit-2023-04/issues/12.",
        "B. If upgradeability is supposed to work with inheritance, there should be dummy variables at the end of each contract in the inheritance hierarchy. Some of these have to be removed when \u201creal\u201d state variables are added. More precisely, it is conventional to use a fixed-size uint256 array __gap, such that the consecutively occupied slots at the beginning (for the \u201creal\u201d state variables) add up to 50 with the size of the array. If state variables are added later, the gap\u2019s size has to be reduced accordingly to maintain this invariant. Currently, the contracts do not declare such a __gap variable.",
        "C. Implementation contracts should not remain uninitalized. To prevent initialization by an attacker \u2013 which, in some cases, can have an impact on the proxy \u2013 the implementation contract\u2019s constructor should call _disableInitializers."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/initialize-committee-members-array-can-contain-duplicates-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < committeeMembers\\_.length; ++i) {\n address member = committeeMembers\\_[i];\n committeeArray.push(member);\n committeeIndexPlusOne[member] = committeeArray.length;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing a nested loop to de-duplicate committee members."
    ],
    "Description": [
        "The initial committee members are given as array argument to the pool\u2019s initialize function. When the array is processed, there is no check for duplicates, and duplicates may also end up in the storage array committeeArray.",
        "code/contracts/Pool.sol:L43-L47",
        "Duplicates will result in a discrepancy between the length of the array \u2013 which is later interpreted as the number of committee members \u2013 and the actual number of (different) committee members. This could lead to more problems, such as an insufficient committee size to reach the threshold."
    ],
    "Recommendation": [
        "The initialize function should verify in the loop that member hasn\u2019t been added before. Note that _executeAddToCommittee refuses to add someone who is already in the committee, and the same technique can be employed here."
    ]
}
----End JSON----

https://solodit.xyz/issues/addpolicy-setpolicy-missing-input-validation-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addPolicy(\n\n",
        "function setPolicy(\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description and Recommendation": [
        "Both addPolicy and setPolicy are missing essential input validation on two main parameters:"
    ],
    "Examples": [
        "code/contracts/Pool.sol:L159",
        "code/contracts/Pool.sol:L143"
    ]
}
----End JSON----

https://solodit.xyz/issues/poolbuy-users-may-end-up-paying-more-than-intended-due-to-changes-in-policyweeklypremium-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 premium = amount\\_.mul(policy.weeklyPremium).div(RATIO\\_BASE);\nuint256 allPremium = premium.mul(toWeek\\_.sub(fromWeek\\_));\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "The price that an insurance buyer has to pay for insurance is determined by the duration of the coverage and the weeklyPremium. The price increases as the weeklyPremium increases. If a buy transaction is waiting in the mempool but eventually front-run by another transaction that increases weeklyPremium, the user will end up paying more than they anticipated for the same insurance coverage (assuming their allowance to the Pool contract is unlimited or at least higher than what they expected to pay)."
    ],
    "Examples": [
        "code/contracts/Pool.sol:L273-L274"
    ],
    "Recommendation": [
        "Consider adding a parameter for the maximum amount to pay, and make sure that the transaction will revert if allPremium is greater than this maximum value."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-validation-checks-in-execute-fixed-consensys-none-tidal-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_executeRemoveFromCommittee(address who\\_) private {\n\n",
        "function \\_executeChangeCommitteeThreshold(uint256 threshold\\_) private {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendations."
    ],
    "Description": [
        "The Pool contract implements a threshold voting mechanism for some changes in the contract state, where either the pool manager or a committee member can propose a change by calling claim, changePoolManager, addToCommittee, removeFromCommittee, or changeCommitteeThreshold, and then the committee has a time period for voting. If the threshold is reached during this period, then anyone can call execute to execute the state change.",
        "While some validation checks are implemented in the proposal phase, this is not enough to ensure that business logic rules around these changes are completely enforced."
    ],
    "Examples": [
        "code/contracts/Pool.sol:L783",
        "code/contracts/Pool.sol:L796"
    ],
    "Recommendation": [
        "Apply the same validation checks in the functions that execute the state change."
    ]
}
----End JSON----

https://solodit.xyz/issues/addpremium-a-back-runner-may-cause-an-insurance-holder-to-lose-their-refunds-by-calling-addpremium-right-after-the-original-call-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "refundMap[policyIndex\\_][week] = incomeMap[policyIndex\\_][week].mul(\n allCovered.sub(maximumToCover)).div(allCovered);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by returning with no-op in case\nincomeMap[policyIndex_][week] = 0, and by doing this eliminate the risk of loss of refunds."
    ],
    "Description": [
        "addPremium is a public function that can be called by anyone and that distributes the weekly premium payments to the pool manager and the rest of the pool share holders. If the collateral deposited is not enough to cover the total coverage offered to insurance holders for a given week, refunds are allocated pro rata for all insurance holders of that particular week and policy. However, in the current implementation, attackers can call addPremium right after the original call to addPremium but before the call to refund; this will cause the insurance holders to lose their refunds, which will be effectively locked forever in the contract (unless the contract is upgraded)."
    ],
    "Examples": [
        "contracts/Pool.sol:L313-L314"
    ],
    "Recommendation": [
        "addPremium should contain a validation check in the beginning of the function that reverts for the case of incomeMap[policyIndex_][week] = 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/refund-attacker-can-lock-insurance-holders-refunds-by-calling-refund-before-a-refund-was-allocated-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function refund(\n uint256 policyIndex\\_,\n uint256 week\\_,\n address who\\_\n) external noReenter {\n Coverage storage coverage = coverageMap[policyIndex\\_][week\\_][who\\_];\n\n require(!coverage.refunded, \"Already refunded\");\n\n uint256 allCovered = coveredMap[policyIndex\\_][week\\_];\n uint256 amountToRefund = refundMap[policyIndex\\_][week\\_].mul(\n coverage.amount).div(allCovered);\n coverage.amount = coverage.amount.mul(\n coverage.premium.sub(amountToRefund)).div(coverage.premium);\n coverage.refunded = true;\n\n IERC20(baseToken).safeTransfer(who\\_, amountToRefund);\n\n if (eventAggregator != address(0)) {\n IEventAggregator(eventAggregator).refund(\n policyIndex\\_,\n week\\_,\n who\\_,\n amountToRefund\n );\n }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "addPremium is used to determine the refund amount that an insurance holder is eligible to claim. The amount is stored in the refundMap mapping and can then later be claimed by anyone on behalf of an insurance holder by calling refund. The refund function can\u2019t be called more than once for a given combination of policyIndex_, week_, and who_, as it would revert with an \u201cAlready refunded\u201d error. This gives an attacker the opportunity to call refund on behalf of any insurance holder with value 0 inside the refundMap, causing any future refund allocated for that holder in a given week and for a given policy to be locked forever in the contract (unless the contract is upgraded)."
    ],
    "Examples": [
        "contracts/Pool.sol:L341-L367"
    ],
    "Recommendation": [
        "There should be a validation check at the beginning of the function that reverts if refundMap[policyIndex_][week_] == 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/addtidal-_updateusertidal-withdrawtidal-wrong-arithmetic-calculations-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "poolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\n amount\\_.mul(SHARE\\_UNITS)).div(poolInfo.totalShare);\n\n",
        "poolInfo.accTidalPerShare = poolInfo.accTidalPerShare.add(\n amount\\_.mul(SHARE\\_UNITS).div(poolInfo.totalShare));\n\n",
        "poolInfo.accTidalPerShare += amount\\_ \\* SHARE\\_UNITS / poolInfo.totalShare;\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.add(\n userInfo.share).div(SHARE\\_UNITS);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.mul(\n userInfo.share).div(SHARE\\_UNITS);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.add(userInfo.share);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare.mul(\n userInfo.share).div(SHARE\\_UNITS);\n\n",
        "uint256 accAmount = poolInfo.accTidalPerShare \\* userInfo.share / SHARE\\_UNITS;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "To further incentivize sellers, anyone \u2013 although it will usually be the pool manager \u2013 can send an arbitrary amount of the Tidal token to a pool, which is then supposed to be distributed proportionally among the share owners. There are several flaws in the calculations that implement this mechanism:",
        "A. addTidal:",
        "contracts/Pool.sol:L543-L544",
        "This should be:",
        "Note the different parenthesization. Without SafeMath:",
        "B. _updateUserTidal:",
        "contracts/Pool.sol:L549-L550",
        "This should be:",
        "Note that add has been replaced with mul. Without SafeMath:",
        "C. withdrawTidal:",
        "contracts/Pool.sol:L568",
        "As in B, this should be:",
        "Note that add has been replaced with mul and that a division by SHARE_UNITS has been appended. Without SafeMath:",
        "As an additional minor point, the division in addTidal will revert with a panic (0x12) if the number of shares in the pool is zero. This case could be handled more gracefully."
    ],
    "Recommendation": [
        "Implement the fixes described above. The versions without SafeMath are easier to read and should be preferred; see issue 3.13."
    ]
}
----End JSON----

https://solodit.xyz/issues/claim-incomplete-and-lenient-implementation-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function claim(\n uint256 policyIndex\\_,\n uint256 amount\\_,\n address receipient\\_\n) external onlyPoolManager {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Acknowledged but not fixed in this version. The client provided the following message: \u201cNo fix for this version. This one is not a bug in the code but is a missing feature on product logic. The product is good for release without a fix. We may implement related functions in the future.\u201d"
    ],
    "Description": [
        "In the current version of the code, the claim function is lacking crucial input validation logic as well as required state changes. Most of the process is implemented in other contracts or off-chain at the moment and is therefore out of scope for this audit, but there might still be issues caused by potential errors in the process. Moreover, pool manager and committee together have unlimited ownership of the deposits and can essentially withdraw all collateral to any desired address."
    ],
    "Examples": [
        "contracts/Pool.sol:L588-L592"
    ],
    "Recommendation": [
        "To ensure a more secure claiming process, we propose adding the following logic to the claim function:"
    ]
}
----End JSON----

https://solodit.xyz/issues/buy-insurance-buyers-trying-to-increase-their-coverage-amount-will-lose-their-previous-coverage-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 w = fromWeek\\_; w < toWeek\\_; ++w) {\n incomeMap[policyIndex\\_][w] =\n incomeMap[policyIndex\\_][w].add(premium);\n coveredMap[policyIndex\\_][w] =\n coveredMap[policyIndex\\_][w].add(amount\\_);\n\n require(coveredMap[policyIndex\\_][w] <= maximumToCover,\n \"Not enough to buy\");\n\n coverageMap[policyIndex\\_][w][\\_msgSender()] = Coverage({\n amount: amount\\_,\n premium: premium,\n refunded: false\n });\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "When a user is willing to buy insurance, he is required to specify the desired amount (denoted as amount_) and to pay the entire premium upfront. In return, he receives the ownership over an entry inside the coverageMap mapping. If a user calls the buy function more than once for the same policy and time frame, his entry in the coverageMap will not represent the accumulated amount that he paid for but only the last coverage amount, which means previous coverage will be lost forever (unless the contract is upgraded)."
    ],
    "Examples": [
        "contracts/Pool.sol:L266-L280"
    ],
    "Recommendation": [
        "The coverage entry that represents the user\u2019s coverage should not be overwritten but should hold the accumulated amount of coverage instead."
    ]
}
----End JSON----

https://solodit.xyz/issues/several-issues-related-to-upgradeability-of-contracts-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Every Pool is a standalone smart contract. It is made upgradeable with OpenZeppelin\u2019s Proxy Upgrade Pattern.\n\n",
        "And there will be multiple proxies and one implementation of the Pools, and one proxy and one implementation of EventAggregator.\n\n",
        "import \"@openzeppelin/contracts-upgradeable/proxy/utils/Initializable.sol\";\n\nimport \"@openzeppelin/contracts/utils/Context.sol\";\nimport \"@openzeppelin/contracts/utils/math/SafeMath.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/IERC20.sol\";\nimport \"@openzeppelin/contracts/token/ERC20/utils/SafeERC20.sol\";\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Partially fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d as auditor\u2019s recommendations were implemented except from introducing __gap variables for NonReentrancy and EventAggregator."
    ],
    "Description": [
        "We did not find a proxy contract or factory in the repository, but the README contains the following information:",
        "README.md:L11",
        "README.md:L56",
        "There are several issues related to upgradeability or, generally, using the contracts as implementations for proxies. All recommendations in this report assume that it is not necessary to remain compatible with an existing deployment.",
        "A. The Pool.sol file imports Initializable.sol from OpenZeppelin\u2019s contracts-upgradeable and several other files from their \u201cregular\u201d contracts package.",
        "contracts/Pool.sol:L5-L10",
        "These two should not be mixed, and in an upgradeable context, all files should be imported from contracts-upgradeable. Note that the import of Ownable.sol in NonReentrancy.sol can be removed completely; see issue 3.20.",
        "B. If upgradeability is supposed to work with inheritance, there should be dummy variables at the end of each contract in the inheritance hierarchy. Some of these have to be removed when \u201creal\u201d state variables are added. More precisely, it is conventional to use a fixed-size uint256 array __gap, such that the consecutively occupied slots at the beginning (for the \u201creal\u201d state variables) add up to 50 with the size of the array. If state variables are added later, the gap\u2019s size has to be reduced accordingly to maintain this invariant. Currently, the contracts do not declare such a __gap variable.",
        "C. Implementation contracts should not remain uninitalized. To prevent initialization by an attacker \u2013 which, in some cases, can have an impact on the proxy \u2013 the implementation contract\u2019s constructor should call _disableInitializers."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/initialize-committee-members-array-can-contain-duplicates-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < committeeMembers\\_.length; ++i) {\n address member = committeeMembers\\_[i];\n committeeArray.push(member);\n committeeIndexPlusOne[member] = committeeArray.length;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing a nested loop to de-duplicate committee members."
    ],
    "Description": [
        "The initial committee members are given as array argument to the pool\u2019s initialize function. When the array is processed, there is no check for duplicates, and duplicates may also end up in the storage array committeeArray.",
        "contracts/Pool.sol:L43-L47",
        "Duplicates will result in a discrepancy between the length of the array \u2013 which is later interpreted as the number of committee members \u2013 and the actual number of (different) committee members. This could lead to more problems, such as an insufficient committee size to reach the threshold."
    ],
    "Recommendation": [
        "The initialize function should verify in the loop that member hasn\u2019t been added before. Note that _executeAddToCommittee refuses to add someone who is already in the committee, and the same technique can be employed here."
    ]
}
----End JSON----

https://solodit.xyz/issues/addpolicy-setpolicy-missing-input-validation-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addPolicy(\n\n",
        "function setPolicy(\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description and Recommendation": [
        "Both addPolicy and setPolicy are missing essential input validation on two main parameters:"
    ],
    "Examples": [
        "contracts/Pool.sol:L159",
        "contracts/Pool.sol:L143"
    ]
}
----End JSON----

https://solodit.xyz/issues/poolbuy-users-may-end-up-paying-more-than-intended-due-to-changes-in-policyweeklypremium-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 premium = amount\\_.mul(policy.weeklyPremium).div(RATIO\\_BASE);\nuint256 allPremium = premium.mul(toWeek\\_.sub(fromWeek\\_));\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "The price that an insurance buyer has to pay for insurance is determined by the duration of the coverage and the weeklyPremium. The price increases as the weeklyPremium increases. If a buy transaction is waiting in the mempool but eventually front-run by another transaction that increases weeklyPremium, the user will end up paying more than they anticipated for the same insurance coverage (assuming their allowance to the Pool contract is unlimited or at least higher than what they expected to pay)."
    ],
    "Examples": [
        "contracts/Pool.sol:L273-L274"
    ],
    "Recommendation": [
        "Consider adding a parameter for the maximum amount to pay, and make sure that the transaction will revert if allPremium is greater than this maximum value."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-validation-checks-in-execute-fixed-consensys-none-tidal-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_executeRemoveFromCommittee(address who\\_) private {\n\n",
        "function \\_executeChangeCommitteeThreshold(uint256 threshold\\_) private {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in 3bbafab926df0ea39f444ef0fd5d2a6197f99a5d by implementing the auditor\u2019s recommendations."
    ],
    "Description": [
        "The Pool contract implements a threshold voting mechanism for some changes in the contract state, where either the pool manager or a committee member can propose a change by calling claim, changePoolManager, addToCommittee, removeFromCommittee, or changeCommitteeThreshold, and then the committee has a time period for voting. If the threshold is reached during this period, then anyone can call execute to execute the state change.",
        "While some validation checks are implemented in the proposal phase, this is not enough to ensure that business logic rules around these changes are completely enforced."
    ],
    "Examples": [
        "contracts/Pool.sol:L783",
        "contracts/Pool.sol:L796"
    ],
    "Recommendation": [
        "Apply the same validation checks in the functions that execute the state change."
    ]
}
----End JSON----

https://solodit.xyz/issues/infinitypool-contract-authorization-bypass-attack-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\n if (vc.value < WAD) revert InvalidParams();\n // can't borrow more than the pool has\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\n Account memory account = \\_getAccount(vc.subject);\n // fresh account, set start epoch and epochsPaid to beginning of current window\n if (account.principal == 0) {\n uint256 currentEpoch = block.number;\n account.startEpoch = currentEpoch;\n account.epochsPaid = currentEpoch;\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\n }\n\n account.principal += vc.value;\n account.save(router, vc.subject, id);\n\n totalBorrowed += vc.value;\n\n emit Borrow(vc.subject, vc.value);\n\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\n asset.transfer(msg.sender, vc.value);\n}\n\n",
        "modifier subjectIsAgentCaller(VerifiableCredential memory vc) {\n if (\n GetRoute.agentFactory(router).agents(msg.sender) != vc.subject\n ) revert Unauthorized();\n \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed by not allowing the vc.subject to be zero."
    ],
    "Description": [
        "An attacker could create their own credential and set the Agent ID to 0, which would bypass the subjectIsAgentCaller modifier. The attacker could use this attack to borrow funds from the pool, draining any available liquidity. For example, only an Agent should be able to borrow funds from the pool and call the borrow function:",
        "code/src/Pool/InfinityPool.sol:L302-L325",
        "The following modifier checks that the caller is an Agent:",
        "code/src/Pool/InfinityPool.sol:L96-L101",
        "But if the caller is not an Agent, the GetRoute.agentFactory(router).agents(msg.sender) will return 0. And if the vc.subject is also zero, the check will be successful with any msg.sender. The attacker can also pass an arbitrary vc.value as the parameter and steal all the funds from the pool."
    ],
    "Recommendation": [
        "Ensure only an Agent can call borrow and pass the subjectIsAgentCaller modifier."
    ]
}
----End JSON----

https://solodit.xyz/issues/agent-data-oracle-signed-credential-front-running-attack-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Mitigated by allowing only the Agent to request credentials."
    ],
    "Description": [
        "For almost every action as an Agent, the owner of the Agent is supposed to request SignedCredential data that contains all the relevant current info about the \u201coff-chain\u201d state of the Agent. New credentials can only be requested when the old one for this Agent is used or expired. Anyone can request these credentials, containing all the data about the call. So if the attacker consistently requests the credentials with the function and parameters that the actual Agent wouldn\u2019t want to call, the Agent won\u2019t be able to generate the credentials that are needed."
    ],
    "Recommendation": [
        "Ensure an Agent can always have new credentials that are needed. One solution would be to allow only an Agent\u2019s owner to request the credentials. The problem is that the beneficiary is also supposed to do that, but the beneficiary may also be a contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/wrong-accounting-for-totalborrowed-in-the-infinitypoolwriteoff-function-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// transfer the assets into the pool\n// whatever we couldn't pay back\nuint256 lostAmt = principalOwed > recoveredFunds ? principalOwed - recoveredFunds : 0;\n\nuint256 totalOwed = interestPaid + principalOwed;\n\nasset.transferFrom(\n msg.sender,\n address(this),\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\n);\n// write off only what we lost\ntotalBorrowed -= lostAmt;\n// set the account with the funds the pool lost\naccount.principal = lostAmt;\n\naccount.save(router, agentID, id);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed."
    ],
    "Description": [
        "Here is a part of the InfinityPool.writeOff function:",
        "code/src/Pool/InfinityPool.sol:L271-L287",
        "The totalBorrowed is decreased by the lostAmt value. Instead, it should be decreased by the original account.principal value to acknowledge the loss."
    ]
}
----End JSON----

https://solodit.xyz/issues/wrong-accounting-for-totalborrowed-in-the-infinitypoolpay-function-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// pay interest and principal\nprincipalPaid = vc.value - interestOwed;\n// the fee basis only applies to the interest payment\nfeeBasis = interestOwed;\n// protect against underflow\ntotalBorrowed -= (principalPaid > totalBorrowed) ? 0 : principalPaid;\n// fully paid off\nif (principalPaid >= account.principal) {\n // remove the account from the pool's list of accounts\n GetRoute.agentPolice(router).removePoolFromList(vc.subject, id);\n // return the amount of funds overpaid\n refund = principalPaid - account.principal;\n // reset the account\n account.reset();\n} else {\n // interest and partial principal payment\n account.principal -= principalPaid;\n // move the `epochsPaid` cursor to mark the account as \"current\"\n account.epochsPaid = block.number;\n}\n\n",
        "totalBorrowed -= (principalPaid > totalBorrowed) ? 0 : principalPaid;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed as recommended in two pull rquests: 1, 2."
    ],
    "Description": [
        "If the Agent pays more than the current interest debt, the remaining payment will be accounted as repayment of the principal debt:",
        "code/src/Pool/InfinityPool.sol:L382-L401",
        "Let\u2019s focus on the totalBorrowed changes:",
        "code/src/Pool/InfinityPool.sol:L387",
        "This value is supposed to be decreased by the principal that is repaid. So there are 2 mistakes in the calculation:"
    ]
}
----End JSON----

https://solodit.xyz/issues/the-beneficiarywithdrawable-function-can-be-called-by-anyone-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function beneficiaryWithdrawable(\n address recipient,\n address sender,\n uint256 agentID,\n uint256 proposedAmount\n) external returns (\n uint256 amount\n) {\n AgentBeneficiary memory beneficiary = \\_agentBeneficiaries[agentID];\n address benneficiaryAddress = beneficiary.active.beneficiary;\n // If the sender is not the owner of the Agent or the beneficiary, revert\n if(\n !(benneficiaryAddress == sender || (IAuth(msg.sender).owner() == sender && recipient == benneficiaryAddress) )) {\n revert Unauthorized();\n }\n (\n beneficiary,\n amount\n ) = beneficiary.withdraw(proposedAmount);\n // update the beneficiary in storage\n \\_agentBeneficiaries[agentID] = beneficiary;\n}\n\n",
        " sendAmount = agentPolice.beneficiaryWithdrawable(receiver, msg.sender, id, sendAmount);\n}\nelse if (msg.sender != owner()) {\n revert Unauthorized();\n}\n\n// unwrap any wfil needed to withdraw\n\\_poolFundsInFIL(sendAmount);\n// transfer funds\npayable(receiver).sendValue(sendAmount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by removing beneficiary logic completely."
    ],
    "Description": [
        "The beneficiaryWithdrawable function is supposed to be called by the Agent when a beneficiary is trying to withdraw funds:",
        "code/src/Agent/AgentPolice.sol:L320-L341",
        "This function reduces the quota that is supposed to be transferred during the withdraw call:",
        "code/src/Agent/Agent.sol:L343-L352",
        "The issue is that anyone can call this function directly, and the quota will be reduced without funds being transferred."
    ],
    "Recommendation": [
        "Ensure only the Agent can call this function."
    ]
}
----End JSON----

https://solodit.xyz/issues/an-agent-can-borrow-even-with-existing-debt-in-interest-payments-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\n if (vc.value < WAD) revert InvalidParams();\n // can't borrow more than the pool has\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\n Account memory account = \\_getAccount(vc.subject);\n // fresh account, set start epoch and epochsPaid to beginning of current window\n if (account.principal == 0) {\n uint256 currentEpoch = block.number;\n account.startEpoch = currentEpoch;\n account.epochsPaid = currentEpoch;\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\n }\n\n account.principal += vc.value;\n account.save(router, vc.subject, id);\n\n totalBorrowed += vc.value;\n\n emit Borrow(vc.subject, vc.value);\n\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\n asset.transfer(msg.sender, vc.value);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by adding a limit to the remaining interest debt when borrowing. So an agent should have an interest debt that is no larger than 1 day."
    ],
    "Description": [
        "To borrow funds, an Agent has to call the borrow function of the pool:",
        "code/src/Pool/InfinityPool.sol:L302-L325",
        "Let\u2019s assume that the Agent already had some funds borrowed. During this function execution, the current debt status is not checked. The principal debt increases after borrowing, but account.epochsPaid remains the same. So the pending debt will instantly increase as if the borrowing happened on account.epochsPaid."
    ],
    "Recommendation": [
        "Ensure the debt is paid when borrowing more funds."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-agentpolicedistributeliquidatedfunds-function-can-have-undistributed-residual-funds-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function distributeLiquidatedFunds(uint256 agentID, uint256 amount) external {\n if (!liquidated[agentID]) revert Unauthorized();\n\n // transfer the assets into the pool\n GetRoute.wFIL(router).transferFrom(msg.sender, address(this), amount);\n \\_writeOffPools(agentID, amount);\n}\n\n",
        "uint256 totalOwed = interestPaid + principalOwed;\n\nasset.transferFrom(\n msg.sender,\n address(this),\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\n);\n// write off only what we lost\ntotalBorrowed -= lostAmt;\n// set the account with the funds the pool lost\naccount.principal = lostAmt;\n\naccount.save(router, agentID, id);\n\nemit WriteOff(agentID, recoveredFunds, lostAmt, interestPaid);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by returning the excess funds in wFil to the Agent\u2019s owner. The only trick here is that the Agent\u2019s owner should be able to manage these funds."
    ],
    "Description": [
        "When an Agent is liquidated, the liquidator (owner of the protocol) is supposed to try to redeem as many funds as possible and re-distribute them to the pools:",
        "code/src/Agent/AgentPolice.sol:L185-L191",
        "The problem is that in the pool, it\u2019s accounted that the amount of funds can be larger than the debt. In that case, the pool won\u2019t transfer more funds than the pool needs:",
        "code/src/Pool/InfinityPool.sol:L275-L289",
        "If that happens, the remaining funds will be stuck in the AgentPolice contract."
    ],
    "Recommendation": [
        "Return the residual funds to the Agent\u2019s owner or process them in some way so they are not lost."
    ]
}
----End JSON----

https://solodit.xyz/issues/an-agent-can-be-upgraded-even-if-there-is-no-new-implementation-fixed-consensys-none-glif-filecoin-infinitypool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function upgradeAgent(\n address agent\n) external returns (address newAgent) {\n IAgent oldAgent = IAgent(agent);\n address owner = IAuth(address(oldAgent)).owner();\n uint256 agentId = agents[agent];\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\n // deploy a new instance of Agent with the same ID and auth\n newAgent = GetRoute.agentDeployer(router).deploy(\n router,\n agentId,\n owner,\n IAuth(address(oldAgent)).operator()\n );\n // Register the new agent and unregister the old agent\n agents[newAgent] = agentId;\n // transfer funds from old agent to new agent and mark old agent as decommissioning\n oldAgent.decommissionAgent(newAgent);\n // delete the old agent from the registry\n agents[agent] = 0;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by introducing a new version control mechanism. This solution also adds centralized power. The owner can create a new deployer with an arbitrary (even lower) version number, while agents can only upgrade to a higher version. Also, agents are forced to upgrade to a new version in another pull request."
    ],
    "Description": [
        "Agents can be upgraded to a new implementation, and only the Agent\u2019s owner can call the upgrade function:",
        "code/src/Agent/AgentFactory.sol:L51-L72",
        "The issue is that the owner can trigger the upgrade even if no new implementation exists. Multiple possible problems derive from it.",
        "The owner also has no control over the new version of the Agent. To increase decentralization, it\u2019s better to pass the deployer\u2019s address as a parameter additionally."
    ],
    "Recommendation": [
        "Ensure the upgrades can only happen when there is a new version of an Agent, and the owner controls this version."
    ]
}
----End JSON----

https://solodit.xyz/issues/infinitypool-contract-authorization-bypass-attack-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\n if (vc.value < WAD) revert InvalidParams();\n // can't borrow more than the pool has\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\n Account memory account = \\_getAccount(vc.subject);\n // fresh account, set start epoch and epochsPaid to beginning of current window\n if (account.principal == 0) {\n uint256 currentEpoch = block.number;\n account.startEpoch = currentEpoch;\n account.epochsPaid = currentEpoch;\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\n }\n\n account.principal += vc.value;\n account.save(router, vc.subject, id);\n\n totalBorrowed += vc.value;\n\n emit Borrow(vc.subject, vc.value);\n\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\n asset.transfer(msg.sender, vc.value);\n}\n\n",
        "modifier subjectIsAgentCaller(VerifiableCredential memory vc) {\n if (\n GetRoute.agentFactory(router).agents(msg.sender) != vc.subject\n ) revert Unauthorized();\n \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed by not allowing the vc.subject to be zero."
    ],
    "Description": [
        "An attacker could create their own credential and set the Agent ID to 0, which would bypass the subjectIsAgentCaller modifier. The attacker could use this attack to borrow funds from the pool, draining any available liquidity. For example, only an Agent should be able to borrow funds from the pool and call the borrow function:",
        "src/Pool/InfinityPool.sol:L302-L325",
        "The following modifier checks that the caller is an Agent:",
        "src/Pool/InfinityPool.sol:L96-L101",
        "But if the caller is not an Agent, the GetRoute.agentFactory(router).agents(msg.sender) will return 0. And if the vc.subject is also zero, the check will be successful with any msg.sender. The attacker can also pass an arbitrary vc.value as the parameter and steal all the funds from the pool."
    ],
    "Recommendation": [
        "Ensure only an Agent can call borrow and pass the subjectIsAgentCaller modifier."
    ]
}
----End JSON----

https://solodit.xyz/issues/agent-data-oracle-signed-credential-front-running-attack-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Mitigated by allowing only the Agent to request credentials."
    ],
    "Description": [
        "For almost every action as an Agent, the owner of the Agent is supposed to request SignedCredential data that contains all the relevant current info about the \u201coff-chain\u201d state of the Agent. New credentials can only be requested when the old one for this Agent is used or expired. Anyone can request these credentials, containing all the data about the call. So if the attacker consistently requests the credentials with the function and parameters that the actual Agent wouldn\u2019t want to call, the Agent won\u2019t be able to generate the credentials that are needed."
    ],
    "Recommendation": [
        "Ensure an Agent can always have new credentials that are needed. One solution would be to allow only an Agent\u2019s owner to request the credentials. The problem is that the beneficiary is also supposed to do that, but the beneficiary may also be a contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/wrong-accounting-for-totalborrowed-in-the-infinitypoolwriteoff-function-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// transfer the assets into the pool\n// whatever we couldn't pay back\nuint256 lostAmt = principalOwed > recoveredFunds ? principalOwed - recoveredFunds : 0;\n\nuint256 totalOwed = interestPaid + principalOwed;\n\nasset.transferFrom(\n msg.sender,\n address(this),\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\n);\n// write off only what we lost\ntotalBorrowed -= lostAmt;\n// set the account with the funds the pool lost\naccount.principal = lostAmt;\n\naccount.save(router, agentID, id);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed."
    ],
    "Description": [
        "Here is a part of the InfinityPool.writeOff function:",
        "src/Pool/InfinityPool.sol:L271-L287",
        "The totalBorrowed is decreased by the lostAmt value. Instead, it should be decreased by the original account.principal value to acknowledge the loss."
    ]
}
----End JSON----

https://solodit.xyz/issues/wrong-accounting-for-totalborrowed-in-the-infinitypoolpay-function-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// pay interest and principal\nprincipalPaid = vc.value - interestOwed;\n// the fee basis only applies to the interest payment\nfeeBasis = interestOwed;\n// protect against underflow\ntotalBorrowed -= (principalPaid > totalBorrowed) ? 0 : principalPaid;\n// fully paid off\nif (principalPaid >= account.principal) {\n // remove the account from the pool's list of accounts\n GetRoute.agentPolice(router).removePoolFromList(vc.subject, id);\n // return the amount of funds overpaid\n refund = principalPaid - account.principal;\n // reset the account\n account.reset();\n} else {\n // interest and partial principal payment\n account.principal -= principalPaid;\n // move the `epochsPaid` cursor to mark the account as \"current\"\n account.epochsPaid = block.number;\n}\n\n",
        "totalBorrowed -= (principalPaid > totalBorrowed) ? 0 : principalPaid;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed as recommended in two pull rquests: 1, 2."
    ],
    "Description": [
        "If the Agent pays more than the current interest debt, the remaining payment will be accounted as repayment of the principal debt:",
        "src/Pool/InfinityPool.sol:L382-L401",
        "Let\u2019s focus on the totalBorrowed changes:",
        "src/Pool/InfinityPool.sol:L387",
        "This value is supposed to be decreased by the principal that is repaid. So there are 2 mistakes in the calculation:"
    ]
}
----End JSON----

https://solodit.xyz/issues/the-beneficiarywithdrawable-function-can-be-called-by-anyone-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function beneficiaryWithdrawable(\n address recipient,\n address sender,\n uint256 agentID,\n uint256 proposedAmount\n) external returns (\n uint256 amount\n) {\n AgentBeneficiary memory beneficiary = \\_agentBeneficiaries[agentID];\n address benneficiaryAddress = beneficiary.active.beneficiary;\n // If the sender is not the owner of the Agent or the beneficiary, revert\n if(\n !(benneficiaryAddress == sender || (IAuth(msg.sender).owner() == sender && recipient == benneficiaryAddress) )) {\n revert Unauthorized();\n }\n (\n beneficiary,\n amount\n ) = beneficiary.withdraw(proposedAmount);\n // update the beneficiary in storage\n \\_agentBeneficiaries[agentID] = beneficiary;\n}\n\n",
        " sendAmount = agentPolice.beneficiaryWithdrawable(receiver, msg.sender, id, sendAmount);\n}\nelse if (msg.sender != owner()) {\n revert Unauthorized();\n}\n\n// unwrap any wfil needed to withdraw\n\\_poolFundsInFIL(sendAmount);\n// transfer funds\npayable(receiver).sendValue(sendAmount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by removing beneficiary logic completely."
    ],
    "Description": [
        "The beneficiaryWithdrawable function is supposed to be called by the Agent when a beneficiary is trying to withdraw funds:",
        "src/Agent/AgentPolice.sol:L320-L341",
        "This function reduces the quota that is supposed to be transferred during the withdraw call:",
        "src/Agent/Agent.sol:L343-L352",
        "The issue is that anyone can call this function directly, and the quota will be reduced without funds being transferred."
    ],
    "Recommendation": [
        "Ensure only the Agent can call this function."
    ]
}
----End JSON----

https://solodit.xyz/issues/an-agent-can-borrow-even-with-existing-debt-in-interest-payments-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function borrow(VerifiableCredential memory vc) external isOpen subjectIsAgentCaller(vc) {\n // 1e18 => 1 FIL, can't borrow less than 1 FIL\n if (vc.value < WAD) revert InvalidParams();\n // can't borrow more than the pool has\n if (totalBorrowableAssets() < vc.value) revert InsufficientLiquidity();\n Account memory account = \\_getAccount(vc.subject);\n // fresh account, set start epoch and epochsPaid to beginning of current window\n if (account.principal == 0) {\n uint256 currentEpoch = block.number;\n account.startEpoch = currentEpoch;\n account.epochsPaid = currentEpoch;\n GetRoute.agentPolice(router).addPoolToList(vc.subject, id);\n }\n\n account.principal += vc.value;\n account.save(router, vc.subject, id);\n\n totalBorrowed += vc.value;\n\n emit Borrow(vc.subject, vc.value);\n\n // interact - here `msg.sender` must be the Agent bc of the `subjectIsAgentCaller` modifier\n asset.transfer(msg.sender, vc.value);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by adding a limit to the remaining interest debt when borrowing. So an agent should have an interest debt that is no larger than 1 day."
    ],
    "Description": [
        "To borrow funds, an Agent has to call the borrow function of the pool:",
        "src/Pool/InfinityPool.sol:L302-L325",
        "Let\u2019s assume that the Agent already had some funds borrowed. During this function execution, the current debt status is not checked. The principal debt increases after borrowing, but account.epochsPaid remains the same. So the pending debt will instantly increase as if the borrowing happened on account.epochsPaid."
    ],
    "Recommendation": [
        "Ensure the debt is paid when borrowing more funds."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-agentpolicedistributeliquidatedfunds-function-can-have-undistributed-residual-funds-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function distributeLiquidatedFunds(uint256 agentID, uint256 amount) external {\n if (!liquidated[agentID]) revert Unauthorized();\n\n // transfer the assets into the pool\n GetRoute.wFIL(router).transferFrom(msg.sender, address(this), amount);\n \\_writeOffPools(agentID, amount);\n}\n\n",
        "uint256 totalOwed = interestPaid + principalOwed;\n\nasset.transferFrom(\n msg.sender,\n address(this),\n totalOwed > recoveredFunds ? recoveredFunds : totalOwed\n);\n// write off only what we lost\ntotalBorrowed -= lostAmt;\n// set the account with the funds the pool lost\naccount.principal = lostAmt;\n\naccount.save(router, agentID, id);\n\nemit WriteOff(agentID, recoveredFunds, lostAmt, interestPaid);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by returning the excess funds in wFil to the Agent\u2019s owner. The only trick here is that the Agent\u2019s owner should be able to manage these funds."
    ],
    "Description": [
        "When an Agent is liquidated, the liquidator (owner of the protocol) is supposed to try to redeem as many funds as possible and re-distribute them to the pools:",
        "src/Agent/AgentPolice.sol:L185-L191",
        "The problem is that in the pool, it\u2019s accounted that the amount of funds can be larger than the debt. In that case, the pool won\u2019t transfer more funds than the pool needs:",
        "src/Pool/InfinityPool.sol:L275-L289",
        "If that happens, the remaining funds will be stuck in the AgentPolice contract."
    ],
    "Recommendation": [
        "Return the residual funds to the Agent\u2019s owner or process them in some way so they are not lost."
    ]
}
----End JSON----

https://solodit.xyz/issues/an-agent-can-be-upgraded-even-if-there-is-no-new-implementation-fixed-consensys-none-glif-filecoin-infinitypool-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function upgradeAgent(\n address agent\n) external returns (address newAgent) {\n IAgent oldAgent = IAgent(agent);\n address owner = IAuth(address(oldAgent)).owner();\n uint256 agentId = agents[agent];\n // only the Agent's owner can upgrade, and only a registered agent can be upgraded\n if (owner != msg.sender || agentId == 0) revert Unauthorized();\n // deploy a new instance of Agent with the same ID and auth\n newAgent = GetRoute.agentDeployer(router).deploy(\n router,\n agentId,\n owner,\n IAuth(address(oldAgent)).operator()\n );\n // Register the new agent and unregister the old agent\n agents[newAgent] = agentId;\n // transfer funds from old agent to new agent and mark old agent as decommissioning\n oldAgent.decommissionAgent(newAgent);\n // delete the old agent from the registry\n agents[agent] = 0;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by introducing a new version control mechanism. This solution also adds centralized power. The owner can create a new deployer with an arbitrary (even lower) version number, while agents can only upgrade to a higher version. Also, agents are forced to upgrade to a new version in another pull request."
    ],
    "Description": [
        "Agents can be upgraded to a new implementation, and only the Agent\u2019s owner can call the upgrade function:",
        "src/Agent/AgentFactory.sol:L51-L72",
        "The issue is that the owner can trigger the upgrade even if no new implementation exists. Multiple possible problems derive from it.",
        "The owner also has no control over the new version of the Agent. To increase decentralization, it\u2019s better to pass the deployer\u2019s address as a parameter additionally."
    ],
    "Recommendation": [
        "Ensure the upgrades can only happen when there is a new version of an Agent, and the owner controls this version."
    ]
}
----End JSON----

https://solodit.xyz/issues/dependencies-with-publicly-known-vulnerabilities-out-of-scope-consensys-none-mobymask-mvp-snap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [
        "The snaps project defines a dependency (@truffle/[[email\u00a0protected]](/cdn-cgi/l/email-protection) within the yarn.lock file vulnerable to publicly known weaknesses rated as High or Medium in the CVSS scoring system. It should be noted that the identified areas were not directly in the scope of the code review and are listed for the sake of completeness.",
        "The following @truffle/[[email\u00a0protected]](/cdn-cgi/l/email-protection) weaknesses were identified:",
        "Review all identified dependencies and update the newest, stable version where applicable. Additionally, review the current patch policy to ensure the components are updated as soon as a fix exists.\nFor the identified vulnerable components, the following versions provide fixes:"
    ]
}
----End JSON----

https://solodit.xyz/issues/potential-reentrancy-into-strategies-consensys-eigenlabs-eigenlayer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdraw(address depositor, IERC20 token, uint256 amountShares)\n    external\n    virtual\n    override\n    onlyWhenNotPaused(PAUSED\\_WITHDRAWALS)\n    onlyStrategyManager\n{\n    require(token == underlyingToken, \"StrategyBase.withdraw: Can only withdraw the strategy token\");\n    // copy `totalShares` value to memory, prior to any decrease\n    uint256 priorTotalShares = totalShares;\n    require(\n        amountShares <= priorTotalShares,\n        \"StrategyBase.withdraw: amountShares must be less than or equal to totalShares\"\n    );\n\n    // Calculate the value that `totalShares` will decrease to as a result of the withdrawal\n    uint256 updatedTotalShares = priorTotalShares - amountShares;\n    // check to avoid edge case where share rate can be massively inflated as a 'griefing' sort of attack\n    require(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES || updatedTotalShares == 0,\n        \"StrategyBase.withdraw: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\n    // Actually decrease the `totalShares` value\n    totalShares = updatedTotalShares;\n\n    /\\*\\*\n \\* @notice calculation of amountToSend \\*mirrors\\* `sharesToUnderlying(amountShares)`, but is different since the `totalShares` has already\n \\* been decremented. Specifically, notice how we use `priorTotalShares` here instead of `totalShares`.\n \\*/\n    uint256 amountToSend;\n    if (priorTotalShares == amountShares) {\n        amountToSend = \\_tokenBalance();\n    } else {\n        amountToSend = (\\_tokenBalance() \\* amountShares) / priorTotalShares;\n    }\n\n    underlyingToken.safeTransfer(depositor, amountToSend);\n}\n\n",
        "function sharesToUnderlyingView(uint256 amountShares) public view virtual override returns (uint256) {\n    if (totalShares == 0) {\n        return amountShares;\n    } else {\n        return (\\_tokenBalance() \\* amountShares) / totalShares;\n    }\n}\n\n",
        "function \\_depositIntoStrategy(address depositor, IStrategy strategy, IERC20 token, uint256 amount)\n    internal\n    onlyStrategiesWhitelistedForDeposit(strategy)\n    returns (uint256 shares)\n{\n    // transfer tokens from the sender to the strategy\n    token.safeTransferFrom(msg.sender, address(strategy), amount);\n\n    // deposit the assets into the specified strategy and get the equivalent amount of shares in that strategy\n    shares = strategy.deposit(token, amount);\n\n",
        "function deposit(IERC20 token, uint256 amount)\n    external\n    virtual\n    override\n    onlyWhenNotPaused(PAUSED\\_DEPOSITS)\n    onlyStrategyManager\n    returns (uint256 newShares)\n{\n    require(token == underlyingToken, \"StrategyBase.deposit: Can only deposit underlyingToken\");\n\n    /\\*\\*\n \\* @notice calculation of newShares \\*mirrors\\* `underlyingToShares(amount)`, but is different since the balance of `underlyingToken`\n \\* has already been increased due to the `strategyManager` transferring tokens to this strategy prior to calling this function\n \\*/\n    uint256 priorTokenBalance = \\_tokenBalance() - amount;\n    if (priorTokenBalance == 0 || totalShares == 0) {\n        newShares = amount;\n    } else {\n        newShares = (amount \\* totalShares) / priorTokenBalance;\n    }\n\n    // checks to ensure correctness / avoid edge case where share rate can be massively inflated as a 'griefing' sort of attack\n    require(newShares != 0, \"StrategyBase.deposit: newShares cannot be zero\");\n    uint256 updatedTotalShares = totalShares + newShares;\n    require(updatedTotalShares >= MIN\\_NONZERO\\_TOTAL\\_SHARES,\n        \"StrategyBase.deposit: updated totalShares amount would be nonzero but below MIN\\_NONZERO\\_TOTAL\\_SHARES\");\n\n    // update total share amount\n    totalShares = updatedTotalShares;\n    return newShares;\n}\n\n",
        "function depositIntoStrategyWithSignature(\n    IStrategy strategy,\n    IERC20 token,\n    uint256 amount,\n    address staker,\n    uint256 expiry,\n    bytes memory signature\n)\n    external\n    onlyWhenNotPaused(PAUSED\\_DEPOSITS)\n    onlyNotFrozen(staker)\n    nonReentrant\n    returns (uint256 shares)\n{\n    require(\n        expiry >= block.timestamp,\n        \"StrategyManager.depositIntoStrategyWithSignature: signature expired\"\n    );\n    // calculate struct hash, then increment `staker`'s nonce\n    uint256 nonce = nonces[staker];\n    bytes32 structHash = keccak256(abi.encode(DEPOSIT\\_TYPEHASH, strategy, token, amount, nonce, expiry));\n    unchecked {\n        nonces[staker] = nonce + 1;\n    }\n    bytes32 digestHash = keccak256(abi.encodePacked(\"\\x19\\x01\", DOMAIN\\_SEPARATOR, structHash));\n\n\n    /\\*\\*\n \\* check validity of signature:\n \\* 1) if `staker` is an EOA, then `signature` must be a valid ECSDA signature from `staker`,\n \\* indicating their intention for this action\n \\* 2) if `staker` is a contract, then `signature` must will be checked according to EIP-1271\n \\*/\n    if (Address.isContract(staker)) {\n        require(IERC1271(staker).isValidSignature(digestHash, signature) == ERC1271\\_MAGICVALUE,\n            \"StrategyManager.depositIntoStrategyWithSignature: ERC1271 signature verification failed\");\n    } else {\n        require(ECDSA.recover(digestHash, signature) == staker,\n            \"StrategyManager.depositIntoStrategyWithSignature: signature not from staker\");\n    }\n\n    shares = \\_depositIntoStrategy(staker, strategy, token, amount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "EigenLabs Quick Summary: The StrategyBase contract may be vulnerable to a token contract that employs some sort of callback to a function like sharesToUnderlyingView, before the balance change is reflected in the contract. The shares have been decremented, which would lead to an incorrect return value from sharesToUnderlyingView.",
        "EigenLabs Response: As noted in the report, this is not an issue if the token contract being used does not allow for reentrancy. For now, we will make it clear both in the contracts as well as the docs that our implementation of StrategyBase.sol does not support tokens with reentrancy. Because of the way our system is designed, anyone can choose to design a strategy with this in mind!"
    ],
    "Description": [
        "The StrategyManager contract is the entry point for deposits into and withdrawals from strategies. More specifically, to deposit into a strategy, a staker calls depositIntoStrategy (or anyone calls depositIntoStrategyWithSignature with the staker\u2019s signature) then the asset is transferred from the staker to the strategy contract. After that, the strategy\u2019s deposit function is called, followed by some bookkeeping in the StrategyManager. For withdrawals (and slashing), the StrategyManager calls the strategy\u2019s withdraw function, which transfers the given amount of the asset to the given recipient. Both token transfers are a potential source of reentrancy if the token allows it.",
        "The StrategyManager uses OpenZeppelin\u2019s ReentrancyGuardUpgradeable as reentrancy protection, and the relevant functions have a nonReentrant modifier. The StrategyBase contract \u2013 from which concrete strategies should be derived \u2013 does not have reentrancy protection. However, the functions deposit and withdraw can only be called from the StrategyManager, so reentering these is impossible.",
        "Nevertheless, other functions could be reentered, for example, sharesToUnderlyingView and underlyingToSharesView, as well as their (supposedly) non-view counterparts.",
        "Let\u2019s look at the withdraw function in StrategyBase. First, the amountShares shares are burnt, and at the end of the function, the equivalent amount of token is transferred to the depositor:",
        "src/contracts/strategies/StrategyBase.sol:L108-L143",
        "If we assume that the token contract has a callback to the recipient of the transfer before the actual balance changes take place, then the recipient could reenter the strategy contract, for example, in sharesToUnderlyingView:",
        "src/contracts/strategies/StrategyBase.sol:L159-L165",
        "The crucial point is: If the callback is executed before the actual balance change, then sharesToUnderlyingView will report a bad result because the shares have already been burnt. Still, the token balance has not been updated yet.",
        "For deposits, the token transfer to the strategy happens first, and the shares are minted after that:",
        "src/contracts/core/StrategyManager.sol:L643-L652",
        "src/contracts/strategies/StrategyBase.sol:L69-L99",
        "That means if there is a callback in the token\u2019s transferFrom function and it is executed after the balance change, a reentering call to sharesToUnderlyingView (for example) will again return a wrong result because shares and token balances are not \u201cin sync.\u201d",
        "In addition to the reversed order of token transfer and shares update, there\u2019s another vital difference between withdraw and deposit: For withdrawals, the call to the token contract originates in the strategy, while for deposits, it is the strategy manager that initiates the call to the token contract (before calling into the strategy). That\u2019s a technicality that has consequences for reentrancy protection: Note that for withdrawals, it is the strategy contract that is reentered, while for deposits, there is not a single contract that is reentered; instead, it is the contract system that is in an inconsistent state when the reentrancy happens. Hence, reentrancy protection on the level of individual contracts is not sufficient.",
        "Finally, we want to discuss though which functions in the strategy contract the system could be reentered. As mentioned, deposit and withdraw can only be called by the strategy manager, so these two can be ruled out. For the examples above, we considered sharesToUnderlyingView, which (as the name suggests) is a view function. As such, it can\u2019t change the state of the contract, so reentrancy through a view function can only be a problem for other contracts that use this function and rely on its return value. However, there is also a potentially state-changing variant, sharesToUnderlying, and similar potentially state-changing functions, such as underlyingToShares and userUnderlying. Currently, these functions are not actually state-changing, but the idea is that they could be and, in some concrete strategy implementations that inherit from StrategyBase, will be. In such cases, these functions could make wrong state changes due to state inconsistency during reentrancy.",
        "The examples above assume that the token contract allows reentrancy through its transfer function before the balance change has been made or in its transferFrom function after. It might be tempting to argue that tokens which don\u2019t fall into this category are safe to use. While the examples discussed above are the most interesting attack vectors we found, there might still be others: To illustrate this point, assume a token contract that allows reentrancy through transferFrom only before any state change in the token takes place. The token transfer is the first thing that happens in StrategyManager._depositIntoStrategy, and the state changes (user shares) and calling the strategy\u2019s deposit function occur later, this might look safe. However, if the deposit happens via StrategyManager.depositIntoStrategyWithSignature, then it can be seen, for example, that the staker\u2019s nonce is updated before the internal _depositIntoStrategy function is called:",
        "src/contracts/core/StrategyManager.sol:L244-L286",
        "Hence, querying the staker\u2019s nonce in reentrancy would still give a result based on an \u201cincomplete state change.\u201d It is, for example, conceivable that the staker still has zero shares, and yet their nonce is already 1. This particular situation is most likely not an issue, but the example shows that reentrancy can be subtle."
    ],
    "Recommendation": [
        "This is fine if the token doesn\u2019t allow reentrancy in the first place. As discussed above, among the tokens that do allow reentrancy, some variants of when reentrancy can happen in relation to state changes in the token seem more dangerous than others, but we have also argued that this kind of reasoning can be dangerous and error-prone. Hence, we recommend employing comprehensive and defensive reentrancy protection based on reentrancy guards such as OpenZeppelin\u2019s ReentrancyGuardUpgradeable, which is already used in the StrategyManager.",
        "Unfortunately, securing a multi-contract system against reentrancy can be challenging, but we hope the preceding discussion and the following pointers will prove helpful:"
    ]
}
----End JSON----

https://solodit.xyz/issues/funds-refunded-from-celer-bridge-might-be-stolen-consensys-socket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (!router.withdraws(transferId)) {\n    router.withdraw(\\_request, \\_sigs, \\_signers, \\_powers);\n}\n\n",
        "if (delayThreshold > 0 && wdmsg.amount > delayThreshold) {\r\n     _addDelayedTransfer(wdId, wdmsg.receiver, wdmsg.token, wdmsg. // <--- here\r\n} else {\r\n      _sendToken(wdmsg.receiver, wdmsg.token, wdmsg.\r\n}\r\n\n",
        "function bridgeAfterSwap(\n    uint256 amount,\n    bytes calldata bridgeData\n) external payable override {\n    CelerBridgeData memory celerBridgeData = abi.decode(\n        bridgeData,\n        (CelerBridgeData)\n    );\n\n",
        "function swapAndBridge(\n    uint32 swapId,\n    bytes calldata swapData,\n    StargateBridgeDataNoToken calldata stargateBridgeData\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the client team in SocketDotTech/socket-ll-contracts#144 by adding checks to see if the refund is received and equal to the expected amount."
    ],
    "Description": [
        "The function refundCelerUser from CelerImpl.sol allows a user that deposited into the Celer pool on the source chain, to be refunded for tokens that were not bridged to the destination chain. The tokens are reimbursed to the user by calling the withdraw method on the Celer pool. This is what the refundCelerUser function is doing.",
        "src/bridges/cbridge/CelerImpl.sol:L413-L415",
        "From the point of view of the Celer bridge, the initial depositor of the tokens is the SocketGateway. As a consequence, the Celer contract transfers the tokens to be refunded to the gateway. The gateway is then in charge of forwarding the tokens to the initial depositor. To achieve this, it keeps a mapping of unique transfer IDs to depositor addresses. Once a refund is processed, the corresponding address in the mapping is reset to the zero address.",
        "Looking at the withdraw function of the Celer pool, we see that for some tokens, it is possible that the reimbursement will not be processed directly, but only after some delay. From the gateway point of view, the reimbursement will be marked as successful, and the address of the original sender corresponding to this transfer ID will be reset to address(0).",
        "It is then the responsibility of the user, once the locking delay has passed, to call another function to claim the tokens. Unfortunately, in our case, this means that the funds will be sent back to the gateway contract and not to the original sender. Because the gateway implements rescueEther, and rescueFunds functions, the admin might be able to send the funds back to the user. However, this requires manual intervention and breaks the trustlessness assumptions of the system. Also, in that case, there is no easy way to trace back the original address of the sender, that corresponds to this refund.",
        "However, there is an additional issue that might allow an attacker to steal some funds from the gateway. Indeed, when claiming the refund, if it is in ETH, the gateway will have some balance when the transaction completes. Any user can then call any function that consumes the gateway balance, such as the swapAndBridge from CelerImpl, to steal the refunded ETH. That is possible as the function relies on a user-provided amount as an input, and not on msg.value.\nAdditionally, if the refund is an ERC-20, an attacker can steal the funds by calling bridgeAfterSwap or swapAndBridge from the Stargate or Celer routes with the right parameters.",
        "src/bridges/cbridge/CelerImpl.sol:L120-L127",
        "src/bridges/stargate/l2/Stargate.sol:L183-L186",
        "Note that this violates the security assumption: \u201cThe contracts are not supposed to hold any funds post-tx execution.\u201d"
    ],
    "Recommendation": [
        "Make sure that CelerImpl supports also the delayed withdrawals functionality and that withdrawal requests are deleted only if the receiver has received the withdrawal in a single transaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/calls-made-to-non-existentremoved-routes-or-controllers-will-not-result-in-failure-consensys-socket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(bool success, bytes memory result) = addressAt(routeId).delegatecall(\n\n",
        ".delegatecall(swapData);\n\n",
        ".delegatecall(swapData);\n\n",
        ".delegatecall(swapData);\n\n",
        ".delegatecall(data);\n\n",
        "function addressAt(uint32 routeId) public view returns (address) {\n    if (routeId < 513) {\n        if (routeId < 257) {\n            if (routeId < 129) {\n                if (routeId < 65) {\n                    if (routeId < 33) {\n                        if (routeId < 17) {\n                            if (routeId < 9) {\n                                if (routeId < 5) {\n                                    if (routeId < 3) {\n                                        if (routeId == 1) {\n                                            return\n                                                0x822D4B4e63499a576Ab1cc152B86D1CFFf794F4f;\n                                        } else {\n                                            return\n                                                0x822D4B4e63499a576Ab1cc152B86D1CFFf794F4f;\n                                        }\n                                    } else {\n\n",
        "if (routes[routeId] == address(0)) revert ZeroAddressNotAllowed();\nreturn routes[routeId];\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the client team in SocketDotTech/socket-ll-contracts#145 by adding a disabledRouteAddress contract to be returned for disabled routes instead of a address(0)."
    ],
    "Description": [
        "This issue was found in commit hash a8d0ad1c280a699d88dc280d9648eacaf215fb41.",
        "In the Ethereum Virtual Machine (EVM), delegatecall will succeed for calls to externally owned accounts and more specifically to the zero address, which presents a potential security risk. We have identified multiple instances of delegatecall being used to invoke smart contract functions.",
        "This, combined with the fact that routes can be removed from the system by the owner of the SocketGateway contract using the disableRoute function, makes it possible for the user\u2019s funds to be lost in case of an executeRoute transaction (for instance) that\u2019s waiting in the mempool is eventually being front-ran by a call to disableRoute."
    ],
    "Examples": [
        "src/SocketGateway.sol:L95",
        "src/bridges/cbridge/CelerImpl.sol:L208",
        "src/bridges/stargate/l1/Stargate.sol:L187",
        "src/bridges/stargate/l2/Stargate.sol:L190",
        "src/controllers/BaseController.sol:L50",
        "Even after the upgrade to commit hash d0841a3e96b54a9d837d2dba471aa0946c3c8e7b, the following bug is still present:",
        "To optimize gas usage, the addressAt function in socketGateway uses a binary search in a hard-coded table to resolve a routeID (routeID <= 512) to a contract address. This is made possible thanks to the factory using the CREATE2 pattern. This allows to pre-compute future addresses of contracts before they are deployed. In case the routeID is strictly greater than 512, addressAt falls back to fetching the address from a state mapping (routes).",
        "The new commit hash adds a check to make sure that the call to the addressAt function reverts in case a routeID is not present in the routes mapping. This prevents delegate-calling to non-existent addresses in various places of the code. However, this does not solve the issue for the hard-coded route addresses (i.e., routeID <= 512). In that case, the addressAt function still returns a valid route contract address, despite the contract not being deployed yet. This will result in a successful delegatecall later in the code and might lead to various side-effects.",
        "src/SocketGateway.sol:L411-L428",
        "src/SocketGateway.sol:L2971-L2972"
    ],
    "Recommendation": [
        "Consider adding a check to validate that the callee of a delegatecall is indeed a contract, you may refer to the Address library by OZ."
    ]
}
----End JSON----

https://solodit.xyz/issues/owner-can-add-arbitrary-code-to-be-executed-from-the-socketgateway-contract-consensys-socket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "celerStorageWrapper.setAddressForTransferId(transferId, msg.sender);\n\n",
        "/\\*\\*\n \\* @title CelerStorageWrapper\n \\* @notice handle storageMappings used while bridging ERC20 and native on CelerBridge\n \\* @dev all functions ehich mutate the storage are restricted to Owner of SocketGateway\n \\* @author Socket dot tech.\n \\*/\ncontract CelerStorageWrapper {\n\n",
        "function setAddressForTransferId(\n\n",
        "function deleteTransferId(bytes32 transferId) external {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client team has responded with the following note:"
    ],
    "Description": [
        "The Socket system is managed by the SocketGateway contract that maintains all routes and controller addresses within its state. There, the address with the Owner role of the SocketGateway contract can add new routes and controllers that would have a delegatecall() executed upon them from the SocketGateway so user transactions can go through the logic required for the bridge, swap, or any other solution integrated with Socket. These routes and controllers would then have arbitrary code that is entirely up to the Owner, though users are not required to go through any specific routes and can decide which routes to pick.",
        "Since these routes are called via delegatecall(), they don\u2019t hold any storage variables that would be used in the Socket systems. However, as Socket aggregates more solutions, unexpected complexities may arise that could require storing and accessing variables through additional contracts. Those contracts would be access control protected to only have the SocketGateway contract have the privileges to modify its variables.",
        "This together with the Owner of the SocketGateway being able to add routes with arbitrary code creates an attack vector where a compromised address with Owner privileges may add a route that would contain code that exploits the special privileges assigned to the SocketGateway contract for their benefit.",
        "For example, the Celer bridge needs extra logic to account for its refund mechanism, so there is an additional CelerStorageWrapper contract that maintains a mapping between individual bridge transfer transactions and their associated msg.sender:",
        "src/bridges/cbridge/CelerImpl.sol:L145",
        "src/bridges/cbridge/CelerStorageWrapper.sol:L6-L12",
        "Consequently, this contract has access-protected functions that may only be called by the SocketGateway to set and delete the transfer IDs:",
        "src/bridges/cbridge/CelerStorageWrapper.sol:L32",
        "src/bridges/cbridge/CelerStorageWrapper.sol:L52",
        "A compromised Owner of SocketGateway could then create a route that calls into the CelerStorageWrapper contract and updates the transfer IDs associated addresses to be under their control via deleteTransferId() and setAddressForTransferId() functions. This could create a significant drain of user funds, though, it depends on a compromised privileged Owner address."
    ],
    "Recommendation": [
        "Although it may indeed be unlikely, for aggregating solutions it is especially important to try and minimize compromised access issues. As future solutions require more complexity, consider architecting their integrations in such a way that they require as few administrative and SocketGateway-initiated transactions as possible. Through conversations with the Socket team, it appears that solutions such as timelocks on adding new routes are being considered as well, which would help catch the problem before it appears as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/dependency-on-third-party-apis-to-create-the-right-payload-consensys-socket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// additional data is generated in off-chain using the OneInch API which takes in\n// fromTokenAddress, toTokenAddress, amount, fromAddress, slippage, destReceiver, disableEstimate\n(bool success, bytes memory result) = ONEINCH\\_AGGREGATOR.call(\n    swapExtraData\n);\n\n",
        "emit SocketSwapTokens(\n    fromToken,\n    toToken,\n    returnAmount,\n    amount,\n    OneInchIdentifier,\n    receiverAddress\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client team has responded with the following note:"
    ],
    "Description": [
        "The Socket system of routes and controllers integrates swaps, bridges, and potentially other solutions that are vastly different from each other. The function arguments that are required to execute them may often seem like a black box of a payload for a typical end user. In fact, even when users explicitly provide a destination token with an associated amount for a swap, these arguments themselves might not even be fully (or at all) used in the route itself. Instead, often the routes and controllers accept a bytes payload that contains all the necessary data for its action. These data payloads are generated off-chain, often via centralized APIs provided by the integrated systems themselves, which is understandable in isolation as they have to be generated somewhere at some point. However, the provided bytes do not get checked for their correctness or matching with the other arguments that the user explicitly provided. Even the events that get emitted refer to the individual arguments of functions as opposed to what actually was being used to execute the logic.",
        "For example, the implementation route for the 1inch swaps explicitly asks the user to provide fromToken, toToken, amount, and receiverAddress, however only fromToken and amount are used meaningfully to transfer the amount to the SocketGateway and approve the fromToken to be spent by the 1inch contract. Everything else is dictated by swapExtraData, including even the true amount that is getting swapped. A mishap in the API providing this data payload could cause much less of a token amount to be swapped, a wrong address to receive the swap, and even the wrong destination token to return.",
        "src/swap/oneinch/OneInchImpl.sol:L59-L63",
        "Even the event at the end of the transaction partially refers to the explicitly provided arguments instead of those that actually facilitated the execution of logic",
        "src/swap/oneinch/OneInchImpl.sol:L84-L91",
        "As Socket aggregates other solutions, it naturally incurs the trust assumptions and risks associated with its integrations. In some ways, they even stack on top of each other, especially in those Socket functions that batch several routes together \u2013 all of them and their associated API calls need to return the correct payloads. So, there is an opportunity to minimize these risks by introducing additional checks into the contracts that would verify the correctness of the payloads that are passed over to the routes and controllers. In fact, creating these payloads within the contracts would allow other systems to integrate Socket more simpler as they could just call the functions with primary logical arguments such as the source token, destination token, and amount."
    ],
    "Recommendation": [
        "Consider allocating additional checks within the route implementations that ensure that the explicitly passed arguments match what is being sent for execution to the integrated solutions, like in the above example with the 1inch implementation."
    ]
}
----End JSON----

https://solodit.xyz/issues/nativeoptimismimpl-events-will-not-be-emitted-in-case-of-non-native-tokens-bridging-consensys-socket-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function bridgeAfterSwap(\n\n",
        "function swapAndBridge(\n\n",
        "function bridgeERC20To(\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the client team in SocketDotTech/socket-ll-contracts#146 by moving the event above the bridging code, making sure events are emitted for all cases, and adding the fix to other functions that had a similar issue."
    ],
    "Description": [
        "In the case of the usage of non-native tokens by users, the SocketBridge event will not be emitted since the code will return early."
    ],
    "Examples": [
        "src/bridges/optimism/l1/NativeOptimism.sol:L110",
        "src/bridges/optimism/l1/NativeOptimism.sol:L187",
        "src/bridges/optimism/l1/NativeOptimism.sol:L283"
    ],
    "Recommendation": [
        "Make sure that the SocketBridge event is emitted for non-native tokens as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketnodedistributordelegate-reentrancy-in-distribute-allows-node-owner-to-drain-distributor-funds-fixed-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Distributes the balance of this contract to its owners\nfunction distribute() override external {\n    // Calculate node share\n    uint256 nodeShare = getNodeShare();\n    // Transfer node share\n    address withdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\n    (bool success,) = withdrawalAddress.call{value : nodeShare}(\"\");\n    require(success);\n    // Transfer user share\n    uint256 userShare = address(this).balance;\n    address rocketTokenRETH = rocketStorage.getAddress(rocketTokenRETHKey);\n    payable(rocketTokenRETH).transfer(userShare);\n    // Emit event\n    emit FeesDistributed(nodeAddress, userShare, nodeShare, block.timestamp);\n}\n\n",
        "// Set a node's withdrawal address\nfunction setWithdrawalAddress(address \\_nodeAddress, address \\_newWithdrawalAddress, bool \\_confirm) external override {\n    // Check new withdrawal address\n    require(\\_newWithdrawalAddress != address(0x0), \"Invalid withdrawal address\");\n    // Confirm the transaction is from the node's current withdrawal address\n    address withdrawalAddress = getNodeWithdrawalAddress(\\_nodeAddress);\n    require(withdrawalAddress == msg.sender, \"Only a tx from a node's withdrawal address can update it\");\n    // Update immediately if confirmed\n    if (\\_confirm) {\n        updateWithdrawalAddress(\\_nodeAddress, \\_newWithdrawalAddress);\n    }\n    // Set pending withdrawal address if not confirmed\n    else {\n        pendingWithdrawalAddresses[\\_nodeAddress] = \\_newWithdrawalAddress;\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in https://github.com/rocket-pool/rocketpool/tree/77d7cca65b7c0557cfda078a4fc45f9ac0cc6cc6 by implementing a custom reentrancy guard via a new state variable lock that is appended to the end of the storage layout. The reentrancy guard is functionally equivalent to the OpenZeppelin implementation. The method was not refactored to give user funds priority over the node share. Additionally, the client provided the following statement:"
    ],
    "Description": [
        "The distribute() function distributes the contract\u2019s balance between the node operator and the user. The node operator is returned their initial collateral, including a fee. The rest is returned to the RETH token contract as user collateral.",
        "After determining the node owner\u2019s share, the contract transfers ETH to the node withdrawal address, which can be the configured withdrawal address or the node address. Both addresses may potentially be a malicious contract that recursively calls back into the distribute() function to retrieve the node share multiple times until all funds are drained from the contract. The distribute() function is not protected against reentrancy:",
        "code/contracts/contract/node/RocketNodeDistributorDelegate.sol:L59-L73",
        "We also noticed that any address could set a withdrawal address as there is no check for the caller to be a registered node. In fact, the caller can be the withdrawal address or node operator.",
        "code/contracts/contract/RocketStorage.sol:L118-L133"
    ],
    "Recommendation": [
        "Add a reentrancy guard to functions that interact with untrusted contracts. Adhere to the checks-effects pattern and send user funds to the \u2018trusted\u2019 RETH contract first. Only then send funds to the node\u2019s withdrawal address."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketminipooldelegateold-node-operator-may-reenter-finalise-to-manipulate-accounting-fixed-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "finalise() --> \r\n  status == MinipoolStatus.Withdrawable  //<-- true\r\n  withdrawalBlock > 0  //<-- true\r\n  _finalise() -->\r\n     !finalised  //<-- true\r\n        _refund()\r\n            nodeRefundBalance = 0  //<-- reset refund balance\r\n              ---> extCall: nodeWithdrawalAddress\r\n                     ---> reenter: finalise()\r\n                        status == MinipoolStatus.Withdrawable  //<-- true\r\n                        withdrawalBlock > 0  //<-- true\r\n                        _finalise() -->\r\n                             !finalised  //<-- true\r\n                             nodeRefundBalance > 0  //<-- false; no refund()\r\n                             address(this).balance to RETH\r\n                             RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral()\r\n                             rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress)  //<-- 1st time\r\n                             eventually call rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress); \r\n                             finalised = true;\r\n                   <--- return from reentrant call\r\n        <--- return from _refund()\r\n     address(this).balance to RETH  //<-- NOP as balance was sent to RETH already\r\n     RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral();   //<-- does not revert\r\n     rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress);  //<-- no revert, increases\r\n     'node.minipools.finalised.count', 'minipools.finalised.count', reduces 'eth.matched.node.amount' one to\r\n     many times\r\n     eventually call rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress);  //<-- manipulates\r\n     'member.validator.unbonded.count' by +1\r\n     finalised = true;  //<-- is already 'true', gracefully continues\r\n<--- returns      \r\n\n",
        "\n// Called by node operator to finalise the pool and unlock their RPL stake\nfunction finalise() external override onlyInitialised onlyMinipoolOwnerOrWithdrawalAddress(msg.sender) {\n    // Can only call if withdrawable and can only be called once\n    require(status == MinipoolStatus.Withdrawable, \"Minipool must be withdrawable\");\n    // Node operator cannot finalise the pool unless distributeBalance has been called\n    require(withdrawalBlock > 0, \"Minipool balance must have been distributed at least once\");\n    // Finalise the pool\n    \\_finalise();\n}\n\n",
        "// Perform any slashings, refunds, and unlock NO's stake\nfunction \\_finalise() private {\n    // Get contracts\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\n    // Can only finalise the pool once\n    require(!finalised, \"Minipool has already been finalised\");\n    // If slash is required then perform it\n    if (nodeSlashBalance > 0) {\n        \\_slash();\n    }\n    // Refund node operator if required\n    if (nodeRefundBalance > 0) {\n        \\_refund();\n    }\n    // Send any left over ETH to rETH contract\n    if (address(this).balance > 0) {\n        // Send user amount to rETH contract\n        payable(rocketTokenRETH).transfer(address(this).balance);\n    }\n    // Trigger a deposit of excess collateral from rETH contract to deposit pool\n    RocketTokenRETHInterface(rocketTokenRETH).depositExcessCollateral();\n    // Unlock node operator's RPL\n    rocketMinipoolManager.incrementNodeFinalisedMinipoolCount(nodeAddress);\n    // Update unbonded validator count if minipool is unbonded\n    if (depositType == MinipoolDeposit.Empty) {\n        RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\n        rocketDAONodeTrusted.decrementMemberUnbondedValidatorCount(nodeAddress);\n    }\n    // Set finalised flag\n    finalised = true;\n}\n\n",
        "function \\_refund() private {\n    // Update refund balance\n    uint256 refundAmount = nodeRefundBalance;\n    nodeRefundBalance = 0;\n    // Get node withdrawal address\n    address nodeWithdrawalAddress = rocketStorage.getNodeWithdrawalAddress(nodeAddress);\n    // Transfer refund amount\n    (bool success,) = nodeWithdrawalAddress.call{value : refundAmount}(\"\");\n    require(success, \"ETH refund amount was not successfully transferred to node operator\");\n    // Emit ether withdrawn event\n    emit EtherWithdrawn(nodeWithdrawalAddress, refundAmount, block.timestamp);\n}\n\n",
        "// Increments \\_nodeAddress' number of minipools that have been finalised\nfunction incrementNodeFinalisedMinipoolCount(address \\_nodeAddress) override external onlyLatestContract(\"rocketMinipoolManager\", address(this)) onlyRegisteredMinipool(msg.sender) {\n    // Update the node specific count\n    addUint(keccak256(abi.encodePacked(\"node.minipools.finalised.count\", \\_nodeAddress)), 1);\n    // Update the total count\n    addUint(keccak256(bytes(\"minipools.finalised.count\")), 1);\n}\n\n\n",
        "}\nfunction decrementMemberUnbondedValidatorCount(address \\_nodeAddress) override external onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) onlyRegisteredMinipool(msg.sender) {\n    subUint(keccak256(abi.encodePacked(daoNameSpace, \"member.validator.unbonded.count\", \\_nodeAddress)), 1);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement:",
        "In a later revision, the development team fixed the issue in the following commit: 73d5792a671db5d2f4dcbd35737e729f9e01aa11"
    ],
    "Description": [
        "In the old Minipool delegate contract, a node operator may call the finalise() function to finalize a Minipool. As part of this process, a call to _refund() may be performed if there is a node refund balance to be transferred. This will send an amount of nodeRefundBalance in ETH to the nodeWithdrawalAddress via a low-level call, handing over control flow to an - in terms of the system - untrusted external account that this node operator controls. The node operator, therefore, is granted to opportunity to call back into finalise(), which is not protected against reentrancy and violates the checks-effects-interactions pattern (finalised = true is only set at the very end), to manipulate the following system settings:",
        "Note: RocketMinipoolDelegateOld is assumed to be the currently deployed MiniPool implementation. Users may upgrade from this delegate to the new version and can roll back at any time and re-upgrade, even within the same transaction (see issue 5.3 ).",
        "The following is an annotated call stack from a node operator calling minipool.finalise() reentering finalise() once more on their Minipool:",
        "code/contracts/contract/old/minipool/RocketMinipoolDelegateOld.sol:L182-L191",
        "_refund() handing over control flow to nodeWithdrawalAddress",
        "code/contracts/contract/old/minipool/RocketMinipoolDelegateOld.sol:L311-L341",
        "code/contracts/contract/old/minipool/RocketMinipoolDelegateOld.sol:L517-L528",
        "Methods adjusting system settings called twice:",
        "code/contracts/contract/old/minipool/RocketMinipoolManagerOld.sol:L265-L272",
        "code/contracts/contract/dao/node/RocketDAONodeTrusted.sol:L139-L142"
    ],
    "Recommendation": [
        "We recommend setting the finalised = true flag immediately after checking for it. Additionally, the function flow should adhere to the checks-effects-interactions pattern whenever possible. We recommend adding generic reentrancy protection whenever the control flow is handed to an untrusted entity."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketminipooldelegate-sandwiching-of-minipool-calls-can-have-unintended-side-effects-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_slash() private {\n    // Get contracts\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\n    // Slash required amount and reset storage value\n    uint256 slashAmount = nodeSlashBalance;\n    nodeSlashBalance = 0;\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\n    // Record slashing\n    slashed = true;\n}\n\n",
        "function \\_slash() private {\n    // Get contracts\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\n    // Slash required amount and reset storage value\n    uint256 slashAmount = nodeSlashBalance;\n    nodeSlashBalance = 0;\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client provided the following statement:",
        "With https://github.com/rocket-pool/rocketpool/tree/77d7cca65b7c0557cfda078a4fc45f9ac0cc6cc6 the slashed flag was moved to RocketNodeStaking.slashRPL() (minipool.rpl.slashed|<msg.sender> = true).",
        "The audit team acknowledges that this issue does not provide a concrete exploit that puts funds at risk. However, due to the sensitive nature and potential for issues regarding future updates, we stand by the initial severity rating as it stands for security vulnerabilities that may not be directly exploitable or require certain conditions to be exploited."
    ],
    "Description": [
        "The RocketMinipoolBase contract exposes the functions delegateUpgrade and delegateRollback, allowing the minipool owner to switch between delegate implementations. While giving the minipool owner a chance to roll back potentially malfunctioning upgrades, the fact that upgrades and rollback are instantaneous also gives them a chance to alternate between executing old and new code (e.g. by utilizing callbacks) and sandwich user calls to the minipool."
    ],
    "Examples": [
        "Assuming the latest minipool delegate implementation, any user can call RocketMinipoolDelegate.slash, which slashes the node operator\u2019s RPL balance if a slashing has been recorded on their validator. To mark the minipool as having been slashed, the slashed contract variable is set to true. A minipool owner can avoid this flag from being set By sandwiching the user calls:",
        "In detail, the new slash implementation:",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L687-L696",
        "Compared to the old slash implementation:",
        "code/contracts/contract/old/minipool/RocketMinipoolDelegateOld.sol:L531-L539",
        "While the bypass of slashed being set is a benign example, the effects of this issue, in general, could result in a significant disruption of minipool operations and potentially affect the system\u2019s funds. The impact highly depends on the changes introduced by future minipool upgrades."
    ],
    "Recommendation": [
        "We recommend limiting upgrades and rollbacks to prevent minipool owners from switching implementations with an immediate effect. A time lock can fulfill this purpose when a minipool owner announces an upgrade to be done at a specific block. A warning can precede user-made calls that an upgrade is pending, and their interaction can have unintended side effects."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaonodetrustedactions-no-way-to-access-eth-provided-by-non-member-votes-acknowledged-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// In the event that the majority/all of members go offline permanently and no more proposals could be passed, a current member or a regular node can 'challenge' a DAO members node to respond\n// If it does not respond in the given window, it can be removed as a member. The one who removes the member after the challenge isn't met, must be another node other than the proposer to provide some oversight\n// This should only be used in an emergency situation to recover the DAO. Members that need removing when consensus is still viable, should be done via the 'kick' method.\nfunction actionChallengeMake(address \\_nodeAddress) override external onlyTrustedNode(\\_nodeAddress) onlyRegisteredNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrustedActions\", address(this)) payable {\n    // Load contracts\n    RocketDAONodeTrustedInterface rocketDAONode = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\n    RocketDAONodeTrustedSettingsMembersInterface rocketDAONodeTrustedSettingsMembers = RocketDAONodeTrustedSettingsMembersInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMembers\"));\n    // Members can challenge other members for free, but for a regular bonded node to challenge a DAO member, requires non-refundable payment to prevent spamming\n    if(rocketDAONode.getMemberIsValid(msg.sender) != true) require(msg.value == rocketDAONodeTrustedSettingsMembers.getChallengeCost(), \"Non DAO members must pay ETH to challenge a members node\");\n    // Can't challenge yourself duh\n    require(msg.sender != \\_nodeAddress, \"You cannot challenge yourself\");\n    // Is this member already being challenged?\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "According to the client, this is the intended behavior. The client provided the following statement:"
    ],
    "Description": [
        "DAO members can challenge nodes to prove liveliness for free. Non-DAO members must provide members.challenge.cost = 1 eth to start a challenge. However, the provided challenge cost is locked within the contract instead of being returned or recycled as system collateral."
    ],
    "Examples": [
        "code/contracts/contract/dao/node/RocketDAONodeTrustedActions.sol:L181-L192"
    ],
    "Recommendation": [
        "We recommend locking the ETH inside the contract during the challenge process. If a challenge is refuted, we recommend feeding the locked value back into the system as protocol collateral. If the challenge succeeds and the node is kicked, it is assumed that the challenger will be repaid the amount they had to lock up to prove non-liveliness."
    ]
}
----End JSON----

https://solodit.xyz/issues/multiple-checks-effects-violations-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Withdraw node balances from the minipool and close it. Only accepts calls from the owner\nfunction close() override external onlyMinipoolOwner(msg.sender) onlyInitialised {\n    // Check current status\n    require(status == MinipoolStatus.Dissolved, \"The minipool can only be closed while dissolved\");\n    // Distribute funds to owner\n    distributeToOwner();\n    // Destroy minipool\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\n    require(rocketMinipoolManager.getMinipoolExists(address(this)), \"Minipool already closed\");\n    rocketMinipoolManager.destroyMinipool();\n    // Clear state\n    nodeDepositBalance = 0;\n    nodeRefundBalance = 0;\n    userDepositBalance = 0;\n    userDepositBalanceLegacy = 0;\n    userDepositAssignedTime = 0;\n}\n\n\n",
        "// Save block to prevent multiple withdrawals within a few blocks\nwithdrawalBlock = block.number;\n\n",
        "/// @dev Slash node operator's RPL balance based on nodeSlashBalance\nfunction \\_slash() private {\n    // Get contracts\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\n    // Slash required amount and reset storage value\n    uint256 slashAmount = nodeSlashBalance;\n    nodeSlashBalance = 0;\n    rocketNodeStaking.slashRPL(nodeAddress, slashAmount);\n    // Record slashing\n    slashed = true;\n}\n\n",
        "// Get desired to amount\nuint256 newBondAmount = getUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.value\", msg.sender)));\nrequire(rocketNodeDeposit.isValidDepositAmount(newBondAmount), \"Invalid bond amount\");\n// Calculate difference\nuint256 existingBondAmount = minipool.getNodeDepositBalance();\nuint256 delta = existingBondAmount.sub(newBondAmount);\n// Get node address\naddress nodeAddress = minipool.getNodeAddress();\n// Increase ETH matched or revert if exceeds limit based on current RPL stake\nrocketNodeDeposit.increaseEthMatched(nodeAddress, delta);\n// Increase node operator's deposit credit\nrocketNodeDeposit.increaseDepositCreditBalance(nodeAddress, delta);\n// Clean up state\ndeleteUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.time\", msg.sender)));\ndeleteUint(keccak256(abi.encodePacked(\"minipool.bond.reduction.value\", msg.sender)));\n\n",
        "// Execute inflation if required\nrplContract.inflationMintTokens();\n// Increment the reward index and update the claim interval timestamp\nincrementRewardIndex();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client provided the following statement:",
        "This finding highlights our concerns about a dangerous pattern used throughout the codebase that may eventually lead to exploitable scenarios if continued to be followed, especially on codebases that do not employ protective measures against reentrant calls. This report also flagged one such exploitable instance, leading to a critical exploitable issue in one of the components.",
        "This repeated occurrence led us to flag this as a major issue to highlight a general error and attack surface present in several places.",
        "From our experience, there are predominantly positive side-effects of adhering to safe coding patterns, even for trusted contract interactions, as developers indirectly follow or pick up the coding style from existing code, reducing the likelihood of following a pattern that may be prone to be taken advantage of.",
        "For example, to a developer, it might not always be directly evident that control flow is passed to potentially untrusted components/addresses from the code itself, especially when calling multiple \u2018trusted\u2019 components in the system. Furthermore, individual components down the call stack may be updated at later times, introducing an untrusted external call (i.e., because funds are refunded) and exposing the initially calling contract to a reentrancy-type issue. Therefore, we highly recommend adhering to a safe checks-effects pattern even though the contracts mainly interact with other trusted components and build secure code based on defense-in-depth principles to contain potential damage in favor of assuming worst-case scenarios."
    ],
    "Description": [
        "Throughout the system, there are various violations of the checks-effects-interactions pattern where the contract state is updated after an external call. Since large parts of the Rocket Pool system\u2019s smart contracts are not guarded against reentrancy, the external call\u2019s recipient may reenter and potentially perform malicious actions that can impact the overall accounting and, thus, system funds."
    ],
    "Examples": [
        "distributeToOwner() sends the contract\u2019s balance to the node or the withdrawal address before clearing the internal accounting:",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L564-L581",
        "The withdrawal block should be set before any other contracts are called:",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L498-L499",
        "The slashed state should be set before any external calls are made:",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L686-L696",
        "In the bond reducer, the accounting values should be cleared before any external calls are made:",
        "code/contracts/contract/minipool/RocketMinipoolBondReducer.sol:L120-L134",
        "The counter for reward snapshot execution should be incremented before RPL gets minted:",
        "code/contracts/contract/rewards/RocketRewardsPool.sol:L210-L213"
    ],
    "Recommendation": [
        "We recommend following the checks-effects-interactions pattern and adjusting any contract state variables before making external calls. With the upgradeable nature of the system, we also recommend strictly adhering to this practice when all external calls are being made to trusted network contracts."
    ]
}
----End JSON----

https://solodit.xyz/issues/minipool-state-machine-design-and-pseudo-states-acknowledged-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement.",
        "We want to emphasize that this finding strongly suggests that there are design deficits in the minipool state machine that, sooner or later, may impact the overall system\u2019s security. We suggest refactoring a clean design with clear transitions and states for the current iteration removing technical debt from future versions. This may mean that it may be warranted to release a new major Rocketpool version as a standalone system with a clean migration path avoiding potential problems otherwise introduced by dealing with the current technical debt."
    ],
    "Description": [
        "The development team has provided the assessment team with a Minipool state machine diagram. In this document, the Destroyed and Finalised states are denoted as fully qualified Minipool states. However, these conditions are pseudo-states. Specifically, the Destroyed pseudo-state leaves the Minipool in the actual Dissolved state and removes it from the Minipool accounting components. The Finalised pseudo-state sets the finalised flag on the Minipool without changing its original state. Actors may still be able to execute functions on the Minipool while it should be in an end state."
    ],
    "Recommendation": [
        "We strongly discourage the use of pseudo-states in state machines as they make the state machine less intuitive and present challenges in mapping state transitions to the code base. Real states and transitions should be used where possible.",
        "Generally, we recommend the following when designing state machines:",
        "In any case, every Minipool should terminate in a clear end state."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketminipooldelegate-redundant-refund-call-on-forced-finalization-fixed-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function refund() override external onlyMinipoolOwnerOrWithdrawalAddress(msg.sender) onlyInitialised {\n    // Check refund balance\n    require(nodeRefundBalance > 0, \"No amount of the node deposit is available for refund\");\n    // If this minipool was distributed by a user, force finalisation on the node operator\n    if (!finalised && userDistributed) {\n        \\_finalise();\n    }\n    // Refund node\n    \\_refund();\n}\n\n",
        "function \\_finalise() private {\n    // Get contracts\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\n    // Can only finalise the pool once\n    require(!finalised, \"Minipool has already been finalised\");\n    // Set finalised flag\n    finalised = true;\n    // If slash is required then perform it\n    if (nodeSlashBalance > 0) {\n        \\_slash();\n    }\n    // Refund node operator if required\n    if (nodeRefundBalance > 0) {\n        \\_refund();\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in https://github.com/rocket-pool/rocketpool/tree/77d7cca65b7c0557cfda078a4fc45f9ac0cc6cc6 by refactoring refund() to avoid a double invocation of _refund() in the _finalise() codepath."
    ],
    "Description": [
        "The RocketMinipoolDelegate.refund function will force finalization if a user previously distributed the pool. However, _finalise already calls _refund() if there is a node refund balance to transfer, making the additional call to _refund() in refund() obsolete."
    ],
    "Examples": [
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L200-L209",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L445-L459"
    ],
    "Recommendation": [
        "We recommend refactoring the if condition to contain _refund() in the else branch."
    ]
}
----End JSON----

https://solodit.xyz/issues/sparse-documentation-and-accounting-complexity-acknowledged-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Sanity check that refund balance is zero\nrequire(nodeRefundBalance == 0, \"Refund balance not zero\");\n\n",
        "// Remove from vacant set\nrocketMinipoolManager.removeVacantMinipool();\n\n",
        "if (ownerCalling) {\n    // Finalise the minipool if the owner is calling\n    \\_finalise();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement:"
    ],
    "Description": [
        "Throughout the project, inline documentation is either sparse or missing altogether. Furthermore, few technical documents about the system\u2019s design rationale are available. The recent releases' increased complexity makes it significantly harder to trace the flow of funds through the system as components change semantics, are split into separate contracts, etc.",
        "It is essential that documentation not only outlines what is being done but also why and what a function\u2019s role in the system\u2019s \u201cbigger picture\u201d is. Many comments in the code base fail to fulfill this requirement and are thus redundant, e.g.",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L292-L293",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L333-L334",
        "code/contracts/contract/minipool/RocketMinipoolDelegate.sol:L381-L383",
        "The increased complexity and lack of documentation can increase the likelihood of developer error. Furthermore, the time spent maintaining the code and introducing new developers to the code base will drastically increase. This effect can be especially problematic in the system\u2019s accounting of funds as the various stages of a Minipool imply different flows of funds and interactions with external dependencies. Documentation should explain the rationale behind specific hardcoded values, such as the magic 8 ether boundary for withdrawal detection. An example of a lack of documentation and distribution across components is the calculation and influence of ethMatched as it plays a role in:"
    ],
    "Recommendation": [
        "As the Rocketpool system grows in complexity, we highly recommend significantly increasing the number of inline comments and general technical documentation and exploring ways to centralize the system\u2019s accounting further to provide a clear picture of which funds move where and at what point in time. Where the flow of funds is obscured because multiple components or multi-step processes are involved, we recommend adding extensive inline documentation to give context."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketnodedistributor-missing-extcodesize-check-in-dynamic-proxy-wont-fix-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "fallback() external payable {\n    address \\_target = rocketStorage.getAddress(distributorStorageKey);\n    assembly {\n        calldatacopy(0x0, 0x0, calldatasize())\n        let result := delegatecall(gas(), \\_target, 0x0, calldatasize(), 0x0, 0)\n        returndatacopy(0x0, 0x0, returndatasize())\n        switch result case 0 {revert(0, returndatasize())} default {return (0, returndatasize())}\n    }\n}\n\n",
        "function getAddress(bytes32 \\_key) override external view returns (address r) {\n    return addressStorage[\\_key];\n}\n\n",
        "assembly {\n    codeSize := extcodesize(\\_target)\n}\nrequire(codeSize > 0);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client decided not to address the finding with the upcoming update. As per their assessment, the scenario outlined would require a series of misconfigurations/failures and hence is unlikely to happen. Following a defense-in-depth approach we, nevertheless, urge to implement safeguards on multiple layers as a condition like this can easily go undetected. However, after reviewing the feedback provided by the client we share the assessment that the finding should be downgraded from Major to Medium as funds are not at immediate risk and they can recover from this problem by fixing the delegate. For transparency, the client provided the following statement:"
    ],
    "Description": [
        "RocketNodeDistributor dynamically retrieves the currently set delegate from the centralized RocketStorage contract. The target contract (delegate) is resolved inside the fallback function. It may return address(0). rocketStorage.getAddress() does not enforce that the requested settings key exists, which may lead to RocketNodeDistributor delegate-calling into address(0), which returns no error. This might stay undetected when calling RocketNodeDistributorDelegate.distribute() as the method does not return a value, which is consistent with calling a target address with no code."
    ],
    "Examples": [
        "code/contracts/contract/node/RocketNodeDistributor.sol:L23-L31",
        "code/contracts/contract/RocketStorage.sol:L153-L155"
    ],
    "Recommendation": [
        "Before delegate-calling into the target contract, check if it exists."
    ]
}
----End JSON----

https://solodit.xyz/issues/kicked-odao-members-votes-taken-into-account-acknowledged-consensys-rocket-pool-atlas-v12-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n    // Update the price\n    updatePrices(\\_block, \\_rplPrice);\n}\n\n",
        "function executeUpdatePrices(uint256 \\_block, uint256 \\_rplPrice) override external onlyLatestContract(\"rocketNetworkPrices\", address(this)) {\n    // Check settings\n\n",
        "RocketDAONodeTrustedSettingsMinipoolInterface rocketDAONodeTrustedSettingsMinipool = RocketDAONodeTrustedSettingsMinipoolInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMinipool\"));\nuint256 quorum = rocketDAONode.getMemberCount().mul(rocketDAONodeTrustedSettingsMinipool.getCancelBondReductionQuorum()).div(calcBase);\nbytes32 totalCancelVotesKey = keccak256(abi.encodePacked(\"minipool.bond.reduction.vote.count\", \\_minipoolAddress));\nuint256 totalCancelVotes = getUint(totalCancelVotesKey).add(1);\nif (totalCancelVotes > quorum) {\n\n",
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodePenaltyThreshold()) {\n    setBool(executedKey, true);\n    incrementMinipoolPenaltyCount(\\_minipoolAddress);\n}\n\n",
        "// Executes incrementMinipoolPenaltyCount if consensus threshold is reached\nfunction executeUpdatePenalty(address \\_minipoolAddress, uint256 \\_block) override external onlyLatestContract(\"rocketNetworkPenalties\", address(this)) {\n    // Get contracts\n    RocketDAOProtocolSettingsNetworkInterface rocketDAOProtocolSettingsNetwork = RocketDAOProtocolSettingsNetworkInterface(getContractAddress(\"rocketDAOProtocolSettingsNetwork\"));\n    // Get submission keys\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement:"
    ],
    "Description": [
        "oDAO members can vote on proposals or submit external data to the system, acting as an oracle. Data submission is based on a vote by itself, and multiple oDAO members must submit the same data until a configurable threshold (51% by default) is reached for the data to be confirmed.",
        "When a member gets kicked or leaves the oDAO after voting, their vote is still accounted for while the total number of oDAO members decreases.",
        "A (group of) malicious oDAO actors may exploit this fact to artificially lower the consensus threshold by voting for a proposal and then leaving the oDAO. This will leave excess votes with the proposal while the total member count decreases.",
        "For example, let\u2019s assume there are 17 oDAO members. 9 members must vote for the proposal for it to pass (52.9%). Let\u2019s assume 8 members voted for, and the rest abstained and is against the proposal (47%, threshold not met). The proposal is unlikely to pass unless two malicious oDAO members leave the DAO, lowering the member count to 15 in an attempt to manipulate the vote, suddenly inflating vote power from 8/17 (47%; rejected) to 8/15 (53.3%; passed).",
        "The crux is that the votes of ex-oDAO members still count, while the quorum is based on the current oDAO member number.",
        "Here are some examples, however, this is a general pattern used for oDAO votes in the system."
    ],
    "Example: RocketNetworkPrices": [
        "Members submit votes via submitPrices(). If the threshold is reached, the proposal is executed. Quorum is based on the current oDAO member count, votes of ex-oDAO members are still accounted for. If a proposal is a near miss, malicious actors can force execute it by leaving the oDAO, lowering the threshold, and then calling executeUpdatePrices() to execute it.",
        "code/contracts/contract/network/RocketNetworkPrices.sol:L75-L79",
        "code/contracts/contract/network/RocketNetworkPrices.sol:L85-L86"
    ],
    "RocketMinipoolBondReducer": [
        "The RocketMinipoolBondReducer contract\u2019s voteCancelReduction function takes old votes of previously kicked oDAO members into account. This results in the vote being significantly higher and increases the potential for malicious actors, even after their removal, to sway the vote. Note that a canceled bond reduction cannot be undone.",
        "code/contracts/contract/minipool/RocketMinipoolBondReducer.sol:L94-L98"
    ],
    "RocketNetworkPenalties": [
        "code/contracts/contract/network/RocketNetworkPenalties.sol:L47-L51",
        "code/contracts/contract/network/RocketNetworkPenalties.sol:L54-L58"
    ],
    "Recommendation": [
        "Track oDAO members' votes and remove them from the tally when the removal from the oDAO is executed."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaoprotocolsettingsrewards-settings-key-collission-acknowledged-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setSettingRewardsClaimer(string memory \\_contractName, uint256 \\_perc) override public onlyDAOProtocolProposal {\n    // Get the total perc set, can't be more than 100\n    uint256 percTotal = getRewardsClaimersPercTotal();\n    // If this group already exists, it will update the perc\n    uint256 percTotalUpdate = percTotal.add(\\_perc).sub(getRewardsClaimerPerc(\\_contractName));\n    // Can't be more than a total claim amount of 100%\n    require(percTotalUpdate <= 1 ether, \"Claimers cannot total more than 100%\");\n    // Update the total\n    setUint(keccak256(abi.encodePacked(settingNameSpace,\"rewards.claims\", \"group.totalPerc\")), percTotalUpdate);\n    // Update/Add the claimer amount\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount\", \\_contractName)), \\_perc);\n    // Set the time it was updated at\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount.updated.time\", \\_contractName)), block.timestamp);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement:"
    ],
    "Description": [
        "A malicious user may craft a DAO protocol proposal to set a rewards claimer for a specific contract, thus overwriting another contract\u2019s settings. This issue arises due to lax requirements when choosing safe settings keys.",
        "code/contracts/contract/dao/protocol/settings/RocketDAOProtocolSettingsRewards.sol:L36-L49",
        "The method updates the rewards claimer for a specific contract by writing to the following two setting keys:",
        "Due to the way the settings hierarchy was chosen in this case, a malicious proposal might define a <_contractName> = .updated.time<targetContract> that overwrites the settings of a different contract with an invalid value.",
        "Note that the issue of delimiter consistency is also discussed in issue 5.12.",
        "The severity rating is based on the fact that this should be detectable by DAO members. However, following a defense-in-depth approach means that such collisions should be avoided wherever possible."
    ],
    "Recommendation": [
        "We recommend enforcing a unique prefix and delimiter when concatenating user-provided input to setting keys. In this specific case, the settings could be renamed as follows:"
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaoprotocolsettingsrewards-missing-setting-delimiters-acknowledged-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setSettingRewardsClaimer(string memory \\_contractName, uint256 \\_perc) override public onlyDAOProtocolProposal {\n    // Get the total perc set, can't be more than 100\n    uint256 percTotal = getRewardsClaimersPercTotal();\n    // If this group already exists, it will update the perc\n    uint256 percTotalUpdate = percTotal.add(\\_perc).sub(getRewardsClaimerPerc(\\_contractName));\n    // Can't be more than a total claim amount of 100%\n    require(percTotalUpdate <= 1 ether, \"Claimers cannot total more than 100%\");\n    // Update the total\n    setUint(keccak256(abi.encodePacked(settingNameSpace,\"rewards.claims\", \"group.totalPerc\")), percTotalUpdate);\n    // Update/Add the claimer amount\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount\", \\_contractName)), \\_perc);\n    // Set the time it was updated at\n    setUint(keccak256(abi.encodePacked(settingNameSpace, \"rewards.claims\", \"group.amount.updated.time\", \\_contractName)), block.timestamp);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement:"
    ],
    "Description": [
        "Settings in the Rocket Pool system are hierarchical, and namespaces are prefixed using dot delimiters.",
        "Calling abi.encodePacked(<string>, <string>) on strings performs a simple concatenation. According to the settings' naming scheme, it is suggested that the following example writes to a key named: <settingNameSpace>.rewards.claims.group.amount.<_contractName>. However, due to missing delimiters, the actual key written to is: <settingNameSpace>.rewards.claimsgroup.amount<_contractName>.",
        "Note that there is no delimiter between claims|group and amount|<_contractName>.",
        "code/contracts/contract/dao/protocol/settings/RocketDAOProtocolSettingsRewards.sol:L36-L49"
    ],
    "Recommendation": [
        "We recommend adding the missing intermediate delimiters. The system should enforce delimiters after the last setting key before user input is concatenated to reduce the risk of accidental namespace collisions."
    ]
}
----End JSON----

https://solodit.xyz/issues/kicked-odao-members-votes-taken-into-account-acknowledged-consensys-rocket-pool-atlas-v12-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n // Update the price\n updatePrices(\\_block, \\_rplPrice);\n}\n\n",
        "function executeUpdatePrices(uint256 \\_block, uint256 \\_rplPrice) override external onlyLatestContract(\"rocketNetworkPrices\", address(this)) {\n // Check settings\n\n",
        "RocketDAONodeTrustedSettingsMinipoolInterface rocketDAONodeTrustedSettingsMinipool = RocketDAONodeTrustedSettingsMinipoolInterface(getContractAddress(\"rocketDAONodeTrustedSettingsMinipool\"));\nuint256 quorum = rocketDAONode.getMemberCount().mul(rocketDAONodeTrustedSettingsMinipool.getCancelBondReductionQuorum()).div(calcBase);\nbytes32 totalCancelVotesKey = keccak256(abi.encodePacked(\"minipool.bond.reduction.vote.count\", \\_minipoolAddress));\nuint256 totalCancelVotes = getUint(totalCancelVotesKey).add(1);\nif (totalCancelVotes > quorum) {\n\n",
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodePenaltyThreshold()) {\n setBool(executedKey, true);\n incrementMinipoolPenaltyCount(\\_minipoolAddress);\n}\n\n",
        "// Executes incrementMinipoolPenaltyCount if consensus threshold is reached\nfunction executeUpdatePenalty(address \\_minipoolAddress, uint256 \\_block) override external onlyLatestContract(\"rocketNetworkPenalties\", address(this)) {\n // Get contracts\n RocketDAOProtocolSettingsNetworkInterface rocketDAOProtocolSettingsNetwork = RocketDAOProtocolSettingsNetworkInterface(getContractAddress(\"rocketDAOProtocolSettingsNetwork\"));\n // Get submission keys\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges the finding and provided the following statement:"
    ],
    "Description": [
        "oDAO members can vote on proposals or submit external data to the system, acting as an oracle. Data submission is based on a vote by itself, and multiple oDAO members must submit the same data until a configurable threshold (51% by default) is reached for the data to be confirmed.",
        "When a member gets kicked or leaves the oDAO after voting, their vote is still accounted for while the total number of oDAO members decreases.",
        "A (group of) malicious oDAO actors may exploit this fact to artificially lower the consensus threshold by voting for a proposal and then leaving the oDAO. This will leave excess votes with the proposal while the total member count decreases.",
        "For example, let\u2019s assume there are 17 oDAO members. 9 members must vote for the proposal for it to pass (52.9%). Let\u2019s assume 8 members voted for, and the rest abstained and is against the proposal (47%, threshold not met). The proposal is unlikely to pass unless two malicious oDAO members leave the DAO, lowering the member count to 15 in an attempt to manipulate the vote, suddenly inflating vote power from 8/17 (47%; rejected) to 8/15 (53.3%; passed).",
        "The crux is that the votes of ex-oDAO members still count, while the quorum is based on the current oDAO member number.",
        "Here are some examples, however, this is a general pattern used for oDAO votes in the system."
    ],
    "Example: RocketNetworkPrices": [
        "Members submit votes via submitPrices(). If the threshold is reached, the proposal is executed. Quorum is based on the current oDAO member count, votes of ex-oDAO members are still accounted for. If a proposal is a near miss, malicious actors can force execute it by leaving the oDAO, lowering the threshold, and then calling executeUpdatePrices() to execute it.",
        "code/contracts/contract/network/RocketNetworkPrices.sol:L75-L79",
        "code/contracts/contract/network/RocketNetworkPrices.sol:L85-L86"
    ],
    "RocketMinipoolBondReducer": [
        "The RocketMinipoolBondReducer contract\u2019s voteCancelReduction function takes old votes of previously kicked oDAO members into account. This results in the vote being significantly higher and increases the potential for malicious actors, even after their removal, to sway the vote. Note that a canceled bond reduction cannot be undone.",
        "code/contracts/contract/minipool/RocketMinipoolBondReducer.sol:L94-L98"
    ],
    "RocketNetworkPenalties": [
        "code/contracts/contract/network/RocketNetworkPenalties.sol:L47-L51",
        "code/contracts/contract/network/RocketNetworkPenalties.sol:L54-L58"
    ],
    "Recommendation": [
        "Track oDAO members\u2019 votes and remove them from the tally when the removal from the oDAO is executed."
    ]
}
----End JSON----

https://solodit.xyz/issues/didtransfershares-function-has-no-access-control-modifier-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_beforeTokenTransfer(\n    address operator,\n    address from,\n    address to,\n    uint256[] memory ids,\n    uint256[] memory amounts,\n    bytes memory data\n) internal virtual override {\n    for (uint256 i = 0; i < ids.length; i++) {\n        if (FortaStakingUtils.isActive(ids[i])) {\n            uint8 subjectType = FortaStakingUtils.subjectTypeOfShares(ids[i]);\n            if (subjectType == DELEGATOR\\_NODE\\_RUNNER\\_SUBJECT && to != address(0) && from != address(0)) {\n                \\_allocator.didTransferShares(ids[i], subjectType, from, to, amounts[i]);\n            }\n\n",
        "function didTransferShares(\n    uint256 sharesId,\n    uint8 subjectType,\n    address from,\n    address to,\n    uint256 sharesAmount\n) external {\n    \\_rewardsDistributor.didTransferShares(sharesId, subjectType, from, to, sharesAmount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The concerned function has now been restricted to be only called by STAKING_CONTRACT_ROLE in a pull request 146 with final commit hash as 97fbd425b64d793252f39d94b378e2655286d947"
    ],
    "Description": [
        "The staked tokens (shares) in Forta are meant to be transferable. Similarly, the rewards allocation for these shares for delegated staking is meant to be transferable as well. This allocation for the shares' owner is tracked in the StakeAllocator. To enable this, the Forta staking contract FortaStaking implements a _beforeTokenTransfer() function that calls _allocator.didTransferShares() when it is appropriate to transfer the underlying allocation.",
        "code/contracts/components/staking/FortaStaking.sol:L572-L585",
        "Due to this, the StakeAllocator.didTransferShares() has an external visibility so it can be called from the FortaStaking contract to perform transfers. However, there is no access control modifier to allow only\nthe staking contract to call this. Therefore, anyone can call this function with whatever parameters they want.",
        "code/contracts/components/staking/allocation/StakeAllocator.sol:L341-L349",
        "Since the allocation isn\u2019t represented as a token standard and is tracked directly in the StakeAllocator and RewardsDistributor, it lacks many standard checks that would prevent abuse of the function. For example, this function does not have a check for allowance or msg.sender==from, so any user could call didTransferShares() with to being their address and from being any address they want to transfer allocation from, and the call would succeed."
    ],
    "Recommendation": [
        "Apply access control modifiers as appropriate for this contract, for example onlyRole()."
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-reward-epoch-start-date-calculation-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function didAllocate(\n    uint8 subjectType,\n    uint256 subject,\n    uint256 stakeAmount,\n    uint256 sharesAmount,\n    address staker\n) external onlyRole(ALLOCATOR\\_CONTRACT\\_ROLE) {\n    bool delegated = getSubjectTypeAgency(subjectType) == SubjectStakeAgency.DELEGATED;\n    if (delegated) {\n        uint8 delegatorType = getDelegatorSubjectType(subjectType);\n        uint256 shareId = FortaStakingUtils.subjectToActive(delegatorType, subject);\n        DelegatedAccRewards storage s = \\_rewardsAccumulators[shareId];\n        s.delegated.addRate(stakeAmount);\n\n",
        "function addRate(Accumulator storage acc, uint256 rate) internal {\n    setRate(acc, latest(acc).rate + rate);\n}\n\n",
        "function setRate(Accumulator storage acc, uint256 rate) internal {\n    EpochCheckpoint memory ckpt = EpochCheckpoint({ timestamp: SafeCast.toUint32(block.timestamp), rate: SafeCast.toUint224(rate), value: getValue(acc) });\n    uint256 length = acc.checkpoints.length;\n    if (length > 0 && isCurrentEpoch(acc.checkpoints[length - 1].timestamp)) {\n        acc.checkpoints[length - 1] = ckpt;\n    } else {\n        acc.checkpoints.push(ckpt);\n    }\n}\n\n",
        "function getCurrentEpochTimestamp() internal view returns (uint256) {\n    return ((block.timestamp / EPOCH\\_LENGTH) \\* EPOCH\\_LENGTH) + TIMESTAMP\\_OFFSET;\n}\n\nfunction isCurrentEpoch(uint256 timestamp) internal view returns (bool) {\n    uint256 currentEpochStart = getCurrentEpochTimestamp();\n    return timestamp > currentEpochStart;\n}\n\n",
        "function getEpochNumber(uint256 timestamp) internal pure returns (uint32) {\n    return SafeCast.toUint32((timestamp - TIMESTAMP\\_OFFSET) / EPOCH\\_LENGTH);\n}\n\n",
        "    function getCurrentEpochTimestamp() public view returns (uint256) {\r\n        return (getEpochNumber(block.timestamp) * EPOCH_LENGTH) + TIMESTAMP_OFFSET;\r\n    }\r\n\n",
        "if (length > 0 && isCurrentEpoch(acc.checkpoints[length - 1].timestamp)) {\n    acc.checkpoints[length - 1] = ckpt;\n} else {\n    acc.checkpoints.push(ckpt);\n\n",
        "    function getEpochEndTimestamp(uint256 epochNumber) public pure returns (uint256) {\r\n        return ((epochNumber + 1) * EPOCH_LENGTH) + TIMESTAMP_OFFSET - 1; <---- so it is 23:59:59 instead of next day 00:00:00\r\n    }\r\n\r\n    function isCurrentEpoch(uint256 timestamp) public view returns (bool) {\r\n        uint256 currentEpochStart = getCurrentEpochTimestamp();\r\n        return timestamp >= currentEpochStart; <--- for the first second on Monday\r\n    }\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The suggested recommendations have been implemented in a pull request 144 with a final hash as b23ffa370596e614c813bd3b882f3d8c6d15067e"
    ],
    "Description": [
        "The Forta rewards system is based on epochs. A privileged address with the role REWARDER_ROLE calls the reward() function with a parameter for a specific epochNumber that consequently distributes the rewards for that epoch. Additionally, as users stake and delegate their stake, accounts in the Forta system accrue weight that is based on the active stake to distribute these rewards. Since accounts can modify their stake as well as delegate or un-delegate it, the rewards weight for each account can be modified, as seen, for example, in the didAllocate() function. In turn, this modifies the DelegatedAccRewards storage struct that stores the accumulated rewards for each share id. To keep track of changes done to the accumulated rewards, epochs with checkpoints are used to manage the accumulated rate of rewards, their value at the checkpoint, and the timestamp of the checkpoint.",
        "For example, in the didAllocate() function the addRate() function is being called to modify the accumulated rewards.",
        "code/contracts/components/staking/rewards/RewardsDistributor.sol:L89-L101",
        "Then the function flow goes into setRate() that checks the existing accumulated rewards storage and modifies it based on the current timestamp.",
        "code/contracts/components/staking/rewards/Accumulators.sol:L34-L36",
        "code/contracts/components/staking/rewards/Accumulators.sol:L42-L50",
        "Namely, it pushes epoch checkpoints to the list of account checkpoints based on its timestamp. If the last checkpoint\u2019s timestamp is during the current epoch, then the last checkpoint is replaced with the new one altogether. If the last checkpoint\u2019s timestamp is different from the current epoch, a new checkpoint is added to the list.\nHowever, the isCurrentEpoch() function calls a function getCurrentEpochTimestamp() that incorrectly determines the start date of the current epoch. In particular, it doesn\u2019t take the offset into account when calculating how many epochs have already passed.",
        "code/contracts/components/staking/rewards/Accumulators.sol:L103-L110",
        "Instead of\n((block.timestamp / EPOCH_LENGTH) * EPOCH_LENGTH) + TIMESTAMP_OFFSET,\nit should be\n(((block.timestamp - TIMESTAMP_OFFSET) / EPOCH_LENGTH) * EPOCH_LENGTH) + TIMESTAMP_OFFSET.\nIn fact, it should simply call the getEpochNumber() function that correctly provides the epoch number for any timestamp.",
        "code/contracts/components/staking/rewards/Accumulators.sol:L95-L97",
        "In other words, the resulting function would look something like the following:",
        "Otherwise, if block.timestamp is such that (block.timestamp - TIMESTAMP_OFFSET) / EPOCH_LENGTH = n and block.timestamp / EPOCH_LENGTH = n+1, which would happen on roughly 4 out of 7 days of the week since EPOCH_LENGTH = 1 weeks and TIMESTAMP_OFFSET = 4 days, this would cause the getCurrentEpochTimestamp() function to return the end timestamp of the epoch (which is in the future) instead of the start. Therefore, if a checkpoint with such a timestamp is committed to the account\u2019s accumulated rewards checkpoints list, it will always fail the below check in the epoch it got submitted, and any checkpoint committed afterwards but during the same epoch with a similar type of block.timestamp (i.e. satisfying the condition at the beginning of this paragraph), would be pushed to the top of the list instead of replacing the previous checkpoint.",
        "code/contracts/components/staking/rewards/Accumulators.sol:L45-L48",
        "This causes several checkpoints to be stored for the same epoch, which would cause issues in functions such as getAtEpoch(), that feeds into getValueAtEpoch() function that provides data for the rewards' share calculation. In the end, this would cause issues in the accounting for the rewards calculation resulting in incorrect distributions.",
        "During the discussion with the Forta Foundation team, it was additionally discovered that there are edge cases around the limits of epochs. Specifically, epoch\u2019s end time and the subsequent epoch\u2019s start time are exactly the same, although it should be that it is only the start of the next epoch. Similarly, that start time isn\u2019t recognized as part of the epoch due to > sign instead of >=. In particular, the following changes need to be made:"
    ],
    "Recommendation": [
        "A refactor of the epoch timestamp calculation functions is recommended to account for:"
    ]
}
----End JSON----

https://solodit.xyz/issues/a-single-unfreeze-dismisses-all-other-slashing-proposal-freezes-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function dismissSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external onlyRole(SLASHING\\_ARBITER\\_ROLE) {\n    \\_transition(\\_proposalId, DISMISSED);\n    \\_submitEvidence(\\_proposalId, DISMISSED, \\_evidence);\n    \\_returnDeposit(\\_proposalId);\n    \\_unfreeze(\\_proposalId);\n}\n\n",
        "function rejectSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external onlyRole(SLASHING\\_ARBITER\\_ROLE) {\n    \\_transition(\\_proposalId, REJECTED);\n    \\_submitEvidence(\\_proposalId, REJECTED, \\_evidence);\n    \\_slashDeposit(\\_proposalId);\n    \\_unfreeze(\\_proposalId);\n}\n\n",
        "function reviewSlashProposalParameters(\n    uint256 \\_proposalId,\n    uint8 \\_subjectType,\n    uint256 \\_subjectId,\n    bytes32 \\_penaltyId,\n    string[] calldata \\_evidence\n) external onlyRole(SLASHING\\_ARBITER\\_ROLE) onlyInState(\\_proposalId, IN\\_REVIEW) onlyValidSlashPenaltyId(\\_penaltyId) onlyValidSubjectType(\\_subjectType) notAgencyType(\\_subjectType, SubjectStakeAgency.DELEGATOR) {\n    // No need to check for proposal existence, onlyInState will revert if \\_proposalId is in undefined state\n    if (!subjectGateway.isRegistered(\\_subjectType, \\_subjectId)) revert NonRegisteredSubject(\\_subjectType, \\_subjectId);\n\n    \\_submitEvidence(\\_proposalId, IN\\_REVIEW, \\_evidence);\n    if (\\_subjectType != proposals[\\_proposalId].subjectType || \\_subjectId != proposals[\\_proposalId].subjectId) {\n        \\_unfreeze(\\_proposalId);\n        \\_freeze(\\_subjectType, \\_subjectId);\n    }\n\n",
        "function revertSlashProposal(uint256 \\_proposalId, string[] calldata \\_evidence) external {\n    \\_authorizeRevertSlashProposal(\\_proposalId);\n    \\_transition(\\_proposalId, REVERTED);\n    \\_submitEvidence(\\_proposalId, REVERTED, \\_evidence);\n    \\_unfreeze(\\_proposalId);\n}\n\n",
        "function executeSlashProposal(uint256 \\_proposalId) external onlyRole(SLASHER\\_ROLE) {\n    \\_transition(\\_proposalId, EXECUTED);\n    Proposal memory proposal = proposals[\\_proposalId];\n    slashingExecutor.slash(proposal.subjectType, proposal.subjectId, getSlashedStakeValue(\\_proposalId), proposal.proposer, slashPercentToProposer);\n    slashingExecutor.freeze(proposal.subjectType, proposal.subjectId, false);\n}\n\n",
        "function \\_unfreeze(uint256 \\_proposalId) private {\n    slashingExecutor.freeze(proposals[\\_proposalId].subjectType, proposals[\\_proposalId].subjectId, false);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "As per the recommendation, the Forta team modified the logic in favor of open proposals. Now, every shareId will have a counter for open proposals, which will be incremented every time a new proposal is launched and will be unfrozen only if the counter is zero. The changes were implemented in a pull request 149 with a final hash 76338b1417bdb7b1da49b7e74ad011b307907f7f"
    ],
    "Description": [
        "In order to retaliate against malicious actors, the Forta staking system allows users to submit slashing proposals that are guarded by submitting along a deposit with a slashing reason. These proposals immediately freeze the proposal\u2019s subject\u2019s stake, blocking them from withdrawing that stake.",
        "At the same time, there can be multiple proposals submitted against the same subject, which works out with freezing \u2013 the subject remains frozen with each proposal submitted. However, once any one of the active proposals against the subject gets to the end of its lifecycle, be it REJECTED, DISMISSED, EXECUTED, or REVERTED, the subject gets unfrozen altogether. The other proposals might still be active, but the stake is no longer frozen, allowing the subject to withdraw it if they would like.",
        "In terms of impact, this allows bad actors to avoid punishment intended by the slashes and freezes. A malicious actor could, for example, submit a faulty proposal against themselves in the hopes that it will get quickly rejected or dismissed while the existing, legitimate proposals against them are still being considered. This would allow them to get unfrozen quickly and withdraw their stake. Similarly, in the event a bad staker has several proposals against them, they could withdraw right after a single slashing proposal goes through."
    ],
    "Examples": [
        "code/contracts/components/staking/slashing/SlashingController.sol:L174-L179",
        "code/contracts/components/staking/slashing/SlashingController.sol:L187-L192",
        "code/contracts/components/staking/slashing/SlashingController.sol:L215-L229",
        "code/contracts/components/staking/slashing/SlashingController.sol:L254-L259",
        "code/contracts/components/staking/slashing/SlashingController.sol:L267-L272",
        "code/contracts/components/staking/slashing/SlashingController.sol:L337-L339"
    ],
    "Recommendation": [
        "Introduce a check in the unfreezing mechanics to first ensure there are no other active proposals for that subject."
    ]
}
----End JSON----

https://solodit.xyz/issues/storage-gap-variables-slightly-off-from-the-intended-size-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    uint64 private _withdrawalDelay;\r\n\r\n    // treasury for slashing\r\n    address private _treasury;\r\n\n",
        "uint256[50] private \\_\\_gap;\n\n",
        "uint256[41] private \\_\\_gap; // 50 - 1 (frontRunningDelay) - 3 (\\_stakeThreshold) - 5 StakeSubjectUpgradeable\n\n",
        "uint256[49] private \\_\\_gap;\n\n",
        "uint256[47] private \\_\\_gap;\n\n",
        "uint256[44] private \\_\\_gap;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The Forta Team worked on the storage layout to maintain a consistent storage buffer in the inheritance tree. The changes were made through multiple pull requests, also an easy-to-understand layout description has been added through a pull request 157.\nHowever, we still found some inconsistencies and recommend doing a thorough review of the buffer space again.",
        "For instance, in FortaStaking (considering the latest commit)",
        "the above-mentioned storage variables will be taking a single slot, however, separate slots are considered for the buffer space(referring to the storage layout description to determine __gap buffer)."
    ],
    "Description": [
        "The Forta staking system is using upgradeable proxies for its deployment strategy. To avoid storage collisions between contract versions during upgrades, uint256[] private __gap array variables are introduced that create a storage buffer. Together with contract state variables, the storage slots should sum up to 50. For example, the __gap variable is present in the BaseComponentUpgradeable component, which is the base of most Forta contracts, and there is a helpful comment in AgentRegistryCore that describes how its relevant __gap variable size was calculated:",
        "code/contracts/components/BaseComponentUpgradeable.sol:L62",
        "code/contracts/components/agents/AgentRegistryCore.sol:L196",
        "However, there are a few places where the __gap size was not computed correctly to get the storage slots up to 50. Some of these are:",
        "code/contracts/components/scanners/ScannerRegistry.sol:L234",
        "code/contracts/components/dispatch/Dispatch.sol:L333",
        "code/contracts/components/node_runners/NodeRunnerRegistryCore.sol:L452",
        "While these still provide large storage buffers, it is best if the __gap variables are calculated to hold the same buffer within contracts of similar types as per the initial intentions to avoid confusion.",
        "During conversations with the Forta Foundation team, it appears that some contracts like ScannerRegistry and AgentRegistry should instead add up to 45 with their __gap variable due to the StakeSubject contracts they inherit from adding 5 from themselves. This is something to note and be careful with as well for future upgrades."
    ],
    "Recommendation": [
        "Provide appropriate sizes for the __gap variables to have a consistent storage layout approach that would help avoid storage issues with future versions of the system."
    ]
}
----End JSON----

https://solodit.xyz/issues/agentregistrycore-agent-creation-dos-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function createAgent(uint256 agentId, address owner, string calldata metadata, uint256[] calldata chainIds)\npublic\n    onlySorted(chainIds)\n    frontrunProtected(keccak256(abi.encodePacked(agentId, owner, metadata, chainIds)), frontRunningDelay)\n{\n    \\_mint(owner, agentId);\n    \\_beforeAgentUpdate(agentId, metadata, chainIds);\n    \\_agentUpdate(agentId, metadata, chainIds);\n    \\_afterAgentUpdate(agentId, metadata, chainIds);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The Forta team as per the recommendations modified the minting logic to allow users to mint an agentId only for their own address in a pull request 155 with final hash as 7426891222e2bcdf2bbbec669905d5041f9fb58e. Also, the team claims that the Agent Ids are generated through the Forta Bot SDK to minimize the collision risk. However, this has not been verified by the auditing team.",
        "We still recommend notifying users to check whether an ID is already registered prior to making any commitment if a front-running delay is enabled, to avoid unintended DoS."
    ],
    "Description": [
        "AgentRegistryCore allows anyone to mint an agentID for the desired owner address. However, in some cases, it may fall prey to DoS, either deliberately or unintentionally.",
        "For instance, let\u2019s assume the Front Running Protection is disabled or the frontRunningDelay is 0. It means anyone can directly create an agent without any prior commitment. Thus, anyone can observe pending transactions and try to front run them to mint an agentID prior to the victim\u2019s restricting it to mint a desired agentID.",
        "Also, it may be possible that a malicious actor succeeds in frontrunning a transaction with manipulated data/chainIDs but with the same owner address and agentID. There is a good chance that victim still accepts the attacker\u2019s transaction as valid, even though its own transaction reverted, due to the fact that the victim is still seeing itself as the owner of that ID.",
        "Taking an instance where let\u2019s assume the frontrunning protection is enabled.\nStill, there is a good chance that two users vouch for the same agentIDs and commits in the same block, thus getting the same frontrunning delay. Then, it will be a game of luck, whoever creates that agent first will get the ID minted to its address, and the other user\u2019s transaction will be reverted wasting the time they have spent on the delay.",
        "As the agentIDs can be picked by users, the chances of collisions with an already minted ID will increase over time causing unnecessary reverts for others.",
        "Adding to the fact that there is no restriction for owner address, anyone can spam mint any agentID to any address for any profitable reason."
    ],
    "Examples": [
        "code/contracts/components/agents/AgentRegistryCore.sol:L68-L77"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/lack-of-checks-for-rewarding-an-epoch-that-has-already-been-rewarded-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function reward(\n    uint8 subjectType,\n    uint256 subjectId,\n    uint256 amount,\n    uint256 epochNumber\n) external onlyRole(REWARDER\\_ROLE) {\n    if (subjectType != NODE\\_RUNNER\\_SUBJECT) revert InvalidSubjectType(subjectType);\n    if (!\\_subjectGateway.isRegistered(subjectType, subjectId)) revert RewardingNonRegisteredSubject(subjectType, subjectId);\n    uint256 shareId = FortaStakingUtils.subjectToActive(getDelegatorSubjectType(subjectType), subjectId);\n    \\_rewardsPerEpoch[shareId][epochNumber] = amount;\n    totalRewardsDistributed += amount;\n    emit Rewarded(subjectType, subjectId, amount, epochNumber);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The suggested recommendations have been implemented in a pull request 150 with final hash 76e1ae8ca16c92851f2bafb905f0e0c86542027c. The reward logic has been modified to register the reward for an epoch only once and revert if called twice."
    ],
    "Description": [
        "To give rewards to the participating stakers, the Forta system utilizes reward epochs for each shareId, i.e. a delegated staking share. Each epoch gets their own reward distribution, and then StakeAllocator and RewardsDistributor contracts along with the Forta staking shares determine how much the users get.",
        "To actually allocate these rewards, a privileged account with the role REWARDER_ROLE calls the RewardsDistributor.reward() function with appropriate parameters to store the amount a shareId gets for that specific epochNumber, and then adds the amount to the totalRewardsDistributed contract variable for tracking. However, there is no check that the shareId already received rewards for that epoch. The new reward amount simply replaces the old reward amount, and totalRewardsDistributed gets the new amount added to it anyway. This causes inconsistencies with accounting in the totalRewardsDistributed variable.",
        "Although totalRewardsDistributed is essentially isolated to the sweep() function to allow transferring out the reward tokens without taking away those tokens reserved for the reward distribution, this still creates an inconsistency, albeit a minor one in the context of the current system.",
        "Similarly, the sweep() function deducts the totalRewardsDistributed amount instead of the amount of pending rewards only. In other words, either there should be a different variable that tracks only pending rewards, or the totalRewardsDistributed should have token amounts deducted from it when users execute the claimRewards() function. Otherwise, after a few epochs there will be a really large totalRewardsDistributed amount that might not reflect the real amount of pending reward tokens left on the contract, and the sweep() function for the reward token is likely to fail for any amount being transferred out."
    ],
    "Examples": [
        "code/contracts/components/staking/rewards/RewardsDistributor.sol:L155-L167"
    ],
    "Recommendation": [
        "Implement checks as appropriate to the reward() function to ensure correct behavior of totalRewardsDistributed tracking. Also, implement necessary changes to the tracking of pending rewards, if necessary."
    ]
}
----End JSON----

https://solodit.xyz/issues/reentrancy-in-fortastaking-during-erc1155-mints-fixed-consensys-forta-delegated-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "contract FortaStaking is BaseComponentUpgradeable, ERC1155SupplyUpgradeable, SubjectTypeValidator, ISlashingExecutor, IStakeMigrator {\n\n",
        "function deposit(\n    uint8 subjectType,\n    uint256 subject,\n    uint256 stakeValue\n) external onlyValidSubjectType(subjectType) notAgencyType(subjectType, SubjectStakeAgency.MANAGED) returns (uint256) {\n    if (address(subjectGateway) == address(0)) revert ZeroAddress(\"subjectGateway\");\n    if (!subjectGateway.isStakeActivatedFor(subjectType, subject)) revert StakeInactiveOrSubjectNotFound();\n    address staker = \\_msgSender();\n    uint256 activeSharesId = FortaStakingUtils.subjectToActive(subjectType, subject);\n    bool reachedMax;\n    (stakeValue, reachedMax) = \\_getInboundStake(subjectType, subject, stakeValue);\n    if (reachedMax) {\n        emit MaxStakeReached(subjectType, subject);\n    }\n    uint256 sharesValue = stakeToActiveShares(activeSharesId, stakeValue);\n    SafeERC20.safeTransferFrom(stakedToken, staker, address(this), stakeValue);\n\n    \\_activeStake.mint(activeSharesId, stakeValue);\n    \\_mint(staker, activeSharesId, sharesValue, new bytes(0));\n    emit StakeDeposited(subjectType, subject, staker, stakeValue);\n    \\_allocator.depositAllocation(activeSharesId, subjectType, subject, staker, stakeValue, sharesValue);\n    return sharesValue;\n}\n\n",
        "function migrate(\n    uint8 oldSubjectType,\n    uint256 oldSubject,\n    uint8 newSubjectType,\n    uint256 newSubject,\n    address staker\n) external onlyRole(SCANNER\\_2\\_NODE\\_RUNNER\\_MIGRATOR\\_ROLE) {\n    if (oldSubjectType != SCANNER\\_SUBJECT) revert InvalidSubjectType(oldSubjectType);\n    if (newSubjectType != NODE\\_RUNNER\\_SUBJECT) revert InvalidSubjectType(newSubjectType); \n    if (isFrozen(oldSubjectType, oldSubject)) revert FrozenSubject();\n\n    uint256 oldSharesId = FortaStakingUtils.subjectToActive(oldSubjectType, oldSubject);\n    uint256 oldShares = balanceOf(staker, oldSharesId);\n    uint256 stake = activeSharesToStake(oldSharesId, oldShares);\n    uint256 newSharesId = FortaStakingUtils.subjectToActive(newSubjectType, newSubject);\n    uint256 newShares = stakeToActiveShares(newSharesId, stake);\n\n    \\_activeStake.burn(oldSharesId, stake);\n    \\_activeStake.mint(newSharesId, stake);\n    \\_burn(staker, oldSharesId, oldShares);\n    \\_mint(staker, newSharesId, newShares, new bytes(0));\n    emit StakeDeposited(newSubjectType, newSubject, staker, stake);\n    \\_allocator.depositAllocation(newSharesId, newSubjectType, newSubject, staker, stake, newShares);\n}\n\n",
        "function initiateWithdrawal(\n    uint8 subjectType,\n    uint256 subject,\n    uint256 sharesValue\n) external onlyValidSubjectType(subjectType) returns (uint64) {\n    address staker = \\_msgSender();\n    uint256 activeSharesId = FortaStakingUtils.subjectToActive(subjectType, subject);\n    if (balanceOf(staker, activeSharesId) == 0) revert NoActiveShares();\n    uint64 deadline = SafeCast.toUint64(block.timestamp) + \\_withdrawalDelay;\n\n    \\_lockingDelay[activeSharesId][staker].setDeadline(deadline);\n\n    uint256 activeShares = Math.min(sharesValue, balanceOf(staker, activeSharesId));\n    uint256 stakeValue = activeSharesToStake(activeSharesId, activeShares);\n    uint256 inactiveShares = stakeToInactiveShares(FortaStakingUtils.activeToInactive(activeSharesId), stakeValue);\n    SubjectStakeAgency agency = getSubjectTypeAgency(subjectType);\n    \\_activeStake.burn(activeSharesId, stakeValue);\n    \\_inactiveStake.mint(FortaStakingUtils.activeToInactive(activeSharesId), stakeValue);\n    \\_burn(staker, activeSharesId, activeShares);\n    \\_mint(staker, FortaStakingUtils.activeToInactive(activeSharesId), inactiveShares, new bytes(0));\n    if (agency == SubjectStakeAgency.DELEGATED || agency == SubjectStakeAgency.DELEGATOR) {\n        \\_allocator.withdrawAllocation(activeSharesId, subjectType, subject, staker, stakeValue, activeShares);\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The Forta team implemented a Reentrancy Guard in a pull request 151 with a final hash 62080c17e9bd2be8105bfe4e59f36fad7be60fe5"
    ],
    "Description": [
        "In the Forta staking system, the staking shares (both \u201cactive\u201d and \u201cinactive\u201d) are represented as tokens implemented according to the ERC1155 standard. The specific implementation that is being used utilizes a smart contract acceptance check _doSafeTransferAcceptanceCheck() upon mints to the recipient.",
        "code/contracts/components/staking/FortaStaking.sol:L54",
        "The specific implementation for ERC1155SupplyUpgradeable contracts can be found here, and the smart contract check can be found here.",
        "This opens up reentrancy into the system\u2019s flow. In fact, the reentrancy occurs on all mints that happen in the below functions, and it happens before a call to another Forta contract for allocation is made via either _allocator.depositAllocation or _allocator.withdrawAllocation:",
        "code/contracts/components/staking/FortaStaking.sol:L273-L295",
        "code/contracts/components/staking/FortaStaking.sol:L303-L326",
        "code/contracts/components/staking/FortaStaking.sol:L365-L387",
        "Although this doesn\u2019t seem to be an issue in the current Forta system of contracts since the allocator\u2019s logic doesn\u2019t seem to be manipulable, this could still be dangerous as it opens up an external execution flow."
    ],
    "Recommendation": [
        "Consider introducing a reentrancy check or emphasize this behavior in the documentation, so that both other projects using this system later and future upgrades along with maintenance work on the Forta staking system itself are implemented safely."
    ]
}
----End JSON----

https://solodit.xyz/issues/oracles-_sanitycheck-for-prices-will-not-work-with-slashing-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 maxPrice = curPrice +\n ((curPrice \\*\n self.PERIOD\\_PRICE\\_INCREASE\\_LIMIT \\*\n \\_periodsSinceUpdate) / PERCENTAGE\\_DENOMINATOR);\n\nuint256 minPrice = curPrice -\n ((curPrice \\*\n self.PERIOD\\_PRICE\\_DECREASE\\_LIMIT \\*\n \\_periodsSinceUpdate) / PERCENTAGE\\_DENOMINATOR);\n\nrequire(\n \\_newPrice >= minPrice && \\_newPrice <= maxPrice,\n \"OracleUtils: price is insane\"\n\n"
    ],
    "preamble": [],
    "Description": [
        "The _sanityCheck is verifying that the new price didn\u2019t change significantly:",
        "code/contracts/Portal/utils/OracleUtilsLib.sol:L405-L417",
        "While the rewards of staking can be reasonably predicted, the balances may also be changed due to slashing. So any slashing event should reduce the price, and if enough ETH is slashed, the price will drop heavily. The oracle will not be updated because of a sanity check. After that, there will be an arbitrage opportunity, and everyone will be incentivized to withdraw as soon as possible. That process will inevitably devaluate gETH to zero.\nThe severity of this issue is also amplified by the fact that operators have no skin in the game and won\u2019t lose anything from slashing."
    ],
    "Recommendation": [
        "Make sure that slashing can be adequately processed when updating the price."
    ]
}
----End JSON----

https://solodit.xyz/issues/multiple-calculation-mistakes-in-the-_findpricesclearbuffer-function-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "return (unbufferedEther / unbufferedSupply, totalEther / supply);\n\n",
        "uint256 unbufferedEther = totalEther -\n (DATASTORE.readUintForId(\\_poolId, \\_dailyBufferMintKey) \\* price) /\n self.gETH.totalSupply(\\_poolId);\n\nunbufferedEther +=\n (DATASTORE.readUintForId(\\_poolId, \\_dailyBufferBurnKey) \\* price) /\n self.gETH.denominator();\n\n",
        "return (unbufferedEther / unbufferedSupply, totalEther / supply);\n\n"
    ],
    "preamble": [],
    "Description": [
        "The _findPricesClearBuffer function is designed to calculate the gETH/ETH prices. The first one (oracle price) is the price at the reference point, for ease of calculation let\u2019s assume it is midnight. The second price is the price at the time the reportOracle is called.",
        "code/contracts/Portal/utils/OracleUtilsLib.sol:L388",
        "To calculate the oracle price at midnight, the current ETH balance is reduced by all the minted gETH (converted to ETH with the old price) and increased by all the burnt gETH (converted to ETH with the old price) starting from midnight to the time transaction is being executed:",
        "code/contracts/Portal/utils/OracleUtilsLib.sol:L368-L374",
        "But in the first calculation, the self.gETH.totalSupply(_poolId) is mistakenly used instead of self.gETH.denominator(). This can lead to the unbufferedEther being much larger, and the eventual oracle price will be much larger too.",
        "There is another serious calculation mistake. In the end, the function returns the following line:",
        "code/contracts/Portal/utils/OracleUtilsLib.sol:L388",
        "But none of these values are multiplied by self.gETH.denominator(); so they are in the same range. Both values will usually be around 1. While the actual price value should be multiplied by self.gETH.denominator();."
    ]
}
----End JSON----

https://solodit.xyz/issues/new-interfaces-can-add-malicious-code-without-any-delay-or-check-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setInterface(\n StakePool storage self,\n DataStoreUtils.DataStore storage DATASTORE,\n uint256 id,\n address \\_interface\n) external {\n DATASTORE.authenticate(id, true, [false, true, true]);\n \\_setInterface(self, DATASTORE, id, \\_interface);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Geode Finance uses an interesting system of contracts for each individual staked ETH derivative. At the base of it all is an ERC1155 gETH contract where planet id acts as a token id. To make it more compatible with the rest of DeFi the Geode team pairs it up with an ERC20 contract that users would normally interact with and where all the allowances are stored. Naturally, since the balances are stored in the gETH contract, ERC20 interfaces need to ask gETH contract to update the balance. It is done in a way where the gETH contract will perform any transfer requested by the interface since the interface is expected to do all the checks and accountings. The issue comes with the fact that planet maintainers can whitelist new interfaces and that process does not require any approval. Planet maintainers could whitelist an interface that will send all the available tokens to the maintainer\u2019s wallet for example. This essentially allows Planet maintainers to steal all derivative tokens in circulation in one transaction."
    ],
    "Examples": [
        "code/contracts/Portal/utils/StakeUtilsLib.sol:L165-L173"
    ],
    "Recommendation": [
        "gETH.sol contract has a concept of avoiders. One of the ways to fix this issue is to have the avoidance be set on a per-interface basis and avoiding new interfaces by default. This way users will need to allow the new tokens to access the balances."
    ]
}
----End JSON----

https://solodit.xyz/issues/minigovernance-fetchupgradeproposal-will-always-revert-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "GEM.newProposal(proposal.CONTROLLER, 2, proposal.NAME, 4 weeks);\n\n",
        "require(\n duration <= MAX\\_PROPOSAL\\_DURATION,\n \"GeodeUtils: duration exceeds MAX\\_PROPOSAL\\_DURATION\"\n);\n\n"
    ],
    "preamble": [],
    "Description": [
        "In the function fetchUpgradeProposal(), newProposal() is called with a hard coded duration of 4 weeks. This means the function will always revert since newProposal() checks that the proposal duration is not more than the constant MAX_PROPOSAL_DURATION of 2 weeks. Effectively, this leaves MiniGovernance non-upgradeable."
    ],
    "Examples": [
        "code/contracts/Portal/MiniGovernance/MiniGovernance.sol:L183",
        "code/contracts/Portal/utils/GeodeUtilsLib.sol:L328-L331"
    ],
    "Recommendation": [
        "Switch the hard coded proposal duration to 2 weeks."
    ]
}
----End JSON----

https://solodit.xyz/issues/reportoracle-can-be-sandwiched-for-profit-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "The fact that price update happens in an on-chain transaction gives the searches the ability to see the future price and then act accordingly."
    ],
    "Examples": [
        "MEV searcher can find the reportOracle transaction in the mem-pool and if the price is about to increase he could proceed to mint as much gETH as he can with a flash loan. They would then bundle the reportOracle transaction. Finally, they would redeem all the gETH for ETH at a higher price per share value as the last transaction in the bundle.",
        "This paired with the fact that oracle might be updated less frequently than once per day, could lead to the fact that profits from this attack will outweigh the fees for performing it.",
        "Fortunately, due to the nature of the protocol, the price fluctuations from day to day will most likely be smaller than the fees encountered during this arbitrage, but this is still something to be aware of when updating the values for DWP donations and fees. But it also makes it crucial to update the oracle every day not to increase the profit margins for this attack."
    ]
}
----End JSON----

https://solodit.xyz/issues/updating-interfaces-of-derivatives-is-done-in-a-dangerous-and-unpredictable-manner-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "mapping(uint256 => mapping(address => uint256)) private \\_balances;\n\n",
        "mapping(address => mapping(address => uint256)) private \\_allowances;\n\n"
    ],
    "preamble": [],
    "Description": [
        "Geode Finance codebase provides planet maintainers with the ability to enable or disable different contracts to act as the main token contract. In fact, multiple separate contracts can be used at the same time if decided so by the planet maintainer. Those contracts will have shared balances but will not share the allowances as you can see below:",
        "code/contracts/Portal/helpers/ERC1155SupplyMinterPauser.sol:L47",
        "code/contracts/Portal/gETHInterfaces/ERC20InterfaceUpgradable.sol:L60",
        "Unfortunately, this approach comes with some implications that are very hard to predict as they involve interactions with other systems, but is possible to say that the consequences of those implications will most always be negative. We will not be able to outline all the implications of this issue, but we can try and outline the pattern that they all would follow."
    ],
    "Examples": [
        "There are really two ways to update an interface: set the new one and immediately unset the old one, or have them both run in parallel for some time. Let\u2019s look at them one by one.",
        "in the first case, the old interface is disabled immediately. Given that interfaces share balances that will lead to some very serious consequences. Imagine the following sequence:",
        "This can happen in pretty much any contract and not just the DWP token. Unless the holders had enough time to withdraw the derivatives back to their wallets all the funds deposited into contracts could be lost.",
        "This leads us to the second case where the two interfaces are active in parallel. This would solve the issue above by allowing Alice to withdraw the old tokens from the DWP and make the new tokens follow. Unfortunately, there is an issue in that case as well.",
        "Some DeFi contracts allow their owners to withdraw any tokens that are not accounted for by the internal accounting. DWP allows the withdrawal of admin fees if the contract has more tokens than balances[] store. Some contracts even allow to withdraw funds that were accidentally sent to the contract by people. Either to recover them or just as a part of dust collection. Let\u2019s call such contracts \u201cdangerous contracts\u201d for our purposes.",
        "One other issue we would like to highlight here is that despite the contracts being expected to have separate allowances, if the old contract has the allowance set, the initial 0 value of the new one will be ignored. Here is an example:",
        "Alice could also give Bob an allowance of 100 tokens in the new contract since that was her original intent, but this would mean that Bob now has 200 token allowance.",
        "This is extremely convoluted and will most likely result in errors made by the planet maintainers when updating the interfaces."
    ],
    "Recommendation": [
        "The safest option is to only allow a list of whitelisted interfaces to be used that are well-documented and audited. Planet maintainers could then choose the once that they see fit."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-sandwich-attack-on-fetchunstake-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function fetchUnstake(\n StakePool storage self,\n DataStoreUtils.DataStore storage DATASTORE,\n uint256 poolId,\n uint256 operatorId,\n bytes[] calldata pubkeys,\n uint256[] calldata balances,\n bool[] calldata isExit\n) external {\n require(\n msg.sender == self.TELESCOPE.ORACLE\\_POSITION,\n \"StakeUtils: sender NOT ORACLE\"\n );\n\n",
        "function swap(\n uint8 tokenIndexFrom,\n uint8 tokenIndexTo,\n uint256 dx,\n uint256 minDy,\n uint256 deadline\n)\n external\n payable\n virtual\n override\n nonReentrant\n whenNotPaused\n deadlineCheck(deadline)\n returns (uint256)\n{\n return swapStorage.swap(tokenIndexFrom, tokenIndexTo, dx, minDy);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Operators are incentivized to withdraw the stake when there is a debt in the system. Withdrawn ETH will be sold in the DWP, and a portion of the arbitrage profit will be sent to the operator. But the operators cannot unstake and earn the arbitrage boost instantly. Node operator will need to start the withdrawal process, signal unstake, and only then, after some time, potentially days, Oracle will trigger fetchUnstake and will take the arbitrage opportunity if it is still there.",
        "code/contracts/Portal/utils/StakeUtilsLib.sol:L1276-L1288",
        "In reality, the DWP contract\u2019s swap function is external and can be used by anyone, so anyone could try and take the arbitrage.",
        "code/contracts/Portal/withdrawalPool/Swap.sol:L341-L358",
        "In fact, one could take this arbitrage with no risk or personal funds. This is due to the fact that fetchUnstake() could get sandwiched. Consider the following case:",
        "At the end of the day, the goal of regaining the peg will be accomplished, but node operators will not be interested in withdrawing early later. This will potentially create unhealthy situations when withdrawals are required in case of a serious de-peg."
    ]
}
----End JSON----

https://solodit.xyz/issues/only-the-governance-can-initialize-the-portal-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize(\n address \\_GOVERNANCE,\n address \\_gETH,\n address \\_ORACLE\\_POSITION,\n address \\_DEFAULT\\_gETH\\_INTERFACE,\n address \\_DEFAULT\\_DWP,\n address \\_DEFAULT\\_LP\\_TOKEN,\n address \\_MINI\\_GOVERNANCE\\_POSITION,\n uint256 \\_GOVERNANCE\\_TAX,\n uint256 \\_COMET\\_TAX,\n uint256 \\_MAX\\_MAINTAINER\\_FEE,\n uint256 \\_BOOSTRAP\\_PERIOD\n) public virtual override initializer {\n \\_\\_ReentrancyGuard\\_init();\n \\_\\_Pausable\\_init();\n \\_\\_ERC1155Holder\\_init();\n \\_\\_UUPSUpgradeable\\_init();\n\n GEODE.SENATE = \\_GOVERNANCE;\n GEODE.GOVERNANCE = \\_GOVERNANCE;\n GEODE.GOVERNANCE\\_TAX = \\_GOVERNANCE\\_TAX;\n GEODE.MAX\\_GOVERNANCE\\_TAX = \\_GOVERNANCE\\_TAX;\n GEODE.SENATE\\_EXPIRY = type(uint256).max;\n\n STAKEPOOL.GOVERNANCE = \\_GOVERNANCE;\n STAKEPOOL.gETH = IgETH(\\_gETH);\n STAKEPOOL.TELESCOPE.gETH = IgETH(\\_gETH);\n STAKEPOOL.TELESCOPE.ORACLE\\_POSITION = \\_ORACLE\\_POSITION;\n STAKEPOOL.TELESCOPE.MONOPOLY\\_THRESHOLD = 20000;\n\n updateStakingParams(\n \\_DEFAULT\\_gETH\\_INTERFACE,\n \\_DEFAULT\\_DWP,\n \\_DEFAULT\\_LP\\_TOKEN,\n \\_MAX\\_MAINTAINER\\_FEE,\n \\_BOOSTRAP\\_PERIOD,\n type(uint256).max,\n type(uint256).max,\n \\_COMET\\_TAX,\n 3 days\n );\n\n",
        "function updateStakingParams(\n address \\_DEFAULT\\_gETH\\_INTERFACE,\n address \\_DEFAULT\\_DWP,\n address \\_DEFAULT\\_LP\\_TOKEN,\n uint256 \\_MAX\\_MAINTAINER\\_FEE,\n uint256 \\_BOOSTRAP\\_PERIOD,\n uint256 \\_PERIOD\\_PRICE\\_INCREASE\\_LIMIT,\n uint256 \\_PERIOD\\_PRICE\\_DECREASE\\_LIMIT,\n uint256 \\_COMET\\_TAX,\n uint256 \\_BOOST\\_SWITCH\\_LATENCY\n) public virtual override {\n require(\n msg.sender == GEODE.GOVERNANCE,\n \"Portal: sender not GOVERNANCE\"\n );\n\n"
    ],
    "preamble": [],
    "Description": [
        "In the Portal\u2019s initialize function, the _GOVERNANCE is passed as a parameter:",
        "code/contracts/Portal/Portal.sol:L156-L196",
        "But then it calls the updateStakingParams function, which requires the msg.sender to be the governance:",
        "code/contracts/Portal/Portal.sol:L651-L665",
        "So only the future governance can initialize the Portal. In the case of the Geode protocol, the governance will be represented by a token contract, making it hard to initialize promptly. Initialization should be done by an actor that is more flexible than governance."
    ],
    "Recommendation": [
        "Split the updateStakingParams function into public and private ones and use them accordingly."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-maintainer-of-the-minigovernance-can-block-the-changemaintainer-function-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function changeMaintainer(\n bytes calldata password,\n bytes32 newPasswordHash,\n address newMaintainer\n)\n external\n virtual\n override\n onlyPortal\n whenNotPaused\n returns (bool success)\n{\n require(\n SELF.PASSWORD\\_HASH == bytes32(0) ||\n SELF.PASSWORD\\_HASH ==\n keccak256(abi.encodePacked(SELF.ID, password))\n );\n SELF.PASSWORD\\_HASH = newPasswordHash;\n\n \\_refreshSenate(newMaintainer);\n\n success = true;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Every entity with an ID has a controller and a maintainer. The controller tends to have more control, and the maintainer is mostly used for operational purposes. So the controller should be able to change the maintainer if that is required. Indeed we see that it is possible in the MiniGovernance too:",
        "code/contracts/Portal/MiniGovernance/MiniGovernance.sol:L224-L246",
        "Here the changeMaintainer function can only be called by the Portal, and only the controller can initiate that call. But the maintainer can pause the MiniGovernance, which will make this call revert because the _refreshSenate function has the whenNotPaused modifier. Thus maintainer could intentionally prevent the controller from replacing it by another maintainer."
    ],
    "Recommendation": [
        "Make sure that the controller can always change the malicious maintainer."
    ]
}
----End JSON----

https://solodit.xyz/issues/entities-are-not-required-to-be-initiated-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier initiator(\n DataStoreUtils.DataStore storage DATASTORE,\n uint256 \\_TYPE,\n uint256 \\_id,\n address \\_maintainer\n) {\n require(\n msg.sender == DATASTORE.readAddressForId(\\_id, \"CONTROLLER\"),\n \"MaintainerUtils: sender NOT CONTROLLER\"\n );\n require(\n DATASTORE.readUintForId(\\_id, \"TYPE\") == \\_TYPE,\n \"MaintainerUtils: id NOT correct TYPE\"\n );\n require(\n DATASTORE.readUintForId(\\_id, \"initiated\") == 0,\n \"MaintainerUtils: already initiated\"\n );\n\n DATASTORE.writeAddressForId(\\_id, \"maintainer\", \\_maintainer);\n\n \\_;\n\n DATASTORE.writeUintForId(\\_id, \"initiated\", block.timestamp);\n\n emit IdInitiated(\\_id, \\_TYPE);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Every entity (Planet, Comet, Operator) has a 3-step creation process:",
        "The last step is crucial, but it is never explicitly checked that the entity is initialized. The initiation always includes the initiator modifier that works with the \"initiated\" slot on DATASTORE:",
        "code/contracts/Portal/utils/MaintainerUtilsLib.sol:L46-L72",
        "But this slot is never actually checked when the entities are used. While we did not find any profitable attack vector using uninitiated entities, the code will be upgraded, which may allow for possible attack vectors related to this issue."
    ],
    "Recommendation": [
        "Make sure the entities are initiated before they are used."
    ]
}
----End JSON----

https://solodit.xyz/issues/node-operators-are-not-risking-anything-when-abandoning-their-activity-or-performing-malicious-actions-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "During the staking process, the node operators need to provide 1 ETH as a deposit for every validator that they would like to initiate. After that is done, Oracle needs to ensure that validator creation has been done correctly and then deposit the remaining 31 ETH on chain as well as reimburse 1 ETH back to the node operator. The node operator can then proceed to withdraw the funds that were used as initial deposits. As the result, node operators operate nodes that have 32 ETH each and none of which originally belonged to the operator. They essentially have no skin in the game to continue managing the validators besides a potential share in staking rewards. Instead, node operators could stop operation, or try to get slashed on purpose to create turmoil around derivatives on the market and try to capitalize while shorting the assets elsewhere."
    ],
    "Recommendation": [
        "Senate will need to be extra careful when approving operator onboarding proposals or potentially only reimburse the node operators the initial deposit after the funds were withdrawn from the MiniGovernance."
    ]
}
----End JSON----

https://solodit.xyz/issues/planets-should-not-act-as-operators-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "The system stores every entity (e.g., planet, comet, and operator) separately in DATASTORE under different IDs. But there is one exception, every planet can also act as an operator by default. This exception bypasses the general rule and goes against some expectations readers might have about the code:"
    ],
    "Recommendation": [
        "Do not allow planets to be operators in the code. If every planet should be able to act as an operator simultaneously, it is better to create separate operator entities for every planet."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-blameoperator-can-be-called-for-an-alienated-validator-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice allows improsening an Operator if the validator have not been exited until expectedExit\n \\* @dev anyone can call this function\n \\* @dev if operator has given enough allowence, they can rotate the validators to avoid being prisoned\n \\*/\nfunction blameOperator(\n StakePool storage self,\n DataStoreUtils.DataStore storage DATASTORE,\n bytes calldata pk\n) external {\n if (\n block.timestamp > self.TELESCOPE.\\_validators[pk].expectedExit &&\n self.TELESCOPE.\\_validators[pk].state != 3\n ) {\n OracleUtils.imprison(\n DATASTORE,\n self.TELESCOPE.\\_validators[pk].operatorId\n );\n }\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The blameOperator  function is designed to be called by anyone. If some operator did not signal to exit in time, anyone can blame and imprison this operator.",
        "code/contracts/Portal/utils/StakeUtilsLib.sol:L1205-L1224",
        "The problem is that it can be called for any state that is not 3 (self.TELESCOPE._validators[pk].state != 3). But it should only be called for active validators whose state equals 2. So the blameOperator can be called an infinite amount of time for alienated or not approved validators. These types of validators cannot switch to state 3.",
        "The severity of the issue is mitigated by the fact that this function is currently unavailable for users to call. But it is intended to be external once the withdrawal process is in place."
    ],
    "Recommendation": [
        "Make sure that you can only blame the operator of an active validator."
    ]
}
----End JSON----

https://solodit.xyz/issues/latency-timelocks-on-certain-functions-can-be-bypassed-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function switchMaintainerFee(\n DataStoreUtils.DataStore storage DATASTORE,\n uint256 id,\n uint256 newFee\n) external {\n DATASTORE.writeUintForId(\n id,\n \"priorFee\",\n DATASTORE.readUintForId(id, \"fee\")\n );\n DATASTORE.writeUintForId(\n id,\n \"feeSwitch\",\n block.timestamp + FEE\\_SWITCH\\_LATENCY\n );\n DATASTORE.writeUintForId(id, \"fee\", newFee);\n\n emit MaintainerFeeSwitched(\n id,\n newFee,\n block.timestamp + FEE\\_SWITCH\\_LATENCY\n );\n}\n\n",
        "function getMaintainerFee(\n DataStoreUtils.DataStore storage DATASTORE,\n uint256 id\n) internal view returns (uint256 fee) {\n if (DATASTORE.readUintForId(id, \"feeSwitch\") > block.timestamp) {\n return DATASTORE.readUintForId(id, \"priorFee\");\n }\n return DATASTORE.readUintForId(id, \"fee\");\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The functions switchMaintainerFee() and switchWithdrawalBoost() add a latency of typically three days to the current timestamp at which the new value is meant to be valid. However, they don\u2019t limit the number of times this value can be changed within the latency period. This allows a malicious maintainer to set their desired value twice and effectively make the change immediately. Let\u2019s take the first function as an example. The first call to it sets a value as the newFee, moving the old value to priorFee, which is effectively the fee in use until the time lock is up. A follow-up call to the function with the same value as a parameter would mean the \u201cnew\u201d value overwrites the old priorFee while remaining in the queue for the switch."
    ],
    "Examples": [
        "code/contracts/Portal/utils/MaintainerUtilsLib.sol:L311-L333",
        "code/contracts/Portal/utils/MaintainerUtilsLib.sol:L296-L304"
    ],
    "Recommendation": [
        "Add a check to make sure only one value can be set between time lock periods."
    ]
}
----End JSON----

https://solodit.xyz/issues/minigovernances-senate-has-almost-unlimited-validity-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "GEM.\\_setSenate(newSenate, block.timestamp + SENATE\\_VALIDITY);\n\n",
        "self.SENATE\\_EXPIRY = block.timestamp + \\_senatePeriod;\n\n"
    ],
    "preamble": [],
    "Description": [
        "A new senate for the MiniGovernance contract is set in the following line:",
        "code/contracts/Portal/MiniGovernance/MiniGovernance.sol:L201",
        "The validity period argument should not include block.timestamp, because it is going to be added a bit later in the code:",
        "code/contracts/Portal/utils/GeodeUtilsLib.sol:L496",
        "So currently, every senate of MiniGovernance will have much longer validity than it is supposed to."
    ],
    "Recommendation": [
        "Pass onlySENATE_VALIDITY in the _refreshSenate function."
    ]
}
----End JSON----

https://solodit.xyz/issues/proposed-validators-not-accounted-for-in-the-monopoly-check-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\n (DATASTORE.readUintForId(operatorId, \"totalActiveValidators\") +\n pubkeys.length) <= self.TELESCOPE.MONOPOLY\\_THRESHOLD,\n \"StakeUtils: IceBear does NOT like monopolies\"\n);\n\n",
        "require(\n (DATASTORE.readUintForId(\n poolId,\n DataStoreUtils.getKey(operatorId, \"proposedValidators\")\n ) +\n DATASTORE.readUintForId(\n poolId,\n DataStoreUtils.getKey(operatorId, \"activeValidators\")\n ) +\n pubkeys.length) <=\n operatorAllowance(DATASTORE, poolId, operatorId),\n \"StakeUtils: NOT enough allowance\"\n);\n\n"
    ],
    "preamble": [],
    "Description": [
        "The Geode team introduced a check that makes sure that node operators do not initiate more validators than a threshold called MONOPOLY_THRESHOLD allows. It is used on call to proposeStake(...) which the operator would call in order to propose new validators. It is worth mentioning that onboarding new validator nodes requires 2 steps: a proposal from the node operator and approval from the planet maintainer. After the first step validators get a status of proposed. After the second step validators get the status of active and all eth accounting is done. The issue we found is that the proposed validators step performs the monopoly check but does not account for previously proposed but not active validators."
    ],
    "Examples": [
        "Assume that MONOPOLY_THRESHOLD is set to 5. The node operator could propose 4 new validators and pass the monopoly check and label those validators as proposed. The node operator could then suggest 4 more validators in a separate transaction and since the monopoly check does not check for the proposed validators, that would pass as well. Then in beaconStake or the step of maintainer approval, there is no monopoly check at all, so 8 validators could be activated at once.",
        "code/contracts/Portal/utils/StakeUtilsLib.sol:L978-L982"
    ],
    "Recommendation": [
        "Include the (DATASTORE.readUintForId(poolId,DataStoreUtils.getKey(operatorId, \"proposedValidators\")) into the require statement, just like in the check for the node operator allowance check.",
        "code/contracts/Portal/utils/StakeUtilsLib.sol:L983-L995"
    ]
}
----End JSON----

https://solodit.xyz/issues/comparison-operator-used-instead-of-assignment-operator-consensys-none-geodefi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "self.\\_validators[\\_pk].state == 2;\n\n",
        "self.\\_validators[\\_pk].state == 3;\n\n"
    ],
    "preamble": [],
    "Description": [
        "A common typo is present twice in the OracleUtilsLib.sol where == is used instead of = resulting in incorrect storage updates."
    ],
    "Examples": [
        "code/contracts/Portal/utils/OracleUtilsLib.sol:L250",
        "code/contracts/Portal/utils/OracleUtilsLib.sol:L269"
    ],
    "Recommendation": [
        "Replace == with =."
    ]
}
----End JSON----

https://solodit.xyz/issues/malicious-maker-can-take-more-takers-funds-than-taker-expected-consensys-1inch-exchange-aggregationrouter-v5-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "actualMakingAmount = \\_getMakingAmount(order.getMakingAmount(), order.takingAmount, actualTakingAmount, order.makingAmount, remainingMakingAmount, orderHash);\nif (actualMakingAmount > remainingMakingAmount) {\n    actualMakingAmount = remainingMakingAmount;\n    actualTakingAmount = \\_getTakingAmount(order.getTakingAmount(), order.makingAmount, actualMakingAmount, order.takingAmount, remainingMakingAmount, orderHash);\n\n",
        "actualMakingAmount = \\_getMakingAmount(order.getMakingAmount(), order.takingAmount, actualTakingAmount, order.makingAmount, remainingMakingAmount, orderHash);\n\n",
        "function \\_getMakingAmount(\n    bytes calldata getter,\n    uint256 orderTakingAmount,\n    uint256 requestedTakingAmount,\n    uint256 orderMakingAmount,\n    uint256 remainingMakingAmount,\n    bytes32 orderHash\n) private view returns(uint256) {\n    if (getter.length == 0) {\n        // Linear proportion\n        return getMakingAmount(orderMakingAmount, orderTakingAmount, requestedTakingAmount);\n    }\n    return \\_callGetter(getter, orderTakingAmount, requestedTakingAmount, orderMakingAmount, remainingMakingAmount, orderHash);\n}\n\n",
        "library OrderLib {\n    struct Order {\n        uint256 salt;\n        address makerAsset;\n        address takerAsset;\n        address maker;\n        address receiver;\n        address allowedSender;  // equals to Zero address on public orders\n        uint256 makingAmount;\n        uint256 takingAmount;\n        uint256 offsets;\n        // bytes makerAssetData;\n        // bytes takerAssetData;\n        // bytes getMakingAmount; // this.staticcall(abi.encodePacked(bytes, swapTakerAmount)) => (swapMakerAmount)\n        // bytes getTakingAmount; // this.staticcall(abi.encodePacked(bytes, swapMakerAmount)) => (swapTakerAmount)\n        // bytes predicate; // this.staticcall(bytes) => (bool)\n        // bytes permit; // On first fill: permit.1.call(abi.encodePacked(permit.selector, permit.2))\n        // bytes preInteraction;\n        // bytes postInteraction;\n        bytes interactions; // concat(makerAssetData, takerAssetData, getMakingAmount, getTakingAmount, predicate, permit, preIntercation, postInteraction)\n    }\n\n",
        "    function \\_callGetter(\n        bytes calldata getter,\n        uint256 orderExpectedAmount,\n        uint256 requestedAmount,\n        uint256 orderResultAmount,\n        uint256 remainingMakingAmount,\n        bytes32 orderHash\n    ) private view returns(uint256) {\n        if (getter.length == 1) {\n            if (OrderLib.getterIsFrozen(getter)) {\n                // On \"x\" getter calldata only exact amount is allowed\n                if (requestedAmount != orderExpectedAmount) revert WrongAmount();\n                return orderResultAmount;\n            } else {\n                revert WrongGetter();\n            }\n        } else {\n            (address target, bytes calldata data) = getter.decodeTargetAndCalldata();\n            (bool success, bytes memory result) = target.staticcall(abi.encodePacked(data, requestedAmount, remainingMakingAmount, orderHash));\n            if (!success || result.length != 32) revert GetAmountCallFailed();\n            return abi.decode(result, (uint256));\n        }\n    }\n}\n\n",
        "actualTakingAmount = \\_getTakingAmount(order.getTakingAmount(), order.makingAmount, actualMakingAmount, order.takingAmount, remainingMakingAmount, orderHash);\n\n",
        "if (actualMakingAmount \\* takingAmount < thresholdAmount \\* actualTakingAmount) revert MakingAmountTooLow();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the 1inch team in 1inch/[email\u00a0protected]9ddc086 by adding a check that reverts when actualTakingAmount > takingAmount",
        "OrderMixin contract allows users to match makers(sellers) and takers(buyers) in an orderbook-like manner. One additional feature this contract has is that both makers and takers are allowed to integrate hooks into their orders to better react to market conditions and manage funds on the fly. Two out of many of these hooks are called: _getMakingAmount and _getTakingAmount. Those particular hooks allow the maker to dynamically respond to the making or taking amounts supplied by the taker. Essentially they allow overriding the rate that was initially set by the maker when creating an order up to a certain extent. To make sure that the newly suggested maker rate is reasonable taker also provides a threshold value or in other words the minimum amount of assets the taker is going to be fine receiving.",
        "Generally speaking, the maker can override the taking amount offered to the taker if the buyer passed a specific making amount in the fill transaction and vice versa. But there is one special case where the maker will be able to override both, which when done right will force the taker to spend an amount larger than the one intended. Specifically, this happens when the taker passed the desired taking amount and the maker returns a suggested making amount that is larger than the remaining order size. In this case, the making amount is being set to the remaining order amount and the taking is being recomputed.",
        "limit-order-protocol/contracts/OrderMixin.sol:L214-L217",
        "Essentially this allows the maker to override the taker amount and as long as the maker keeps the price intact or changed within a certain threshold like described in this issue, they can take all taking tokens of the buyer up to an amount of the token balance or approval limit whatever comes first.",
        "Consider the following example scenario:",
        "When taker tries to fill this order taker passes the takingAmount to be 100. Since OrderMixin received the taking amount we go this route:",
        "limit-order-protocol/contracts/OrderMixin.sol:L214",
        "However, note that when executing the _getMakingAmount() function, it first evaluates the order.getMakingAmount() argument which is evaluated as bytes calldata _getter within the function.",
        "limit-order-protocol/contracts/OrderMixin.sol:L324-L337",
        "That is because the Order struct that is made and signed by the maker actually contains the necessary bytes within it that can be decoded to construct a target and calldata for static calls, which in this case are supposed to be used to return the making asset amounts that the maker determines to be appropriate, as seen in the comments under the uint256 offsets part of the struct.",
        "limit-order-protocol/contracts/OrderLib.sol:L7-L27",
        "Finally, if these bytes indeed contain data (i.e. length>0), they are passed to the _callGetter() function that asks the previously mentioned target for the data.",
        "limit-order-protocol/contracts/OrderMixin.sol:L354-L377",
        "However, since the getter is set in the Order struct, and the Order is set by the maker, the getter itself is entirely under the maker\u2019s control and can return whatever the maker wants, with no regard for the taker\u2019s passed actualTakingAmount or any arguments at all for that matter.\nSo, in our example, the return value could be 100.1 ETH, i.e. just above the total order size. That will get us on the route of recomputing the taking amount since 100.1 is over the 100ETH remaining in the order.",
        "limit-order-protocol/contracts/OrderMixin.sol:L217",
        "This branch will set the actualMakingAmount to 100ETH and then the malicious maker will say the actualTakingAmount is 10000 DAI, this can be done via the _getTakingAmount static call in the same exact way as the making amount was manipulated.",
        "Then the threshold check would look like this as defined by its formula:",
        "limit-order-protocol/contracts/OrderMixin.sol:L222",
        "then: 100ETH * 100DAI < 1ETH*10000DAI This condition will be false so we will pass this check.",
        "Then we proceed to taker interaction. Assuming the taker did not pass any interaction, the actualTakingAmount will not change.",
        "Then we proceed to exchange tokens between maker and taker in the amount of actualTakingAmount and actualMakingAmount.",
        "The scenario allows the maker to take the taker\u2019s funds up to an amount of taker\u2019s approval or balance. Essentially while taker wanted to only spend 100 DAI, potentially they ended up spending much more. This paired with infinite approvals that are currently enabled on the 1inch UI could lead to funds being lost.",
        "While this does not introduce a price discrepancy this attack can be profitable to the malicious actor.\nThe attacker could put an order to sell a large amount of new not trustworthy tokens for sale who\u2019s supply the attacker controls. Then after a short marketing campaign when people will cautiously try to buy a small amount of those tokens for let\u2019s say a small amount of USDC due to this bug attacker could drain all of their USDC.",
        "We advise that 1inch team treats this issue with extra care since a similar issue is present in a currently deployed production version of 1inch OrderMixin. One potential solution to this bug is introducing a global threshold that would represent by how much the actual taking amount can differ from the taker provided taking amount."
    ]
}
----End JSON----

https://solodit.xyz/issues/invalidating-users-orders-consensys-1inch-exchange-aggregationrouter-v5-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "{  // Stack too deep\n    uint256 info = order.info;\n    // Check time expiration\n    uint256 expiration = uint128(info) >> 64;\n    if (expiration != 0 && block.timestamp > expiration) revert OrderExpired(); // solhint-disable-line not-rely-on-time\n    \\_invalidateOrder(maker, info, 0);\n}\n\n"
    ],
    "preamble": [
        "1inch team has implemented a more streamlined version of the order book that is called OrderRFQMixin. This version has no hooks and is meant to be more straightforward than the main order book contract.",
        "One significant difference between those contracts is that the RFQ version invalidates the orders even after they have been only partially filled.",
        "limit-order-protocol/contracts/OrderRFQMixin.sol:L197-L203",
        "Since makers have to sign the orders, only makers can place the remainder of the original order as a new one. Given that information, an attacker could take all the orders and fill them with 1 wei of taking assets. While this will cost an attacker gas, on some chains it would be possible to make the operations of the protocol unreliable and impractical for makers.",
        "One way to fix that without making significant changes to the logic is to introduce a threshold that will determine the smallest taking amount for each order. That could be a percent of the taking amount specified in the order. This change will make the attack more expensive and less likely to happen."
    ]
}
----End JSON----

https://solodit.xyz/issues/ecdsa-library-has-a-vulnerability-for-signature-malleability-of-eip-2098-compact-signatures-consensys-1inch-exchange-aggregationrouter-v5-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Remediated as per the 1inch team in 1inch/[email\u00a0protected]166353b by adding a warning note in the comments of the library code.",
        "The 1inch ECDSA library supports several types of signatures and forms in which they could be provided. However, for compact signatures there is a recently found malleability attack vector. Specifically, the issue arises when contracts use transaction replay protection through signature uniqueness (i.e. by marking it as used). While this may not be the case in the scope of other contracts of this audit, this ECDSA library is meant to be a general use library so it should be fixed so as to not mislead others who might use this.",
        "For more details and context, find below the advisory notice and fix in the OpenZeppelin\u2019s ECDSA library:\nhttps://github.com/OpenZeppelin/openzeppelin-contracts/security/advisories/GHSA-4h98-2769-gh6h\nOpenZeppelin/[email\u00a0protected]d693d89"
    ]
}
----End JSON----

https://solodit.xyz/issues/ethereum-reimbursements-sent-to-an-incorrect-address-consensys-1inch-exchange-aggregationrouter-v5-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (msg.value > amount) {\n    // Return remainder if exist\n    unchecked {\n        (bool success, ) = to.call{value: msg.value - amount}(\"\");  // solhint-disable-line avoid-low-level-calls\n        if (!success) revert ETHSendFailed();\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the 1inch team as of 1inch/[email\u00a0protected]6b1a3df by adding the correct recipient of the refund.",
        "1inch team has written a library called UniERC20 that extends the traditional ERC20 standard to also support eth transfers seamlessly. In the case of the uniTransferFrom function call, the library checks that the msg.value of the transaction is bigger or equal to the amount passed in the function argument. If the msg.value is larger than the amount required, the difference, or extra funds, should be sent to the sender. In the actual implementation Instead of returning the funds to the sender, extra funds are actually sent to the destination.",
        "solidity-utils/contracts/libraries/UniERC20.sol:L59-L65",
        "Given that this code is packed as a library and allows for easy reusability by the 1inch team and outside developers it is crucial that this logic is written well and well tested.",
        "We recommend reconsidering reimbursing the sender when an incorrect amount is being sent because it introduces an easy-to-oversee reentrancy backdoor with call() that is mentioned in issue 6.4. Reverting was a default behavior in similar cases across the rest of the 1inch contracts.",
        "If this functionality is required, a fix we could recommend is replacing the to with from. We can also suggest running a fuzzing campaign against this library."
    ]
}
----End JSON----

https://solodit.xyz/issues/ecdsa-incorrect-size-provided-for-calldata-in-the-static-call-consensys-1inch-exchange-aggregationrouter-v5-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if staticcall(gas(), signer, ptr, 0xa5, 0, 0x20) {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the 1inch team in 1inch/[email\u00a0protected]cfdc889 by passing the correct data size.",
        "The ECDSA library implements support for IERC1271 interfaces that verify provided signature for the data through the different isValidSignature functions that depend on the type of signature used.",
        "However, the library passes an incorrect size for the calldata in the static call for signatures that are of the form (bytes32 r, bytes32 vs). It should be 0xa4 (164 bytes) instead of 0xa5 (165 bytes).",
        "solidity-utils/contracts/libraries/ECDSA.sol:L178",
        "The impact could vary and depends on the signature verifier. For example, it could be significant if the signature verifier performs a check on the calldatasize for this specific type of signature and reverts on incorrect sizes, thereby having valid signatures return false when passed to isValidSignature."
    ]
}
----End JSON----

https://solodit.xyz/issues/re-entrancy-risk-in-unierc20-consensys-1inch-exchange-aggregationrouter-v5-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "(bool success, ) = to.call{value: amount}(\"\");  // solhint-disable-line avoid-low-level-calls\n\n",
        "(bool success, ) = to.call{value: msg.value - amount}(\"\");  // solhint-disable-line avoid-low-level-calls\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated as per the 1inch team in 1inch/[email\u00a0protected]6b1a3df by forwarding a limited amount of gas to guard against complex execution at the target but still allow for smart contract receipt that may require a bit more gas than usual EOA receipts.",
        "UniERC20 is a general library for facilitating transfers of any ERC20 or native coin assets. It features gas-efficient code and could be easily integrated into large systems of contract, such as those that are used in this audit \u2013 1inch routers and limit order protocol.",
        "However, it also utilizes .call(){value:X} method of transferring chain native assets, such as ETH. This introduces a large risk in the form of re-entrancy attacks, so any system implementing this library would have to handle them. While 1inch\u2019s projects in the scope of this audit do not seem to have re-entrancy attack vectors, other projects that could be utilizing this library might. Since this is an especially efficient and convenient library, the likelihood that some other project using this suffers and then sufferring a re-entrancy attack is significant.",
        "solidity-utils/contracts/libraries/UniERC20.sol:L45",
        "solidity-utils/contracts/libraries/UniERC20.sol:L62",
        "Consider instead implementing transfer() or send() methods for transferring chain native assets, such as ETH, instead of performing a .call()"
    ]
}
----End JSON----

https://solodit.xyz/issues/vaultconfigsetvaultconfig-doesnt-check-all-critical-arguments-consensys-notional-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Token memory assetToken = TokenHandler.getAssetToken(vaultConfig.borrowCurrencyId);\nToken memory underlyingToken = TokenHandler.getUnderlyingToken(vaultConfig.borrowCurrencyId);\nrequire(!assetToken.hasTransferFee && !underlyingToken.hasTransferFee);\n\n",
        "uint256 vaultSharesToLiquidator;\n{\n    vaultSharesToLiquidator = vaultAccount.tempCashBalance.toUint()\n        .mul(vaultConfig.liquidationRate.toUint())\n        .mul(vaultAccount.vaultShares)\n        .div(vaultShareValue.toUint())\n        .div(uint256(Constants.RATE\\_PRECISION));\n}\n\nvaultAccount.vaultShares = vaultAccount.vaultShares.sub(vaultSharesToLiquidator);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated per Notional\u2019s team notes in commit by adding the following checks:",
        "Check for maxBorrowMarketIndex was not added. The Notional team will review this parameter on a case-by-case basis as for some vaults borrowing idiosyncratic fCash may not be an issue"
    ],
    "Description": [
        "The Notional Strategy Vaults need to get whitelisted and have specific Notional parameters set in order to interact with the rest of the Notional system. This is done through VaultAction.updateVault() where the owner address can provide a VaultConfigStorage calldata vaultConfig argument to either whitelist a new vault or change an existing one. While this is to be performed by a trusted privileged actor (the owner), and it could be assumed they are careful with their updates, the contracts themselves don\u2019t perform enough checks on the validity of the parameters, either in isolation or when compared against the existing vault state. Below are examples of arguments that should be better checked."
    ],
    "borrowCurrencyId": [
        "The borrowCurrencyId parameter gets provided to TokenHandler.getAssetToken() and TokenHandler.getUnderlyingToken() to retrieve its associated TokenStorage object and verify that the currency doesn\u2019t have transfer fees.",
        "contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L162-L164",
        "However, these calls retrieve data from the mapping from storage which returns an empty struct for an unassigned currency ID. This would pass the check in the last require statement regarding the transfer fees and would successfully allow to set the currency even if isn\u2019t actually registered in Notional. The recommendation would be to check that the returned TokenStorage object has data inside of it, perhaps by checking the decimals on the token.",
        "In the event that this is a call to update the configuration on a vault instead of whitelisting a whole new vault, this would also allow to switch the borrow currency without checking that the existing borrow and lending accounting has been cleared. This could cause accounting issues. A check for existing debt before swapping the borrow currency IDs is recommended."
    ],
    "liquidationRate and minCollateralRatioBPS": [
        "To ensure that the system doesn\u2019t have bad debt, it employs a liquidation engine that depends on a few parameters, in particular the vault\u2019s liquidationRate that incentivises liquidators and minCollateralRatioBPS that determines when an account can be liquidated.minCollateralRationBPS+100% (since the collateral ratio is calculated starting from 0% not 100%) would need to be greater than liquidationRate (that is calculated from 100%) or the system could run into problems liquidating small accounts entering the vault.\nThere is an edge case during liquidation where if the account is below the minimum collateral ratio but doesn\u2019t have to be liquidated fully, the leftover position from that account would be too small for liquidators to profitably liquidate (due to gas costs) as per another configuration parameter minAccountBorrowSize. In this edge case, the system would set the whole account to be liquidated and determine that the liquidator deposit required would be equal to that account\u2019s total debt, which would be normally seen as vaultAccount.fCash. The liquidator in this case would roughly receive as much value as vaultAccount.fCash*liquidationRate denominated in that vault account\u2019s vaultAccount.vaultShares, which is the existing assets of that vault account. In fact the liquidator gets:",
        "contracts-v2/contracts/external/actions/VaultAccountAction.sol:L274-L283",
        "Where vaultAccount.tempCashBalance has the liquidator deposit, which in this case would be the account\u2019s debt and equal to vaultAccount.fCash. However, since we know that this account is being liquidated, we know that fCash*(1+minCollateralRationBPS) >= vaultShareValue. Similarly, assuming the liquidation rate was set incorrectly as defined in the beginning of this section, i.e. liquidationRate > (1+minCollateralRationBPS), we can determine that fCash*(liquidationRate) > vaultShareValue as well. Therefore, we will get some number vaultSharesToLiquidator=X*vaultAccount.vaultShares, where X=(vaultAccount.tempCashBalance*vaultConfig.liquidationRate)/(vaultShareValue) and X>1, so the result will be vaultSharesToLiquidator>vaultAccount.vaultShares, which will cause a revert once the liquidator shares get subtracted from that vault account\u2019s vault share balance. This will cause the account to remain in the system until the account is possibly insolvent , potentially causing bad debt.\nThe recommendation would be to check that the liquidation rate is less than the minimum collateral ratio, of course in the appropriate denomination (i.e. do minCollateral+1) and precision."
    ],
    "maxBorrowMarketIndex": [
        "The current Strategy Vault implementation does not allow for idiosyncratic cash because it causes issues during exits as there are no active markets for the account\u2019s maturity. Therefore, the configuration shouldn\u2019t be set with maxBorrowMarketIndex >=3 as that would open up the 1 Year maturity for vault accounts that could cause idiosyncratic fCash. The recommendation would be to add that check."
    ],
    "secondaryBorrowCurrencies": [
        "Similarly to the borrowCurrencyId, there are few checks that actually determine that the secondaryBorrowCurrencies[] given are actually registered in Notional. This is, however, more inline with how some vaults are supposed to work as they may have no secondary currencies at all, such as when the secondaryBorrowCurrencies[] id is given as 0.\nIn the event that this is a call to update the configuration on a vault instead of whitelisting a whole new vault, this would also allow to switch the secondary borrow currency without checking that the existing borrow and lending accounting has been cleared. For example, the VaultAction.updateSecondaryBorrowCapacity() function could be invoked on the new set of secondary currencies and simply increase the borrow there. This could cause accounting issues. A check for existing debt before swapping the borrow currency IDs is recommended."
    ]
}
----End JSON----

https://solodit.xyz/issues/handle-division-by-0-consensys-notional-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "int256 settledVaultValue = settlementRate.convertToUnderlying(residualAssetCashBalance)\n    .add(totalStrategyTokenValueAtSettlement);\n\n// If the vault is insolvent (meaning residualAssetCashBalance < 0), it is necessarily\n// true that totalStrategyTokens == 0 (meaning all tokens were sold in an attempt to\n// repay the debt). That means settledVaultValue == residualAssetCashBalance, strategyTokenClaim == 0\n// and assetCashClaim == totalAccountValue. Accounts that are still solvent will be paid from the\n// reserve, accounts that are insolvent will have a totalAccountValue == 0.\nstrategyTokenClaim = totalAccountValue.mul(vaultState.totalStrategyTokens.toInt())\n    .div(settledVaultValue).toUint();\n\nassetCashClaim = totalAccountValue.mul(residualAssetCashBalance)\n    .div(settledVaultValue);\n\n",
        "uint256 vaultSharesToLiquidator;\n{\n    vaultSharesToLiquidator = vaultAccount.tempCashBalance.toUint()\n        .mul(vaultConfig.liquidationRate.toUint())\n        .mul(vaultAccount.vaultShares)\n        .div(vaultShareValue.toUint())\n        .div(uint256(Constants.RATE\\_PRECISION));\n}\n\n",
        "VaultSecondaryBorrowStorage storage balance =\n    LibStorage.getVaultSecondaryBorrow()[vaultConfig.vault][maturity][currencyId];\nuint256 totalfCashBorrowed = balance.totalfCashBorrowed;\nuint256 totalAccountDebtShares = balance.totalAccountDebtShares;\n\nfCashToLend = debtSharesToRepay.mul(totalfCashBorrowed).div(totalAccountDebtShares).toInt();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Remediated per Notional\u2019s team notes in commit by adding the following checks:",
        "The Notional team also acknowledged that the contract will revert when vaultShareValue = 0. The team decided to not make any changes related to that since liquidation will not accomplish anything for an account with no vault share value."
    ],
    "Description": [
        "There are a few places in the code where division by zero may occur but isn\u2019t handled."
    ],
    "Examples": [
        "If the vault settles at exactly 0 value with 0 remaining strategy token value, there may be an unhandled division by zero trying to divide claims on the settled assets:",
        "contracts-v2/contracts/internal/vaults/VaultAccount.sol:L424-L436",
        "If a vault account is entirely insolvent and its vaultShareValue is zero, there will be an unhandled division by zero during liquidation:",
        "contracts-v2/contracts/external/actions/VaultAccountAction.sol:L274-L281",
        "If a vault account\u2019s secondary debt is being repaid when there is none, there will be an unhandled division by zero:",
        "contracts-v2/contracts/internal/vaults/VaultConfiguration.sol:L661-L666",
        "While these cases may be unlikely today, this code could be reutilized in other circumstances later that could cause reverts and even disrupt operations more frequently."
    ],
    "Recommendation": [
        "Handle the cases where the denominator could be zero appropriately."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-virtual-price-may-not-correspond-to-the-actual-price-in-the-pool-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "A Curve pool has a function that returns a \u201cvirtual price\u201d of the LP token; this price is resistant to flash-loan attacks and any manipulations in the Curve pool. While this price formula works well in some cases, there may be a significant period when a trade cannot be executed with this price. So the deposit or withdrawal will also be done under another price and will have a different result than the one estimated under the \u201cvirtual price\u201d.",
        "When depositing into Curve, Brahma is doing it in 2 steps. First, when depositing the user\u2019s ETH to the Vault, the user\u2019s share is calculated according to the \u201cvirtual price\u201d. And then, in a different transaction, the funds are deposited into the Curve pool. These funds only consist of ETH, and if the deposit price does not correspond (with 0.3% slippage) to the virtual price, it will revert.",
        "So we have multiple problems here:"
    ]
}
----End JSON----

https://solodit.xyz/issues/convexpositionhandler_claimrewards-incorrectly-calculates-amount-of-lp-tokens-to-unstake-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 currentSharePrice = ethStEthPool.get\\_virtual\\_price();\nif (currentSharePrice > prevSharePrice) {\n    // claim any gain on lp token yields\n    uint256 contractLpTokenBalance = lpToken.balanceOf(address(this));\n    uint256 totalLpBalance = contractLpTokenBalance +\n        baseRewardPool.balanceOf(address(this));\n    uint256 yieldEarned = (currentSharePrice - prevSharePrice) \\*\n        totalLpBalance;\n\n",
        "uint256 lpTokenEarned = yieldEarned / NORMALIZATION\\_FACTOR; // 18 decimal from virtual price\n\n"
    ],
    "preamble": [],
    "Description": [
        "ConvexPositionHandler._claimRewards is an internal function that harvests Convex reward tokens and takes the generated yield in ETH out of the Curve pool by calculating the difference in LP token price. To do so, it receives the current share price of the curve LP tokens and compares it to the last one stored in the contract during the last rewards claim. The difference in share price is then multiplied by the LP token balance to get the ETH yield via the yieldEarned variable:",
        "code/contracts/ConvexExecutor/ConvexPositionHandler.sol:L293-L300",
        "However, to receive this ETH yield, LP tokens need to be unstaked from the Convex pool and then converted via the Curve pool. To do this, the contract introduces lpTokenEarned:",
        "code/contracts/ConvexExecutor/ConvexPositionHandler.sol:L302",
        "This calculation is incorrect. It uses yieldEarned which is denominated in ETH and simply divides it by the normalization factor to get the correct number of decimals, which still returns back an amount denominated in ETH, whereas an amount denominated in LP tokens should be returned instead.",
        "This could lead to significant accounting issues including losses in the \u201cno-loss\u201d parts of the vault\u2019s strategy as 1 LP token is almost always guaranteed to be worth more than 1 ETH. So, when the intention is to withdraw X ETH worth of an LP token, withdrawing X LP tokens will actually withdraw Y ETH worth of an LP token, where Y>X. As a result, less than expected ETH will remain in the Convex handler part of the vault, and the ETH yield will go to the Lyra options, which are much riskier. In the event Lyra options don\u2019t work out and there is more ETH withdrawn than expected, there is a possibility that this would result in a loss for the vault."
    ],
    "Recommendation": [
        "The fix is straightforward and that is to calculate lpTokenEarned using the currentSharePrice already received from the Curve pool. That way, it is the amount of LP tokens that will be sent to be unwrapped and unstaked from the Convex and Curve pools. This will also take care of the normalization factor.\nuint256 lpTokenEarned = yieldEarned / currentSharePrice;"
    ]
}
----End JSON----

https://solodit.xyz/issues/the-weth-tokens-are-not-taken-into-account-in-the-convextradeexecutortotalfunds-function-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function totalFunds() public view override returns (uint256, uint256) {\n    return ConvexPositionHandler.positionInWantToken();\n}\n\n",
        "function positionInWantToken()\n    public\n    view\n    override\n    returns (uint256, uint256)\n{\n    (\n        uint256 stakedLpBalanceInETH,\n        uint256 lpBalanceInETH,\n        uint256 ethBalance\n    ) = \\_getTotalBalancesInETH(true);\n\n    return (\n        stakedLpBalanceInETH + lpBalanceInETH + ethBalance,\n        block.number\n    );\n}\n\n",
        "function \\_getTotalBalancesInETH(bool useVirtualPrice)\n    internal\n    view\n    returns (\n        uint256 stakedLpBalance,\n        uint256 lpTokenBalance,\n        uint256 ethBalance\n    )\n{\n    uint256 stakedLpBalanceRaw = baseRewardPool.balanceOf(address(this));\n    uint256 lpTokenBalanceRaw = lpToken.balanceOf(address(this));\n\n    uint256 totalLpBalance = stakedLpBalanceRaw + lpTokenBalanceRaw;\n\n    // Here, in order to prevent price manipulation attacks via curve pools,\n    // When getting total position value -> its calculated based on virtual price\n    // During withdrawal -> calc\\_withdraw\\_one\\_coin() is used to get an actual estimate of ETH received if we were to remove liquidity\n    // The following checks account for this\n    uint256 totalLpBalanceInETH = useVirtualPrice\n        ? \\_lpTokenValueInETHFromVirtualPrice(totalLpBalance)\n        : \\_lpTokenValueInETH(totalLpBalance);\n\n    lpTokenBalance = useVirtualPrice\n        ? \\_lpTokenValueInETHFromVirtualPrice(lpTokenBalanceRaw)\n        : \\_lpTokenValueInETH(lpTokenBalanceRaw);\n\n    stakedLpBalance = totalLpBalanceInETH - lpTokenBalance;\n    ethBalance = address(this).balance;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The totalFunds function of every executor should include all the funds that belong to the contract:",
        "code/contracts/ConvexTradeExecutor.sol:L21-L23",
        "The ConvexTradeExecutor uses this function for calculations:",
        "code/contracts/ConvexExecutor/ConvexPositionHandler.sol:L121-L137",
        "code/contracts/ConvexExecutor/ConvexPositionHandler.sol:L337-L365",
        "This function includes ETH balance, LP balance, and staked balance. But WETH balance is not included here.\nWETH tokens are initially transferred to the contract, and before the withdrawal, the contract also stores WETH."
    ],
    "Recommendation": [
        "Include WETH balance into the totalFunds."
    ]
}
----End JSON----

https://solodit.xyz/issues/lyrapositionhandlerl2-inaccurate-modifier-onlyauthorized-may-lead-to-funds-loss-if-keeper-is-compromised-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier onlyAuthorized() {\n    require(\n        ((msg.sender == L2CrossDomainMessenger &&\n            OptimismL2Wrapper.messageSender() == positionHandlerL1) ||\n            msg.sender == keeper),\n        \"ONLY\\_AUTHORIZED\"\n    );\n    \\_;\n}\n\n",
        "function closePosition(bool toSettle) public override onlyAuthorized {\n    LyraController.\\_closePosition(toSettle);\n    UniswapV3Controller.\\_estimateAndSwap(\n        false,\n        LyraController.sUSD.balanceOf(address(this))\n    );\n}\n\n/\\*///////////////////////////////////////////////////////////////\n MAINTAINANCE FUNCTIONS\n//////////////////////////////////////////////////////////////\\*/\n\n/// @notice Sweep tokens\n/// @param \\_token Address of the token to sweepr\nfunction sweep(address \\_token) public override onlyAuthorized {\n    IERC20(\\_token).transfer(\n        msg.sender,\n        IERC20(\\_token).balanceOf(address(this))\n    );\n}\n\n/// @notice socket registry setter\n/// @param \\_socketRegistry new address of socket registry\nfunction setSocketRegistry(address \\_socketRegistry) public onlyAuthorized {\n    socketRegistry = \\_socketRegistry;\n}\n\n/// @notice keeper setter\n/// @param \\_keeper new keeper address\nfunction setKeeper(address \\_keeper) public onlyAuthorized {\n    keeper = \\_keeper;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The LyraPositionHandlerL2 contract is operated either by the L2 keeper or by the L1 LyraPositionHandler via the L2CrossDomainMessenger. This is implemented through the onlyAuthorized modifier:",
        "code/contracts/LyraL2/LyraPositionHandlerL2.sol:L187-L195",
        "This is set on:",
        "Functions 1-3 have a corresponding implementation on the L1 LyraPositionHandler, so they could indeed be called by it with the right parameters. However, 4-8 do not have an implemented way to call them from L1, and this modifier creates an unnecessarily expanded list of authorised entities that can call them.",
        "Additionally, even if their implementation is provided, it needs to be done carefully because msg.sender in their case is going to end up being the L2CrossDomainMessenger. For example, the sweep() function sends any specified token to msg.sender, with the intention likely being that the recipient is under the team\u2019s or the governance\u2019s control \u2013 yet, it will be L2CrossDomainMessenger and the tokens will likely be lost forever instead.",
        "On the other hand, the setKeeper() function would need a way to be called by something other than the keeper because it is intended to change the keeper itself. In the event that the access to the L2 keeper is compromised, and the L1 LyraPositionHandler has no way to call setKeeper() on the LyraPositionHandlerL2, the whole contract and its funds will be compromised as well. So, there needs to be some way to at least call the setKeeper() by something other than the keeper to ensure security of the funds on L2."
    ],
    "Examples": [
        "code/contracts/LyraL2/LyraPositionHandlerL2.sol:L153-L184"
    ],
    "Recommendation": [
        "Create an additional modifier for functions intended to be called just by the keeper (onlyKeeper) such as functions 4-7, and create an additional modifier onlyGovernance for the setKeeper() function. As an example, the L1 Vault contract also has a setKeeper() function that has a onlyGovernance() modifier. Please note that this will likely require implementing a function for the system\u2019s governance that can call LyraPositionHandlerL2.setKeeper() via the L2CrossDomainMessenger."
    ]
}
----End JSON----

https://solodit.xyz/issues/harvesterharvest-swaps-have-no-slippage-parameters-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_swapLidoForWETH(uint256 amountToSwap) internal {\n    IUniswapSwapRouter.ExactInputSingleParams\n        memory params = IUniswapSwapRouter.ExactInputSingleParams({\n            tokenIn: address(ldo),\n            tokenOut: address(weth),\n            fee: UNISWAP\\_FEE,\n            recipient: address(this),\n            deadline: block.timestamp,\n            amountIn: amountToSwap,\n            amountOutMinimum: 0,\n            sqrtPriceLimitX96: 0\n        });\n    uniswapRouter.exactInputSingle(params);\n}\n\n",
        "if (cvxBalance > 0) {\n    cvxeth.exchange(1, 0, cvxBalance, 0, false);\n}\n// swap CRV to WETH\nif (crvBalance > 0) {\n    crveth.exchange(1, 0, crvBalance, 0, false);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "As part of the vault strategy, all reward tokens for staking in the Convex ETH-stETH pool are claimed and swapped into ETH. The swaps for these tokens are done with no slippage at the moment, i.e. the expected output amount for all of them is given as 0.",
        "In particular, one reward token that is most susceptible to slippage is LDO, and its swap is implemented through the Uniswap router:",
        "code/contracts/ConvexExecutor/Harvester.sol:L142-L155",
        "The swap is called with amountOutMinimum: 0, meaning that there is no slippage protection in this swap. This could result in a significant loss of yield from this reward as MEV bots could \u201csandwich\u201d this swap by manipulating the price before this transaction and immediately reversing their action after the transaction, profiting at the expense of our swap. Moreover, the Uniswap pools seem to have low liquidity for the LDO token as opposed to Balancer or Sushiswap, further magnifying slippage issues and susceptibility to frontrunning.",
        "The other two tokens - CVX and CRV - are being swapped through their Curve pools, which have higher liquidity and are less susceptible to slippage. Nonetheless, MEV strategies have been getting more advanced and calling these swaps with 0 as expected output may place these transactions in danger of being frontrun and \u201csandwiched\u201d as well.",
        "code/contracts/ConvexExecutor/Harvester.sol:L120-L126",
        "In these calls .exchange , the last 0 is the min_dy argument in the Curve pools swap functions that represents the minimum expected amount of tokens received after the swap, which is 0 in our case."
    ],
    "Recommendation": [
        "Introduce some slippage parameters into the swaps."
    ]
}
----End JSON----

https://solodit.xyz/issues/harvesterrewardtokens-doesnt-account-for-ldo-tokens-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// get list of tokens to transfer to harvester\naddress[] memory rewardTokens = harvester.rewardTokens();\n//transfer them\nuint256 balance;\nfor (uint256 i = 0; i < rewardTokens.length; i++) {\n    balance = IERC20(rewardTokens[i]).balanceOf(address(this));\n\n    if (balance > 0) {\n        IERC20(rewardTokens[i]).safeTransfer(\n            address(harvester),\n            balance\n        );\n    }\n}\n\n// convert all rewards to WETH\nharvester.harvest();\n\n",
        "function rewardTokens() external pure override returns (address[] memory) {\n    address[] memory rewards = new address[](2);\n    rewards[0] = address(crv);\n    rewards[1] = address(cvx);\n    return rewards;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "As part of the vault\u2019s strategy, the reward tokens for participating in Curve\u2019s ETH-stETH pool and Convex staking are claimed and swapped for ETH. This is done by having the ConvexPositionHandler contract call the reward claims API from Convex via baseRewardPool.getReward(), which transfers the reward tokens to the handler\u2019s address. Then, the tokens are iterated through and sent to the harvester to be swapped from ConvexPositionHandler by getting their list from harvester.rewardTokens() and calling harvester.harvest()",
        "code/contracts/ConvexExecutor/ConvexPositionHandler.sol:L274-L290",
        "However, harvester.rewardTokens() doesn\u2019t have the LDO token\u2019s address in its list, so they will not be transferred to the harvester to be swapped.",
        "code/contracts/ConvexExecutor/Harvester.sol:L77-L82",
        "As a result, harvester.harvest() will not be able to execute its _swapLidoForWETH() function since its ldoBalance will be 0. This results in missed rewards and therefore yield for the vault as part of its normal flow.",
        "There is a possible mitigation in the current state of the contract that would require governance to call sweep() on the LDO balance from the BaseTradeExecutor contract (that ConvexPositionHandler inherits) and then transferring those LDO tokens to the harvester contract to perform the swap at a later rewards claim. This, however, requires transactions separate from the intended flow of the system as well as governance intervention."
    ],
    "Recommendation": [
        "Add the LDO token address to the rewardTokens() function by adding the following line\nrewards[2] = address(ldo);"
    ]
}
----End JSON----

https://solodit.xyz/issues/keeper-design-complexity-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "shares = totalSupply() > 0\n    ? (totalSupply() \\* amountIn) / totalVaultFunds()\n    : amountIn;\n\n",
        "function totalVaultFunds() public view returns (uint256) {\n    return\n        IERC20(wantToken).balanceOf(address(this)) + totalExecutorFunds();\n}\n\n",
        "function totalFunds() public view override returns (uint256, uint256) {\n    return ConvexPositionHandler.positionInWantToken();\n}\n\n",
        "function positionInWantToken()\n    public\n    view\n    override\n    returns (uint256, uint256)\n{\n    (\n        uint256 stakedLpBalanceInETH,\n        uint256 lpBalanceInETH,\n        uint256 ethBalance\n    ) = \\_getTotalBalancesInETH(true);\n\n    return (\n        stakedLpBalanceInETH + lpBalanceInETH + ethBalance,\n        block.number\n    );\n}\n\n",
        "function totalFunds()\n    public\n    view\n    override\n    returns (uint256 posValue, uint256 lastUpdatedBlock)\n{\n    return (\n        positionInWantToken.posValue +\n            IERC20(vaultWantToken()).balanceOf(address(this)),\n        positionInWantToken.lastUpdatedBlock\n    );\n}\n\n",
        "function setPosValue(uint256 \\_posValue) public onlyKeeper {\n    LyraPositionHandler.\\_setPosValue(\\_posValue);\n}\n\n",
        "function \\_setPosValue(uint256 \\_posValue) internal {\n    positionInWantToken.posValue = \\_posValue;\n    positionInWantToken.lastUpdatedBlock = block.number;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The current design of the protocol relies on the keeper being operated correctly in a complex manner. Since the offchain code for the keeper wasn\u2019t in scope of this audit, the following is a commentary on the complexity of the keeper operations in the context of the contracts. Keeper logic such as the order of operations and function argument parameters with log querying are some examples where if the keeper doesn\u2019t execute them correctly, there may be inconsistencies and issues with accounting of vault shares and vault funds resulting in unexpected behaviour. While it may represent little risk or issues to the current Brahma-fi team as the vault is recently live, the keeper logic and exact steps should be well documented so that public keepers (if and when they are enabled) can execute the logic securely and future iterations of the vault code can account for any intricacies of the keeper logic."
    ],
    "Examples": [
        "1. Order of operations: Convex rewards & new depositors profiting at the expense of old depositors' yielded reward tokens.\nAs part of the vault\u2019s strategy, the depositors' ETH is provided to Curve and the LP tokens are staked in Convex, which yield rewards such as CRV, CVX, and LDO tokens. As new depositors provide their ETH, the vault shares minted for their deposits will be less compared to old deposits as they account for the increasing value of LP tokens staked in these pools. In other words, if the first depositor provides 1 ETH, then when a new depositor provides 1 ETH much later, the new depositor will get less shares back as the totalVaultFunds() will increase:",
        "code/contracts/Vault.sol:L97-L99",
        "code/contracts/Vault.sol:L127-L130",
        "code/contracts/ConvexTradeExecutor.sol:L21-L23",
        "code/contracts/ConvexExecutor/ConvexPositionHandler.sol:L121-L137",
        "However, this does not account for the reward tokens yielded throughout that time. From the smart contract logic alone, there is no requirement to first execute the reward token harvest. It is up to the keeper to execute ConvexTradeExecutor.claimRewards in order to claim and swap their rewards into ETH, which only then will be included into the yield in the above ConvexPositionHandler.positionInWantToken function. If this is not done prior to processing new deposits and minting new shares, new depositors would unfairly benefit from the reward tokens' yield that was generated before they deposited but accounted for in the vault funds only after they deposited.",
        "2. Order of operations: closing Lyra options before processing new deposits.",
        "The other part of the vault\u2019s strategy is utilising the yield from Convex to purchase options from Lyra on Optimism. While Lyra options are risky and can become worthless in the event of bad trades, only yield is used for them, therefore keeping user deposits' initial value safe. However, their value could also yield significant returns, increasing the overall funds of the vault. Just as with ConvexTradeExecutor, LyraTradeExecutor also has a totalFunds() function that feeds into the vault\u2019s totalVaultFunds() function. In Lyra\u2019s case, however, it is a manually set value by the keeper that is supposed to represent the value of Lyra L2 options:",
        "code/contracts/LyraTradeExecutor.sol:L42-L53",
        "code/contracts/LyraTradeExecutor.sol:L61-L63",
        "code/contracts/LyraExecutor/LyraPositionHandler.sol:L218-L221",
        "Solely from the smart contract logic, there is a possibility that a user deposits when Lyra options are valued high, meaning the total vault funds are high as well, thus decreasing the amount of shares the user would have received if it weren\u2019t for the Lyra options' value. Consequently, if after the deposit the Lyra options become worthless, decreasing the total vault funds, the user\u2019s newly minted shares will now represent less than what they have deposited.",
        "While this is not currently mitigated by smart contract logic, it may be worked around by the keeper first settling and closing all Lyra options and transferring all their yielded value in ETH, if any, to the Convex trade executor. Only then the keeper would process new deposits and mint new shares. This order of operations is critical to maintain the vault\u2019s intended safe strategy of maintaining the user\u2019s deposited value, and is dependent entirely on the keeper offchain logic.",
        "3. Order of operations: additional trade executors and their specific management\nSimilarly to the above examples, as more trade executors and position handlers are added to the vault, the complexity for the keeper will go up significantly, requiring it to maintain all correct orders of operations not just to keep the shares and funds accounting intact, but simply for the trade executors to function normally. For example, in the case of Lyra, the keepers need to manually call confirmDeposit and confirmWithdraw to update their depositStatus and withdrawalStatus respectively to continue normal operations or otherwise new deposits and withdrawals wouldn\u2019t be processed. On the other hand, the Convex executor does it automatically.\nDue to the system design, there may be no single standard way to handle a trade executor. New executors may also require specific calls to be done manually, increasing overall complexity keeper logic to support the system.",
        "4. Keeper calls & arguments: depositFunds/batchDeposit and initiateWithdrawal/batchWithdraw userAddresses[] array + gas overhead\nWith the current gated approach and batching for deposits and withdrawals to and from the vault, users aren\u2019t able to directly mint and redeem their vault shares. Instead, they interact with the Batcher contract that then communicates with the Vault contract with the help of the keeper. However, while each user\u2019s deposit and withdrawal amounts are registered in the contract state variables such as depositLedger[user] and withdrawLedger[user], and there is an event emitted with the user address and their action, to process them the keeper is required to keep track of all the user addresses in the batch they need to process. In particular, the keeper needs to provide address[] memory users for both batchDeposit() and batchWithdraw() functions that communicate with the vault. There is no stored list of users within the contract that could provide or verify the right users, so it is entirely up to the keeper\u2019s offchain logic to query the logs and retrieve the addresses required.\nTherefore, depending on the size of the address[] memory users array, the keepers may need to consider the transaction gas limit, possibly requiring splitting the array up and doing several transactions to process all of them.\nIn addition, in the event of withdrawals, the keepers need to calculate how much of the wantToken (WETH in our case) will be required to process the withdrawals, and call withdrawFromExecutor() with that amount to provide enough assets to cover withdrawals from the vault.",
        "5. Timing: 50 block radius for updates on trade executors that need to have their values updated via a call\nSome trade executors, like the Convex one, can retrieve their funds value at any time from Layer 1, thereby always being up to date with the current block. Others, like the Lyra trade executor, require the keeper to update their position value by initiating a call, which also updates their positionInWantToken.lastUpdatedBlock state variable. However, this variable is also called during during the vault.totalVaultFunds()call during deposits and withdrawals via totalExecutorFunds(), which eventually calls areFundsUpdated(blockUpdated). This is a check to ensure that the current transaction\u2019s block.number <= _blockUpdated + BLOCK_LIMIT, where BLOCK_LIMIT=50 blocks, i.e. roughly 12-15 min.\nAs a result, keepers need to make sure that all executors that require a call for this have their position values updated before and rather close to processing and deposits or withdrawals, or areFundsUpdated() will revert those calls."
    ],
    "Recommendation": [
        "Document the exact order of operations, steps, necessary logs and parameters that keepers need to keep track of in order for the vault strategy to succeed."
    ]
}
----End JSON----

https://solodit.xyz/issues/vaultdeposit-possible-front-running-attack-consensys-brahma-fi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "To determine the number of shares to mint to a depositor, (totalSupply() * amountIn) / totalVaultFunds() is used. Potential attackers can spot a call to Vault.deposit and front-run it with a transaction that sends tokens to the contract, causing the victim to receive fewer shares than what he expected.",
        "In case totalVaultFunds() is greater than totalSupply() * amountIn, then the number of shares the depositor receives will be 0, although amountIn of tokens will be still pulled from the depositor\u2019s balance.",
        "An attacker with access to enough liquidity and to the mem-pool data can spot a call to Vault.deposit(amountIn, receiver) and front-run it by sending at least totalSupplyBefore * (amountIn - 1) + 1 tokens to the contract . This way, the victim will get 0 shares, but amountIn will still be pulled from its account balance. Now the price for a share is inflated, and all shareholders can redeem this profit using Vault.withdraw.",
        "The attack vector mentioned above is the general front runner case, the most profitable attack vector will be the case when the attacker is able to determine the share price (for instance if the attacker mints the first share). In this scenario, the attacker will need to send at least attackerShares * (amountIn -1) + 1  to the contract,(attackerShares is completely controlled by the attacker), and this amount can be then entirely redeemed by the attacker himself (alongside the victim\u2019s deposit) by calling Vault.withdraw. The attacker can lower the risk of losing the funds he sent to the contract to some other front-runner by using the flashbots api. Although both Vault.deposit and Vault.withdraw are callable only by the Batcher contract, the keeper bot can still be tricked to process user deposits in a way that allows this attack to happen."
    ],
    "Recommendation": [
        "The specific case that\u2019s mentioned in the last paragraph can be mitigated by adding a validation check to Vault.Deposit enforcing that shares > 0. However, it will not solve the general case since the victim can still lose value due to rounding errors. In order to fix that, Vault.Deposit should validate that shares >= amountMin where amountMin is an argument that should be determined by the depositor off-chain."
    ]
}
----End JSON----

https://solodit.xyz/issues/reactivated-gauges-cant-queue-up-rewards-fixed-consensys-tribe-dao-flywheel-v2-xtribe-xerc4626-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "gaugeQueuedRewards[gauge] = QueuedRewards({\n    priorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,\n    cycleRewards: uint112(nextRewards),\n    storedCycle: currentCycle\n});\n\n",
        "assert(queuedRewards.storedCycle == 0 || queuedRewards.storedCycle >= lastCycle);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in fei-protocol/[email\u00a0protected]e765d24 by making it so all gauges are always included in cycles, thus keeping in sync their storedCycle values with the contract\u2019s state and passing them to the rest of the contract. Downstream gaugeToken. calculateGaugeAllocation now handles deprecated gauges by returning 0 for them."
    ],
    "Description": [
        "Active gauges as set in ERC20Gauges.addGauge() function by authorised users get their rewards queued up in the FlywheelGaugeRewards._queueRewards() function. As part of it, their associated struct QueuedRewards updates its storedCycle value to the cycle in which they get queued up:",
        "code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L202-L206",
        "However, these gauges may be deactivated in ERC20Gauges.removeGauge(), and they will now be ignored in either FlywheelGaugeRewards.queueRewardsForCycle() or FlywheelGaugeRewards.queueRewardsForCyclePaginated() because both use gaugeToken.gauges() to get the set of gauges for which to queue up rewards for the cycle, and that only gives active gauges. Therefore, any updates FlywheelGaugeRewards makes to its state will not be done to deactivated gauges' QueuedRewards structs. In particular, the gaugeCycle contract state variable will keep advancing throughout its cycles, while QueuedRewards.storedCycle will retain its previously set value, which is the cycle where it was queued and not 0.",
        "Once reactivated later with at least 1 full cycle being done without it, it will produce issues. It will now be returned by gaugeToken.gauges() to be processed in either FlywheelGaugeRewards.queueRewardsForCycle()or FlywheelGaugeRewards.queueRewardsForCyclePaginated(), but, once the reactivated gauge is passed to _queueRewards(), it will fail an assert:",
        "code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L196",
        "This is because it already has a set value from the cycle it was processed in previously (i.e. storedCycle>0), and, since that cycle is at least 1 full cycle behind the state contract, it will also not pass the second condition queuedRewards.storedCycle >= lastCycle.",
        "The result is that this gauge is locked out of queuing up for rewards because queuedRewards.storedCycle is only synchronised with the contract\u2019s cycle later in _queueRewards() which will now always fail for this gauge."
    ],
    "Recommendation": [
        "Account for the reactivated gauges that previously went through the rewards queue process, such as introducing a separate flow for newly activated gauges. However, any changes such as removing the above mentioned assert() should be carefully validated for other downstream logic that may use the QueuedRewards.storedCycle value. Therefore, it is recommended to review the state transitions as opposed to only passing this specific check."
    ]
}
----End JSON----

https://solodit.xyz/issues/reactivated-gauges-have-incorrect-accounting-for-the-last-cycles-rewards-fixed-consensys-tribe-dao-flywheel-v2-xtribe-xerc4626-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint112 completedRewards = queuedRewards.storedCycle == lastCycle ? queuedRewards.cycleRewards : 0;\n\n",
        "priorCycleRewards: queuedRewards.priorCycleRewards + completedRewards,\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in fei-protocol/[email\u00a0protected]e765d24 by making it so all gauges are always included in cycles, thus keeping in sync their storedCycle values with the contract\u2019s state."
    ],
    "Description": [
        "As described in https://github.com/ConsenSysDiligence/fei-labs-audit-2022-04/issues/3, reactivated gauges that previously had queued up rewards have a mismatch between their storedCycle and contract\u2019s gaugeCycle state variable.",
        "Due to this mismatch, there is also a resulting issue with the accounting logic for its completed rewards:",
        "code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L198",
        "Consequently, this then produces an incorrect value for QueuedRewards.priorCycleRewards:",
        "code-flywheel-v2/src/rewards/FlywheelGaugeRewards.sol:L203",
        "As now completedRewards will be equal to 0 instead of the previous cycle\u2019s rewards for that gauge. This may cause a loss of rewards accounted for this gauge as this value is later used in getAccruedRewards()."
    ],
    "Recommendation": [
        "Consider changing the logic of the check so that storedCycle values further in the past than lastCycle may produce the right rewards return for this expression, such as using <= instead of == and adding an explicit check for storedCycle == 0 to account for the initial scenario."
    ]
}
----End JSON----

https://solodit.xyz/issues/xtribeemitvotingbalances-delegatevoteschanged-event-can-be-emitted-by-anyone-fixed-consensys-tribe-dao-flywheel-v2-xtribe-xerc4626-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function emitVotingBalances(address[] calldata accounts) external {\n    uint256 size = accounts.length;\n\n    for (uint256 i = 0; i < size; ) {\n        emit DelegateVotesChanged(accounts[i], 0, getVotes(accounts[i]));\n\n        unchecked {\n            i++;\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in fei-protocol/[email\u00a0protected]ea9705b by adding authentication."
    ],
    "Description": [
        "xTRIBE.emitVotingBalances is an external function without authentication constraints. It means anyone can call it and emit DelegateVotesChanged which may impact other layers of code that rely on these events."
    ],
    "Examples": [
        "code-xTRIBE/src/xTRIBE.sol:L89-L99"
    ],
    "Recommendation": [
        "Consider restricting access to this function for allowed accounts only."
    ]
}
----End JSON----

https://solodit.xyz/issues/accounts-that-claim-incentives-immediately-before-the-migration-will-be-stuck-consensys-notional-protocol-v21-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 timeSinceMigration = finalMigrationTime - lastClaimTime;\n\n// (timeSinceMigration \\* INTERNAL\\_TOKEN\\_PRECISION \\* finalEmissionRatePerYear) / YEAR\nuint256 incentiveRate =\n    timeSinceMigration\n        .mul(uint256(Constants.INTERNAL\\_TOKEN\\_PRECISION))\n        // Migration emission rate is stored as is, denominated in whole tokens\n        .mul(finalEmissionRatePerYear).mul(uint256(Constants.INTERNAL\\_TOKEN\\_PRECISION))\n        .div(Constants.YEAR);\n\n// Returns the average supply using the integral of the total supply.\nuint256 avgTotalSupply = finalTotalIntegralSupply.sub(lastClaimIntegralSupply).div(timeSinceMigration);\n\n"
    ],
    "preamble": [],
    "Description": [
        "For accounts that existed before the migration to the new incentive calculation, the following happens when they claim incentives for the first time after the migration: First, the incentives that are still owed from before the migration are computed according to the old formula; the incentives since the migration are calculated according to the new logic, and the two values are added together. The first part \u2013 calculating the pre-migration incentives according to the old formula \u2013 happens in function MigrateIncentives.migrateAccountFromPreviousCalculation; the following lines are of particular interest in the current context:",
        "code-582dc37/contracts/external/MigrateIncentives.sol:L39-L50",
        "The division in the last line will throw if finalMigrationTime and lastClaimTime are equal. This will happen if an account claims incentives immediately before the migration happens \u2013 where \u201cimmediately\u201d means in the same block. In such a case, the account will be stuck as any attempt to claim incentives will revert."
    ],
    "Recommendation": [
        "The function should return 0 if finalMigrationTime and lastClaimTime are equal. Moreover, the variable name timeSinceMigration is misleading, as the variable doesn\u2019t store the time since the migration but the time between the last incentive claim and the migration."
    ]
}
----End JSON----

https://solodit.xyz/issues/flasherftm-unsolicited-invocation-of-the-callback-cream-auth-bypass-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Routing Function for Flashloan Provider\n \\* @param info: struct information for flashLoan\n \\* @param \\_flashnum: integer identifier of flashloan provider\n \\*/\nfunction initiateFlashloan(FlashLoan.Info calldata info, uint8 \\_flashnum) external isAuthorized override {\n if (\\_flashnum == 0) {\n \\_initiateGeistFlashLoan(info);\n } else if (\\_flashnum == 2) {\n \\_initiateCreamFlashLoan(info);\n } else {\n revert(Errors.VL\\_INVALID\\_FLASH\\_NUMBER);\n }\n}\n\n",
        "modifier isAuthorized() {\n require(\n msg.sender == \\_fujiAdmin.getController() ||\n msg.sender == \\_fujiAdmin.getFliquidator() ||\n msg.sender == owner(),\n Errors.VL\\_NOT\\_AUTHORIZED\n );\n \\_;\n}\n\n",
        "/\\*\\*\n \\* @dev Initiates an CreamFinance flashloan.\n \\* @param info: data to be passed between functions executing flashloan logic\n \\*/\nfunction \\_initiateCreamFlashLoan(FlashLoan.Info calldata info) internal {\n address crToken = info.asset == \\_FTM\n ? 0xd528697008aC67A21818751A5e3c58C8daE54696\n : \\_crMappings.addressMapping(info.asset);\n\n // Prepara data for flashloan execution\n bytes memory params = abi.encode(info);\n\n // Initialize Instance of Cream crLendingContract\n ICTokenFlashloan(crToken).flashLoan(address(this), address(this), info.amount, params);\n}\n\n",
        "address initiator,\n\n",
        " \\*/\nfunction onFlashLoan(\n address sender,\n address underlying,\n uint256 amount,\n uint256 fee,\n bytes calldata params\n) external override returns (bytes32) {\n // Check Msg. Sender is crToken Lending Contract\n // from IronBank because ETH on Cream cannot perform a flashloan\n address crToken = underlying == \\_WFTM\n ? 0xd528697008aC67A21818751A5e3c58C8daE54696\n : \\_crMappings.addressMapping(underlying);\n require(msg.sender == crToken && address(this) == sender, Errors.VL\\_NOT\\_AUTHORIZED);\n\n"
    ],
    "preamble": [],
    "Description": [
        "TL;DR: Anyone can call ICTokenFlashloan(crToken).flashLoan(address(FlasherFTM), address(FlasherFTM), info.amount, params) directly and pass validation checks in onFlashLoan(). This call forces it to accept unsolicited flash loans and execute the actions provided under the attacker\u2019s FlashLoan.Info.",
        "receiver.onFlashLoan(initiator, token, amount, ...) is called when receiving a flash loan.\nAccording to EIP-3156, the initiator is msg.sender so that one can use it to check if the call to receiver.onFlashLoan() was unsolicited or not.",
        "For example, the Geist lending contract configured with this system is upgradeable. Upgradeable contracts bear the risk that one cannot assume that the contract is always running the same code. In the worst case, for example, a malicious proxy admin (leaked keys, insider, \u2026) could upgrade the contract and perform unsolicited calls with arbitrary data to Flash Loan consumers in an attempt to exploit them. It, therefore, is highly recommended to verify that flash loan callbacks in the system can only be called if the contract was calling out to the provider to provide a Flash Loan and that the conditions of the flash loan (returned data, amount) are correct.",
        "Cream Finance, for example, allows users to set an arbitrary initiator when requesting a flash loan. This deviates from EIP-3156 and was reported to the Cream development team as a security issue. Hence, anyone can spoof that initiator and potentially bypass authentication checks in the consumers\u2019 receiver.onFlashLoan().\nDepending on the third-party application consuming the flash loan is doing with the funds, the impact might range from medium to critical with funds at risk. For example, projects might assume that the flash loan always originates from their trusted components, e.g., because they use them to refinance switching funds between pools or protocols."
    ],
    "Examples": [
        "code/contracts/fantom/flashloans/FlasherFTM.sol:L66-L79",
        "code/contracts/fantom/flashloans/FlasherFTM.sol:L46-L55",
        "code/contracts/fantom/flashloans/FlasherFTM.sol:L144-L158",
        "Note: The Cream implementation does not send sender=msg.sender to the onFlashLoan() callback - like any other flash loan provider does and EIP-3156 suggests - but uses the value that was passed in as initiator when requesting the callback. This detail completely undermines the authentication checks implemented in onFlashLoan as the sender value cannot be trusted.",
        "contracts/CCollateralCapErc20.sol:L187",
        "code/contracts/fantom/flashloans/FlasherFTM.sol:L162-L175"
    ],
    "Recommendation": [
        "Cream Finance",
        "We\u2019ve reached out to the Cream developer team, who have confirmed the issue. They are planning to implement countermeasures. Our recommendation can be summarized as follows:",
        "FujiDAO (and other flash loan consumers)",
        "We recommend not assuming that FlashLoan.Info contains trusted or even validated data when a third-party flash loan provider provides it! Developers should ensure that the data received was provided when the flash loan was requested.",
        "The contract should reject unsolicited flash loans. In the scenario where a flash loan provider is exploited, the risk of an exploited trust relationship is less likely to spread to the rest of the system.",
        "The Cream initiator provided to the onFlashLoan() callback cannot be trusted until the Cream developers fix this issue. The initiator can easily be spoofed to perform unsolicited flash loans. We, therefore, suggest:",
        "Values received from untrusted third parties should always be validated with the utmost scrutiny.",
        "Smart contract upgrades are risky, so we recommend implementing the means to pause certain flash loan providers.",
        "Ensure that flash loan handler functions should never re-enter the system. This provides additional security guarantees in case a flash loan provider gets breached.",
        "Note: The Fuji development team implemented a hotfix to prevent unsolicited calls from Cream by storing the hash(FlashLoan.info) in a state variable just before requesting the flash loan. Inside the onFlashLoan callback, this state is validated and cleared accordingly.",
        "An improvement to this hotfix would be, to check _paramsHash before any external calls are made and clear it right after validation at the beginning of the function. Additionally, hash==0x0 should be explicitly disallowed. By doing so, the check also serves as a reentrancy guard and helps further reduce the risk of a potentially malicious flash loan re-entering the function."
    ]
}
----End JSON----

https://solodit.xyz/issues/lack-of-reentrancy-protection-in-token-interactions-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function univTransfer(\n IERC20 token,\n address payable to,\n uint256 amount\n) internal {\n if (amount > 0) {\n if (isFTM(token)) {\n (bool sent, ) = to.call{ value: amount }(\"\");\n require(sent, \"Failed to send Ether\");\n } else {\n token.safeTransfer(to, amount);\n }\n }\n}\n\n",
        "/\\*\\*\n \\* @dev Paybacks the underlying asset and withdraws collateral in a single function call from activeProvider\n \\* @param \\_paybackAmount: amount of underlying asset to be payback, pass -1 to pay full amount\n \\* @param \\_collateralAmount: amount of collateral to be withdrawn, pass -1 to withdraw maximum amount\n \\*/\nfunction paybackAndWithdraw(int256 \\_paybackAmount, int256 \\_collateralAmount) external payable {\n updateF1155Balances();\n \\_internalPayback(\\_paybackAmount);\n \\_internalWithdraw(\\_collateralAmount);\n}\n\n",
        "/\\*\\*\n \\* @dev Paybacks Vault's type underlying to activeProvider - called by users\n \\* @param \\_repayAmount: token amount of underlying to repay, or\n \\* pass any 'negative number' to repay full ammount\n \\* Emits a {Repay} event.\n \\*/\nfunction payback(int256 \\_repayAmount) public payable override {\n updateF1155Balances();\n \\_internalPayback(\\_repayAmount);\n}\n\n",
        "/\\*\\*\n \\* @dev Deposits collateral and borrows underlying in a single function call from activeProvider\n \\* @param \\_collateralAmount: amount to be deposited\n \\* @param \\_borrowAmount: amount to be borrowed\n \\*/\nfunction depositAndBorrow(uint256 \\_collateralAmount, uint256 \\_borrowAmount) external payable {\n updateF1155Balances();\n \\_internalDeposit(\\_collateralAmount);\n \\_internalBorrow(\\_borrowAmount);\n}\n\n",
        "/\\*\\*\n \\* @dev Borrows Vault's type underlying amount from activeProvider\n \\* @param \\_borrowAmount: token amount of underlying to borrow\n \\* Emits a {Borrow} event.\n \\*/\nfunction borrow(uint256 \\_borrowAmount) public override nonReentrant {\n updateF1155Balances();\n \\_internalBorrow(\\_borrowAmount);\n}\n\n",
        "depositAndBorrow\n updateBalances\n internalDeposit ->\n ERC777(collateralAsset).safeTransferFrom() ---> calls back!\n ---callback:beforeTokenTransfer---->\n !! depositAndBorrow\n updateBalances\n internalDeposit\n --> ERC777.safeTransferFrom()\n <--\n \\_deposit\n mint\n internalBorrow\n mint\n \\_borrow\n ERC777(borrowAsset).univTransfer(msg.sender) --> might call back\n\n <-------------------------------\n \\_deposit\n mint\n internalBorrow\n mint\n \\_borrow \n --> ERC777(borrowAsset).univTransfer(msg.sender) --> might call back\n <--\n\n"
    ],
    "preamble": [],
    "Description": [
        "Token operations may potentially re-enter the system. For example, univTransfer may perform a low-level to.call{value}() and, depending on the token\u2019s specification (e.g. ERC-20 extension or ERC-20 compliant ERC-777), token may implement callbacks when being called as  token.safeTransfer(to, amount) (or token.transfer*()).",
        "Therefore, it is crucial to strictly adhere to the checks-effects pattern and safeguard affected methods using a mutex."
    ],
    "Examples": [
        "code/contracts/fantom/libraries/LibUniversalERC20FTM.sol:L26-L40",
        "code/contracts/fantom/FujiVaultFTM.sol:L172-L182",
        "code/contracts/fantom/FujiVaultFTM.sol:L232-L241",
        "code/contracts/fantom/FujiVaultFTM.sol:L161-L171",
        "code/contracts/fantom/FujiVaultFTM.sol:L222-L230",
        "Here\u2019s an example call stack for depositAndBorrow that outlines how a reentrant ERC20 token (e.g. ERC777) may call back into depositAndBorrow again, updateBalances twice in the beginning before tokens are even transferred and then continues to call internalDeposit, internalBorrow, internalBorrow without an update before the 2nd borrow. Note that both internalDeposit and internalBorrow read indexes that may now be outdated."
    ],
    "Recommendation": [
        "Consider decorating methods that may call back to untrusted sources (i.e., native token transfers, callback token operations) as nonReentrant and strictly follow the checks-effects pattern for all contracts in the code-base."
    ]
}
----End JSON----

https://solodit.xyz/issues/lack-of-segregation-of-duties-excessive-owner-permissions-misleading-authentication-modifiers-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier onlyPermit() {\n require(addrPermit[\\_msgSender()] || msg.sender == owner(), Errors.VL\\_NOT\\_AUTHORIZED);\n \\_;\n}\n\n",
        "function updateState(uint256 \\_assetID, uint256 newBalance) external override onlyPermit {\n uint256 total = totalSupply(\\_assetID);\n if (newBalance > 0 && total > 0 && newBalance > total) {\n uint256 newIndex = (indexes[\\_assetID] \\* newBalance) / total;\n indexes[\\_assetID] = uint128(newIndex);\n }\n}\n\n",
        "/\\*\\*\n \\* @dev Throws if caller is not the 'owner' or the '\\_controller' address stored in {FujiAdmin}\n \\*/\nmodifier isAuthorized() {\n require(\n msg.sender == owner() || msg.sender == \\_fujiAdmin.getController(),\n Errors.VL\\_NOT\\_AUTHORIZED\n );\n \\_;\n}\n\n",
        "function setFujiERC1155(address \\_fujiERC1155) external isAuthorized {\n require(\\_fujiERC1155 != address(0), Errors.VL\\_ZERO\\_ADDR);\n fujiERC1155 = \\_fujiERC1155;\n\n vAssets.collateralID = IFujiERC1155(\\_fujiERC1155).addInitializeAsset(\n IFujiERC1155.AssetType.collateralToken,\n address(this)\n );\n vAssets.borrowID = IFujiERC1155(\\_fujiERC1155).addInitializeAsset(\n IFujiERC1155.AssetType.debtToken,\n address(this)\n );\n emit F1155Changed(\\_fujiERC1155);\n}\n\n",
        "\\*/\nmodifier isAuthorized() {\n require(msg.sender == owner(), Errors.VL\\_NOT\\_AUTHORIZED);\n \\_;\n}\n\n",
        "modifier onlyOwner() {\n require(\\_msgSender() == owner(), \"Ownable: caller is not the owner\");\n \\_;\n}\n\n",
        "\n/\\*\\*\n\\* @dev Throws if caller is not 'owner'.\n\\*/\nmodifier isAuthorized() {\n require(\n msg.sender == \\_fujiAdmin.getController() ||\n msg.sender == \\_fujiAdmin.getFliquidator() ||\n msg.sender == owner(),\n Errors.VL\\_NOT\\_AUTHORIZED\n );\n \\_;\n}\n\n"
    ],
    "preamble": [],
    "Descriptio": [
        "In the FujiERC1155 contract, the onlyPermit modifier should not include owner.",
        "The FujiERC1155 is claimable (ownable) via F1155Manager. The onlyPermit modifier includes contracts explicitly permitted to perform actions, and the owner, in a lot of cases, has separate duties. Note that the owner can add new contracts to the onlyPermit whitelist.",
        "code/contracts/abstracts/fujiERC1155/F1155Manager.sol:L34-L37",
        "However, the owner can also wholly mess up accounting as they are permitted to call updateState(), which should only be callable by vaults:",
        "code/contracts/FujiERC1155.sol:L53-L59",
        "The same is true for FujiERC1155.{mint|mintBatch|burn|burnBatch|addInitializeAsset} unless there is a reason to allow owner to freely burn/mint/initialize tokens and updateState for borrowed assets to arbitrary values.",
        "Multiple methods in FujiVault are decorated with the access control isAuthorized that grants the owner and the currently configured controller access. The controller, however, does not implement any means to call some of the methods on the Vault.",
        "Furthermore, the owner is part of isAuthorized, too, and can switch out the debt-management token while one is already configured without any migration. This is likely to create an inconsistent state with the Vault, and no one will be able to withdraw their now non-existent token.",
        "code/contracts/fantom/FujiVaultFTM.sol:L65-L74",
        "The owner can call methods \u201cout of band,\u201d bypassing steps the contract system would enforce otherwise, e.g. controller calling setActiveProvider.",
        "It is assumed that setOracle, setFactor should probably be onlyOwner instead.",
        "code/contracts/fantom/FujiVaultFTM.sol:L354-L367",
        "Note ensure that setProviders can only ever be set by a trusted entity or multi-sig as the Vault delegatecalls the provider logic (via VaultControlUpgradeable) and, hence, the provider has total control over the Vault storage!",
        "The contract is already Claimable; therefore, use the already existing modifier Claimable.onlyOwner instead.",
        "code/contracts/fantom/FliquidatorFTM.sol:L86-L91",
        "code/contracts/abstracts/claimable/Claimable.sol:L48-L51",
        "Use Claimable.onlyOwner instead.",
        "code/contracts/fantom/flashloans/FlasherFTM.sol:L42-L54",
        "All vaults need to be in the onlyPermit ACL whitelist. No additional checks enforce that the calling vault can only modify its token balances. Furthermore, FujiVaultFTM is upgradeable; thus, the contract logic may be altered to allow the vault to modify any other token id\u2019s balance. To reduce this risk and the potential of an exploited contract affecting other token balances in the system, it is suggested to change the coarse onlyPermit ACL to one that checks that the calling vault can only manage their token IDs."
    ],
    "Recommendation": [
        "Reconsider the authentication concept and make it more transparent. Segregate duties and clearly define roles and capabilities. Avoid having overly powerful actors and reduce their capabilities to the bare minimum needed to segregate risk. If an actor is part of an ACL in a third-party contract, they also should have the means to call that method in a controlled way or else remove them from the ACL. To avoid conveying a false sense of trust towards certain actors within the smart contract system, it is suggested to use the centralized onlyOwner decorator for methods only the owner can call. This more accurately depicts \u201cwho can do what\u201d in the system and makes it easier to trust the project team managing it.",
        "Avoid excessively powerful owners that can change/mint/burn anything in the system as this is a risk for the general consistency.",
        "Remove owner from methods/modifiers they don\u2019t need to be part of/have access to.",
        "Ensure owner is a time-locked multi-sig or governance contract. Rename authentication modifiers to describe better what callers they allow."
    ]
}
----End JSON----

https://solodit.xyz/issues/unchecked-return-values-icerc20-repayborrow-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nfunction repayBorrow(uint256 repayAmount) external returns (uint256);\n\n",
        "function repayBorrowInternal(uint repayAmount) internal nonReentrant returns (uint, uint) {\n uint error = accrueInterest();\n if (error != uint(Error.NO\\_ERROR)) {\n // accrueInterest emits logs on errors, but we still want to log the fact that an attempted borrow failed\n return (fail(Error(error), FailureInfo.REPAY\\_BORROW\\_ACCRUE\\_INTEREST\\_FAILED), 0);\n }\n // repayBorrowFresh emits repay-borrow-specific logs on errors, so we don't need to\n return repayBorrowFresh(msg.sender, msg.sender, repayAmount);\n}\n\n",
        "if (allowed != 0) {\n return (failOpaque(Error.COMPTROLLER\\_REJECTION, FailureInfo.REPAY\\_BORROW\\_COMPTROLLER\\_REJECTION, allowed), 0);\n}\n\n/\\* Verify market's block number equals current block number \\*/\nif (accrualBlockNumber != getBlockNumber()) {\n return (fail(Error.MARKET\\_NOT\\_FRESH, FailureInfo.REPAY\\_BORROW\\_FRESHNESS\\_CHECK), 0);\n}\n\nRepayBorrowLocalVars memory vars;\n\n/\\* We remember the original borrowerIndex for verification purposes \\*/\nvars.borrowerIndex = accountBorrows[borrower].interestIndex;\n\n/\\* We fetch the amount the borrower owes, with accumulated interest \\*/\n(vars.mathErr, vars.accountBorrows) = borrowBalanceStoredInternal(borrower);\nif (vars.mathErr != MathError.NO\\_ERROR) {\n return (failOpaque(Error.MATH\\_ERROR, FailureInfo.REPAY\\_BORROW\\_ACCUMULATED\\_BALANCE\\_CALCULATION\\_FAILED, uint(vars.mathErr)), 0);\n}\n\n",
        "\n // Check there is enough balance to pay\n require(erc20token.balanceOf(address(this)) >= \\_amount, \"Not-enough-token\");\n erc20token.univApprove(address(cyTokenAddr), \\_amount);\n cyToken.repayBorrow(\\_amount);\n}\n\n",
        "require(erc20token.balanceOf(address(this)) >= \\_amount, \"Not-enough-token\");\nerc20token.univApprove(address(cyTokenAddr), \\_amount);\ncyToken.repayBorrow(\\_amount);\n\n",
        "if (\\_isETH(\\_asset)) {\n // Create a reference to the corresponding cToken contract\n ICEth cToken = ICEth(cTokenAddr);\n\n cToken.repayBorrow{ value: msg.value }();\n} else {\n // Create reference to the ERC20 contract\n IERC20 erc20token = IERC20(\\_asset);\n\n // Create a reference to the corresponding cToken contract\n ICErc20 cToken = ICErc20(cTokenAddr);\n\n // Check there is enough balance to pay\n require(erc20token.balanceOf(address(this)) >= \\_amount, \"Not-enough-token\");\n erc20token.univApprove(address(cTokenAddr), \\_amount);\n cToken.repayBorrow(\\_amount);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "ICErc20.repayBorrow returns a non-zero uint on error. Multiple providers do not check for this error condition and might return success even though repayBorrow failed, returning an error code.",
        "This can potentially allow a malicious user to call paybackAndWithdraw() while not repaying by causing an error in the sub-call to Compound.repayBorrow(), which ends up being silently ignored. Due to the missing success condition check, execution continues normally with _internalWithdraw().",
        "Also, see issue 4.5.",
        "code/contracts/interfaces/compound/ICErc20.sol:L11-L12",
        "The method may return an error due to multiple reasons:",
        "contracts/CToken.sol:L808-L816",
        "contracts/CToken.sol:L855-L873"
    ],
    "Examples": [
        "Multiple providers, here are some examples:",
        "code/contracts/fantom/providers/ProviderCream.sol:L168-L173",
        "code/contracts/fantom/providers/ProviderScream.sol:L170-L172",
        "code/contracts/mainnet/providers/ProviderCompound.sol:L139-L155"
    ],
    "Recommendation": [
        "Check for cyToken.repayBorrow(_amount) != 0 or Error.NO_ERROR."
    ]
}
----End JSON----

https://solodit.xyz/issues/unchecked-return-values-icomptroller-exitmarket-entermarket-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (amountOwed != 0) {\n return fail(Error.NONZERO\\_BORROW\\_BALANCE, FailureInfo.EXIT\\_MARKET\\_BALANCE\\_OWED);\n}\n\n/\\* Fail if the sender is not permitted to redeem all of their tokens \\*/\nuint allowed = redeemAllowedInternal(cTokenAddress, msg.sender, tokensHeld);\nif (allowed != 0) {\n return failOpaque(Error.REJECTION, FailureInfo.EXIT\\_MARKET\\_REJECTION, allowed);\n}\n\n",
        " /\\*\\*\n \\* @notice Removes asset from sender's account liquidity calculation\n \\* @dev Sender must not have an outstanding borrow balance in the asset,\n \\* or be providing necessary collateral for an outstanding borrow.\n \\* @param cTokenAddress The address of the asset to be removed\n \\* @return Whether or not the account successfully exited the market\n \\*/\n function exitMarket(address cTokenAddress) external returns (uint) {\n CToken cToken = CToken(cTokenAddress);\n /\\* Get sender tokensHeld and amountOwed underlying from the cToken \\*/\n (uint oErr, uint tokensHeld, uint amountOwed, ) = cToken.getAccountSnapshot(msg.sender);\n require(oErr == 0, \"exitMarket: getAccountSnapshot failed\"); // semi-opaque error code\n\n /\\* Fail if the sender has a borrow balance \\*/\n if (amountOwed != 0) {\n return fail(Error.NONZERO\\_BORROW\\_BALANCE, FailureInfo.EXIT\\_MARKET\\_BALANCE\\_OWED);\n }\n\n /\\* Fail if the sender is not permitted to redeem all of their tokens \\*/\n uint allowed = redeemAllowedInternal(cTokenAddress, msg.sender, tokensHeld);\n if (allowed != 0) {\n return failOpaque(Error.REJECTION, FailureInfo.EXIT\\_MARKET\\_REJECTION, allowed);\n }\n\n",
        "function \\_exitCollatMarket(address \\_cyTokenAddress) internal {\n // Create a reference to the corresponding network Comptroller\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\n\n comptroller.exitMarket(\\_cyTokenAddress);\n}\n\n",
        "function \\_exitCollatMarket(address \\_cyTokenAddress) internal {\n // Create a reference to the corresponding network Comptroller\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\n\n comptroller.exitMarket(\\_cyTokenAddress);\n}\n\n",
        "function \\_exitCollatMarket(address \\_cTokenAddress) internal {\n // Create a reference to the corresponding network Comptroller\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\n\n comptroller.exitMarket(\\_cTokenAddress);\n}\n\n",
        "function \\_exitCollatMarket(address \\_cyTokenAddress) internal {\n // Create a reference to the corresponding network Comptroller\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\n\n comptroller.exitMarket(\\_cyTokenAddress);\n}\n\n",
        "function \\_enterCollatMarket(address \\_cyTokenAddress) internal {\n // Create a reference to the corresponding network Comptroller\n IComptroller comptroller = IComptroller(\\_getComptrollerAddress());\n\n address[] memory cyTokenMarkets = new address[](1);\n cyTokenMarkets[0] = \\_cyTokenAddress;\n comptroller.enterMarkets(cyTokenMarkets);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "IComptroller.exitMarket(), IComptroller.enterMarkets() may return a non-zero uint on error but none of the Providers check for this error condition. Together with issue 4.10, this might suggest that unchecked return values may be a systemic problem.",
        "Here\u2019s the upstream implementation:",
        "contracts/Comptroller.sol:L179-L187"
    ],
    "Examples": [
        "All Providers exhibit the same issue, probably due to code reuse. (also see https://github.com/ConsenSysDiligence/fuji-protocol-audit-2022-02/issues/19). Some examples:",
        "code/contracts/fantom/providers/ProviderCream.sol:L52-L57",
        "code/contracts/fantom/providers/ProviderScream.sol:L52-L57",
        "code/contracts/mainnet/providers/ProviderCompound.sol:L46-L51",
        "code/contracts/mainnet/providers/ProviderIronBank.sol:L52-L57",
        "All Providers exhibit the same issue, probably due to code reuse. (also see https://github.com/ConsenSysDiligence/fuji-protocol-audit-2022-02/issues/19). For example:",
        "code/contracts/fantom/providers/ProviderCream.sol:L39-L46"
    ],
    "Recommendation": [
        "Require that return value is ERROR.NO_ERROR or 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/fliquidator-excess-funds-of-native-tokens-are-not-returned-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (vAssets.borrowAsset == FTM) {\n require(msg.value >= debtTotal, Errors.VL\\_AMOUNT\\_ERROR);\n} else {\n\n"
    ],
    "preamble": [],
    "Description": [
        "FliquidatorFTM.batchLiquidate accepts the FTM native token and checks if at least an amount of debtTotal was provided with the call. The function continues using the debtTotal value. If a caller provides msg.value > debtTotal, excess funds are not returned and remain in the contract. FliquidatorFTM is not upgradeable, and there is no way to recover the surplus funds."
    ],
    "Examples": [
        "code/contracts/fantom/FliquidatorFTM.sol:L148-L150"
    ],
    "Recommendation": [
        "Consider returning excess funds. Consider making _constructParams public to allow the caller to pre-calculate the debtTotal that needs to be provided with the call.",
        "Consider removing support for native token FTM entirely to reduce the overall code complexity. The wrapped equivalent can be used instead."
    ]
}
----End JSON----

https://solodit.xyz/issues/unsafe-arithmetic-casts-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\u21d2 solidity-shell\n\n\ud83d\ude80 Entering interactive Solidity ^0.8.11 shell. '.help' and '.exit' are your friends.\n \u00bb \u2139\ufe0f ganache-mgr: starting temp. ganache instance ...\n \u00bb uint(int(-100))\n115792089237316195423570985008687907853269984665640564039457584007913129639836\n \u00bb int256(uint(2\\*\\*256-100))\n-100\n\n",
        "// Compute how much collateral needs to be swapt\nuint256 collateralInPlay = \\_getCollateralInPlay(\n vAssets.collateralAsset,\n vAssets.borrowAsset,\n debtTotal + bonus\n);\n\n// Burn f1155\n\\_burnMulti(addrs, borrowBals, vAssets, \\_vault, f1155);\n\n// Withdraw collateral\nIVault(\\_vault).withdrawLiq(int256(collateralInPlay));\n\n",
        "// Compute how much collateral needs to be swapt for all liquidated users\nuint256 collateralInPlay = \\_getCollateralInPlay(\n vAssets.collateralAsset,\n vAssets.borrowAsset,\n \\_amount + \\_flashloanFee + bonus\n);\n\n// Burn f1155\n\\_burnMulti(\\_addrs, \\_borrowBals, vAssets, \\_vault, f1155);\n\n// Withdraw collateral\nIVault(\\_vault).withdrawLiq(int256(collateralInPlay));\n\n",
        "uint256 amount = \\_amount < 0 ? debtTotal : uint256(\\_amount);\n\n",
        "function withdrawLiq(int256 \\_withdrawAmount) external override nonReentrant onlyFliquidator {\n // Logic used when called by Fliquidator\n \\_withdraw(uint256(\\_withdrawAmount), address(activeProvider));\n IERC20Upgradeable(vAssets.collateralAsset).univTransfer(\n payable(msg.sender),\n uint256(\\_withdrawAmount)\n );\n}\n\n",
        "function updateState(uint256 \\_assetID, uint256 newBalance) external override onlyPermit {\n uint256 total = totalSupply(\\_assetID);\n if (newBalance > 0 && total > 0 && newBalance > total) {\n uint256 newIndex = (indexes[\\_assetID] \\* newBalance) / total;\n indexes[\\_assetID] = uint128(newIndex);\n }\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The reason for using signed integers in some situations appears to be to use negative values as an indicator to withdraw everything. Using a whole bit of uint256 for this is quite a lot when using type(uint256).max would equal or better serve as a flag to withdraw everything.",
        "Furthermore, even though the code uses solidity 0.8.x, which safeguards arithmetic operations against under/overflows, arithmetic typecast is not protected.",
        "Also, see issue 4.9 for a related issue."
    ],
    "Examples": [
        "code/contracts/fantom/FliquidatorFTM.sol:L167-L178",
        "code/contracts/fantom/FliquidatorFTM.sol:L264-L276",
        "code/contracts/fantom/FliquidatorFTM.sol:L334-L334",
        "code/contracts/fantom/FujiVaultFTM.sol:L213-L220",
        "code/contracts/FujiERC1155.sol:L53-L59"
    ],
    "Recommendation": [
        "If negative values are only used as a flag to indicate that all funds should be used for an operation, use type(uint256).max instead. It is wasting less value-space for a simple flag than using the uint256 high-bit range. Avoid typecast where possible. Use SafeCast instead or verify that the casts are safe because the values they operate on cannot under- or overflow. Add inline code comments if that\u2019s the case."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-input-validation-on-flash-close-fee-factors-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setFlashCloseFee(uint64 \\_newFactorA, uint64 \\_newFactorB) external isAuthorized {\n flashCloseF.a = \\_newFactorA;\n flashCloseF.b = \\_newFactorB;\n\n"
    ],
    "preamble": [],
    "Description": [
        "The FliquidatorFTM contract allows authorized parties to set the flash close fee factor. The factor is provided as two integers denoting numerator and denominator. Due to a lack of boundary checks, it is possible to set unrealistically high factors, which go well above 1. This can have unexpected effects on internal accounting and the impact of flashloan balances."
    ],
    "Examples": [
        "code/contracts/fantom/FliquidatorFTM.sol:L657-L659"
    ],
    "Recommendation": [
        "Add a requirement making sure that flashCloseF.a <= flashCloseF.b."
    ]
}
----End JSON----

https://solodit.xyz/issues/separation-of-concerns-and-consistency-in-vaults-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdraw(int256 \\_withdrawAmount) public override nonReentrant {\n updateF1155Balances();\n \\_internalWithdraw(\\_withdrawAmount);\n}\n\n",
        "uint256 amountToWithdraw = \\_withdrawAmount < 0\n ? providedCollateral - neededCollateral\n : uint256(\\_withdrawAmount);\n\n",
        "function withdrawLiq(int256 \\_withdrawAmount) external override nonReentrant onlyFliquidator {\n // Logic used when called by Fliquidator\n \\_withdraw(uint256(\\_withdrawAmount), address(activeProvider));\n IERC20Upgradeable(vAssets.collateralAsset).univTransfer(\n payable(msg.sender),\n uint256(\\_withdrawAmount)\n );\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The FujiVaultFTM contract contains multiple balance-changing functions. Most notably, withdraw is passed an int256 denoted amount parameter. Negative values of this parameter are given to the _internalWithdraw function, where they trigger the withdrawal of all collateral. This approach can result in accounting mistakes in the future as beyond a certain point in the vault\u2019s accounting; amounts are expected to be only positive. Furthermore, the concerns of withdrawing and entirely withdrawing are not separated.",
        "The above issue applies analogously to the payback function and its dependency on _internalPayback.",
        "For consistency, withdrawLiq also takes an int256 amount parameter. This function is only accessible to the Fliquidator contract and withdraws collateral from the active provider. However, all occurrences of the _withdrawAmount parameter are cast to uint256."
    ],
    "Examples": [
        "The withdraw entry point:",
        "code/contracts/fantom/FujiVaultFTM.sol:L201-L204",
        "_internalWithdraw\u2019s negative amount check:",
        "code/contracts/fantom/FujiVaultFTM.sol:L654-L657",
        "The withdrawLiq entry point for the Fliquidator:",
        "code/contracts/fantom/FujiVaultFTM.sol:L213-L220"
    ],
    "Recommendation": [
        "We recommend splitting the withdraw(int256) function into two: withdraw(uint256) and withdrawAll(). These will provide the same functionality while rendering the updated code of _internalWithdraw easier to read, maintain, and harder to manipulate. The recommendation applies to payback and _internalPayback.",
        "Similarly, withdrawLiq\u2019s parameter should be a uint256 to prevent unnecessary casts."
    ]
}
----End JSON----

https://solodit.xyz/issues/aavegeist-interface-declaration-mismatch-and-unchecked-return-values-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_getAaveProvider() internal pure returns (IAaveLendingPoolProvider) {\n return IAaveLendingPoolProvider(0xB53C1a33016B2DC2fF3653530bfF1848a515c8c5);\n}\n\n",
        "// SPDX-License-Identifier: MIT\n\npragma solidity ^0.8.0;\n\ninterface IAaveLendingPool {\n function flashLoan(\n address receiverAddress,\n address[] calldata assets,\n uint256[] calldata amounts,\n uint256[] calldata modes,\n address onBehalfOf,\n bytes calldata params,\n uint16 referralCode\n ) external;\n\n function deposit(\n address \\_asset,\n uint256 \\_amount,\n address \\_onBehalfOf,\n uint16 \\_referralCode\n ) external;\n\n function withdraw(\n address \\_asset,\n uint256 \\_amount,\n address \\_to\n ) external;\n\n function borrow(\n address \\_asset,\n uint256 \\_amount,\n uint256 \\_interestRateMode,\n uint16 \\_referralCode,\n address \\_onBehalfOf\n ) external;\n\n function repay(\n address \\_asset,\n uint256 \\_amount,\n uint256 \\_rateMode,\n address \\_onBehalfOf\n ) external;\n\n function setUserUseReserveAsCollateral(address \\_asset, bool \\_useAsCollateral) external;\n}\n\n",
        "...\n if (amount == type(uint256).max) {\n amountToWithdraw = userBalance;\n }\n...\n return amountToWithdraw;\n\n",
        "function withdraw(address \\_asset, uint256 \\_amount) external payable override {\n IAaveLendingPool aave = IAaveLendingPool(\\_getAaveProvider().getLendingPool());\n\n bool isFtm = \\_asset == \\_getFtmAddr();\n address \\_tokenAddr = isFtm ? \\_getWftmAddr() : \\_asset;\n\n aave.withdraw(\\_tokenAddr, \\_amount, address(this));\n\n // convert WFTM to FTM\n if (isFtm) {\n address unwrapper = \\_getUnwrapper();\n IERC20(\\_tokenAddr).univTransfer(payable(unwrapper), \\_amount);\n IUnwrapper(unwrapper).withdraw(\\_amount);\n }\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The two lending providers, Geist & Aave, do not seem to be directly affiliated even though one is a fork of the other. However, the interfaces may likely diverge in the future. Using the same interface declaration for both protocols might become problematic with future upgrades to either protocol.\nThe interface declaration does not seem to come from the original upstream project. The interface IAaveLendingPool does not declare any return values while some of the functions called in Geist or Aave return them.",
        "Note: that we have not verified all interfaces for correctness. However, we urge the client to only use official interface declarations from the upstream projects and verify that all other interfaces match."
    ],
    "Examples": [
        "The ILendingPool configured in ProviderAave (0xB53C1a33016B2DC2fF3653530bfF1848a515c8c5 -> implementation: 0xc6845a5c768bf8d7681249f8927877efda425baf)",
        "code/contracts/mainnet/providers/ProviderAave.sol:L19-L21",
        "The IAaveLendingPool does not declare return values for any function, while upstream does.",
        "code/contracts/interfaces/aave/IAaveLendingPool.sol:L1-L46",
        "Methods: withdraw(), repay() return uint256 in the original implementation for Aave, see:",
        "https://etherscan.io/address/0xc6845a5c768bf8d7681249f8927877efda425baf#code",
        "The ILendingPool configured for Geist:",
        "Methods withdraw(), repay() return uint256 in the original implementation for Geist, see:",
        "https://ftmscan.com/address/0x3104ad2aadb6fe9df166948a5e3a547004862f90#code",
        "Note: that the actual amount withdrawn does not necessarily need to match the amount provided with the function argument. Here\u2019s an excerpt of the upstream LendingProvider.withdraw():",
        "And here\u2019s the code in Fuji that calls that method. This will break the withdrawAll functionality of LendingProvider if token isFTM.",
        "code/contracts/fantom/providers/ProviderGeist.sol:L151-L165",
        "Similar for repay(), which returns the actual amount repaid."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/missing-slippage-protection-for-rewards-swap-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "transaction.data = abi.encodeWithSelector(\n IUniswapV2Router01.swapExactETHForTokens.selector,\n 0,\n path,\n msg.sender,\n type(uint256).max\n);\n\n",
        "// Swap rewards -> collateralAsset\n(success, ) = swapTransaction.to.call{ value: swapTransaction.value }(swapTransaction.data);\nrequire(success, \"failed to swap rewards\");\n\n",
        "require(\n (priceDelta \\* SLIPPAGE\\_LIMIT\\_DENOMINATOR) / priceFromOracle < SLIPPAGE\\_LIMIT\\_NUMERATOR,\n Errors.VL\\_SWAP\\_SLIPPAGE\\_LIMIT\\_EXCEED\n);\n\n"
    ],
    "preamble": [],
    "Description": [
        "In FujiVaultFTM.harvestRewards a swap transaction is generated using a call to SwapperFTM.getSwapTransaction. In all relevant scenarios, this call uses a minimum output amount of zero, which de-facto deactivates slippage checks. Most values from harvesting rewards can thus be siphoned off by sandwiching such calls."
    ],
    "Examples": [
        "amountOutMin is 0, effectively disabling slippage control in the swap method.",
        "code/contracts/fantom/SwapperFTM.sol:L49-L55",
        "Only success required",
        "code/contracts/fantom/FujiVaultFTM.sol:L565-L567"
    ],
    "Recommendation": [
        "Use a slippage check such as for liquidator swaps:",
        "code/contracts/fantom/FliquidatorFTM.sol:L476-L479",
        "Or specify a non-zero amountOutMin argument in calls to IUniswapV2Router01.swapExactETHForTokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-due-to-admin-front-running-or-general-bad-timing-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\"FujiAdmin\": {\n \"address\": \"0x4cB46032e2790D8CA10be6d0001e8c6362a76adA\",\n \"abi\": [\n\n",
        "{\n \"FujiAdmin\": {\n \"address\": \"0xaAb2AAfBFf7419Ff85181d3A846bA9045803dd67\",\n \"deployer\": \"0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148\",\n \"abi\": [\n\n"
    ],
    "preamble": [],
    "Description": [
        "In several cases, the owner of deployed contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, contract owners (a 2/3 EOA Gnosis Multisig) could use front running to make malicious changes just ahead of incoming transactions, or purely accidental adverse effects could occur due to unfortunate timing of changes.",
        "Some instances of this are more important than others, but in general, users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "The owner of FujiAdmin is 0x0e1484c9a9f9b31ff19300f082e843415a575f4f and this address is a proxy to a Gnosis Safe: Mastercopy 1.2.0 implementation, requiring 2/3 signatures to execute transactions. All three signees are EOA\u2019s.",
        "code/artifacts/1-core.deploy:L958-L960",
        "//",
        "\n",
        "The owner of controller seems to be a single EOA:",
        "https://etherscan.io/address/0x3f366802F4e7576FC5DAA82890Cc6e04c85f3736#readContract",
        "The owner of FujiOracle seems to be a single EOA:",
        "https://etherscan.io/address/0xadF849079d415157CbBdb21BB7542b47077734A8#readContract",
        "The owner of FujiERC1155 seems to be a single EOA:",
        "https://etherscan.io/address/0xa2d62f8b02225fbFA1cf8bF206C8106bDF4c692b#readProxyContract",
        "Deployer is 0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148 which is an EOA.",
        "code/artifacts/250-core.deploy:L1-L5",
        "FujiAdmin.owner is 0x40578f7902304e0e34d7069fb487ee57f841342e which is a GnosisSafeProxy",
        ""
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, all onlyOwner functionality requires two steps with a mandatory time window between them. The first step merely tells users that a particular change is coming, and the second step commits that change after a reasonable waiting period."
    ]
}
----End JSON----

https://solodit.xyz/issues/fujioracle-_getusdprice-does-not-detect-stale-oracle-prices-general-oracle-risks-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Calculates the USD price of asset.\n \\* @param \\_asset: the asset address.\n \\* Returns the USD price of the given asset\n \\*/\nfunction \\_getUSDPrice(address \\_asset) internal view returns (uint256 price) {\n require(usdPriceFeeds[\\_asset] != address(0), Errors.ORACLE\\_NONE\\_PRICE\\_FEED);\n\n (, int256 latestPrice, , , ) = AggregatorV3Interface(usdPriceFeeds[\\_asset]).latestRoundData();\n\n price = uint256(latestPrice);\n}\n\n",
        "\\* @return updatedAt is the timestamp when the round last was updated (i.e.\n\\* answer was last computed)\n\n"
    ],
    "preamble": [],
    "Description": [
        "The external Chainlink oracle, which provides index price information to the system, introduces risk inherent to any dependency on third-party data sources. For example, the oracle could fall behind or otherwise fail to be maintained, resulting in outdated data being fed to the index price calculations. Oracle reliance has historically resulted in crippled on-chain systems, and complications that lead to these outcomes can arise from things as simple as network congestion.",
        "This is more extreme in lesser-known tokens with fewer ChainLink Price feeds to update the price frequently.",
        "Ensuring that unexpected oracle return values are correctly handled will reduce reliance on off-chain components and increase the resiliency of the smart contract system that depends on them.",
        "The codebase, as is, relies on chainLinkOracle.latestRoundData() and does not check the timestamp or answeredIn round of the returned price."
    ],
    "Examples": [
        "code/contracts/FujiOracle.sol:L66-L77",
        "contracts/src/v0.6/FluxAggregator.sol:L489-L490"
    ],
    "Recommendation": [
        "Perform sanity checks on the price returned by the oracle. If the price is older, not within configured limits, revert or handle in other means.",
        "The oracle does not provide any means to remove a potentially broken price-feed (e.g., by updating its address to address(0) or by pausing specific feeds or the complete oracle). The only way to pause an oracle right now is to deploy a new oracle contract. Therefore, consider adding minimally invasive functionality to pause the price-feeds if the oracle becomes unreliable.",
        "Monitor the oracle data off-chain and intervene if it becomes unreliable.",
        "On-chain, realistically, both answeredInRound and updatedAt must be checked within acceptable bounds."
    ]
}
----End JSON----

https://solodit.xyz/issues/unclaimed-or-front-runnable-proxy-implementations-consensys-fuji-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize(\n address \\_fujiadmin,\n address \\_oracle,\n address \\_collateralAsset,\n address \\_borrowAsset\n) external initializer {\n\n",
        "\"deployer\": \"0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148\",\n\n",
        "{\n \"FujiAdmin\": {\n \"address\": \"0xaAb2AAfBFf7419Ff85181d3A846bA9045803dd67\",\n \"deployer\": \"0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148\",\n \"abi\": [\n {\n \"anonymous\": false,\n\n"
    ],
    "preamble": [],
    "Description": [
        "Various smart contracts in the system require initialization functions to be called. The point when these calls happen is up to the deploying address. Deployment and initialization in one transaction are typically safe, but it can potentially be front-run if the initialization is done in a separate transaction.",
        "A frontrunner can call these functions to silently take over the contracts and provide malicious parameters or plant a backdoor during the deployment.",
        "Leaving proxy implementations uninitialized further aides potential phishing attacks where users might claim that - just because a contract address is listed in the official documentation/code-repo - a contract is a legitimate component of the system. At the same time, it is \u2018only\u2019 a proxy implementation that an attacker claimed. For the end-user, it might be hard to distinguish whether this contract is part of the system or was a maliciously appropriated implementation."
    ],
    "Examples": [
        "code/contracts/mainnet/FujiVault.sol:L97-L102",
        "\nAnother FujiVault was deployed by deployer initialized in a 2-step approach that can theoretically silently be front-run.",
        "code/artifacts/250-core.deploy:L2079-L2079",
        "Transactions of deployer:",
        "https://ftmscan.com/txs?a=0xb98d4D4e205afF4d4755E9Df19BD0B8BD4e0f148&p=2",
        "The specific contract was initialized 19 blocks after deployment.",
        "https://ftmscan.com/address/0x8513c2db99df213887f63300b23c6dd31f1d14b0",
        "",
        "code/artifacts/250-core.deploy:L1-L7"
    ],
    "Recommendation": [
        "It is recommended to use constructors wherever possible to immediately initialize proxy implementations during deploy-time. The code is only run when the implementation is deployed and affects the proxy initializations. If other initialization functions are used, we recommend enforcing deployer access restrictions or a standardized, top-level initialized boolean, set to true on the first deployment and used to prevent future initialization.",
        "Using constructors and locked-down initialization functions will significantly reduce potential developer errors and the possibility of attackers re-initializing vital system components."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-hypervisordeposit-function-does-not-check-the-msgsender-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Partially fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by allowing only whitelistedAddress to call deposit, or anyone if whitelisted = false (currently it is set to true by default)."
    ],
    "Description": [
        "Hypervisor.deposit pulls pre-approved ERC20 tokens from the from address to the contract. Later it mints shares to the to address. Attackers can determine both the from and to addresses as they wish, and thus steal shares (that can be redeemed to tokens immediately) from users that pre-approved the contract to spend ERC20 tokens on their behalf."
    ],
    "Recommendation": [
        "As described in https://github.com/ConsenSys/gamma-audit-2022-02/issues/10, we recommend restricting access to this function only for UniProxy. Moreover, the UniProxy contract should validate that from == msg.sender."
    ]
}
----End JSON----

https://solodit.xyz/issues/uniproxydepositswap-tokens-are-not-approved-before-calling-routerexactinput-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "router = ISwapRouter(\\_router);\nuint256 amountOut;\nuint256 swap;\nif(swapAmount < 0) {\n    //swap token1 for token0\n\n    swap = uint256(swapAmount \\* -1);\n    IHypervisor(pos).token1().transferFrom(msg.sender, address(this), deposit1+swap);\n    amountOut = router.exactInput(\n        ISwapRouter.ExactInputParams(\n            path,\n            address(this),\n            block.timestamp + swapLife,\n            swap,\n            deposit0\n        )\n    );\n}\nelse{\n    //swap token1 for token0\n    swap = uint256(swapAmount);\n    IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\n\n    amountOut = router.exactInput(\n        ISwapRouter.ExactInputParams(\n            path,\n            address(this),\n            block.timestamp + swapLife,\n            swap,\n            deposit1\n        )\n    );     \n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by deleting the depositSwap function."
    ],
    "Description": [
        "the call to Router.exactInputrequires the sender to pre-approve the tokens. We could not find any reference for that, thus we assume that a call to UniProxy.depositSwap will always revert."
    ],
    "Examples": [
        "code/contracts/UniProxy.sol:L202-L234"
    ],
    "Recommendation": [
        "Consider approving the exact amount of input tokens before the swap."
    ]
}
----End JSON----

https://solodit.xyz/issues/uniproxydepositswap-_router-should-not-be-determined-by-the-caller-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function depositSwap(\n  int256 swapAmount, // (-) token1, (+) token0 for token1; amount to swap\n  uint256 deposit0,\n  uint256 deposit1,\n  address to,\n  address from,\n  bytes memory path,\n  address pos,\n  address \\_router\n) external returns (uint256 shares) {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by deleting the depositSwap function."
    ],
    "Description": [
        "Uniproxy.depositSwap uses _router that is determined by the caller, which in turn might inject a \u201cfake\u201d contract, and thus may steal funds stuck in the UniProxy contract.",
        "The UniProxy contract has certain trust assumptions regarding the router. The router is supposed to return not less than deposit1(or deposit0) amount of tokens but that fact is never checked."
    ],
    "Examples": [
        "code/contracts/UniProxy.sol:L168-L177"
    ],
    "Recommendation": [
        "Consider removing the _router parameter from the function, and instead, use a storage variable that will be initialized in the constructor."
    ]
}
----End JSON----

https://solodit.xyz/issues/re-entrancy-flash-loan-attack-can-invalidate-price-check-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (twapCheck || positions[pos].twapOverride) {\n  // check twap\n  checkPriceChange(\n    pos,\n    (positions[pos].twapOverride ? positions[pos].twapInterval : twapInterval),\n    (positions[pos].twapOverride ? positions[pos].priceThreshold : priceThreshold)\n  );\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "The UniProxy contract has a price manipulation protection:",
        "code/contracts/UniProxy.sol:L75-L82",
        "But after that, the tokens are transferred from the user, if the token transfer allows an attacker to hijack the call-flow of the transaction inside, the attacker can manipulate the Uniswap price there, after the check happened.\nThe Hypervisor\u2019s deposit function itself is vulnerable to the flash-loan attack."
    ],
    "Recommendation": [
        "Make sure the price does not change before the Hypervisor.deposit call. For example, the token transfers can be made at the beginning of the UniProxy.deposit function."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-deposit-function-of-the-hypervisor-contract-should-only-be-called-from-uniproxy-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Partially fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by allowing only whitelistedAddress to call deposit, or anyone if whitelisted = false (currently it is set to true by default)."
    ],
    "Description": [
        "The deposit function is designed to be called only from the UniProxy contract, but everyone can call it. This function does not have any protection against price manipulation in the Uniswap pair. A deposit can be frontrunned, and the depositor\u2019s funds may be \u201cstolen\u201d."
    ],
    "Recommendation": [
        "Make sure only UniProxy can call the deposit function."
    ]
}
----End JSON----

https://solodit.xyz/issues/uniproxyproperdepositratio-proper-ratio-will-not-prevent-liquidity-imbalance-for-all-possible-scenarios-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function properDepositRatio(\n  address pos,\n  uint256 deposit0,\n  uint256 deposit1\n) public view returns (bool) {\n  (uint256 hype0, uint256 hype1) = IHypervisor(pos).getTotalAmounts();\n  if (IHypervisor(pos).totalSupply() != 0) {\n    uint256 depositRatio = deposit0 == 0 ? 10e18 : deposit1.mul(1e18).div(deposit0);\n    depositRatio = depositRatio > 10e18 ? 10e18 : depositRatio;\n    depositRatio = depositRatio < 10e16 ? 10e16 : depositRatio;\n    uint256 hypeRatio = hype0 == 0 ? 10e18 : hype1.mul(1e18).div(hype0);\n    hypeRatio = hypeRatio > 10e18 ? 10e18 : hypeRatio;\n    hypeRatio = hypeRatio < 10e16 ? 10e16 : hypeRatio;\n    return (FullMath.mulDiv(depositRatio, deltaScale, hypeRatio) < depositDelta &&\n            FullMath.mulDiv(hypeRatio, deltaScale, depositRatio) < depositDelta);\n  }\n  return true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by deleting the properDepositRatio function."
    ],
    "Description": [
        "UniProxy.properDepositRatio purpose is to be used as a mechanism to prevent liquidity imbalance. The idea is to compare the deposit ratio with the hypeRatio, which is the ratio between the tokens held by the Hypervisor contract. In practice, however, this function will not prevent a skewed deposit ratio in many cases. deposit1 / deposit0 might be a huge number, while 10^16 <= depositRatio <= 10^18, and 10^16 <= hypeRatio <= 10^18. Let us consider the case where hype1 / hype0 >= 10, that means hypeRatio = 10^18, and now if deposit1 / deposit0 = 10^200 for example, depositRatio = 10^18, and the transaction will pass, which is clearly not intended."
    ],
    "Examples": [
        "code/contracts/UniProxy.sol:L258-L275"
    ],
    "Recommendation": [
        "Consider removing the cap of [0.1,10] both for depositRatio and for hypeRatio."
    ]
}
----End JSON----

https://solodit.xyz/issues/uniproxy-safeerc20-is-declared-but-safe-functions-are-not-used-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "The UniProxy contract declares the usage of the SafeERC20 library for functions of the IERC20 type. However, unsafe functions are used instead of safe ones."
    ],
    "Examples": []
}
----End JSON----

https://solodit.xyz/issues/missingwrong-implementation-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [],
    "Examples": [],
    "Recommendations": []
}
----End JSON----

https://solodit.xyz/issues/hypervisorwithdraw-possible-reentrancy-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by implementing the auditor\u2019s recommendation."
    ],
    "Description": [
        "Hypervisor.withdraw can be used by a liquidity provider to withdraw its deposit from the Hypervisor contract. A user can get his deposited liquidity back in exchange for the burn of his shares. The function is transferring token0,1 to the user first and then burns his shares. In theory, the contracts of token0,1 may hijack the execution call-flow causing a reentrant call to deposit, which will use the stale value for totalSupply() to evaluate the number of shares to be minted. Since this value will be greater than what it should be, the attacker will be able to mint shares for free, that could be later redeemed for actual tokens stolen from other depositors."
    ],
    "Recommendation": [
        "Consider adding a ReentrancyGuard both to Hypervisor.withdraw and Hypervisor.deposit"
    ]
}
----End JSON----

https://solodit.xyz/issues/uniproxydepositswap-doesnt-deposit-all-the-users-funds-fixed-consensys-gamma-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "else{\n    //swap token1 for token0\n    swap = uint256(swapAmount);\n    IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\n\n    amountOut = router.exactInput(\n        ISwapRouter.ExactInputParams(\n            path,\n            address(this),\n            block.timestamp + swapLife,\n            swap,\n            deposit1\n        )\n    );     \n}\n\nrequire(amountOut > 0, \"Swap failed\");\n\nif (positions[pos].version < 2) {\n  // requires lp token transfer from proxy to msg.sender\n  shares = IHypervisor(pos).deposit(deposit0, deposit1, address(this));\n  IHypervisor(pos).transfer(to, shares);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by deleting the depositSwap function."
    ],
    "Description": [
        "When executing the swap, the minimal amount out is passed to the router (deposit1 in this example), but the actual swap amount will be amountOut. But after the trade, instead of depositing amountOut, the contract tries to deposit deposit1, which is lower. This may result in some users' funds staying in the UniProxy contract.",
        "code/contracts/UniProxy.sol:L220-L242"
    ],
    "Recommendation": [
        "Deposit all the user\u2019s funds to the Hypervisor."
    ]
}
----End JSON----

https://solodit.xyz/issues/hypervisor-multiple-sandwiching-front-running-vectors-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (swapQuantity != 0) {\n    pool.swap(\n        address(this),\n        swapQuantity > 0,\n        swapQuantity > 0 ? swapQuantity : -swapQuantity,\n        swapQuantity > 0 ? TickMath.MIN\\_SQRT\\_RATIO + 1 : TickMath.MAX\\_SQRT\\_RATIO - 1,\n        abi.encode(address(this))\n    );\n}\n\n",
        "function \\_mintLiquidity(\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 liquidity,\n    address payer\n) internal returns (uint256 amount0, uint256 amount1) {\n    if (liquidity > 0) {\n        (amount0, amount1) = pool.mint(\n            address(this),\n            tickLower,\n            tickUpper,\n            liquidity,\n            abi.encode(payer)\n        );\n    }\n}\n\n",
        "function \\_burnLiquidity(\n    int24 tickLower,\n    int24 tickUpper,\n    uint128 liquidity,\n    address to,\n    bool collectAll\n) internal returns (uint256 amount0, uint256 amount1) {\n    if (liquidity > 0) {\n        // Burn liquidity\n        (uint256 owed0, uint256 owed1) = pool.burn(tickLower, tickUpper, liquidity);\n\n        // Collect amount owed\n        uint128 collect0 = collectAll ? type(uint128).max : \\_uint128Safe(owed0);\n        uint128 collect1 = collectAll ? type(uint128).max : \\_uint128Safe(owed1);\n        if (collect0 > 0 || collect1 > 0) {\n            (amount0, amount1) = pool.collect(to, tickLower, tickUpper, collect0, collect1);\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by removing the call to pool.swap, and adopting the auditor recommendation for pool.mint, pool.burn with slippage = 10%"
    ],
    "Description": [
        "The amount of tokens received from UniswapV3Pool functions might be manipulated by front-runners due to the decentralized nature of AMMs, where the order of transactions can not be pre-determined.\nA potential \u201csandwicher\u201d may insert a buying order before the user\u2019s call to Hypervisor.rebalance for instance, and a sell order after.",
        "More specifically, calls to pool.swap, pool.mint, pool.burn are susceptible to \u201csandwiching\u201d vectors."
    ],
    "Examples": [
        "Hypervisor.rebalance",
        "code/contracts/Hypervisor.sol:L278-L286",
        "code/contracts/Hypervisor.sol:L348-L363",
        "code/contracts/Hypervisor.sol:L365-L383"
    ],
    "Recommendation": [
        "Consider adding an amountMin parameter(s) to ensure that at least the amountMin of tokens was received."
    ]
}
----End JSON----

https://solodit.xyz/issues/full-test-suite-is-necessary-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "The test suite at this stage is not complete. It is crucial to have a full test coverage that includes the edge cases and failure scenarios, especially for complex system like Gamma.",
        "As we\u2019ve seen in some smart contract incidents, a complete test suite can prevent issues that might be hard to find with manual reviews.",
        "Some issues such as https://github.com/ConsenSys/gamma-audit-2022-02/issues/5, issue 3.2 could be caught by a full-coverage test suite."
    ]
}
----End JSON----

https://solodit.xyz/issues/uniproxydepositswap-doesnt-deposit-all-the-users-funds-fixed-consensys-gamma-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "else{\n //swap token1 for token0\n swap = uint256(swapAmount);\n IHypervisor(pos).token0().transferFrom(msg.sender, address(this), deposit0+swap);\n\n amountOut = router.exactInput(\n ISwapRouter.ExactInputParams(\n path,\n address(this),\n block.timestamp + swapLife,\n swap,\n deposit1\n )\n ); \n}\n\nrequire(amountOut > 0, \"Swap failed\");\n\nif (positions[pos].version < 2) {\n // requires lp token transfer from proxy to msg.sender\n shares = IHypervisor(pos).deposit(deposit0, deposit1, address(this));\n IHypervisor(pos).transfer(to, shares);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in GammaStrategies/[email\u00a0protected]9a7a3dd by deleting the depositSwap function."
    ],
    "Description": [
        "When executing the swap, the minimal amount out is passed to the router (deposit1 in this example), but the actual swap amount will be amountOut. But after the trade, instead of depositing amountOut, the contract tries to deposit deposit1, which is lower. This may result in some users\u2019 funds staying in the UniProxy contract.",
        "code/contracts/UniProxy.sol:L220-L242"
    ],
    "Recommendation": [
        "Deposit all the user\u2019s funds to the Hypervisor."
    ]
}
----End JSON----

https://solodit.xyz/issues/stableswapoperatorv1-resistantfei-value-is-not-correct-in-the-resistantbalanceandfei-function-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// get the amount of tokens in the pool\n(uint256 \\_3crvAmount, uint256 \\_feiAmount) = (\n    IStableSwap2(pool).balances(\\_3crvIndex),\n    IStableSwap2(pool).balances(\\_feiIndex)\n);\n// ... and the expected amount of 3crv in it after deposit\nuint256 \\_3crvAmountAfter = \\_3crvAmount + \\_3crvBalanceAfter;\n \n// get the usd value of 3crv in the pool\nuint256 \\_3crvUsdValue = \\_3crvAmountAfter \\* IStableSwap3(\\_3pool).get\\_virtual\\_price() / 1e18;\n \n// compute the number of FEI to deposit\nuint256 \\_feiToDeposit = 0;\nif (\\_3crvUsdValue > \\_feiAmount) {\n    \\_feiToDeposit = \\_3crvUsdValue - \\_feiAmount;\n}\n\n",
        "uint256[2] memory \\_minAmounts; // [0, 0]\nIERC20(pool).approve(pool, \\_lpToWithdraw);\nuint256 \\_3crvBalanceBefore = IERC20(\\_3crv).balanceOf(address(this));\nIStableSwap2(pool).remove\\_liquidity(\\_lpToWithdraw, \\_minAmounts);\n\n",
        "resistantBalance = \\_lpPriceUSD / 2;\nresistantFei = resistantBalance;\n\n"
    ],
    "preamble": [],
    "Description": [
        "The resistantBalanceAndFei function of a PCVDeposit contract is supposed to return the amount of funds that the contract controls; it is then used to evaluate the total value of PCV (collateral in the protocol). Additionally, this function returns the number of FEI tokens that are protocol-controlled. These FEI tokens are \u201ctemporarily minted\u201d; they are not backed up by the collateral and shouldn\u2019t be used in calculations that determine the collateralization of the protocol.",
        "Ideally, the amount of these FEI tokens should be the same during the deposit, withdrawal, and the resistantBalanceAndFei function call. In the StableSwapOperatorV1  contract, all these values are totally different:",
        "code/contracts/pcv/curve/StableSwapOperatorV1.sol:L156-L171",
        "code/contracts/pcv/curve/StableSwapOperatorV1.sol:L255-L258",
        "code/contracts/pcv/curve/StableSwapOperatorV1.sol:L348-L349",
        "Some of these values may be equal under some circumstances, but that is not enforced. After one of the steps (deposit or withdrawal), the total PCV value and collateralization may be changed significantly."
    ],
    "Recommendation": [
        "Make sure that deposit, withdrawal, and the resistantBalanceAndFei are consistent and won\u2019t instantly change the PCV value significantly."
    ]
}
----End JSON----

https://solodit.xyz/issues/collateralizationoracle-fei-in-excluded-deposits-contributes-to-usercirculatingfei-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice returns the Protocol-Controlled Value, User-circulating FEI, and\n/// Protocol Equity.\n/// @return protocolControlledValue : the total USD value of all assets held\n/// by the protocol.\n/// @return userCirculatingFei : the number of FEI not owned by the protocol.\n/// @return protocolEquity : the difference between PCV and user circulating FEI.\n/// If there are more circulating FEI than $ in the PCV, equity is 0.\n/// @return validityStatus : the current oracle validity status (false if any\n/// of the oracles for tokens held in the PCV are invalid, or if\n/// this contract is paused).\nfunction pcvStats() public override view returns (\n  uint256 protocolControlledValue,\n  uint256 userCirculatingFei,\n  int256 protocolEquity,\n  bool validityStatus\n) {\n    uint256 \\_protocolControlledFei = 0;\n    validityStatus = !paused();\n\n    // For each token...\n    for (uint256 i = 0; i < tokensInPcv.length(); i++) {\n        address \\_token = tokensInPcv.at(i);\n        uint256 \\_totalTokenBalance  = 0;\n\n        // For each deposit...\n        for (uint256 j = 0; j < tokenToDeposits[\\_token].length(); j++) {\n            address \\_deposit = tokenToDeposits[\\_token].at(j);\n\n            // ignore deposits that are excluded by the Guardian\n            if (!excludedDeposits[\\_deposit]) {\n                // read the deposit, and increment token balance/protocol fei\n                (uint256 \\_depositBalance, uint256 \\_depositFei) = IPCVDepositBalances(\\_deposit).resistantBalanceAndFei();\n                \\_totalTokenBalance += \\_depositBalance;\n                \\_protocolControlledFei += \\_depositFei;\n            }\n        }\n\n        // If the protocol holds non-zero balance of tokens, fetch the oracle price to\n        // increment PCV by \\_totalTokenBalance \\* oracle price USD.\n        if (\\_totalTokenBalance != 0) {\n            (Decimal.D256 memory \\_oraclePrice, bool \\_oracleValid) = IOracle(tokenToOracle[\\_token]).read();\n            if (!\\_oracleValid) {\n                validityStatus = false;\n            }\n            protocolControlledValue += \\_oraclePrice.mul(\\_totalTokenBalance).asUint256();\n        }\n    }\n\n    userCirculatingFei = fei().totalSupply() - \\_protocolControlledFei;\n    protocolEquity = int256(protocolControlledValue) - int256(userCirculatingFei);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "CollateralizationOracle.pcvStats iterates over all deposits, queries the resistant balance and FEI for each deposit, and accumulates the total value of the resistant balances and the total resistant FEI. Any Guardian or Governor can exclude (and re-include) a deposit that has become problematic in some way, for example, because it is reporting wrong numbers.\nFinally, the pcvStats function computes the userCirculatingFei as the total FEI supply minus the accumulated resistant FEI balances; the idea here is to determine the amount of \u201cfree\u201d FEI, or FEI that is not PCV. However, the FEI balances from excluded deposits contribute to the userCirculatingFei, although they are clearly not \u201cfree\u201d FEI. That leads to a wrong protocolEquity and a skewed collateralization ratio and might therefore have a significant impact on the economics of the system.",
        "It should be noted that even the exclusion from the total PCV leads to a protocolEquity and a collateralization ratio that could be considered skewed (again, it might depend on the exact reasons for exclusion), but \u201cadding\u201d the missing FEI to the userCirculatingFei distorts these numbers even more.",
        "In the extreme scenario that all deposits have been excluded, the entire Fei supply is currently reported as userCirculatingFei.",
        "code/contracts/oracle/CollateralizationOracle.sol:L278-L328"
    ],
    "Recommendation": [
        "It is unclear how to fix this. One might want to exclude the FEI in excluded deposits entirely from the calculation, but not knowing the amount was the reason to exclude the deposit in the first place.",
        "One option could be to let the entity that excludes a deposit specify substitute values that should be used instead of querying the numbers from the deposit. However, it is questionable whether this approach is practical if the numbers we\u2019d like to see as substitute values change quickly or repeatedly over time. Ultimately, the querying function itself should be fixed. Moreover, as the substitute values can dramatically impact the system economics, we\u2019d only like to trust the Governor with this and not give this permission to a Guardian. However, the original intention was to give a role with less trust than the Governor the possibility to react quickly to a deposit that reports wrong numbers; if the exclusion of deposits becomes the Governor\u2019s privilege, such a quick and lightweight intervention isn\u2019t possible anymore.",
        "Independently, we recommend taking proper care of the situation that all deposits \u2013 or just too many \u2013 have been excluded, for example, by setting the returned validityStatus to false, as in this case, there is not enough information to compute the collateralization ratio even as a crude approximation."
    ]
}
----End JSON----

https://solodit.xyz/issues/stableswapoperatorv1-the-_minlpout-value-is-not-accurate-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// slippage check on metapool deposit\nuint256 \\_balanceDeposited = IERC20(pool).balanceOf(address(this)) - \\_balanceBefore;\n{\n    uint256 \\_metapoolVirtualPrice = IStableSwap2(pool).get\\_virtual\\_price();\n    uint256 \\_minLpOut = (\\_feiToDeposit + \\_3crvBalanceAfter) \\* 1e18 / \\_metapoolVirtualPrice \\* (Constants.BASIS\\_POINTS\\_GRANULARITY - depositMaxSlippageBasisPoints) / Constants.BASIS\\_POINTS\\_GRANULARITY;\n    require(\\_balanceDeposited >= \\_minLpOut, \"StableSwapOperatorV1: metapool deposit slippage too high\");\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "When depositing, the expected minimum amount of the output LP tokens is calculated:",
        "code/contracts/pcv/curve/StableSwapOperatorV1.sol:L194-L200",
        "The problem is that the get_virtual_price function returns a valid price only if the tokens in the pool are expected to have a price equal to $1 which is not the case. Also, the balances of deposited FEI and 3pool lp tokens are just added to each other while they have a different price: _feiToDeposit + _3crvBalanceAfter.",
        "The price of the 3pool lp tokens is currently very close to 1$ so this difference is not that visible at the moment, but this can slowly change over time."
    ]
}
----End JSON----

https://solodit.xyz/issues/stableswapoperatorv1-fei-tokens-in-the-contract-are-not-considerred-as-protocol-owned-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "Every PCVDeposit contract should return the amount of PCV controlled by this contract in the resistantBalanceAndFei. In addition to that, this function returns the amount of protocol-controlled FEI, which is not supposed to be collateralized. These values are crucial for evaluating the collateralization of the protocol.",
        "Unlike some other PCVDeposit contracts, protocol-controlled FEI is not minted during the deposit and not burnt during the withdrawal. These FEI tokens are transferred beforehand, so when depositing, all the FEI that are instantly becoming protocol-controlled and heavily impact the collateralization rate. The opposite impact, but as much significant, happens during the withdrawal.",
        "The amount of FEI needed for the deposited is calculated dynamically, it is hard to predict the exact amount beforehand. There may be too many FEI tokens in the contract and the leftovers will be considered as the user-controlled FEI."
    ],
    "Recommendation": [
        "There may be different approaches to solve this issue. One of them would be to make sure that the Fei transfers to/from the contract and the deposit/withdraw calls are happening in a single transaction. These FEI should be minted, burnt, or re-used as the protocol-controlled FEI in the same transaction. Another option would be to consider all the FEI balance in the contract as the protocol-controlled FEI.",
        "If the intention is to have all these FEI collateralized, the other solution is needed: make sure that resistantBalanceAndFei always returns resistantFei equals zero."
    ]
}
----End JSON----

https://solodit.xyz/issues/balancerlbpswapper-init-can-be-front-run-to-potentially-steal-tokens-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function init(IWeightedPool \\_pool) external {\n    require(address(pool) == address(0), \"BalancerLBPSwapper: initialized\");\n\n    pool = \\_pool;\n    IVault \\_vault = \\_pool.getVault();\n\n    vault = \\_vault;\n\n    // Check ownership\n    require(\\_pool.getOwner() == address(this), \"BalancerLBPSwapper: contract not pool owner\");\n\n\n",
        "IERC20(tokenSpent).approve(address(\\_vault), type(uint256).max);\nIERC20(tokenReceived).approve(address(\\_vault), type(uint256).max);\n\n"
    ],
    "preamble": [],
    "Description": [
        "The deployment process for BalancerLBPSwapper appears to be the following:",
        "This process may be split across multiple transactions as in the v2Phase1.js deployment scenario.",
        "Between step (1) and (3) there is a window of opportunity for someone to maliciously initialize contract. This should be easily detectable because calling init() twice should revert the second transaction. If this is not caught in the deployment script this may have more severe security implications. Otherwise, this window can be used to grief the deployment initializing it before the original initializer does forcing them to redeploy the contract or to steal any tokenSpent/tokenReceived that are owned by the contract at this time.",
        "Note: It is assumed that the contract will not own a lot of tokens right after deployment rendering the scenario of stealing tokens more unlikely. However, that highly depends on the deployment script for the contract system."
    ],
    "Examples": [
        "code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L107-L117",
        "code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L159-L160"
    ],
    "Recommendation": [
        "protect BalancerLBPSwapper.init() and only allow a trusted entity (e.g. the initial deployer) to call this method."
    ]
}
----End JSON----

https://solodit.xyz/issues/pcvequityminter-and-balancerlbpswapper-desynchronisation-race-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_afterMint() internal override {\n    IPCVSwapper(target).swap();\n}\n\n",
        "function swap() external override afterTime whenNotPaused {\n    (\n        uint256 spentReserves,\n        uint256 receivedReserves, \n        uint256 lastChangeBlock\n    ) = getReserves();\n\n    // Ensures no actor can change the pool contents earlier in the block\n    require(lastChangeBlock < block.number, \"BalancerLBPSwapper: pool changed this block\");\n\n\n"
    ],
    "preamble": [],
    "Description": [
        "There is nothing that prevents other actors from calling BalancerLBPSwapper.swap() afterTime but right before PCVEquityMinter.mint() would as long as the minAmount required for the call to pass is deposited to BalancerLBPSwapper.",
        "Both the PCVEquityMinter.mint() and BalancerLBPSwapper.swap() are timed (via the afterTime modifier) and are ideally in sync. In an ideal world the incentive to call mint() would be enough to ensure that both contracts are always in sync, however, a malicious actor might interfere by calling .swap() directly, providing the minAmount required for the call to pass. This will have two effects:",
        "Note: There are not a lot of incentives to actually exploit this other than preventing protocol inflation (mint) and potentially griefing users. A malicious user will lose out on the incentivized call and has to ensure that the minAmount required for .swap() to work is available. It is, however, in the best interest of security to defuse the unpredictable racy character of the contract interaction."
    ],
    "Examples": [
        "code/contracts/token/PCVEquityMinter.sol:L91-L93",
        "code/contracts/pcv/balancer/BalancerLBPSwapper.sol:L172-L181"
    ],
    "Recommendation": [
        "If BalancerLBPSwapper.swap() is only to be called within the flows of action from a PCVEquityMinter.mint() it is suggested to authenticate the call and only let PCVEquityMinter call .swap()"
    ]
}
----End JSON----

https://solodit.xyz/issues/collateralizationoraclewrapper-the-deviation-threshold-check-in-update-always-returns-false-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    require(\\_validityStatus, \"CollateralizationOracleWrapper: CollateralizationOracle is invalid\");\n\n    // set cache variables\n    cachedProtocolControlledValue = \\_protocolControlledValue;\n    cachedUserCirculatingFei = \\_userCirculatingFei;\n    cachedProtocolEquity = \\_protocolEquity;\n\n    // reset time\n    \\_initTimed();\n\n    // emit event\n    emit CachedValueUpdate(\n        msg.sender,\n        cachedProtocolControlledValue,\n        cachedUserCirculatingFei,\n        cachedProtocolEquity\n    );\n\n    return outdated\n        || \\_isExceededDeviationThreshold(cachedProtocolControlledValue, \\_protocolControlledValue)\n        || \\_isExceededDeviationThreshold(cachedUserCirculatingFei, \\_userCirculatingFei);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "A call to update() returns a boolean flag indicating whether the update was performed on outdated data. This flag is being checked in updateIfOutdated() which is typically called by an incentivized keeper function.",
        "The _isExceededDeviationThreshold calls at the end of the _update() function always return false as they are comparing the same values (cachedProtocolControlledValue to the _protocolControlledValue value and cachedProtocolControlledValue has just been set to _protocolControlledValue a couple of lines before). _isExceededDeviationThreshold will, therefore, never detect a deviation and return `false\u00b4.",
        "There may currently be no incentive (e.g. from the keeper side) to call update() if the values are not outdated but they deviated too much from the target. However, anyone can force an update by calling the non-incentivized public update() method instead."
    ],
    "Examples": [
        "code/contracts/oracle/CollateralizationOracleWrapper.sol:L156-L177"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/chainlinkoraclewrapper-latestrounddata-might-return-stale-results-consensys-fei-protocol-v2-phase-1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice read the oracle price\n/// @return oracle price\n/// @return true if price is valid\nfunction read() external view override returns (Decimal.D256 memory, bool) {\n    (uint80 roundId, int256 price,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();\n    bool valid = !paused() && price > 0 && answeredInRound == roundId;\n\n    Decimal.D256 memory value = Decimal.from(uint256(price)).div(oracleDecimalsNormalizer);\n    return (value, valid);\n}\n\n",
        "/// @notice determine if read value is stale\n/// @return true if read value is stale\nfunction isOutdated() external view override returns (bool) {\n    (uint80 roundId,,,, uint80 answeredInRound) = chainlinkOracle.latestRoundData();\n    return answeredInRound != roundId;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The oracle wrapper calls out to a chainlink oracle receiving the latestRoundData(). It then checks freshness by verifying that the answer is indeed for the last known round. The returned updatedAt timestamp is not checked.",
        "If there is a problem with chainlink starting a new round and finding consensus on the new value for the oracle (e.g. chainlink nodes abandon the oracle, chain congestion, vulnerability/attacks on the chainlink system) consumers of this contract may continue using outdated stale data (if oracles are unable to submit no new round is started)"
    ],
    "Examples": [
        "code/contracts/oracle/ChainlinkOracleWrapper.sol:L49-L58",
        "code/contracts/oracle/ChainlinkOracleWrapper.sol:L42-L47"
    ],
    "Recommendation": [
        "Consider checking the oracle responses updatedAt value after calling out to chainlinkOracle.latestRoundData() verifying that the result is within an allowed margin of freshness."
    ]
}
----End JSON----

https://solodit.xyz/issues/reward-rate-changes-are-not-taken-into-account-in-lp-staking-consensys-pstake-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from pSTAKE Finance team:"
    ],
    "Description": [
        "When users update their reward (e.g., by calling the calculateRewards function), the reward amount is calculated according to all reward rate changes after the last update. So it does not matter when and how frequently you update the reward; in the end, you\u2019re going to have the same amount.",
        "On the other hand, we can\u2019t say the same about the lp staking provided in the StakeLPCoreV8 contract. The amount of these rewards depends on when you call the calculateRewardsAndLiquidity function, and the reward amount can even decrease over time.",
        "Two main factors lead to this:"
    ],
    "Recommendation": [
        "The most preferred staking solution is to have an algorithm that is not giving people an incentive to gather the rewards earlier or later."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-withdrawunstakedtokens-may-run-out-of-gas-consensys-pstake-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdrawUnstakedTokens(address staker)\n\tpublic\n\tvirtual\n\toverride\n\twhenNotPaused\n{\n\trequire(staker == \\_msgSender(), \"LQ20\");\n\tuint256 \\_withdrawBalance;\n\tuint256 \\_unstakingExpirationLength = \\_unstakingExpiration[staker]\n\t\t.length;\n\tuint256 \\_counter = \\_withdrawCounters[staker];\n\tfor (\n\t\tuint256 i = \\_counter;\n\t\ti < \\_unstakingExpirationLength;\n\t\ti = i.add(1)\n\t) {\n\t\t//get getUnstakeTime and compare it with current timestamp to check if 21 days + epoch difference has passed\n\t\t(uint256 \\_getUnstakeTime, , ) = getUnstakeTime(\n\t\t\t\\_unstakingExpiration[staker][i]\n\t\t);\n\t\tif (block.timestamp >= \\_getUnstakeTime) {\n\t\t\t//if 21 days + epoch difference has passed, then add the balance and then mint uTokens\n\t\t\t\\_withdrawBalance = \\_withdrawBalance.add(\n\t\t\t\t\\_unstakingAmount[staker][i]\n\t\t\t);\n\t\t\t\\_unstakingExpiration[staker][i] = 0;\n\t\t\t\\_unstakingAmount[staker][i] = 0;\n\t\t\t\\_withdrawCounters[staker] = \\_withdrawCounters[staker].add(1);\n\t\t}\n\t}\n\n\trequire(\\_withdrawBalance > 0, \"LQ21\");\n\temit WithdrawUnstakeTokens(staker, \\_withdrawBalance, block.timestamp);\n\t\\_uTokens.mint(staker, \\_withdrawBalance);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from pSTAKE Finance team:"
    ],
    "Description": [
        "The withdrawUnstakedTokens is iterating over all batches of unstaked tokens. One user, if unstaked many times, could get their tokens stuck in the contract.",
        "code/contracts/LiquidStakingV2.sol:L369-L403"
    ],
    "Recommendation": [
        "Limit the number of processed unstaked batches, and possibly add pagination."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-_calculatependingrewards-can-run-out-of-gas-consensys-pstake-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setRewardRate(uint256 rewardRate)\n\tpublic\n\tvirtual\n\toverride\n\treturns (bool success)\n{\n\t// range checks for rewardRate. Since rewardRate cannot be more than 100%, the max cap\n\t// is \\_valueDivisor \\* 100, which then brings the fees to 100 (percentage)\n\trequire(rewardRate <= \\_valueDivisor.mul(100), \"ST17\");\n\trequire(hasRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender()), \"ST2\");\n\t\\_rewardRate.push(rewardRate);\n\t\\_lastMovingRewardTimestamp.push(block.timestamp);\n\temit SetRewardRate(rewardRate);\n\n\treturn true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from pSTAKE Finance team:"
    ],
    "Description": [
        "The reward rate in STokens can be changed, and the history of these changes are stored in the contract:",
        "code/contracts/STokensV2.sol:L124-L139",
        "When the reward is calculated for each user, all changes of the _rewardRate are considered. So there is a for loop that iterates over all changes since the last reward update. If the reward rate was changed many times, the _calculatePendingRewards function could run out of gas."
    ],
    "Recommendation": [
        "Provide an option to partially update the reward, so the full update can be split in multiple transactions."
    ]
}
----End JSON----

https://solodit.xyz/issues/increase-test-coverage-consensys-pstake-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from pSTAKE Finance team:"
    ],
    "Description": [
        "Test coverage is fairly limited.\nLPStaking tests only cover the happy path.\nStakeLPCoreV8 has no tests.\nMany test descriptions are inaccurate."
    ],
    "Examples": [
        "Test description inaccuracy examples:"
    ],
    "Recommendation": [
        "Increase test coverage for entire codebase.\nAdd tests for the inherited contracts from OpenZeppelin.\nTest for edge cases, and multiple expected cases.\nEnsure that the test description matches the functionality that is actually tested."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-calculaterewards-should-not-be-callable-by-the-whitelisted-contract-consensys-pstake-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function calculateRewards(address to)\n\tpublic\n\tvirtual\n\toverride\n\twhenNotPaused\n\treturns (bool success)\n{\n\trequire(to == \\_msgSender(), \"ST5\");\n\tuint256 reward = \\_calculateRewards(to);\n\temit TriggeredCalculateRewards(to, reward, block.timestamp);\n\treturn true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from pSTAKE Finance team:"
    ],
    "Description": [
        "The calculateRewards function should only be called for non-whitelisted addresses:",
        "code/contracts/STokensV2.sol:L348-L359",
        "For all the whitelisted addresses, the calculateHolderRewards function is called. But if the calculateRewards function is called by the whitelisted address directly, the function will execute, and the rewards will be distributed to the caller instead of the intended recipients."
    ],
    "Recommendation": [
        "While this scenario is unlikely to happen, adding the additional check in the calculateRewards is a good option."
    ]
}
----End JSON----

https://solodit.xyz/issues/presence-of-testnet-code-consensys-pstake-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize(address pauserAddress) public virtual initializer {\n\t\\_\\_ERC20\\_init(\"pSTAKE Token\", \"PSTAKE\");\n\t\\_\\_AccessControl\\_init();\n\t\\_\\_Pausable\\_init();\n\t\\_setupRole(DEFAULT\\_ADMIN\\_ROLE, \\_msgSender());\n\t\\_setupRole(PAUSER\\_ROLE, pauserAddress);\n\t// PSTAKE IS A SIMPLE ERC20 TOKEN HENCE 18 DECIMAL PLACES\n\t\\_setupDecimals(18);\n\t// pre-allocate some tokens to an admin address which will air drop PSTAKE tokens\n\t// to each of holder contracts. This is only for testnet purpose. in Mainnet, we\n\t// will use a vesting contract to allocate tokens to admin in a certain schedule\n\t\\_mint(\\_msgSender(), 5000000000000000000000000);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from pSTAKE Finance team:"
    ],
    "Description": [
        "Based on the discussions with pStake team and in-line comments, there are a few instances of code and commented code in the code base under audit that are not finalized for mainnet deployment."
    ],
    "Examples": [
        "code/contracts/PSTAKE.sol:L25-L37",
        "The initialize function currently mints all the tokens to msg.sender, however the goal for mainnet is to use a vesting contract which is not present in the current code."
    ],
    "Recommendation": [
        "It is recommended to fully test the final code before deployment to the mainnet."
    ]
}
----End JSON----

https://solodit.xyz/issues/transactionmanager-user-might-steal-routers-locked-funds-fixed-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This issue has been fixed."
    ],
    "Description": [
        "TransactionManager.removeLiquidity is intended to be restricted for routers only, but in practice, it\u2019s callable by users that had deposited funds to the contract using TransactionManager.prepare. A user may initiate a prepare transaction, wait for the router to lock his funds (by calling prepare on the receiving chain), then the user can call removeLiquidity, and fulfill (on the receiving chain), thus stealing router\u2019s locked funds while claiming his locked funds back."
    ],
    "Recommendation": [
        "Consider using a data structure different than issuedShares for storing user deposits. This way, withdrawals by users will only be allowed when calling TransactionManager.cancel."
    ]
}
----End JSON----

https://solodit.xyz/issues/transactionmanager-receiver-side-check-also-on-sending-side-unverified-fix-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Sanity check: fee <= amount. Allow `=` in case of only wanting to execute\n// 0-value crosschain tx, so only providing the fee amount\nrequire(relayerFee <= txData.amount, \"#F:023\");\n\n",
        "// Check provided callData matches stored hash\nrequire(keccak256(callData) == txData.callDataHash, \"#F:024\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The Connext team claims to have fixed this in commit 4adbfd52703441ee5de655130fc2e0252eae4661. We have not reviewed this commit or, generally, the codebase at this point."
    ],
    "Description": [
        "The functions prepare, cancel, and fulfill in the TransactionManager all have a \u201ccommon part\u201d that is executed on both the sending and the receiving chain and side-specific parts that are only executed either on the sending or on the receiving side.",
        "The following lines occur in fulfill\u2019s common part, but this should only be checked on the receiving chain. In fact, on the sending chain, we might even compare amounts of different assets.",
        "code2/packages/contracts/contracts/TransactionManager.sol:L476-L478",
        "This could prevent a legitimate fulfill on the sending chain, causing a loss of funds for the router."
    ],
    "Recommendation": [
        "Move these lines to the receiving-side part."
    ],
    "Remark": [
        "The callData supplied to fulfill is not used at all on the sending chain, but the check whether its hash matches txData.callDataHash happens in the common part.",
        "code2/packages/contracts/contracts/TransactionManager.sol:L480-L481",
        "In principle, this check could also be moved to the receiving-chain part, allowing the router to save some gas by calling sending-side fulfill with empty callData and skip the check. Note, however, that the TransactionFulfilled event will then also emit the \u201cwrong\u201d callData on the sending chain, so the off-chain code has to be able to deal with that if you want to employ this optimization."
    ]
}
----End JSON----

https://solodit.xyz/issues/transactionmanager-flawed-shares-arithmetic-fixed-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from Connext:"
    ],
    "Description": [
        "To support a wide variety of tokens, the TransactionManager uses a per-asset shares system to represent fractional ownership of the contract\u2019s balance in a token. There are several flaws in the shares-related arithmetic, such as:"
    ],
    "Recommendation": [
        "The shares logic was added late to the contract and is still in a pretty rough shape. While providing a full-fledged solution is beyond the scope of this review, we hope that the points raised above provide pointers and guidelines to inform a major overhaul."
    ]
}
----End JSON----

https://solodit.xyz/issues/router-handlemetatxrequest-gas-griefing-race-conditions-missing-validations-free-meta-transactions-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const fulfillData: MetaTxFulfillPayload = data.data;\n// Validate that metatx request matches with known data about fulfill\n// Is this needed? Can we just submit to chain without validating?\n// Technically this is ok, but perhaps we want to validate only for our own\n// logging purposes.\n// Would also be bad if router had no gas here\n// Next, prepare the tx object\n// - Get chainId from data\n// - Get fulfill fee from data and validate it covers gas\n// - etc.\n// Send to txService\n// Update metrics\n\n// TODO: make sure fee is something we want to accept\n\nthis.logger.info({ method, methodId, requestContext, chainId, data }, \"Submitting tx\");\nconst res = await this.txManager\n  .fulfill(\n    chainId,\n\n"
    ],
    "preamble": [],
    "Description": [
        "There\u2019s a comment in handleMetaTxRequest that asks whether data needs to be validated before interacting with the contract and the answer is yes, always, or else this opens up a gas griefing vector on the router side.",
        "For example, someone might flood broadcast masses of metaTx requests (*.*.metatx) and all online routers will race to call TransactionManager.fulfill(). Even if only one transaction should be able to successfully go through all the others will loose on gas (until up to the first require failing).",
        "Given that there is no rate limiting and it is a broadcast that is very cheap to perform on the client-side (I can just spawn a lot of nodes spamming messages) this can be very severe, keeping the router busy sending transactions that are deemed to fail until the routers balance falls below the min gas limit configured.",
        "Even if the router would check the contracts current state first (performing read-only calls that can be done offline) to check if the transaction has a chance to succeed, it will still compete in a race for the current block (mempool)."
    ],
    "Examples": [
        "code/packages/router/src/handler.ts:L459-L477"
    ],
    "Recommendation": [
        "For state-changing transactions that actually cost gas there is no way around implementing strict validation whenever possible and avoid performing the transaction in case validation fails. Contract state should always be validated before issuing new online transactions but this might not fix the problem that routers still compete for their transaction to be included in the next block (mempool not monitored). The question therefore is, whether it would be better to change the metaTX flow to have a router confirm that they will send the tx via the messaging service first so others know they do not even have to try to send it. However, even this scenario may allow to DoS the system by maliciously responding with such a method.",
        "In general, there\u2019re a lot of ways to craft a message that forces the router to issue an on-chain transaction that may fail with no consequences for the sender of the metaTx message.",
        "Additionally, the relayerFee is currently unchecked which may lead to the router loosing funds because they effectively accept zero-fee relays.",
        "As noted in https://github.com/ConsenSys/connext-audit-2021-07/issues/3, the missing return after detecting that the metatx is destined for a TransactionManager that is not supported allows for explicit gas griefing attacks (deploy a fake TransactionManager.fulfill that mines all the gas for a beneficiary).",
        "The contract methods should additionally validate that the sender balance can cover for the gas required to send the transaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/router-subgraphloop-may-process-transactions-the-router-was-not-configured-for-code-fragility-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "allSenderPrepared = await sdk.GetSenderTransactions({\n  routerId: this.routerAddress.toLowerCase(),\n  sendingChainId: chainId,\n  status: TransactionStatus.Prepared,\n});\n\n",
        "// create list of txIds for each receiving chain\nconst receivingChains: Record<string, string[]> = {};\nallSenderPrepared.router?.transactions.forEach(({ transactionId, receivingChainId }) => {\n  if (receivingChains[receivingChainId]) {\n    receivingChains[receivingChainId].push(transactionId);\n  } else {\n    receivingChains[receivingChainId] = [transactionId];\n  }\n});\n\n",
        "let correspondingReceiverTxs: any[];\ntry {\n  const queries = await Promise.all(\n    Object.entries(receivingChains).map(async ([cId, txIds]) => {\n      const \\_sdk = this.sdks[Number(cId)];\n      if (!\\_sdk) {\n        this.logger.error({ chainId: cId, method, methodId }, \"No config for chain, this should not happen\");\n        return [];\n      }\n      const query = await \\_sdk.GetTransactions({ transactionIds: txIds.map((t) => t.toLowerCase()) });\n      return query.transactions;\n    }),\n  );\n  correspondingReceiverTxs = queries.flat();\n} catch (err) {\n\n"
    ],
    "preamble": [],
    "Description": [
        "subgraphLoop gets all sending transactions for the router, chain, status triplet.",
        "code/packages/router/src/subgraph.ts:L155-L159",
        "and then sorts the results by receiving chain id. Note that this keeps track of chainID\u2019s the router was not configured for.",
        "code/packages/router/src/subgraph.ts:L168-L176",
        "In a next step, transactions are resolved from the various chains. This filters out chainID\u2019s the router was not configured for (and just returns an empty array), however, the GetTransactions query assumes that transactionID\u2019s are unique across the subgraph which might not be true!",
        "code/packages/router/src/subgraph.ts:L179-L193",
        "In the last step, all chainID\u2019s (even the one\u2019s the router was not configured for) are iterated again (which might be unnecessary). TransactionID\u2019s are loosely matched from the previously flattened results from all the various chains. Since transactionID\u2019s don\u2019t necessarily need to be unique across chains or within the chain, it is likely that the subsequent matching of transactionID\u2019s (correspondingReceiverTxs.find) returns more than 1 entry. However, find() just returns the first item and covers up the fact that there might be multiple matches. Also, since the code returned an empty array for chains it was not configured for, the find will return undef satisfying the !corresponding branch and fire an SenderTransactionPrepared triggering the handler to perform an on-chain action that will most definitely fail at some point."
    ],
    "Recommendation": [
        "The code in this module is generally very fragile. It is based on assumptions that can likely be exploited by a third party re-using transactionID\u2019s (or other values). It is highly recommended to rework the code making it more resilient to potential corner cases.",
        "Also see issue 5.2"
    ]
}
----End JSON----

https://solodit.xyz/issues/router-handler-reports-an-error-condition-but-continues-execution-instead-of-aborting-it-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (utils.getAddress(data.to) !== utils.getAddress(chainConfig.transactionManagerAddress)) {\n  const err = new HandlerError(HandlerError.reasons.ConfigError, {\n    requestContext,\n    calling: \"chainConfig.transactionManagerAddress\",\n    methodId,\n    method,\n    configError: `Provided transactionManagerAddress does not map to our configured transactionManagerAddress`,\n  });\n  this.logger.error({ method, methodId, requestContext, err: err.toJson() }, \"Error in config\");\n}\n\n\n",
        "if (!chainConfig) {\n  const err = new HandlerError(HandlerError.reasons.ConfigError, {\n    requestContext,\n    calling: \"getConfig\",\n    methodId,\n    method,\n    configError: `No chainConfig for ${chainId}`,\n  });\n  this.logger.error({ method, methodId, requestContext, err: err.toJson() }, \"Error in config\");\n}\n\n",
        "if (data.type === \"Fulfill\") {\n\n"
    ],
    "preamble": [],
    "Description": [
        "There are some code paths that detect and log an error but then continue the execution flow instead of returning the error condition to the caller. This may allow for a variety of griefing vectors (e.g. gas griefing)."
    ],
    "Examples": [
        "code/packages/router/src/handler.ts:L448-L458",
        "code/packages/router/src/handler.ts:L436-L445",
        "code/packages/router/src/handler.ts:L447-L447"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/router-spawns-unauthenticated-admin-api-endpoint-listening-on-all-interfaces-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nserver.listen(8080, \"0.0.0.0\", (err, address) => {\n  if (err) {\n    console.error(err);\n    process.exit(1);\n  }\n  console.log(`Server listening at ${address}`);\n});\n\n"
    ],
    "preamble": [],
    "Description": [
        "pot. allows any local or remote unpriv user with access to the endpoint to steal the routers liquidity /remove-liquidity -> req.body.recipientAddress"
    ],
    "Examples": [
        "code/packages/router/src/index.ts:L123-L130"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/todo-comments-should-be-resolved-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "As part of the process of bringing the application to production readiness, dev comments (especially TODOs) should be resolved. In many cases, these comments indicate a missing functionality that should be implemented, or some missing necessary validation checks."
    ]
}
----End JSON----

https://solodit.xyz/issues/transactionmanager-missing-nonreentrant-modifier-on-removeliquidity-fixed-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice This is used by any router to decrease their available\n \\* liquidity for a given asset.\n \\* @param shares The amount of liquidity to remove for the router in shares\n \\* @param assetId The address (or `address(0)` if native asset) of the\n \\* asset you're removing liquidity for\n \\* @param recipient The address that will receive the liquidity being removed\n \\*/\nfunction removeLiquidity(\n  uint256 shares,\n  address assetId,\n  address payable recipient\n) external override {\n  // Sanity check: recipient is sensible\n  require(recipient != address(0), \"#RL:007\");\n\n  // Sanity check: nonzero shares\n  require(shares > 0, \"#RL:035\");\n\n  // Get stored router shares\n  uint256 routerShares = issuedShares[msg.sender][assetId];\n\n  // Get stored outstanding shares\n  uint256 outstanding = outstandingShares[assetId];\n\n  // Sanity check: owns enough shares\n  require(routerShares >= shares, \"#RL:018\");\n\n  // Convert shares to amount\n  uint256 amount = getAmountFromIssuedShares(\n    shares,\n    outstanding,\n    Asset.getOwnBalance(assetId)\n  );\n\n  // Update router issued shares\n  // NOTE: unchecked due to require above\n  unchecked {\n    issuedShares[msg.sender][assetId] = routerShares - shares;\n  }\n\n  // Update the total shares for asset\n  outstandingShares[assetId] = outstanding - shares;\n\n  // Transfer from contract to specified recipient\n  Asset.transferAsset(assetId, recipient, amount);\n\n  // Emit event\n  emit LiquidityRemoved(\n    msg.sender,\n    assetId,\n    shares,\n    amount,\n    recipient\n  );\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been fixed."
    ],
    "Description": [
        "The removeLiquidity function does not have a nonReentrant modifier.",
        "code/packages/contracts/contracts/TransactionManager.sol:L274-L329",
        "Assuming we\u2019re dealing with a token contract that allows execution of third-party-supplied code, that means it is possible to leave the TransactionManager contract in one of the functions that call into the token contract and then reenter via removeLiquidity. Alternatively, we can leave the contract in removeLiquidity and reenter through an arbitrary external function, even if it has a nonReentrant modifier."
    ],
    "Example": [
        "Assume a token contract allows the execution of third-party-supplied code in its transfer function before the actual balance change takes place. If a router calls removeLiquidity with half of their shares and then, in a reentering removeLiquidity call, supplies the other half of their shares, they will receive more tokens than if they had liquidated all their shares at once because the reentering call occurs after the (first half of the) shares have been burnt but before the corresponding amount of tokens has actually been transferred out of the contract, leading to an artificially increased share value in the reentering call.\nSimilarly, reentering the contract with a fulfill call on the receiving chain instead of a second removeLiquidity would transfer too many tokens to the recipient due to the artificially inflated share value."
    ],
    "Recommendation": [
        "While tokens that behave as described in the example might be rare or not exist at all, caution is advised when integrating with unknown tokens or calling untrusted code in general. We strongly recommend adding a nonReentrant modifier to removeLiquidity."
    ]
}
----End JSON----

https://solodit.xyz/issues/transactionmanager-relayer-may-use-users-cancel-after-expiry-signature-to-steal-users-funds-by-colluding-with-a-router-acknowledged-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "      require(msg.sender == txData.user || recoverSignature(txData.transactionId, relayerFee, \"cancel\", signature) == txData.user, \"#C:022\");\n\n      Asset.transferAsset(txData.sendingAssetId, payable(msg.sender), relayerFee);\n    }\n\n    // Get the amount to refund the user\n    uint256 toRefund;\n    unchecked {\n      toRefund = amount - relayerFee;\n    }\n\n    // Return locked funds to sending chain fallback\n    if (toRefund > 0) {\n      Asset.transferAsset(txData.sendingAssetId, payable(txData.sendingChainFallback), toRefund);\n    }\n  }\n\n} else {\n  // Receiver side, router liquidity is returned\n  if (txData.expiry >= block.timestamp) {\n    // Timeout has not expired and tx may only be cancelled by user\n    // Validate signature\n    require(msg.sender == txData.user || recoverSignature(txData.transactionId, relayerFee, \"cancel\", signature) == txData.user, \"#C:022\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This has been acknowledged by the Connext team. As discussed below in the \u201cRecommendation\u201d, it is not a flaw in the contracts per se but rather a high-risk situation caused by cancellation signatures working on both sender and receiver side.\nAs immediate mitigation, sender-side cancellation via signature has been removed completely. The \u201csignature rules\u201d explained below still apply and have to be followed."
    ],
    "Description": [
        "Users that are willing to have a lower trust dependency on a relayer should have the ability to opt-in only for the service that allows the relayer to withdraw back users\u2019 funds from the sending chain after expiry. However, in practice, a user is forced to opt-in for the service that refunds the router before the expiry, since the same signature is used for both services (lines 795,817 use the same signature).",
        "Let\u2019s consider the case of a user willing to call fulfill on his own, but to use the relayer only to withdraw back his funds from the sending chain after expiry. In this case, the relayer can collude with the router and use the user\u2019s cancel signature (meant for withdrawing his only after expiry) as a front-running transaction for a user call to fulfill. This way the router will be able to withdraw both his funds and the user\u2019s funds since the user\u2019s fulfill signature is now public data residing in the mem-pool."
    ],
    "Examples": [
        "code/packages/contracts/contracts/TransactionManager.sol:L795-L817"
    ],
    "Recommendation": [
        "The crucial point here is that the user must never sign a \u201ccancel\u201d that could be used on the receiving chain while fulfillment on the sending chain is still a possibility.",
        "Or, to put it differently: A user may only sign a \u201ccancel\u201d that is valid on the receiving chain after sending-chain expiry or if they never have and won\u2019t ever sign a \u201cfulfill\u201d (or at least won\u2019t sign until sending-chain expiry \u2014 but it is pointless to sign a \u201cfulfill\u201d after that, so \u201cnever\u201d is a reasonable simplification).",
        "Or, finally, a more symmetric perspective on this requirement: If a user has signed \u201cfulfill\u201d, they must not sign a receiving-chain-valid \u201ccancel\u201d until sending-chain expiry, and if they have signed a receiving-chain-valid \u201ccancel\u201d, they must not sign a \u201cfulfill\u201d (until sending-chain expiry).",
        "In this sense, \u201ccancel\u201d signatures that are valid on the receiving chain are dangerous, while sending-side cancellations are not. So the principle stated in the previous paragraph might be easier to follow with different signatures for sending- and receiving-chain cancellations."
    ]
}
----End JSON----

https://solodit.xyz/issues/router-handlesenderprepare-missing-validation-unchecked-bidexpiry-unchecked-expiry-unchecked-chainidsswaps-race-conidtions-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        ".andThen(() => {\n  // TODO: anything else? seems unnecessary to validate everything\n  if (!BigNumber.from(bid.amount).eq(amount) || bid.transactionId !== txData.transactionId) {\n    return err(\n      new HandlerError(HandlerError.reasons.PrepareValidationError, {\n        method,\n        methodId,\n        calling: \"\",\n        requestContext,\n        prepareError: \"Bid params not equal to tx data\",\n      }),\n    );\n  }\n  return ok(undefined);\n});\n\n",
        "// encode the data for contract call\n// Send to txService\nthis.receiverPreparing.set(txData.transactionId, true);\nthis.logger.info(\n  { method, methodId, requestContext, transactionId: txData.transactionId },\n  \"Sending receiver prepare tx\",\n);\n\n"
    ],
    "preamble": [],
    "Description": [
        "This finding highlights a collection of issues with the handleSenderPrepare method. The code and coding style appears fragile. Validation should be strictly enforced and protective measures against potential race conditions should be implemented.",
        "The following list highlights individual findings that contribute risk and therefore broaden the attack surface of this method:",
        "code/packages/router/src/handler.ts:L612-L626",
        "code/packages/router/src/handler.ts:L663-L669"
    ]
}
----End JSON----

https://solodit.xyz/issues/router-handlenewauction-fragile-code-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// validate that assets/chains are supported and there is enough liquidity\n// and gas on both sender and receiver side.\n// TODO: will need to track this offchain\nconst amountReceived = mutateAmount(amount);\n\n\n",
        "const config = getConfig();\nconst sendingConfig = config.chainConfig[sendingChainId];\nconst receivingConfig = config.chainConfig[receivingChainId];\n\n",
        "// validate config\nconst config = getConfig();\nconst sendingConfig = config.chainConfig[sendingChainId];\nconst receivingConfig = config.chainConfig[receivingChainId];\nif (\n  !sendingConfig.providers ||\n  sendingConfig.providers.length === 0 ||\n  !receivingConfig.providers ||\n  receivingConfig.providers.length === 0\n) {\n\n",
        ".andThen((balances) => {\n  const [senderBalance, receiverBalance] = balances as BigNumber[];\n  if (senderBalance.lt(sendingConfig.minGas) || receiverBalance.lt(receivingConfig.minGas)) {\n    return errAsync(\n\n",
        "dryRun,\n\n",
        "this.messagingService.publishAuctionResponse(inbox, { bid, bidSignature: dryRun ? undefined : bidSignature }),\n\n",
        "return combine([\n  ResultAsync.fromPromise(\n    this.txService.getBalance(sendingChainId, this.signer.address),\n    (err) =>\n      new HandlerError(HandlerError.reasons.TxServiceError, {\n        calling: \"txService.getBalance => sending\",\n        method,\n        methodId,\n        requestContext,\n        txServiceError: jsonifyError(err as NxtpError),\n      }),\n  ),\n  ResultAsync.fromPromise(\n    this.txService.getBalance(receivingChainId, this.signer.address),\n    (err) =>\n      new HandlerError(HandlerError.reasons.TxServiceError, {\n        calling: \"txService.getBalance => receiving\",\n        method,\n        methodId,\n        requestContext,\n        txServiceError: jsonifyError(err as NxtpError),\n      }),\n  ),\n\n"
    ],
    "preamble": [],
    "Description": [
        "This finding highlights a collection of issues with the handleNewAuction. The code and coding style appears fragile. Validation should be strictly enforced, debugging code should be removed or disabled in production and protective measures should be taken from abusive clients.",
        "The following list highlights individual findings that contribute risk and therefore broaden the attack surface of this method:",
        "code/packages/router/src/handler.ts:L197-L201",
        "code/packages/router/src/handler.ts:L202-L204",
        "code/packages/router/src/handler.ts:L231-L240",
        "code/packages/router/src/handler.ts:L315-L318",
        "code/packages/router/src/handler.ts:L194-L194",
        "code/packages/router/src/handler.ts:L385-L385",
        "code/packages/router/src/handler.ts:L290-L312"
    ]
}
----End JSON----

https://solodit.xyz/issues/router-cancel-is-not-implemented-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// TODO: this just cancels a transaction, it is misnamed, has nothing to do with expiries\npublic async cancelExpired(cancelParams: CancelParams, chainId: number): Promise<providers.TransactionResponse> {\n  const method = this.cancelExpired.name;\n  const methodId = getRandomBytes32();\n  this.logger.info({ method, methodId, cancelParams, chainId }, \"Method started\");\n  const cancelRes = await this.transactionManager.cancel(chainId, cancelParams);\n  if (cancelRes.isOk()) {\n    this.logger.info({ method, methodId }, \"Method complete\");\n    return cancelRes.value;\n  } else {\n    throw cancelRes.error;\n  }\n}\n\n",
        "  \"Do not cancel ATM, figure out why we are in this case first\",\n);\n// const cancelRes = await this.txManager.cancel(txData.sendingChainId, {\n// txData,\n// signature: \"0x\",\n// relayerFee: \"0\",\n// });\n// if (cancelRes.isOk()) {\n// this.logger.warn(\n// { method, methodId, transactionHash: cancelRes.value.transactionHash },\n// \"Cancelled transaction\",\n// );\n// } else {\n// this.logger.error({ method, methodId }, \"Could not cancel transaction after error!\");\n// }\n\n"
    ],
    "preamble": [],
    "Description": [
        "Canceling of failed/expired swaps does not seem to be implemented in the router. This may allow a user to trick the router into preparing all its funds which will not automatically be reclaimed after expiration (router DoS)."
    ],
    "Examples": [
        "code/packages/sdk/src/sdk.ts:L873-L885",
        "code/packages/router/src/handler.ts:L719-L733"
    ],
    "Recommendation": [
        "Implement the cancel flow."
    ]
}
----End JSON----

https://solodit.xyz/issues/transactionmanagerprepare-possible-griefingdenial-of-service-by-front-running-unverified-fix-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from Connext:",
        "Indeed, since the user has to sign messages, it has to be an EOA, and, consequently, the suggested solution would exclude contracts from calling prepare. A slight modification of the recommendation should work, though: Instead of checking msg.sender == invariantData.user, add a new member initiator (or msgSender or something similar) to the InvariantTransactionData struct, and check msg.sender == invariantData.initiator in the prepare function.\nThat would fix the issue and still allow prepare calls from a contract.",
        "The Connext team claims to have implemented this solution in commit 6811bb2681f44f34ce28906cb842db49fb73d797. We have not reviewed this commit or, generally, the codebase at this point."
    ],
    "Description": [
        "A call to TransactionManager.prepare might be front-run with a transaction using the same invariantData but with a different amount and/or expiry values. By choosing a tiny amount of assets, the attacker may prevent the user from locking his original desired amount. The attacker can repeat this process for any new transactionId presented by the user, thus effectively denying the service for him."
    ],
    "Recommendation": [
        "Consider adding a require(msg.sender == invariantData.user) restriction to TransactionManager.prepare."
    ]
}
----End JSON----

https://solodit.xyz/issues/router-provide-and-enforce-safe-defaults-config-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "export const TChainConfig = Type.Object({\n  providers: Type.Array(Type.String()),\n  confirmations: Type.Number({ minimum: 1 }),\n  subgraph: Type.String(),\n\n",
        "{\n  \"adminToken\": \"blahblah\",\n  \"chainConfig\": {\n    \"4\": {\n      \"providers\": [\"https://rinkeby.infura.io/v3/\"],\n      \"confirmations\": 1,\n      \"subgraph\": \"https://api.thegraph.com/subgraphs/name/connext/nxtp-rinkeby\"\n    },\n    \"5\": {\n      \"providers\": [\"https://goerli.infura.io/v3/\"],\n      \"confirmations\": 1,\n      \"subgraph\": \"https://api.thegraph.com/subgraphs/name/connext/nxtp-goerli\"\n    }\n  },\n  \"logLevel\": \"info\",\n  \"mnemonic\": \"candy maple cake sugar pudding cream honey rich smooth crumble sweet treat\"\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Chain confirmations default to 1 which is not safe. In case of a re-org the router might (temporarily) get out of sync with the chain and perform actions it should not perform. This may put funds at risk."
    ],
    "Examples": [
        "the schema requires an unsafe minimum of 1 confirmation",
        "code/packages/router/src/config.ts:L33-L36",
        "the default configuration uses 1 confirmation",
        "code/packages/router/config.json.example:L1-L17"
    ],
    "Recommendation": [
        "Give guidance, provide and enforce safe defaults."
    ]
}
----End JSON----

https://solodit.xyz/issues/proposedownable-two-step-ownership-transfer-should-be-confirmed-by-the-new-owner-fixed-consensys-connext-nxtp-noncustodial-xchain-transfer-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Transfers ownership of the contract to a new account (`newOwner`).\n \\* Can only be called by the current owner.\n \\*/\nfunction acceptProposedOwner() public virtual onlyOwner {\n  require((block.timestamp - \\_proposedTimestamp) > \\_delay, \"#APO:030\");\n  \\_setOwner(\\_proposed);\n}\n\n",
        "function renounced() public view override returns (bool) {\n  return owner() == address(0);\n}\n\n",
        "modifier onlyOwner() {\n    require(owner() == msg.sender, \"#OO:029\");\n    \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "All recommendations given below have been implemented. In addition to that, the privilege to manage assets and the privilege to manage routers can now be renounced separately."
    ],
    "Description": [
        "In order to avoid losing control of the contract, the two-step ownership transfer should be confirmed by the new owner\u2019s address instead of the current owner."
    ],
    "Examples": [
        "code/packages/contracts/contracts/ProposedOwnable.sol:L89-L96",
        "code/packages/contracts/contracts/TransactionManager.sol:L160-L162",
        "code/packages/contracts/contracts/ProposedOwnable.sol:L76-L79"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/tribalchief-a-wrong-userrewarddebt-value-is-calculated-during-the-withdrawfromdeposit-function-call-consensys-fei-tribechief-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint128 virtualAmountDelta = uint128( ( amount \\* poolDeposit.multiplier ) / SCALE\\_FACTOR );\n\n// Effects\npoolDeposit.amount -= amount;\nuser.rewardDebt = user.rewardDebt - toSigned128(user.virtualAmount \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\nuser.virtualAmount -= virtualAmountDelta;\npool.virtualTotalSupply -= virtualAmountDelta;\n\n"
    ],
    "preamble": [],
    "Description": [
        "When withdrawing a single deposit, the reward debt is updated:",
        "contracts/staking/TribalChief.sol:L468-L474",
        "Instead of the user.virtualAmount in reward debt calculation, the virtualAmountDelta  should be used.\nBecause of that bug, the reward debt is much lower than it would be, which means that the reward itself will be much larger during the harvest.\nBy making multiple deposit-withdraw actions, any user can steal all the Tribe tokens from the contract."
    ],
    "Recommendation": [
        "Use the virtualAmountDelta instead of the user.virtualAmount."
    ]
}
----End JSON----

https://solodit.xyz/issues/tribalchief-setting-the-totalallocpoint-to-zero-shouldnt-be-allowed-consensys-fei-tribechief-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "TribalChief.updatePool will revert in the case totalAllocPoint = 0, which will essentially cause users' funds and rewards to be locked."
    ],
    "Recommendation": [
        "TribalChief.add and TribalChief.set should assert that totalAllocPoint > 0. A similar validation check should be added to TribalChief.updatePool as well."
    ]
}
----End JSON----

https://solodit.xyz/issues/tribalchief-unlocking-users-funds-in-a-pool-where-a-multiplier-has-been-increased-is-missing-consensys-fei-tribechief-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function governorAddPoolMultiplier(\n    uint256 \\_pid,\n    uint64 lockLength,\n    uint64 newRewardsMultiplier\n) external onlyGovernor {\n    PoolInfo storage pool = poolInfo[\\_pid];\n    uint256 currentMultiplier = rewardMultipliers[\\_pid][lockLength];\n    // if the new multplier is less than the current multiplier,\n    // then, you need to unlock the pool to allow users to withdraw\n    if (newRewardsMultiplier < currentMultiplier) {\n        pool.unlocked = true;\n    }\n    rewardMultipliers[\\_pid][lockLength] = newRewardsMultiplier;\n\n    emit LogPoolMultiplier(\\_pid, lockLength, newRewardsMultiplier);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "When a user deposits funds to a pool, the current multiplier in use for this pool is being stored locally for this deposit. The value that is used later in a withdrawal operation is the local one, and not the one that is changing when a governor calls governorAddPoolMultiplier. It means that a decrease in the multiplier value for a given pool does not affect users that already deposited, but an increase does. Users that had already deposited should have the right to withdraw their funds when the multiplier for their pool increases by the governor."
    ],
    "Examples": [
        "code/contracts/staking/TribalChief.sol:L143-L158"
    ],
    "Recommendation": [
        "Replace the < operator with > in TribalChief line 152."
    ]
}
----End JSON----

https://solodit.xyz/issues/tribalchief-unsafe-down-castings-consensys-fei-tribechief-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "user.rewardDebt = int128(user.virtualAmount \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\n\n",
        "pool.accTribePerShare = uint128(pool.accTribePerShare + ((tribeReward \\* ACC\\_TRIBE\\_PRECISION) / virtualSupply));\n\n",
        "userPoolData.rewardDebt += int128(virtualAmountDelta \\* pool.accTribePerShare) / toSigned128(ACC\\_TRIBE\\_PRECISION);\n\n"
    ],
    "preamble": [],
    "Description": [
        "TribalChief consists of multiple unsafe down-casting operations. While the usage of types that can be packed into a single storage slot is more gas efficient, it may introduce hidden risks in some cases that can lead to loss of funds."
    ],
    "Examples": [
        "Various instances in TribalChief, including (but not necessarily only) :",
        "code/contracts/staking/TribalChief.sol:L429",
        "code/contracts/staking/TribalChief.sol:L326",
        "code/contracts/staking/TribalChief.sol:L358"
    ],
    "Recommendation": [
        "Given the time constraints of this audit engagement, we could not verify the implications and provide mitigation actions for each of the unsafe down-castings operations. However, we do recommend to either use numeric types that use 256 bits, or to add proper validation checks and handle these scenarios to avoid silent over/under-flow errors. Keep in mind that reverting these scenarios can sometimes lead to a denial of service, which might be harmful in some cases."
    ]
}
----End JSON----

https://solodit.xyz/issues/ethcompoundpcvdeposit-should-provide-means-to-recover-eth-consensys-fei-tribechief-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "EthCompoundPCVDeposit accepts ETH via receive(). Anyone can call EthCompoundPCVDeposit.deposit() to mint CToken for the contracts ETH balance.",
        "The CToken to be used is configured on EthCompoundPCVDeposit deployment. It is not checked, whether the provided CToken address is actually a valid CToken.",
        "If the configured CToken ceases to work correctly (e.g. CToken.mint|redeem* disabled or the configured CToken address is invalid), ETH held by the contract may be locked up."
    ],
    "Recommendation": [
        "Similar to EthLidoPCVDeposit add a method witdrawETH, access-restricted to onlyPCVController, that allows recovering ETH from the EthCompoundPCVDeposit contract in case the CToken contract throws. (Consider moving this functionality to PCVDeposit where withdrawERC20 is implemented to avoid having to implement this over and over again)",
        "In CompoundPCVDepositBase consider verifying, that the CToken constructor argument is actually a valid CToken by checking require(ctoken.isCToken(), \"not a valid CToken\")."
    ]
}
----End JSON----

https://solodit.xyz/issues/tribalchief-unlocking-users-funds-in-a-pool-where-a-multiplier-has-been-increased-is-missing-consensys-fei-tribechief-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function governorAddPoolMultiplier(\n uint256 \\_pid,\n uint64 lockLength,\n uint64 newRewardsMultiplier\n) external onlyGovernor {\n PoolInfo storage pool = poolInfo[\\_pid];\n uint256 currentMultiplier = rewardMultipliers[\\_pid][lockLength];\n // if the new multplier is less than the current multiplier,\n // then, you need to unlock the pool to allow users to withdraw\n if (newRewardsMultiplier < currentMultiplier) {\n pool.unlocked = true;\n }\n rewardMultipliers[\\_pid][lockLength] = newRewardsMultiplier;\n\n emit LogPoolMultiplier(\\_pid, lockLength, newRewardsMultiplier);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "When a user deposits funds to a pool, the current multiplier in use for this pool is being stored locally for this deposit. The value that is used later in a withdrawal operation is the local one, and not the one that is changing when a governor calls governorAddPoolMultiplier. It means that a decrease in the multiplier value for a given pool does not affect users that already deposited, but an increase does. Users that had already deposited should have the right to withdraw their funds when the multiplier for their pool increases by the governor."
    ],
    "Examples": [
        "code/contracts/staking/TribalChief.sol:L143-L158"
    ],
    "Recommendation": [
        "Replace the < operator with > in TribalChief line 152."
    ]
}
----End JSON----

https://solodit.xyz/issues/tribalchief-a-wrong-userrewarddebt-value-is-calculated-during-the-withdrawfromdeposit-function-call-consensys-none-fei-tribechief-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint128 virtualAmountDelta = uint128( ( amount * poolDeposit.multiplier ) / SCALE_FACTOR );\n\n// Effects\npoolDeposit.amount -= amount;\nuser.rewardDebt = user.rewardDebt - toSigned128(user.virtualAmount * pool.accTribePerShare) / toSigned128(ACC_TRIBE_PRECISION);\nuser.virtualAmount -= virtualAmountDelta;\npool.virtualTotalSupply -= virtualAmountDelta;\n\n"
    ],
    "preamble": [],
    "Description": [
        "When withdrawing a single deposit, the reward debt is updated:",
        "contracts/staking/TribalChief.sol:L468-L474",
        "Instead of the user.virtualAmount in reward debt calculation, the virtualAmountDelta  should be used.\nBecause of that bug, the reward debt is much lower than it would be, which means that the reward itself will be much larger during the harvest.\nBy making multiple deposit-withdraw actions, any user can steal all the Tribe tokens from the contract."
    ],
    "Recommendation": [
        "Use the virtualAmountDelta instead of the user.virtualAmount."
    ]
}
----End JSON----

https://solodit.xyz/issues/idlecdo_deposit-allows-re-entrancy-from-hookable-tokens-consensys-idle-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_deposit(uint256 \\_amount, address \\_tranche) internal returns (uint256 \\_minted) {\n  // check that we are not depositing more than the contract available limit\n  \\_guarded(\\_amount);\n  // set \\_lastCallerBlock hash\n  \\_updateCallerBlock();\n  // check if strategyPrice decreased\n  \\_checkDefault();\n  // interest accrued since last depositXX/withdrawXX/harvest is splitted between AA and BB\n  // according to trancheAPRSplitRatio. NAVs of AA and BB are updated and tranche\n  // prices adjusted accordingly\n  \\_updateAccounting();\n  // mint tranche tokens according to the current tranche price\n  \\_minted = \\_mintShares(\\_amount, msg.sender, \\_tranche);\n  // get underlyings from sender\n  IERC20Detailed(token).safeTransferFrom(msg.sender, address(this), \\_amount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The development team has addressed this concern in commit 5fbdc0506c94a172abbd4122276ed2bd489d1964. This change has not been reviewed by the audit team."
    ],
    "Description": [
        "The function IdleCDO._deposit() updates the system\u2019s internal accounting and mints shares to the caller, then transfers the deposited funds from the user. Some token standards, such as ERC777, allow a callback to the source of the funds before the balances are updated in transferFrom(). This callback could be used to re-enter the protocol while already holding the minted tranche tokens and at a point where the system accounting reflects a receipt of funds that has not yet occurred.",
        "While an attacker could not interact with IdleCDO.withdraw() within this callback because of the _checkSameTx() restriction, they would be able to interact with the rest of the protocol.",
        "code/contracts/IdleCDO.sol:L230-L245"
    ],
    "Recommendation": [
        "Move the transferFrom() action in _deposit() to immediately after _updateCallerBlock()."
    ]
}
----End JSON----

https://solodit.xyz/issues/idlecdovirtualprice-and-_updateprices-yield-different-prices-in-a-number-of-cases-consensys-idle-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (BBTotSupply == 0) {\n  // if there are no BB holders, all gain to AA\n  AAGain = gain;\n} else if (AATotSupply == 0) {\n  // if there are no AA holders, all gain to BB\n  BBGain = gain;\n} else {\n  // split the gain between AA and BB holders according to trancheAPRSplitRatio\n  AAGain = gain \\* trancheAPRSplitRatio / FULL\\_ALLOC;\n  BBGain = gain - AAGain;\n}\n\n",
        "if (\\_tranche == AATranche) {\n  // calculate gain for AA tranche\n  // trancheGain (AAGain) = gain \\* trancheAPRSplitRatio / FULL\\_ALLOC;\n  trancheNAV = lastNAVAA + (gain \\* \\_trancheAPRSplitRatio / FULL\\_ALLOC);\n} else {\n  // calculate gain for BB tranche\n  // trancheGain (BBGain) = gain \\* (FULL\\_ALLOC - trancheAPRSplitRatio) / FULL\\_ALLOC;\n  trancheNAV = lastNAVBB + (gain \\* (FULL\\_ALLOC - \\_trancheAPRSplitRatio) / FULL\\_ALLOC);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The development team implemented a new version of both functions using a third method, virtualPricesAux(), to perform the primary price calculation. Additionally, _updatePrices() was renamed to _updateAccounting().",
        "This change was incorporated in commit ff0b69380828657f16df8683c35703b325a6b656."
    ],
    "Description": [
        "The function IdleCDO.virtualPrice() is used to determine the current price of a tranche. Similarly, IdleCDO._updatePrices() is used to store the latest price of a tranche, as well as update other parts of the system accounting. There are a number of cases where the prices yielded by these two functions differ. While these are primarily corner cases that are not obviously exploitable in practice, potential violations of key accounting invariants should always be considered serious.",
        "Additionally, the use of two separate implementations of the same calculation suggest the potential for more undiscovered discrepancies, possibly of higher consequence.",
        "As an example, in _updatePrices() the precision loss from splitting the strategy returns favors BB tranche holders. In virtualPrice() both branches of the price calculation incur precision loss, favoring the IdleCDO contract itself."
    ],
    "_updatePrices()": [
        "code/contracts/IdleCDO.sol:L331-L341"
    ],
    "virtualPrice()": [
        "code/contracts/IdleCDO.sol:L237-L245"
    ],
    "Recommendation": [
        "Implement a single method that determines the current price for a tranche, and use this same implementation anywhere the price is needed."
    ]
}
----End JSON----

https://solodit.xyz/issues/idlecdoharvest-allows-price-manipulation-in-certain-circumstances-consensys-idle-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function harvest(bool \\_skipRedeem, bool \\_skipIncentivesUpdate, bool[] calldata \\_skipReward, uint256[] calldata \\_minAmount) external {\n  require(msg.sender == rebalancer || msg.sender == owner(), \"IDLE:!AUTH\");\n\n",
        "// approve the uniswap router to spend our reward\nIERC20Detailed(rewardToken).safeIncreaseAllowance(address(\\_uniRouter), \\_currentBalance);\n// do the uniswap trade\n\\_uniRouter.swapExactTokensForTokensSupportingFeeOnTransferTokens(\n  \\_currentBalance,\n  \\_minAmount[i],\n  \\_path,\n  address(this),\n  block.timestamp + 1\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The development team has addressed this concern in a pull request with a final commit hash of 5341a9391f9c42cadf26d72c9f804ca75a15f0fb. This change has not been reviewed by the audit team."
    ],
    "Description": [
        "The function IdleCDO.harvest() uses Uniswap to liquidate rewards earned by the contract\u2019s strategy, then updates the relevant positions and internal accounting. This function can only be called by the contract owner or the designated rebalancer address, and it accepts an array which indicates the minimum buy amounts for the liquidation of each reward token.",
        "The purpose of permissioning this method and specifying minimum buy amounts is to prevent a sandwiching attack from manipulating the reserves of the Uniswap pools and forcing the IdleCDO contract to incur loss due to price slippage.",
        "However, this does not effectively prevent price manipulation in all cases. Because the contract sells it\u2019s entire balance of redeemed rewards for the specified minimum buy amount, this approach does not enforce a minimum price for the executed trades. If the balance of IdleCDO or the amount of claimable rewards increases between the submission of the harvest() transaction and its execution, it may be possible to perform a profitable sandwiching attack while still satisfying the required minimum buy amounts.",
        "The viability of this exploit depends on how effectively an attacker can increase the amount of rewards tokens to be sold without incurring an offsetting loss. The strategy contracts used by IdleCDO are expected to vary widely in their implementations, and this manipulation could potentially be done either through direct interaction with the protocol or as part of a flashbots bundle containing a large position adjustment from an honest user.",
        "code/contracts/IdleCDO.sol:L564-L565",
        "code/contracts/IdleCDO.sol:L590-L599"
    ],
    "Recommendation": [
        "Update IdleCDO.harvest() to enforce a minimum price rather than a minimum buy amount. One method of doing so would be taking an additional array parameter indicating the amount of each token to sell in exchange for the respective buy amount."
    ]
}
----End JSON----

https://solodit.xyz/issues/frontrunning-attacks-by-the-owner-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 constant MAXIMUM\\_DEPOSIT\\_FEE = 5e16; // 5%\nuint256 constant DEFAULT\\_DEPOSIT\\_FEE = 0e16; // 0%\n  \nuint256 constant MAXIMUM\\_PERFORMANCE\\_FEE = 50e16; // 50%\nuint256 constant DEFAULT\\_PERFORMANCE\\_FEE = 10e16; // 10%\n\n",
        "function gulp(uint256 \\_minRewardAmount) external onlyEOAorWhitelist nonReentrant\n{\n  uint256 \\_pendingReward = \\_getPendingReward();\n  if (\\_pendingReward > 0) {\n      \\_withdraw(0);\n  }\n  {\n      uint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\n      uint256 \\_feeReward = \\_totalReward.mul(performanceFee) / 1e18;\n      Transfers.\\_pushFunds(rewardToken, collector, \\_feeReward);\n  }\n  if (rewardToken != routingToken) {\n      require(exchange != address(0), \"exchange not set\");\n      uint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\n      Transfers.\\_approveFunds(rewardToken, exchange, \\_totalReward);\n      IExchange(exchange).convertFundsFromInput(rewardToken, routingToken, \\_totalReward, 1);\n  }\n  if (routingToken != reserveToken) {\n      require(exchange != address(0), \"exchange not set\");\n      uint256 \\_totalRouting = Transfers.\\_getBalance(routingToken);\n      Transfers.\\_approveFunds(routingToken, exchange, \\_totalRouting);\n      IExchange(exchange).joinPoolFromInput(reserveToken, routingToken, \\_totalRouting, 1);\n  }\n  uint256 \\_totalBalance = Transfers.\\_getBalance(reserveToken);\n  require(\\_totalBalance >= \\_minRewardAmount, \"high slippage\");\n  \\_deposit(\\_totalBalance);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "There are few possible attack vectors by the owner:",
        "wheat-v1-core-audit/contracts/PancakeSwapCompoundingStrategyToken.sol:L29-L33",
        "When a user deposits tokens, expecting to have zero deposit fees, the owner can frontrun the deposit and increase fees to 5%. If the deposit size is big enough, that may be a significant amount of money.\n2. In the gulp function, the reward tokens are exchanged for the reserve tokens on the exchange:",
        "wheat-v1-core-audit/contracts/PancakeSwapCompoundingStrategyToken.sol:L218-L244",
        "The owner can change the exchange parameter to the malicious address that steals tokens. The owner then calls gulp with _minRewardAmount==0, and all the rewards will be stolen. The same attack can be implemented in fee collectors and the buyback contract."
    ],
    "Recommendation": [
        "Use a timelock to avoid instant changes of the parameters."
    ]
}
----End JSON----

https://solodit.xyz/issues/new-deposits-are-instantly-getting-a-share-of-undistributed-rewards-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "When a new deposit is happening, the current pending rewards are not withdrawn and re-invested yet. And they are not taken into account when calculating the number of shares that the depositor receives. The number of shares is calculated as if there were no pending rewards.\nThe other side of this issue is that all the withdrawals are also happening without considering the pending rewards. So currently, it makes more sense to withdraw right after gulp to gather the rewards.\nIn addition to the general \u201cunfairness\u201d of the reward distribution during the deposit/withdrawal, there is also an attack vector created by this issue.",
        "The Attack",
        "If the deposit is made right before the gulp function is called, the rewards from the gulp are distributed evenly across all the current deposits, including the ones that were just recently made. So if the deposit-gulp-withdraw sequence is executed, the caller receives guaranteed profit. If the attacker also can execute these functions briefly (in one block or transaction) and take a huge loan to deposit a lot of tokens, almost all the rewards from the gulp will be stolen by the attacker.\nThe easy 1-transaction attack with a flashloan can be done by the owner, miner, whitelisted contracts, or any contract if the onlyEOAorWhitelist modifier is disabled or stops working (https://github.com/ConsenSys/growthdefi-audit-2021-06/issues/3). Even if onlyEOAorWhitelist is working properly, anyone can take a regular loan to make the attack. The risk is not that big because no price manipulation is required. The price will likely remain the same during the attack (few blocks maximum)."
    ],
    "Recommendation": [
        "If issue issue 6.3 is fixed while allowing anyone call the gulp contract, the best solution would be to include the gulp call at the beginning of the deposit and withdraw. In case of withdrawing, there should also be an option to avoid calling gulp as the emergency case."
    ]
}
----End JSON----

https://solodit.xyz/issues/proactive-sandwiching-of-the-gulp-calls-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "Each strategy token contract provides a gulp method to fetch pending rewards, convert them into the reserve token and split up the balances. One share is sent to the fee collector as a performance fee, while the rest is deposited into the respective MasterChef contract to accumulate more rewards. Suboptimal trades are prevented by passing a minimum slippage value with the function call, which results in revert if the expected reserve token amount cannot be provided by the trade(s).",
        "The slippage parameter and the trades performed in gulp open the function up to proactive sandwich attacks. The slippage parameter can be freely set by the attacker, resulting in the system performing arbitrarily bad trades based on how much the attacker can manipulate the liquidity of involved assets around the gulp function call.",
        "This attack vector is significant under the following assumptions:"
    ],
    "Examples": [
        "This affects the gulp functions in all the strategies:",
        "and also fees collectors and the buyback adapters:"
    ],
    "Recommendation": [
        "There are different possible solutions to this issue and all have some tradeoffs. Initially, we came up with the following suggestion:",
        "But in order to fix another issue (https://github.com/ConsenSys/growthdefi-audit-2021-06/issues/8), we came up with the alternative solution:"
    ]
}
----End JSON----

https://solodit.xyz/issues/expected-amounts-of-tokens-in-the-withdraw-function-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdraw(uint256 \\_shares, uint256 \\_minAmount) external onlyEOAorWhitelist nonReentrant\n{\n\taddress \\_from = msg.sender;\n\t(uint256 \\_amount, uint256 \\_withdrawalAmount, uint256 \\_netAmount) = \\_calcAmountFromShares(\\_shares);\n\trequire(\\_netAmount >= \\_minAmount, \"high slippage\");\n\t\\_burn(\\_from, \\_shares);\n\t\\_withdraw(\\_amount);\n\tTransfers.\\_pushFunds(reserveToken, \\_from, \\_withdrawalAmount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Client\u2019s statement : \u201cThis issue did not really need fixing. The mitigation was already in place by depositing a tiny amount of the reserve into the contract, if necessary\u201d"
    ],
    "Description": [
        "Every withdraw function in the strategy contracts is calculating the expected amount of the returned tokens before withdrawing them:",
        "wheat-v1-core-audit/contracts/PantherSwapCompoundingStrategyToken.sol:L200-L208",
        "After that, the contract is trying to transfer this pre-calculated amount to the msg.sender. It is never checked whether the intended amount was actually transferred to the strategy contract. If the amount is lower, that may result in reverting the withdraw function all the time and locking up tokens.",
        "Even though we did not find any specific case of returning a different amount of tokens, it is still a good idea to handle this situation to minimize relying on the security of the external contracts."
    ],
    "Recommendation": [
        "There are a few options how to mitigate the issue:"
    ]
}
----End JSON----

https://solodit.xyz/issues/emergency-mode-of-the-masterchef-contracts-is-not-supported-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    // Withdraw without caring about rewards. EMERGENCY ONLY.\n    function emergencyWithdraw(uint256 \\_pid) public nonReentrant {\n        PoolInfo storage pool = poolInfo[\\_pid];\n        UserInfo storage user = userInfo[\\_pid][msg.sender];\n        uint256 amount = user.amount;\n        user.amount = 0;\n        user.rewardDebt = 0;\n        user.rewardLockedUp = 0;\n        user.nextHarvestUntil = 0;\n        pool.lpToken.safeTransfer(address(msg.sender), amount);\n        emit EmergencyWithdraw(msg.sender, \\_pid, amount);\n    }\n\n",
        "    // Withdraw without caring about rewards. EMERGENCY ONLY.\n    function emergencyWithdraw(uint256 \\_pid) public {\n        PoolInfo storage pool = poolInfo[\\_pid];\n        UserInfo storage user = userInfo[\\_pid][msg.sender];\n        pool.lpToken.safeTransfer(address(msg.sender), user.amount);\n        emit EmergencyWithdraw(msg.sender, \\_pid, user.amount);\n        user.amount = 0;\n        user.rewardDebt = 0;\n    }\n\n",
        "    // Withdraw without caring about rewards. EMERGENCY ONLY.\n    function emergencyWithdraw(uint256 \\_pid) public nonReentrant {\n        PoolInfo storage pool = poolInfo[\\_pid];\n        UserInfo storage user = userInfo[\\_pid][msg.sender];\n\n        uint256 wantLockedTotal =\n            IStrategy(poolInfo[\\_pid].strat).wantLockedTotal();\n        uint256 sharesTotal = IStrategy(poolInfo[\\_pid].strat).sharesTotal();\n        uint256 amount = user.shares.mul(wantLockedTotal).div(sharesTotal);\n\n        IStrategy(poolInfo[\\_pid].strat).withdraw(msg.sender, amount);\n\n        pool.want.safeTransfer(address(msg.sender), amount);\n        emit EmergencyWithdraw(msg.sender, \\_pid, amount);\n        user.shares = 0;\n        user.rewardDebt = 0;\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "All the underlying MasterChef contracts have the emergency withdrawal mode, which allows simpler withdrawal (excluding the rewards):",
        "While it\u2019s hard to predict how and why the emergency mode can be enabled in the underlying MasterChef contracts, these functions are there for a reason, and it\u2019s safer to be able to use them. If some emergency happens and this is the only way to withdraw funds, the funds in the strategy contracts will be locked forever."
    ],
    "Recommendation": [
        "Add the emergency mode implementation."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-capping-mechanism-for-panther-token-leads-to-increased-fees-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function gulp(uint256 \\_minRewardAmount) external onlyEOAorWhitelist nonReentrant\n{\n\tuint256 \\_pendingReward = \\_getPendingReward();\n\tif (\\_pendingReward > 0) {\n\t\t\\_withdraw(0);\n\t}\n\tuint256 \\_\\_totalReward = Transfers.\\_getBalance(rewardToken);\n\t(uint256 \\_feeReward, uint256 \\_retainedReward) = \\_capFeeAmount(\\_\\_totalReward.mul(performanceFee) / 1e18);\n\tTransfers.\\_pushFunds(rewardToken, buyback, \\_feeReward);\n\tif (rewardToken != routingToken) {\n\t\trequire(exchange != address(0), \"exchange not set\");\n\t\tuint256 \\_totalReward = Transfers.\\_getBalance(rewardToken);\n\t\t\\_totalReward = \\_capTransferAmount(rewardToken, \\_totalReward, \\_retainedReward);\n\t\tTransfers.\\_approveFunds(rewardToken, exchange, \\_totalReward);\n\t\tIExchange(exchange).convertFundsFromInput(rewardToken, routingToken, \\_totalReward, 1);\n\t}\n\tif (routingToken != reserveToken) {\n\t\trequire(exchange != address(0), \"exchange not set\");\n\t\tuint256 \\_totalRouting = Transfers.\\_getBalance(routingToken);\n\t\t\\_totalRouting = \\_capTransferAmount(routingToken, \\_totalRouting, \\_retainedReward);\n\t\tTransfers.\\_approveFunds(routingToken, exchange, \\_totalRouting);\n\t\tIExchange(exchange).joinPoolFromInput(reserveToken, routingToken, \\_totalRouting, 1);\n\t}\n\tuint256 \\_totalBalance = Transfers.\\_getBalance(reserveToken);\n\t\\_totalBalance = \\_capTransferAmount(reserveToken, \\_totalBalance, \\_retainedReward);\n\trequire(\\_totalBalance >= \\_minRewardAmount, \"high slippage\");\n\t\\_deposit(\\_totalBalance);\n}\n\n",
        "(uint256 \\_feeReward, uint256 \\_retainedReward) = \\_capFeeAmount(\\_\\_totalReward.mul(performanceFee) / 1e18);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "Panther token has a cap in transfer sizes, so any transfer in the contract is limited beforehand:",
        "wheat-v1-core-audit/contracts/PantherSwapCompoundingStrategyToken.sol:L218-L245",
        "Fees here are calculated from the full amount of rewards (__totalReward ):",
        "wheat-v1-core-audit/contracts/PantherSwapCompoundingStrategyToken.sol:L225",
        "But in fact, if the amount of the rewards is too big, it will be capped, and the residuals will be \u201ctaxed\u201d again during the next call of the gulp function. That behavior leads to multiple taxations of the same tokens, which means increased fees."
    ],
    "Recommendation": [
        "The best solution would be to cap __totalReward  first and then calculate fees from the capped value."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-_capfeeamount-function-is-not-working-as-intended-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_capFeeAmount(uint256 \\_amount) internal view returns (uint256 \\_capped, uint256 \\_retained)\n{\n\t\\_retained = 0;\n\tuint256 \\_limit = \\_calcMaxRewardTransferAmount();\n\tif (\\_amount > \\_limit) {\n\t\t\\_amount = \\_limit;\n\t\t\\_retained = \\_amount.sub(\\_limit);\n\t}\n\treturn (\\_amount, \\_retained);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Client\u2019s statement : \u201cWith the fix of 6.6 this code was removed and therefore no changes were required.\n\""
    ],
    "Description": [
        "Panther token has a limit on the transfer size. Because of that, all the Panther transfer values in the PantherSwapCompoundingStrategyToken are also capped beforehand. The following function is called to cap the size of fees:",
        "wheat-v1-core-audit/contracts/PantherSwapCompoundingStrategyToken.sol:L357-L366",
        "This function should return the capped amount and the amount of retained tokens. But because the _amount is changed before calculating the _retained, the retained amount will always be 0."
    ],
    "Recommendation": [
        "Calculate the retained value before changing the amount."
    ]
}
----End JSON----

https://solodit.xyz/issues/stale-split-ratios-in-universalbuyback-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 \\_amount1 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK1\\_SHARE) / 1e18;\nuint256 \\_amount2 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK2\\_SHARE) / 1e18;\n\n",
        "uint256 \\_amount1 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK1\\_SHARE) / 1e18;\nuint256 \\_amount2 = \\_balance.mul(DEFAULT\\_REWARD\\_BUYBACK2\\_SHARE) / 1e18;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "The gulp and pendingBurning functions of the UniversalBuyback contract use the hardcoded, constant values of DEFAULT_REWARD_BUYBACK1_SHARE and DEFAULT_REWARD_BUYBACK2_SHARE to determine the ratio the trade value is split with.",
        "Consequently, any call to setRewardSplit to set a new ratio will be ineffective but still result in a ChangeRewardSplit event being emitted. This event can deceive system operators and users as it does not reflect the correct values of the contract."
    ],
    "Examples": [
        "wheat-v1-core-audit/contracts/UniversalBuyback.sol:L80-L81",
        "wheat-v1-core-audit/contracts/UniversalBuyback.sol:L97-L98"
    ],
    "Recommendation": [
        "Instead of the default values, rewardBuyback1Share and rewardBuyback2Share should be used."
    ]
}
----End JSON----

https://solodit.xyz/issues/future-proofness-of-the-onlyeoaorwhitelist-modifier-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "**wheat-v1-core-audit/contracts/WhitelistGuard.sol:L21-L28**\n```solidity\nmodifier onlyEOAorWhitelist()\n{\n  if (enabled) {\n      address _from = _msgSender();\n      require(tx.origin == _from || whitelist.contains(_from), \"access denied\");\n  }\n  _;\n}\n",
        "\nAnd in the deployment script, this modifier is disabled for testing purposes, and it\u2019s important not to forget to turn it in on the production:\n\n\n**wheat-v1-core-audit/migrations/02\\_deploy\\_contracts.js:L50**\n\n\n\n",
        "* The attack can usually be split into multiple transactions. Miners can put these transactions closely together and don\u2019t take any additional risk. Regular users can take a risk, take the loan, and execute the attack in multiple transactions or even blocks.\n\n\n#### Recommendation\n\n\nIt is strongly recommended to monitor the progress of this EIP and its potential implementation on the Binance Smart Chain. If this functionality gets enabled, the development team should update the contract system to use the new opcodes.\nWe also strongly recommend relying less on the fact that only EOA will call the functions. It is better to write the code that can be called by the external smart contracts without compromising its security.\n\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "The onlyEOAorWhitelist modifier is used in various locations throughout the code. It performs a check that asserts the message sender being equal to the transaction origin to assert the calling party is not a smart contract.",
        "This approach may stop working if EIP-3074 and its AUTH and AUTHCALL opcodes get deployed.",
        "While the OpenZeppelin reentrancy guard does not depend on tx.origin, the EOA check does. Its evasion can result in additional attack vectors such as flash loans opening up. It is noteworthy that preventing smart contract interaction with the protocol may limit its opportunities as smart contracts cannot integrate with it in the same way that GrowthDeFi integrates with its third-party service providers.",
        "The onlyEOAorWhitelist modifier may give a false sense of security because it won\u2019t allow making a flash loan attack by most of the users. But the same attack can still be made by some people or with more risk:",
        "await pancakeSwapFeeCollector.setWhitelistEnabled(false); // allows testing"
    ]
}
----End JSON----

https://solodit.xyz/issues/exchange-owner-might-steal-users-funds-using-reentrancy-consensys-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function convertFundsFromInput(address \\_from, address \\_to, uint256 \\_inputAmount, uint256 \\_minOutputAmount) external override returns (uint256 \\_outputAmount)\n{\n\taddress \\_sender = msg.sender;\n\tTransfers.\\_pullFunds(\\_from, \\_sender, \\_inputAmount);\n\t\\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\n\t\\_outputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromInput(router, \\_from, \\_to, \\_inputAmount, \\_minOutputAmount);\n\t\\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\n\tTransfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\n\treturn \\_outputAmount;\n}\n\n",
        "function joinPoolFromInput(address \\_pool, address \\_token, uint256 \\_inputAmount, uint256 \\_minOutputShares) external override returns (uint256 \\_outputShares)\n{\n\taddress \\_sender = msg.sender;\n\tTransfers.\\_pullFunds(\\_token, \\_sender, \\_inputAmount);\n\t\\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_token)); // deals with potential transfer tax\n\t\\_outputShares = UniswapV2LiquidityPoolAbstraction.\\_joinPoolFromInput(router, \\_pool, \\_token, \\_inputAmount, \\_minOutputShares);\n\t\\_outputShares = Math.\\_min(\\_outputShares, Transfers.\\_getBalance(\\_pool)); // deals with potential transfer tax\n\tTransfers.\\_pushFunds(\\_pool, \\_sender, \\_outputShares);\n\treturn \\_outputShares;\n}\n\n",
        "function convertFundsFromOutput(address \\_from, address \\_to, uint256 \\_outputAmount, uint256 \\_maxInputAmount) external override returns (uint256 \\_inputAmount)\n{\n\taddress \\_sender = msg.sender;\n\tTransfers.\\_pullFunds(\\_from, \\_sender, \\_maxInputAmount);\n\t\\_maxInputAmount = Math.\\_min(\\_maxInputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\n\t\\_inputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromOutput(router, \\_from, \\_to, \\_outputAmount, \\_maxInputAmount);\n\tuint256 \\_refundAmount = \\_maxInputAmount - \\_inputAmount;\n\t\\_refundAmount = Math.\\_min(\\_refundAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\n\tTransfers.\\_pushFunds(\\_from, \\_sender, \\_refundAmount);\n\t\\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\n\tTransfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\n\treturn \\_inputAmount;\n}\n\n",
        "function recoverLostFunds(address \\_token) external onlyOwner\n{\n\tuint256 \\_balance = Transfers.\\_getBalance(\\_token);\n\tTransfers.\\_pushFunds(\\_token, treasury, \\_balance);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "The practice of pulling funds from a user (by using safeTransferFrom) and then later pushing (some) of the funds back to the user occurs in various places in the Exchange contract. In case one of the used token contracts (or one of its dependent calls) externally calls the Exchange owner, the owner may utilize that to call back Exchange.recoverLostFunds and drain (some) user funds."
    ],
    "Examples": [
        "wheat-v1-core-audit/contracts/Exchange.sol:L80-L89",
        "wheat-v1-core-audit/contracts/Exchange.sol:L121-L130",
        "wheat-v1-core-audit/contracts/Exchange.sol:L99-L111",
        "wheat-v1-core-audit/contracts/Exchange.sol:L139-L143"
    ],
    "Recommendation": [
        "Reentrancy guard protection should be added to Exchange.convertFundsFromInput, Exchange.convertFundsFromOutput, Exchange.joinPoolFromInput, Exchange.recoverLostFunds at least, and in general to all public/external functions since gas price considerations are less relevant for contracts deployed on BSC."
    ]
}
----End JSON----

https://solodit.xyz/issues/exchange-owner-might-steal-users-funds-using-reentrancy-consensys-growthdefi-wheat-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function convertFundsFromInput(address \\_from, address \\_to, uint256 \\_inputAmount, uint256 \\_minOutputAmount) external override returns (uint256 \\_outputAmount)\n{\n address \\_sender = msg.sender;\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_inputAmount);\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\n \\_outputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromInput(router, \\_from, \\_to, \\_inputAmount, \\_minOutputAmount);\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\n return \\_outputAmount;\n}\n\n",
        "function joinPoolFromInput(address \\_pool, address \\_token, uint256 \\_inputAmount, uint256 \\_minOutputShares) external override returns (uint256 \\_outputShares)\n{\n address \\_sender = msg.sender;\n Transfers.\\_pullFunds(\\_token, \\_sender, \\_inputAmount);\n \\_inputAmount = Math.\\_min(\\_inputAmount, Transfers.\\_getBalance(\\_token)); // deals with potential transfer tax\n \\_outputShares = UniswapV2LiquidityPoolAbstraction.\\_joinPoolFromInput(router, \\_pool, \\_token, \\_inputAmount, \\_minOutputShares);\n \\_outputShares = Math.\\_min(\\_outputShares, Transfers.\\_getBalance(\\_pool)); // deals with potential transfer tax\n Transfers.\\_pushFunds(\\_pool, \\_sender, \\_outputShares);\n return \\_outputShares;\n}\n\n",
        "function convertFundsFromOutput(address \\_from, address \\_to, uint256 \\_outputAmount, uint256 \\_maxInputAmount) external override returns (uint256 \\_inputAmount)\n{\n address \\_sender = msg.sender;\n Transfers.\\_pullFunds(\\_from, \\_sender, \\_maxInputAmount);\n \\_maxInputAmount = Math.\\_min(\\_maxInputAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\n \\_inputAmount = UniswapV2ExchangeAbstraction.\\_convertFundsFromOutput(router, \\_from, \\_to, \\_outputAmount, \\_maxInputAmount);\n uint256 \\_refundAmount = \\_maxInputAmount - \\_inputAmount;\n \\_refundAmount = Math.\\_min(\\_refundAmount, Transfers.\\_getBalance(\\_from)); // deals with potential transfer tax\n Transfers.\\_pushFunds(\\_from, \\_sender, \\_refundAmount);\n \\_outputAmount = Math.\\_min(\\_outputAmount, Transfers.\\_getBalance(\\_to)); // deals with potential transfer tax\n Transfers.\\_pushFunds(\\_to, \\_sender, \\_outputAmount);\n return \\_inputAmount;\n}\n\n",
        "function recoverLostFunds(address \\_token) external onlyOwner\n{\n uint256 \\_balance = Transfers.\\_getBalance(\\_token);\n Transfers.\\_pushFunds(\\_token, treasury, \\_balance);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client communicated this issue was addressed in commit 34c6b355795027d27ae6add7360e61eb6b01b91b."
    ],
    "Description": [
        "The practice of pulling funds from a user (by using safeTransferFrom) and then later pushing (some) of the funds back to the user occurs in various places in the Exchange contract. In case one of the used token contracts (or one of its dependent calls) externally calls the Exchange owner, the owner may utilize that to call back Exchange.recoverLostFunds and drain (some) user funds."
    ],
    "Examples": [
        "wheat-v1-core-audit/contracts/Exchange.sol:L80-L89",
        "wheat-v1-core-audit/contracts/Exchange.sol:L121-L130",
        "wheat-v1-core-audit/contracts/Exchange.sol:L99-L111",
        "wheat-v1-core-audit/contracts/Exchange.sol:L139-L143"
    ],
    "Recommendation": [
        "Reentrancy guard protection should be added to Exchange.convertFundsFromInput, Exchange.convertFundsFromOutput, Exchange.joinPoolFromInput, Exchange.recoverLostFunds at least, and in general to all public/external functions since gas price considerations are less relevant for contracts deployed on BSC."
    ]
}
----End JSON----

https://solodit.xyz/issues/expected-amounts-of-tokens-in-the-withdraw-function-consensys-none-growthdefi-wheat-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdraw(uint256 _shares, uint256 _minAmount) external onlyEOAorWhitelist nonReentrant\n{\n\taddress _from = msg.sender;\n\t(uint256 _amount, uint256 _withdrawalAmount, uint256 _netAmount) = _calcAmountFromShares(_shares);\n\trequire(_netAmount >= _minAmount, \"high slippage\");\n\t_burn(_from, _shares);\n\t_withdraw(_amount);\n\tTransfers._pushFunds(reserveToken, _from, _withdrawalAmount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Client\u2019s statement : \u201cThis issue did not really need fixing. The mitigation was already in place by depositing a tiny amount of the reserve into the contract, if necessary\u201d"
    ],
    "Description": [
        "Every withdraw function in the strategy contracts is calculating the expected amount of the returned tokens before withdrawing them:",
        "wheat-v1-core-audit/contracts/PantherSwapCompoundingStrategyToken.sol:L200-L208",
        "After that, the contract is trying to transfer this pre-calculated amount to the msg.sender. It is never checked whether the intended amount was actually transferred to the strategy contract. If the amount is lower, that may result in reverting the withdraw function all the time and locking up tokens.",
        "Even though we did not find any specific case of returning a different amount of tokens, it is still a good idea to handle this situation to minimize relying on the security of the external contracts."
    ],
    "Recommendation": [
        "There are a few options how to mitigate the issue:"
    ]
}
----End JSON----

https://solodit.xyz/issues/yearn-re-entrancy-attack-during-deposit-consensys-pooltogether-sushi-and-yearn-v2-yield-sources-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function supplyTokenTo(uint256 \\_amount, address to) override external {\n    uint256 shares = \\_tokenToShares(\\_amount);\n\n    \\_mint(to, shares);\n\n    // NOTE: we have to deposit after calculating shares to mint\n    token.safeTransferFrom(msg.sender, address(this), \\_amount);\n\n    \\_depositInVault();\n\n    emit SuppliedTokenTo(msg.sender, shares, \\_amount, to);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "During the deposit in the supplyTokenTo function, the token transfer is happening after the shares are minted and before tokens are deposited to the yearn vault:",
        "code/pooltogether-yearnv2-yield-source/contracts/yield-source/YearnV2YieldSource.sol:L117-L128",
        "If the token allows the re-entrancy (e.g., ERC-777), the attacker can do one more transaction during the token transfer and call the supplyTokenTo function again. This second call will be done with already modified shares from the first deposit but non-modified token balances. That will lead to an increased amount of shares minted during the supplyTokenTo.\nBy using that technique, it\u2019s possible to steal funds from other users of the contract."
    ],
    "Recommendation": [
        "Have the re-entrancy guard on all the external functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/yearn-partial-deposits-are-not-processed-properly-consensys-pooltogether-sushi-and-yearn-v2-yield-sources-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// this will deposit full balance (for cases like not enough room in Vault)\nreturn v.deposit();\n\n",
        "function supplyTokenTo(uint256 \\_amount, address to) override external {\n    uint256 shares = \\_tokenToShares(\\_amount);\n\n    \\_mint(to, shares);\n\n    // NOTE: we have to deposit after calculating shares to mint\n    token.safeTransferFrom(msg.sender, address(this), \\_amount);\n\n    \\_depositInVault();\n\n    emit SuppliedTokenTo(msg.sender, shares, \\_amount, to);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The deposit is usually made with all the token balance of the contract:",
        "code/pooltogether-yearnv2-yield-source/contracts/yield-source/YearnV2YieldSource.sol:L171-L172",
        "The Yearn vault contract has a limit of how many tokens can be deposited there. If the deposit hits the limit, only part of the tokens is deposited (not to exceed the limit). That case is not handled properly, the shares are minted as if all the tokens are accepted, and the \u201cchange\u201d is not transferred back to the caller:",
        "code/pooltogether-yearnv2-yield-source/contracts/yield-source/YearnV2YieldSource.sol:L117-L128"
    ],
    "Recommendation": [
        "Handle the edge cases properly."
    ]
}
----End JSON----

https://solodit.xyz/issues/sushi-redeemtoken-redeems-less-than-it-should-consensys-pooltogether-sushi-and-yearn-v2-yield-sources-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Redeems tokens from the yield source from the msg.sender, it burn yield bearing tokens and return token to the sender.\n/// @param amount The amount of `token()` to withdraw. Denominated in `token()` as above.\n/// @return The actual amount of tokens that were redeemed.\nfunction redeemToken(uint256 amount) public override returns (uint256) {\n    ISushiBar bar = ISushiBar(sushiBar);\n    ISushi sushi = ISushi(sushiAddr);\n\n    uint256 totalShares = bar.totalSupply();\n    uint256 barSushiBalance = sushi.balanceOf(address(bar));\n    uint256 requiredShares = amount.mul(totalShares).div(barSushiBalance);\n\n    uint256 barBeforeBalance = bar.balanceOf(address(this));\n    uint256 sushiBeforeBalance = sushi.balanceOf(address(this));\n\n    bar.leave(requiredShares);\n\n    uint256 barAfterBalance = bar.balanceOf(address(this));\n    uint256 sushiAfterBalance = sushi.balanceOf(address(this));\n\n    uint256 barBalanceDiff = barBeforeBalance.sub(barAfterBalance);\n    uint256 sushiBalanceDiff = sushiAfterBalance.sub(sushiBeforeBalance);\n\n    balances[msg.sender] = balances[msg.sender].sub(barBalanceDiff);\n    sushi.transfer(msg.sender, sushiBalanceDiff);\n    return (sushiBalanceDiff);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The redeemToken function takes as argument the amount of SUSHI to redeem. Because the SushiBar\u2019s leave function \u2013 which has to be called to achieve this goal \u2013 takes an amount of xSUSHI that is to be burned in exchange for SUSHI, redeemToken has to compute the amount of xSUSHI that will result in a return of as many SUSHI tokens as were requested.",
        "code/sushi-pooltogether/contracts/SushiYieldSource.sol:L62-L87",
        "Because the necessary calculations involve division and amounts have to be integral values, it is usually not possible to get the exact amount of SUSHI tokens that were requested. More precisely, let a denote the total supply of xSUSHI and b the SushiBar\u2019s balance of SUSHI at a certain point in time. If the SushiBar\u2019s leave function is supplied with x xSUSHI, then it will transfer floor(x * b / a) SUSHI. (We assume throughout this discussion that the numbers involved are small enough such that no overflow occurs and that a and b are not zero.)",
        "Hence, if y is the amount of SUSHI requested, it would make sense to call leave with the biggest number x that satisfies floor(x * b / a) <= y or the smallest number x that satisfies floor(x * b / a) >= y. Which of the two is \u201cbetter\u201d or \u201ccorrect\u201d needs to be specified, based on the requirements of the caller of redeemToken. It seems plausible, though, that the first variant is the one that makes more sense in this context, and the current implementation of redeemToken supports this hypothesis. It calls leave with x1 := floor(y * a / b), which gives us floor(x1 * b / a) <= y. However, x1 is not necessarily the biggest number that satisfies the relation, so the caller of redeemToken might end up with less SUSHI than they could have gotten while still not exceeding y.",
        "The correct amount to call leave with isx2 := floor((y * a + a - 1) / b) = max { x | floor(x * b / a) <= y }.\nSince |x2 - x1| <= 1, the difference in SUSHI is at most floor(b / a). Nevertheless, even this small difference might subvert fairly reasonable expectations. For example, if someone queries balanceOfToken and immediately after that feeds the result into redeemToken, they might very well expect to redeem exactly the given amount and not less; it\u2019s their current balance, after all. However, that\u2019s not always the case with the current implementation."
    ],
    "Recommendation": [
        "Calculate requiredShares based on the formula above (x2). We also recommend dealing in a clean way with the special cases totalShares == 0 and barSushiBalance == 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/sushi-balanceoftoken-underestimates-balance-consensys-pooltogether-sushi-and-yearn-v2-yield-sources-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Returns the total balance (in asset tokens). This includes the deposits and interest.\n/// @return The underlying balance of asset tokens\nfunction balanceOfToken(address addr) public override returns (uint256) {\n    if (balances[addr] == 0) return 0;\n    ISushiBar bar = ISushiBar(sushiBar);\n\n    uint256 shares = bar.balanceOf(address(this));\n    uint256 totalShares = bar.totalSupply();\n\n    uint256 sushiBalance =\n        shares.mul(ISushi(sushiAddr).balanceOf(address(sushiBar))).div(\n            totalShares\n        );\n    uint256 sourceShares = bar.balanceOf(address(this));\n\n    return (balances[addr].mul(sushiBalance).div(sourceShares));\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The balanceOfToken computation is too pessimistic, i.e., it can underestimate the current balance slightly.",
        "code/sushi-pooltogether/contracts/SushiYieldSource.sol:L29-L45",
        "First, it calculates the amount of SUSHI that \u201cbelongs to\u201d the yield source contract (sushiBalance), and then it determines the fraction of that amount that would be owed to the address in question. However, the \u201cbelongs to\u201d above is a purely theoretical concept; it never happens that the yield source contract as a whole redeems and then distributes that amount among its shareholders; instead, if a shareholder redeems tokens, their request is passed through to the SushiBar.\nSo in reality, there\u2019s no reason for this two-step process, and the holder\u2019s balance of SUSHI is more accurately computed as balances[addr].mul(ISushi(sushiAddr).balanceOf(address(sushiBar))).div(totalShares), which can be greater than what balanceOfToken currently returns. Note that this is the amount of SUSHI that addr could withdraw directly from the SushiBar, based on their amount of shares. Observe also that if we sum these numbers up over all holders in the yield source contract, the result is smaller than or equal to sushiBalance. So the sum still doesn\u2019t exceed what \u201cbelongs to\u201d the yield source contract."
    ],
    "Recommendation": [
        "The balanceOfToken function should use the formula above."
    ]
}
----End JSON----

https://solodit.xyz/issues/insufficient-tests-consensys-nuts-finance-btcplus-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from NUTS Finance team:"
    ],
    "Description": [
        "It is crucial to write tests with possibly 100% coverage for smart contract systems. Given that BTCPlus has inner complexity and also integrates many DeFi projects, using unit testing and fuzzing in all code paths is essential to a secure system.",
        "Currently there are only 63 unit tests (with 1 failing) for the main components (Plus/Composite token, Governance, Liquidity Gauge, etc) which are only testing the predetermined code execution paths. There are also DeFi protocol specific tests that are not well organized to be able to find the coverage on the system."
    ],
    "Recommendation": [
        "Write proper tests for all possible code flows and specially edge cases (Price volatility, token transfer failure, 0 amounts, etc). It is useful to have one command to run all tests and have a code coverage report at the end. Also using libraries like eth-gas-reporter it\u2019s possible to know the gas usage of different functionalities in order to optimize and prevent lock ups in the future."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-incomplete-dead-code-zwithdraw-and-zdeposit-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function zDeposit(address to) external payable onlyZauction {\n        ethbalance[to] = SafeMath.add(ethbalance[to], msg.value);\n        emit zDeposited(to, msg.value);\n    }\n\n    function zWithdraw(address from, uint256 amount) external onlyZauction {\n        ethbalance[from] = SafeMath.sub(ethbalance[from], amount);\n        emit zWithdrew(from, amount);\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "obsolete with changes from zer0-os/[email\u00a0protected]135b2aa removing the zAccountAccountant."
    ],
    "Description": [
        "The code generally does not appear to be production-ready. The methods zWithdraw and zDeposit do not appear to be properly implemented. zWithdraw rather burns ETH balance than withdrawing it for an account (missing transfer) and zDeposit manipulates an accounts balance but never receives the ETH amount it credits to an account."
    ],
    "Examples": [
        "zAuction/contracts/zAuctionAccountant.sol:L44-L52"
    ],
    "Recommendation": [
        "The methods do not seem to be used by the zAuction contract. It is highly discouraged from shipping incomplete implementations in productive code. Remove dead/unreachable code. Fix the implementations to perform proper accounting before reintroducing them if they are called by zAuction."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-unpredictable-behavior-for-users-due-to-admin-front-running-or-general-bad-timing-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function SetZauction(address zauctionaddress) external onlyAdmin{\n        zauction = zauctionaddress;\n        emit ZauctionSet(zauctionaddress);\n    }\n\n    function SetAdmin(address newadmin) external onlyAdmin{\n        admin = newadmin;\n        emit AdminSet(msg.sender, newadmin);\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "obsolete with changes from zer0-os/[email\u00a0protected]135b2aa removing the zAccountAccountant. The client provided the following remark:"
    ],
    "Description": [
        "An administrator of zAuctionAccountant contract can update the zAuction contract without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.",
        "In general users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "zAuction/contracts/zAuctionAccountant.sol:L60-L68"
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.",
        "Validate arguments before updating contract addresses (at least != current/0x0). Consider implementing a 2-step admin ownership transfer (transfer+accept) to avoid losing control of the contract by providing the wrong ETH address."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-zns-bids-cannot-be-cancelled-never-expire-and-the-auction-lifecycle-is-unclear-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\n    require(!randUsed[rand], 'Random nonce already used');\n    randUsed[rand] = true;\n    IERC721 nftcontract = IERC721(nftaddress);\n    accountant.Exchange(bidder, msg.sender, bid);\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\n}\n\n\n",
        "  function fulfillDomainBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  uint256 royaltyAmount,\n  string memory bidIPFSHash,\n  string memory name,\n  string memory metadata,\n  bytes memory signature,\n  bool lockOnCreation,\n  address recipient\n) external {\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\n  address recoveredBidder = recover(recoveredBidHash, signature);\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\n  registrar.setDomainMetadataUri(id, metadata);\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\n  registrar.transferFrom(controller, recoveredBidder, id);\n  if (lockOnCreation) {\n    registrar.lockDomainMetadataForOwner(id);\n  }\n  approvedBids[hashOfSig] = false;\n  emit DomainBidFulfilled(\n    metadata,\n    name,\n    recoveredBidder,\n    id,\n    parentId\n  );\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The stateless nature of auctions may make it hard to enforce bid/sale expirations and it is not possible to cancel a bid/offer that should not be valid anymore. The expiration reduces the risk of old offers being used as they now automatically invalidate after time, however, it is still likely that multiple valid offers may be present at the same time. As outlined in the recommendation, one option would be to allow someone who signed a commitment to explicitly cancel it in the contract. Another option would be to create a stateful auction where the entity that puts up something for \u201cstarts\u201d an auction, creating an auction id, requiring bidders to bid on that auction id. Once a bid is accepted the auction id is invalidated which invalidates all bids that might be floating around.",
        "UPDATE Fixed with zer0-os/[email\u00a0protected]2f92aa1 for zAuction/zSale by allowing the seller (zSale) to cancel their offer, and by allowing the bidder (zAuction) to cancel bids (pot. more than one per auction) up to a certain price threshold. Since auctionId can only be used once, all other bids for an auction are automatically invalidated after a bid is accepted. Note that the current version is using a unique number as an auction id. There can be concurrent auctions that by chance or maliciously use the same auction id. The first auction to pass will cancel the competing auction that was using the same id. This fact can be used as a griefing vector to terminate running auctions by reusing the other auctions id and self-accepting the bid. The other auction cannot be fulfilled anymore."
    ],
    "Description": [
        "The lifecycle of a bid both for zAuction and zNS is not clear, and has many flaws."
    ],
    "Examples": [
        "zAuction/contracts/zAuction.sol:L35-L45",
        "zNS/contracts/StakingController.sol:L120-L152"
    ],
    "Recommendation": [
        "Consider adding an expiration field to the message signed by the bidder both for zAuction and zNS.\nConsider adding auction control, creating an auctionId, and have users bid on specific auctions. By adding this id to the signed message, all other bids are invalidated automatically and users would have to place new bids for a new auction. Optionally allow users to cancel bids explicitly."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-pot-initialization-fronrunning-and-unnecessary-init-function-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function init(address accountantaddress) external {\n    require(!initialized);\n    initialized = true;\n    accountant = zAuctionAccountant(accountantaddress);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]135b2aa and the following statement:"
    ],
    "Description": [
        "The zAuction initialization method is unprotected and while only being executable once, can be called by anyone. This might allow someone to monitor the mempool for new deployments of this contract and fron-run the initialization to initialize it with different parameters.",
        "A mitigating factor is that this condition can be detected by the deployer as subsequent calls to init() will fail."
    ],
    "Examples": [
        "zAuction/contracts/zAuction.sol:L22-L26"
    ],
    "Recommendation": [
        "The contract is not used in a proxy pattern, hence, the initialization should be performed in the constructor instead."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-unclear-upgrade-path-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function SetZauction(address zauctionaddress) external onlyAdmin{\n    zauction = zauctionaddress;\n    emit ZauctionSet(zauctionaddress);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "obsolete with changes from zer0-os/[email\u00a0protected]135b2aa removing the zAccountAccountant."
    ],
    "Description": [
        "zAuction appears to implement an upgrade path for the auction system via zAuctionAccountant. zAuction itself does not hold any value. The zAuctionAccountant can be configured to allow only one zAution contract to interact with it. The update of the contract reference takes effect immediately (https://github.com/ConsenSys/zer0-zauction-audit-2021-05/issues/7).",
        "Acceptance of bids via the accountant on the old contract immediately fail after an admin updates the referenced zAuction contract while WETH bids may still continue. This may create an unfavorable scenario where two contracts may be active in parallel accepting WETH bids.",
        "It should also be noted that 2nd layer bids (signed data) using the accountant for the old contract will not be acceptable anymore."
    ],
    "Examples": [
        "zAuction/contracts/zAuctionAccountant.sol:L60-L63"
    ],
    "Recommendation": [
        "Consider re-thinking the upgrade path. Avoid keeping multiple versions of the auction contact active."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-zns-gas-griefing-by-spamming-offchain-fake-bids-acknowledged-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function fulfillDomainBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  uint256 royaltyAmount,\n  string memory bidIPFSHash,\n  string memory name,\n  string memory metadata,\n  bytes memory signature,\n  bool lockOnCreation,\n  address recipient\n) external {\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\n  address recoveredBidder = recover(recoveredBidHash, signature);\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\n  registrar.setDomainMetadataUri(id, metadata);\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\n  registrar.transferFrom(controller, recoveredBidder, id);\n  if (lockOnCreation) {\n    registrar.lockDomainMetadataForOwner(id);\n  }\n  approvedBids[hashOfSig] = false;\n  emit DomainBidFulfilled(\n    metadata,\n    name,\n    recoveredBidder,\n    id,\n    parentId\n  );\n}\n\n",
        "function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\n    require(!randUsed[rand], 'Random nonce already used');\n    randUsed[rand] = true;\n    IERC721 nftcontract = IERC721(nftaddress);\n    accountant.Exchange(bidder, msg.sender, bid);\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed and acknowledged with changes from zer0-os/[email\u00a0protected]135b2aa. The client provided the following remark:"
    ],
    "Description": [
        "The execution status of both zAuction.acceptBid and StakingController.fulfillDomainBid transactions depend on the bidder, as his approval is needed, his signature is being validated, etc. However, these transactions can be submitted by accounts that are different from the bidder account, or for accounts that do not have the required funds/deposits available, luring the account that has to perform the on-chain call into spending gas on a transaction that is deemed to fail (gas griefing). E.g. posting high-value fake bids for zAuction without having funds deposited or WETH approved."
    ],
    "Examples": [
        "zNS/contracts/StakingController.sol:L120-L152",
        "zAuction/contracts/zAuction.sol:L35-L44"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/zauction-functionality-outlined-in-specification-that-is-not-implemented-yet-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "implemented as zSale with changes from zer0-os/[email\u00a0protected]135b2aa."
    ],
    "Description": [
        "The specification outlines three main user journeys of which one does not seem to be implemented."
    ],
    "Recommendation": [
        "User flow (2) is not implemented in the smart contract system. Consider updating the spec or clearly highlighting functionality that is still in development for it to be excluded from security testing."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-auctionsoffers-can-be-terminated-by-reusing-the-auction-id-fixed-consensys-zer0-zauction-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]8ff0eab by binding saleId to the seller in zSale and the auctionId to the bidder in zAuction.",
        "In the zSale case the saleId is chosen by the seller. The offer (signed offer parameters including saleid) is shared on an off-chain channel. The buyer calls zSale.purchase to buy the token from the offer. The offer and all offers containing the same seller+saleid are then invalidated.",
        "In zAuction there is no seller or someone who initiates an auction. Anyone can bid for nft\u2019s held by anyone else. The bidder chooses an auction id. There might be multiple bidders. Since the auctionId is an individual choice and the smart contract does not enforce an auction to be started there may be multiple auctions for the same token but using different auction ids. The current mechanism automatically invalidates all current bids for the token+auctionId combination for the winning bidder. Bids by other holders are not automatically invalidated but they can be invalidated manually via cancelBidsUnderPrice for an auctionId. Note that the winning bid is chosen by the nftowner/seller. The new owner of the nft may be able to immediately accept another bid and transfer the token [seller]--acceptBid-->[newOwner-A]--acceptBid-->[newOwner-B]."
    ],
    "Description": [
        "zer0-os/[email\u00a0protected]2f92aa1 introduced a way of tracking auctions/sales by using an auctionId/saleId. The id\u2019s are unique and the same id cannot be used for multiple auctions/offers.",
        "Two different auctions/offers may pick the same id, the first auction/offer will go through while the latter cannot be fulfilled anymore. This may happen accidentally or intentionally be forced by a malicious actor to terminate active auctions/sales (griefing, front-running)."
    ],
    "Examples": [
        "Alice puts out an offer for someone to buy nft X at a specific price. Bob decides to accept that offer and buy the nft by calling zSale.purchase(saleid, price, token, ...). Mallory monitors the mempool, sees this transaction, front-runs it to fulfill its own sale (for a random nft he owns) reusing the saleid from Bobs transaction. Since Mallories transaction marks the saleid as consumed it terminates Alie\u2019s offer and hence Bob cannot buy the token as the transaction will revert."
    ],
    "Recommendation": [
        "Consider using keccak(saleid+nftcontract+nfttokenid) as the unique sale/auction identifier instead, or alternatively associate the bidder address with the auctionId (require that consumed[bidder][auctionId]== false)"
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-dynamicliquidtokenconverter-ineffective-reentrancy-protection-fixed-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function reduceWeight(IERC20Token \\_reserveToken)\n    public\n    validReserve(\\_reserveToken)\n    ownerOnly\n{\n    \\_protected();\n\n",
        "contract ReentrancyGuard {\n    // true while protected code is being executed, false otherwise\n    bool private locked = false;\n\n    /\\*\\*\n \\* @dev ensures instantiation only by sub-contracts\n \\*/\n    constructor() internal {}\n\n    // protects a function against reentrancy attacks\n    modifier protected() {\n        \\_protected();\n        locked = true;\n        \\_;\n        locked = false;\n    }\n\n    // error message binary size optimization\n    function \\_protected() internal view {\n        require(!locked, \"ERR\\_REENTRANCY\");\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with zer0-os/[email\u00a0protected]ff3d913 by following the recommendation."
    ],
    "Description": [
        "reduceWeight calls _protected() in an attempt to protect from reentrant calls but this check is insufficient as it will only check for the locked statevar but never set it. A potential for direct reentrancy might be present when an erc-777 token is used as reserve.",
        "It is assumed that the developer actually wanted to use the protected modifier that sets the lock before continuing with the method."
    ],
    "Examples": [
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L123-L128"
    ],
    "Recommendation": [
        "To mitigate potential attack vectors from reentrant calls remove the call to _protected() and decorate the function with protected instead. This will properly set the lock before executing the function body rejecting reentrant calls."
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-dynamicliquidtokenconverter-input-validation-fixed-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setMinimumWeight(uint32 \\_minimumWeight)\n    public\n    ownerOnly\n    inactive\n{\n    //require(\\_minimumWeight > 0, \"Min weight 0\");\n    //\\_validReserveWeight(\\_minimumWeight);\n    minimumWeight = \\_minimumWeight;\n    emit MinimumWeightUpdated(\\_minimumWeight);\n}\n\n",
        "function setStepWeight(uint32 \\_stepWeight)\n    public\n    ownerOnly\n    inactive\n{\n    //require(\\_stepWeight > 0, \"Step weight 0\");\n    //\\_validReserveWeight(\\_stepWeight);\n    stepWeight = \\_stepWeight;\n    emit StepWeightUpdated(\\_stepWeight);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "fixed with zer0-os/[email\u00a0protected]ff3d913 by checking that the provided values are at least 0% < p <= 100%."
    ],
    "Description": [
        "Check that the value in PPM is within expected bounds before updating system settings that may lead to functionality not working correctly. For example, setting out-of-bounds values for stepWeight or setMinimumWeight may make calls to reduceWeight fail. These values are usually set in the beginning of the lifecycle of the contract and misconfiguration may stay unnoticed until trying to reduce the weights. The settings can be fixed, however, by setting the contract inactive and updating it with valid settings. Setting the contract to inactive may temporarily interrupt the normal operation of the contract which may be unfavorable."
    ],
    "Examples": [
        "Both functions allow the full uint32 range to be used, which, interpreted as PPM would range from 0% to 4.294,967295%",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L75-L84",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L92-L101"
    ],
    "Recommendation": [
        "Reintroduce the checks for _validReserveWeight to check that a percent value denoted in PPM is within valid bounds _weight > 0 && _weight <= PPM_RESOLUTION. There is no need to separately check for the value to be >0 as this is already ensured by _validReserveWeight.",
        "Note that there is still room for misconfiguration (step size too high, min-step too high), however, this would at least allow to catch obviously wrong and often erroneously passed parameters early."
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-dynamicliquidtokenconverter-introduces-breaking-changes-to-the-underlying-bancorprotocol-base-fixed-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "import \"../../interfaces/ITypedConverterFactory.sol\";\n\n",
        "function converterType() public pure returns (uint16) {\n    return 3;\n}\n\n",
        "{\n    DSToken token = new DSToken(\\_name, \\_symbol, \\_decimals);\n\n    token.issue(msg.sender, \\_initialSupply);\n\n    emit NewToken(token);\n\n    createConverter(\n      token,\n      \\_reserveToken,\n      \\_reserveWeight,\n      \\_reserveBalance,\n      \\_registry,\n      \\_maxConversionFee,\n      \\_minimumWeight,\n      \\_stepWeight,\n      \\_marketCapThreshold\n    );\n\n    return token;\n}\n\n",
        "    function upgradeOld(DynamicLiquidTokenConverter \\_converter, bytes32 \\_version) public {\n        \\_version;\n        DynamicLiquidTokenConverter converter = DynamicLiquidTokenConverter(\\_converter);\n        address prevOwner = converter.owner();\n        acceptConverterOwnership(converter);\n        DynamicLiquidTokenConverter newConverter = createConverter(converter);\n       \n        copyReserves(converter, newConverter);\n        copyConversionFee(converter, newConverter);\n        transferReserveBalances(converter, newConverter);\n        IConverterAnchor anchor = converter.token();\n       \n        // get the activation status before it's being invalidated\n        bool activate = isV28OrHigherConverter(converter) && converter.isActive();\n       \n        if (anchor.owner() == address(converter)) {\n            converter.transferTokenOwnership(address(newConverter));\n            newConverter.acceptAnchorOwnership();\n        }\n\n        handleTypeSpecificData(converter, newConverter, activate);\n        converter.transferOwnership(prevOwner);\n       \n        newConverter.transferOwnership(prevOwner);\n       \n        emit ConverterUpgrade(address(converter), address(newConverter));\n    }\n\n",
        "function upgradeOld(\n    IConverter \\_converter,\n    bytes32 /\\* \\_version \\*/\n) public {\n    // the upgrader doesn't require the version for older converters\n    upgrade(\\_converter, 0);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]ff3d913 by removing the modifications in favor of surgical and more simple changes, keeping the factory and upgrade components as close as possible to the forked bancor contracts.",
        "Additionally, the client provided the following statement:"
    ],
    "Description": [
        "Introducing major changes to the complex underlying smart contract system that zBanc was forked from(bancorprotocol) may result in unnecessary complexity to be added. Complexity usually increases the attack surface and potentially introduces software misbehavior. Therefore, it is recommended to focus on reducing the changes to the base system as much as possible and comply with the interfaces and processes of the system instead of introducing diverging behavior.",
        "For example, DynamicLiquidTokenConverterFactory does not implement the ITypedConverterFactory while other converters do. Furthermore, this interface and the behavior may be expected to only perform certain tasks e.g. when called during an upgrade process. Not adhering to the base systems expectations may result in parts of the system failing to function for the new convertertype. Changes introduced to accommodate the custom behavior/interfaces may result in parts of the system failing to operate with existing converters. This risk is best to be avoided.",
        "In the case of DynamicLiquidTokenConverterFactory the interface is imported but not implemented at all (unused import). The reason for this is likely because the function createConverter in DynamicLiquidTokenConverterFactory does not adhere to the bancor-provided interface anymore as it is doing way more than \u201cjust\u201d creating and returning a new converter. This can create problems when trying to upgrade the converter as the upgraded expected the shared interface to be exposed unless the update mechanisms are modified as well.",
        "In general, the factories createConverter method appears to perform more tasks than comparable type factories. It is questionable if this is needed but may be required by the design of the system. We would, however, highly recommend to not diverge from how other converters are instantiated unless it is required to provide additional security guarantees (i.e. the token was instantiated by the factory and is therefore trusted).",
        "The ConverterUpgrader changed in a way that it now can only work with the DynamicLiquidTokenconverter instead of the more generalized IConverter interface. This probably breaks the update for all other converter types in the system.",
        "The severity is estimated to be medium based on the fact that the development team seems to be aware of the breaking changes but the direction of the design of the system was not yet decided."
    ],
    "Examples": [
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverterFactory.sol:L6-L6",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverterFactory.sol:L144-L146",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverterFactory.sol:L54-L74",
        "zBanc/solidity/contracts/converter/ConverterUpgrader.sol:L96-L122",
        "solidity/contracts/converter/ConverterUpgrader.sol:L95-L101"
    ],
    "Recommendation": [
        "It is a fundamental design decision to either follow the bancorsystems converter API or diverge into a more customized system with a different design, functionality, or even security assumptions. From the current documentation, it is unclear which way the development team wants to go.",
        "However, we highly recommend re-evaluating whether the newly introduced type and components should comply with the bancor API (recommended; avoid unnecessary changes to the underlying system,) instead of changing the API for the new components. Decide if the new factory should adhere to the usually commonly shared ITypedConverterFactory (recommended) and if not, remove the import and provide a new custom shared interface. It is highly recommended to comply and use the bancor systems extensibility mechanisms as intended, keeping the previously audited bancor code in-tact and voiding unnecessary re-assessments of the security impact of changes."
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-dynamicliquidtokenconverter-isactive-should-only-be-returned-if-converter-is-fully-configured-and-converter-parameters-should-only-be-updateable-while-converter-is-inactive-fixed-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev returns true if the converter is active, false otherwise\n \\*\n \\* @return true if the converter is active, false otherwise\n\\*/\nfunction isActive() public view virtual override returns (bool) {\n    return anchor.owner() == address(this);\n}\n\n",
        "  \\* @dev returns true if the converter is active, false otherwise\n  \\*\n  \\* @return true if the converter is active, false otherwise\n\\*/\nfunction isActive() public view override returns (bool) {\n    return super.isActive() && address(priceOracle) != address(0);\n}\n\n",
        "function activate(\n    IERC20Token \\_primaryReserveToken,\n    IChainlinkPriceOracle \\_primaryReserveOracle,\n    IChainlinkPriceOracle \\_secondaryReserveOracle)\n    public\n    inactive\n    ownerOnly\n    validReserve(\\_primaryReserveToken)\n    notThis(address(\\_primaryReserveOracle))\n    notThis(address(\\_secondaryReserveOracle))\n    validAddress(address(\\_primaryReserveOracle))\n    validAddress(address(\\_secondaryReserveOracle))\n{\n\n",
        "\n    modifier ifActiveOnlyUpgrader(){\n      if(isActive()){\n        require(owner == addressOf(CONVERTER\\_UPGRADER), \"ERR\\_ACTIVE\\_NOTUPGRADER\");\n      }\n      \\_;\n    }\n\n",
        "uint32 public minimumWeight = 30000;\nuint32 public stepWeight = 10000;\nuint256 public marketCapThreshold = 10000 ether;\nuint256 public lastWeightAdjustmentMarketCap = 0;\n\n",
        "function setMarketCapThreshold(uint256 \\_marketCapThreshold)\n    public\n    ownerOnly\n    ifActiveOnlyUpgrader\n{\n    marketCapThreshold = \\_marketCapThreshold;\n    emit MarketCapThresholdUpdated(\\_marketCapThreshold);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]ff3d913 by removing the custom ACL modifier falling back to checking whether the contract is configured (isActive, inactive modifiers). When a new contract is deployed it will be inactive until the main vars are set by the owner (upgrade contract). The upgrade path is now aligned with how the LiquidityPoolV2Converter performs upgrades.",
        "Additionally, the client provided the following statement:"
    ],
    "Description": [
        "By default, a converter is active once the anchor ownership was transferred. This is true for converters that do not require to be properly set up with additional parameters before they can be used.",
        "zBanc/solidity/contracts/converter/ConverterBase.sol:L272-L279",
        "For a simple converter, this might be sufficient. If a converter requires additional setup steps (e.g. setting certain internal variables, an oracle, limits, etc.) it should return inactive until the setup completes. This is to avoid that users are interacting with (or even pot. frontrunning) a partially configured converter as this may have unexpected outcomes.",
        "For example, the LiquidityPoolV2Converter overrides the isActive method to require additional variables be set (oracle) to actually be in active state.",
        "zBanc/solidity/contracts/converter/types/liquidity-pool-v2/LiquidityPoolV2Converter.sol:L79-L85",
        "Additionally, settings can only be updated while the contract is inactive which will be the case during an upgrade. This ensures that the owner cannot adjust settings at will for an active contract.",
        "zBanc/solidity/contracts/converter/types/liquidity-pool-v2/LiquidityPoolV2Converter.sol:L97-L109",
        "The DynamicLiquidTokenConverter is following a different approach. It inherits the default isActive which sets the contract active right after anchor ownership is transferred. This kind of breaks the upgrade process for DynamicLiquidTokenConverter as settings cannot be updated while the contract is active (as anchor ownership might be transferred before updating values). To unbreak this behavior a new authentication modifier was added, that allows updates for the upgrade contradict while the contract is active. Now this is a behavior that should be avoided as settings should be predictable while a contract is active. Instead it would make more sense initially set all the custom settings of the converter to zero (uninitialized) and require them to be set and only the return the contract as active. The behavior basically mirrors the upgrade process of LiquidityPoolV2Converter.",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L44-L50",
        "Pre initialized variables should be avoided. The marketcap threshold can only be set by the calling entity as it may be very different depending on the type of reserve (eth, token).",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L17-L20",
        "Here\u2019s one of the setter functions that can be called while the contract is active (only by the upgrader contract but changing the ACL commonly followed with other converters).",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L67-L74"
    ],
    "Recommendation": [
        "Align the upgrade process as much as possible to how LiquidityPoolV2Converter performs it. Comply with the bancor API."
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-dynamicliquidtokenconverter-frontrunner-can-grief-owner-when-calling-reduceweight-acknowledged-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function reduceWeight(IERC20Token \\_reserveToken)\n        public\n        validReserve(\\_reserveToken)\n        ownerOnly\n    {\n        \\_protected();\n        uint256 currentMarketCap = getMarketCap(\\_reserveToken);\n        require(currentMarketCap > (lastWeightAdjustmentMarketCap.add(marketCapThreshold)), \"ERR\\_MARKET\\_CAP\\_BELOW\\_THRESHOLD\");\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledged this issue by providing the following statement:"
    ],
    "Description": [
        "The owner of the converter is allowed to reduce the converters weights once the marketcap surpasses a configured threshhold. The thresshold is configured on first deployment. The marketcap at the beginning of the call is calculated as reserveBalance / reserve.weight and stored as lastWeightAdjustmentMarketCap after reducing the weight.",
        "zBanc/solidity/contracts/converter/types/liquid-token/DynamicLiquidTokenConverter.sol:L130-L138",
        "The reserveBalance can be manipulated by buying (adding reserve token) or selling liquidity tokens (removing reserve token). The success of a call to reduceWeight is highly dependant on the marketcap. A malicious actor may, therefore, attempt to grief calls made by the owner by sandwiching them with buy and sell calls in an attempt to (a) raise the barrier for the next valid payout marketcap or (b) temporarily lower the marketcap if they are a major token holder in an attempt to fail the reduceWeights call.",
        "In both cases the griefer may incur some losses due to conversion errors, bancor fees if they are set, and gas spent. It is, therefore, unlikely that a third party may spend funds on these kinds of activities. However, the owner as a potential major liquid token holder may use this to their own benefit by artificially lowering the marketcap to the absolute minimum (old+threshold) by selling liquidity and buying it back right after reducing weights."
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-outdated-fork-acknowledged-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "According to the client the system was forked off bancor v0.6.18 (Oct 2020). The current version 0.6.x is v0.6.36 (Apr 2021)."
    ],
    "Recommendation": [
        "It is recommended to check if relevant security fixes were released after v0.6.18 and it should be considered to rebase with the current stable release."
    ]
}
----End JSON----

https://solodit.xyz/issues/zbanc-inconsistent-dynamiccontractregistry-admin-risks-fixed-consensys-zer0-zbanc-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function registerAddress(bytes32 \\_contractName, address \\_contractAddress)\n    public\n    ownerOnly\n    validAddress(\\_contractAddress)\n{\n\n",
        "function addressOf(bytes32 \\_contractName) public view override returns (address) {\n    if(items[\\_contractName].contractAddress != address(0)){\n      return items[\\_contractName].contractAddress;\n    }else{\n      return contractRegistry.addressOf(\\_contractName);\n    }\n}\n\n",
        "/\\*\\*\n \\* @dev returns the number of items in the registry\n \\*\n \\* @return number of items\n\\*/\nfunction itemCount() public view returns (uint256) {\n    return contractNames.length;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledged the admin risk and addressed the itemCount concerns by exposing another method that only returns the overridden entries. The following statement was provided:"
    ],
    "Description": [
        "DynamicContractRegistry is a wrapper registry that allows the zBanc to use the custom upgrader contract while still providing access to the normal bancor registry.",
        "For this to work, the registry owner can add or override any registry setting. Settings that don\u2019t exist in this contract are attempted to be retrieved from an underlying registry (contractRegistry).",
        "zBanc/solidity/contracts/utility/DynamicContractRegistry.sol:L66-L70",
        "If the item does not exist in the registry, the request is forwarded to the underlying registry.",
        "zBanc/solidity/contracts/utility/DynamicContractRegistry.sol:L52-L58",
        "According to the documentation this registry is owned by zer0 admins and this means users have to trust zer0 admins to play fair.",
        "The owner of the registry (zer0 admins) can change the underlying registry contract at will. The owner can also add new or override any settings that already exist in the underlying registry. This may for example allow a malicious owner to change the upgrader contract in an attempt to potentially steal funds from a token converter or upgrade to a new malicious contract. The owner can also front-run registry calls changing registry settings and thus influencing the outcome. Such an event will not go unnoticed as events are emitted.",
        "It should also be noted that itemCount will return only the number of items in the wrapper registry but not the number of items in the underlying registry. This may have an unpredictable effect on components consuming this information.",
        "zBanc/solidity/contracts/utility/DynamicContractRegistry.sol:L36-L43"
    ],
    "Recommendation": [
        "Require the owner/zer0 admins to be a DAO or multisig and enforce 2-step (notify->wait->upgrade) registry updates (e.g. by requiring voting or timelocks in the admin contract). Provide transparency about who is the owner of the registry as this may not be clear for everyone. Evaluate the impact of itemCount only returning the number of settings in the wrapper not taking into account entries in the subcontract (including pot. overlaps)."
    ]
}
----End JSON----

https://solodit.xyz/issues/zdao-token-specification-violation-snapshots-are-never-taken-partially-addressed-consensys-zer0-zdao-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "contract ZeroDAOToken is\n  OwnableUpgradeable,\n  ERC20Upgradeable,\n  ERC20PausableUpgradeable,\n  ERC20SnapshotUpgradeable\n{\n\n",
        "\\_updateAccountSnapshot(sender);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]81946d4 by exposing the _snapshot() method to a dedicated snapshot role (likely to be a DAO) and the owner of the contract.",
        "We would like to note that we informed the client that depending on how the snapshot method is used and how predictably snapshots are consumed this might open up a frontrunning vector where someone observing that a _snapshot() is about to be taken might sandwich the snapshot call, accumulate a lot of stake (via 2nd markets, lending platforms), and returning it right after it\u2019s been taken. The risk of losing funds may be rather low (especially if performed by a miner) and the benefit from a DAO proposal using this snapshot might outweigh it. It is still recommended to increase the number of snapshots taken or take them on a regular basis (e.g. with every first transaction to the contract in a block) to make it harder to sandwich the snapshot taking."
    ],
    "Description": [
        "According to the zDAO Token specification the DAO token should implement a snapshot functionality to allow it being used for DAO governance votings.",
        "While the corresponding functionality is implemented and appears to update balances for snapshots, _snapshot() is never called, therefore, the snapshot is never taken. e.g. attempting to call balanceOfAt always results in an error as no snapshot is available.",
        "zDAO-Token/contracts/ZeroDAOToken.sol:L12-L17",
        "zDAO-Token/contracts/ZeroDAOToken.sol:L83-L83",
        "Note that this is an explicit requirement as per specification but unit tests do not seem to attempt calls to balanceOfAt at all."
    ],
    "Recommendation": [
        "Actually, take a snapshot by calling _snapshot() once per block when executing the first transaction in a new block. Follow the openzeppeling documentation for ERC20Snapshot."
    ]
}
----End JSON----

https://solodit.xyz/issues/zns-domain-bid-might-be-approved-by-non-owner-account-fixed-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function approveDomainBid(\n    uint256 parentId,\n    string memory bidIPFSHash,\n    bytes memory signature\n) external authorizedOwner(parentId) {\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  approvedBids[hashOfSig] = true;\n  emit DomainBidApproved(bidIPFSHash);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected] by storing the domain request data on-chain."
    ],
    "Description": [
        "The spec allows anyone to place a bid for a domain, while only parent domain owners are allowed to approve a bid. Bid placement is actually enforced and purely informational. In practice, approveDomainBid allows any parent domain owner to approve bids (signatures) for any other domain even if they do not own it. Once approved, anyone can call fulfillDomainBid to create a domain."
    ],
    "Examples": [
        "zNS/contracts/StakingController.sol:L95-L103"
    ],
    "Recommendation": [
        "Consider adding a validation check that allows only the parent domain owner to approve bids on one of its domains. Reconsider the design of the system introducing more on-chain guarantees for bids."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-zns-bids-cannot-be-cancelled-never-expire-and-the-auction-lifecycle-is-unclear-fixed-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\n    require(!randUsed[rand], 'Random nonce already used');\n    randUsed[rand] = true;\n    IERC721 nftcontract = IERC721(nftaddress);\n    accountant.Exchange(bidder, msg.sender, bid);\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\n}\n\n\n",
        "  function fulfillDomainBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  uint256 royaltyAmount,\n  string memory bidIPFSHash,\n  string memory name,\n  string memory metadata,\n  bytes memory signature,\n  bool lockOnCreation,\n  address recipient\n) external {\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\n  address recoveredBidder = recover(recoveredBidHash, signature);\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\n  registrar.setDomainMetadataUri(id, metadata);\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\n  registrar.transferFrom(controller, recoveredBidder, id);\n  if (lockOnCreation) {\n    registrar.lockDomainMetadataForOwner(id);\n  }\n  approvedBids[hashOfSig] = false;\n  emit DomainBidFulfilled(\n    metadata,\n    name,\n    recoveredBidder,\n    id,\n    parentId\n  );\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The stateless nature of auctions may make it hard to enforce bid/sale expirations and it is not possible to cancel a bid/offer that should not be valid anymore. The expiration reduces the risk of old offers being used as they now automatically invalidate after time, however, it is still likely that multiple valid offers may be present at the same time. As outlined in the recommendation, one option would be to allow someone who signed a commitment to explicitly cancel it in the contract. Another option would be to create a stateful auction where the entity that puts up something for \u201cstarts\u201d an auction, creating an auction id, requiring bidders to bid on that auction id. Once a bid is accepted the auction id is invalidated which invalidates all bids that might be floating around.",
        "UPDATE Fixed with zer0-os/[email\u00a0protected]2f92aa1 for zAuction/zSale by allowing the seller (zSale) to cancel their offer, and by allowing the bidder (zAuction) to cancel bids (pot. more than one per auction) up to a certain price threshold. Since auctionId can only be used once, all other bids for an auction are automatically invalidated after a bid is accepted. Note that the current version is using a unique number as an auction id. There can be concurrent auctions that by chance or maliciously use the same auction id. The first auction to pass will cancel the competing auction that was using the same id. This fact can be used as a griefing vector to terminate running auctions by reusing the other auctions id and self-accepting the bid. The other auction cannot be fulfilled anymore."
    ],
    "Description": [
        "The lifecycle of a bid both for zAuction and zNS is not clear, and has many flaws."
    ],
    "Examples": [
        "zAuction/contracts/zAuction.sol:L35-L45",
        "zNS/contracts/StakingController.sol:L120-L152"
    ],
    "Recommendation": [
        "Consider adding an expiration field to the message signed by the bidder both for zAuction and zNS.\nConsider adding auction control, creating an auctionId, and have users bid on specific auctions. By adding this id to the signed message, all other bids are invalidated automatically and users would have to place new bids for a new auction. Optionally allow users to cancel bids explicitly."
    ]
}
----End JSON----

https://solodit.xyz/issues/zns-insufficient-protection-against-replay-attacks-fixed-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function createBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  string memory bidIPFSHash,\n  string memory name\n) public pure returns(bytes32) {\n  return keccak256(abi.encode(parentId, bidAmount, bidIPFSHash, name));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected] by avoiding the use of digital signatures and storing the domain request data on-chain."
    ],
    "Description": [
        "There is no dedicated data structure to prevent replay attacks on StakingController. approvedBids mapping offers only partial mitigation, due to the fact that after a domain bid is fulfilled, the only mechanism in place to prevent a replay attack is the Registrar contract that might be replaced in the case where StakingController is being re-deployed with a different Registrar instance. Additionally, the digital signature used for domain bids does not identify the buyer request uniquely enough. The bidder\u2019s signature could be replayed in future similar contracts that are deployed with a different registrar or in a different network."
    ],
    "Examples": [
        "zNS/contracts/StakingController.sol:L176-L183"
    ],
    "Recommendation": [
        "Consider adding a dedicated mapping to store the a unique identifier of a bid, as well as adding address(this), block.chainId, registrar and nonce to the message that is being signed by the bidder."
    ]
}
----End JSON----

https://solodit.xyz/issues/zns-domain-name-collisions-fixed-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function registerDomain(\n  uint256 parentId,\n  string memory name,\n  address domainOwner,\n  address minter\n) external override onlyController returns (uint256) {\n  // Create the child domain under the parent domain\n  uint256 labelHash = uint256(keccak256(bytes(name)));\n  address controller = msg.sender;\n\n  // Domain parents must exist\n  require(\\_exists(parentId), \"Zer0 Registrar: No parent\");\n\n  // Calculate the new domain's id and create it\n  uint256 domainId =\n    uint256(keccak256(abi.encodePacked(parentId, labelHash)));\n  \\_createDomain(domainId, domainOwner, minter, controller);\n\n  emit DomainCreated(domainId, name, labelHash, parentId, minter, controller);\n\n  return domainId;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]ab7d62a by disallowing empty names for domain registrations. The name validation in off-chain components (e.g. subgraph components) has not been verified."
    ],
    "Description": [
        "Domain registration accepts an empty (zero-length) name. This may allow a malicious entity to register two different NFT\u2019s for the same visually indinstinguishable text representation of a domain. Similar to this the domain name is mapped to an NFT via a subgraph that connects parent names to the new subdomain using a domain separation character (dot/slash/\u2026). Someone might be able to register a.b to cats.cool which might resolve to the same domain as if someone registers cats.cool.a and then cats.cool.a.b."
    ],
    "Examples": [
        "zNS/contracts/Registrar.sol:L76-L96"
    ],
    "Recommendation": [
        "Disallow empty subdomain names. Disallow domain separators in names (in the offchain component or smart contract)."
    ]
}
----End JSON----

https://solodit.xyz/issues/zauction-zns-gas-griefing-by-spamming-offchain-fake-bids-acknowledged-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function fulfillDomainBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  uint256 royaltyAmount,\n  string memory bidIPFSHash,\n  string memory name,\n  string memory metadata,\n  bytes memory signature,\n  bool lockOnCreation,\n  address recipient\n) external {\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\n  address recoveredBidder = recover(recoveredBidHash, signature);\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\n  registrar.setDomainMetadataUri(id, metadata);\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\n  registrar.transferFrom(controller, recoveredBidder, id);\n  if (lockOnCreation) {\n    registrar.lockDomainMetadataForOwner(id);\n  }\n  approvedBids[hashOfSig] = false;\n  emit DomainBidFulfilled(\n    metadata,\n    name,\n    recoveredBidder,\n    id,\n    parentId\n  );\n}\n\n",
        "function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\n    require(!randUsed[rand], 'Random nonce already used');\n    randUsed[rand] = true;\n    IERC721 nftcontract = IERC721(nftaddress);\n    accountant.Exchange(bidder, msg.sender, bid);\n    nftcontract.transferFrom(msg.sender, bidder, tokenid);\n    emit BidAccepted(bidder, msg.sender, bid, nftaddress, tokenid);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed and acknowledged with changes from zer0-os/[email\u00a0protected]135b2aa. The client provided the following remark:"
    ],
    "Description": [
        "The execution status of both zAuction.acceptBid and StakingController.fulfillDomainBid transactions depend on the bidder, as his approval is needed, his signature is being validated, etc. However, these transactions can be submitted by accounts that are different from the bidder account, or for accounts that do not have the required funds/deposits available, luring the account that has to perform the on-chain call into spending gas on a transaction that is deemed to fail (gas griefing). E.g. posting high-value fake bids for zAuction without having funds deposited or WETH approved."
    ],
    "Examples": [
        "zNS/contracts/StakingController.sol:L120-L152",
        "zAuction/contracts/zAuction.sol:L35-L44"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/zns-anyone-can-front-run-fulfilldomainbid-to-lock-the-domain-setting-or-set-different-metadata-fixed-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function fulfillDomainBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  uint256 royaltyAmount,\n  string memory bidIPFSHash,\n  string memory name,\n  string memory metadata,\n  bytes memory signature,\n  bool lockOnCreation,\n  address recipient\n) external {\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\n  address recoveredBidder = recover(recoveredBidHash, signature);\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\n  registrar.setDomainMetadataUri(id, metadata);\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\n  registrar.transferFrom(controller, recoveredBidder, id);\n  if (lockOnCreation) {\n    registrar.lockDomainMetadataForOwner(id);\n  }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected]ab7d62a by restricting the method to only be callable by the requester."
    ],
    "Description": [
        "Anyone observing a call to fulfillDomainBid can front-run this call for the original bidder, provide different metadata/royalty amount, or lock the metadata, as these parameters are not part of the bidder\u2019s signature.\nThe impact is limited as both metadata, royalty amount, and lock state can be changed by the domain owner after creation."
    ],
    "Examples": [
        "zNS/contracts/StakingController.sol:L120-L143"
    ],
    "Recommendation": [
        "Consider adding metadata, royaltyAmount, and lockOnCreation to the message signed by the bidder if the parent should have some control over metadata and lockstatus and restrict access to this function to msg.sender==recoveredbidder."
    ]
}
----End JSON----

https://solodit.xyz/issues/zns-using-a-digital-signature-as-a-hash-preimage-fixed-consensys-zer0-zns-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  function fulfillDomainBid(\n  uint256 parentId,\n  uint256 bidAmount,\n  uint256 royaltyAmount,\n  string memory bidIPFSHash,\n  string memory name,\n  string memory metadata,\n  bytes memory signature,\n  bool lockOnCreation,\n  address recipient\n) external {\n  bytes32 recoveredBidHash = createBid(parentId, bidAmount, bidIPFSHash, name);\n  address recoveredBidder = recover(recoveredBidHash, signature);\n  require(recipient == recoveredBidder, \"ZNS: bid info doesnt match/exist\");\n  bytes32 hashOfSig = keccak256(abi.encode(signature));\n  require(approvedBids[hashOfSig] == true, \"ZNS: has been fullfilled\");\n  infinity.safeTransferFrom(recoveredBidder, controller, bidAmount);\n  uint256 id = registrar.registerDomain(parentId, name, controller, recoveredBidder);\n  registrar.setDomainMetadataUri(id, metadata);\n  registrar.setDomainRoyaltyAmount(id, royaltyAmount);\n  registrar.transferFrom(controller, recoveredBidder, id);\n  if (lockOnCreation) {\n    registrar.lockDomainMetadataForOwner(id);\n  }\n  approvedBids[hashOfSig] = false;\n  emit DomainBidFulfilled(\n    metadata,\n    name,\n    recoveredBidder,\n    id,\n    parentId\n  );\n}\n\n",
        "function acceptBid(bytes memory signature, uint256 rand, address bidder, uint256 bid, address nftaddress, uint256 tokenid) external {\n    address recoveredbidder = recover(toEthSignedMessageHash(keccak256(abi.encode(rand, address(this), block.chainid, bid, nftaddress, tokenid))), signature);\n    require(bidder == recoveredbidder, 'zAuction: incorrect bidder');\n    require(!randUsed[rand], 'Random nonce already used');\n    randUsed[rand] = true;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with zer0-os/[email\u00a0protected] by avoiding the use of digital signatures."
    ],
    "Description": [
        "Using the encoded signature (r,s,v) or the hash of the signature to prevent replay or track if signatures have been seen/used is not recommended in general, as it may introduce signature malleability issues, as two different signature params (r,s,v) may be producable that validly sign the same data.",
        "The impact for this codebase, however, is limited, due to the fact that openzeppelins ECDSA wrapper library is used which checks for malleable ECDSA signatures (high s value). We still decided to keep this as a medium issue to raise awareness, that it is bad practice to rely on the hash of signatures instead of the hash of the actual signed data for checks.",
        "In another instance in zAuction, a global random nonce is used to prevent replay attacks. This is suboptimal and instead, the hash of the signed data (including a nonce) should be used."
    ],
    "Examples": [
        "zNS/contracts/StakingController.sol:L120-L152",
        "zAuction/contracts/zAuction.sol:L35-L39"
    ],
    "Recommendation": [
        "Consider creating the bid identifier by hashing the concatenation of all bid parameters instead. Ensure to add replay protection https://github.com/ConsenSys/zer0-zns-audit-2021-05/issues/19. Always check for the hash of the signed data instead of the hash of the encoded signature to track whether a signature has been seen before.",
        "Consider implementing Ethereum typed structured data hashing and signing according to EIP-712."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketrewardpool-unpredictable-staking-rewards-as-stake-can-be-added-just-before-claiming-and-rewards-may-be-paid-to-to-operators-that-do-not-provide-a-service-to-the-system-partially-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "-- reward period ends -- front-run other claimers to maximize profits\r\n[create x minipools]\r\n[stake to max effective RPL for amount of minipools; locked for 14 days]\r\n[claim rewards for inflated effective RPL stake]\r\n[dissolve(), close() minipools -> refund NETH]\r\n[burn NETH for ETH]\r\n... wait 14 days\r\n[withdraw stake OR start again creating Minipools, claiming rewards while the Minipools are dissolved right after, freeing the ETH]\r\n\n",
        "[stake max effective amount for the number of minipools]\r\n[claim() to claim the previous period even though we did not provide any stake for the duration]\r\n[optionally dissolve Minipools unlocking ETH]\r\n-- stake is locked for at least 14 days --\r\n-- 14 days forward - new reward period started --\r\n[claim() the period]\r\n[withdraw() (leaving min pool stake OR everything if we dissolve all the Minipool)]\r\n[lend RPL to other platforms and earn interest]\r\n-- 14 days forward -new reward period started --\r\n[get RPL back from another platform]\r\n[stake & create minipools to inflate effective stake]\r\n[claim()]\r\n[optionally dissolve Minipools to unlock node ETH]\r\n-- stake is locked for at least 14 days --\r\n-- 14 days forward - new reward period started --\r\n[claim() the period]\r\n[withdraw() (leaving min pool stake OR everything if we dissolve all the Minipools)]\r\n[lend RPL to other platforms and earn interest]\r\n...\r\n\n",
        "require(block.number.sub(getNodeRPLStakedBlock(msg.sender)) >= rocketDAOProtocolSettingsRewards.getRewardsClaimIntervalBlocks(), \"The withdrawal cooldown period has not passed\");\n// Get & check node's current RPL stake\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Partially addressed in branch rp3.0-updates (rocket-pool/[email\u00a0protected]b424ca1) by changing the withdrawal requirements to 150% of the effective RPL.",
        "The client provided the following statement:"
    ],
    "Description": [
        "Nodes/TrustedNodes earn rewards based on the current share of the effective RPL stake provided backing the number of Minipools they run. The reward is paid out regardless of when the effective node stake was provided, as long as it is present just before the call to claim(). This means the reward does not take into account how long the stake was provided. The effective RPL stake is the nodes RPL stake capped at a maximum of halfDepositUserAmount * 150% * nr_of_minipools(node) / RPLPrice. If the node does not run any Minipools, the effective RPL stake is zero.",
        "Since effective stake can be added just before calling the claim() method (effectively trying to get a reward for a period that passed without RPL being staked for the full duration), this might create an unpredictable outcome for other participants, as adding significant stake (requires creating Minipools and staking the max per pool; the stake is locked for at least the duration of a reward period rpl.rewards.claim.period.blocks) shifts the shares users get for the fixed total amount of rewards. This can be unfair if the first users claimed their reward, and then someone is artificially inflating the total amount of shares by adding more stake to get a bigger part of the remaining reward. However, this comes at the cost of the registered node having to create more Minipools to stake more, requiring an initial deposit (16ETH, or 0ETH under certain circumstances for trusted nodes) by the actor attempting to get a larger share of the rewards. The risk of losing funds for this actor, however, is rather low, as they can immediately dissolve() and close() the Minipool to refund their node deposit as NETH right after claiming the reward only losing the gas spent on the various transactions.",
        "This can be extended to a node operator creating a Minipool and staking the maximum amount before calling claim to remove the Minipool right after, freeing up the ETH that was locked in the Minipool until the next reward period starts. The node operator is not providing any service to the network, loses some value in ETH for gas but may compensate that with the RPL staking rewards. If the node amassed a significant amount of RPL stake, they might even try to flash-loan enough ETH to spawn Minipools to inflate their effective stake and earn most of the rewards to return the loan RPL profit.",
        "By staking just before claiming, the node effectively can earn rewards for 2 reward periods by only staking RPL for the duration of one period (claim the previous period, leave it in for 14 days, claim another period, withdraw).",
        "The stake can be withdrawn at the earliest 14 days after staking. However, it can be added back at any time, and the stake addition takes effect immediately. This allows for optimizing the staking reward as follows (assuming we front-run other claimers to maximize profits and perform all transactions in one block):",
        "Note that withdraw() can be called right at the time the new reward period starts:",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/node/RocketNodeStaking.sol:L165-L166"
    ],
    "Examples": [],
    "Recommendation": [
        "Review the incentive model for the RPL rewards. Consider adjusting it so that nodes that provide a service get a better share of the rewards. Consider accruing rewards for the duration the stake was provided instead of taking a snapshot whenever the node calls claim(). Require stake to be locked for > 14 days instead of >=14 days (withdraw()) or have users skip the first reward period after staking."
    ]
}
----End JSON----

https://solodit.xyz/issues/esms-use-of-sanitized-user_amount-user_id-values-fixed-consensys-gitcoin-token-distribution-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "try:\n    int(user\\_id)\nexcept ValueError:\n    gtc\\_sig\\_app.logger.error('Invalid user\\_id received!')\n    return Response('{\"message\":\"ESMS error\"}', status=400, mimetype='application/json')\n# make sure it's an int\ntry:\n    int(user\\_amount)\nexcept ValueError:\n    gtc\\_sig\\_app.logger.error('Invalid user\\_amount received!')\n    return Response('{\"message\":\"ESMS error\"}', status=400, mimetype='application/json')\n\n",
        "try:\n    leaf = proofs[str(user\\_id)]['leaf']\n    proof = proofs[str(user\\_id)]['proof']\n    leaf\\_bytes = Web3.toBytes(hexstr=leaf)\n\n",
        "# this is a bit of hack to avoid bug in old web3 on frontend\n# this means that user\\_amount is not converted back to wei before tx is broadcast! \nuser\\_amount\\_in\\_eth = Web3.fromWei(user\\_amount, 'ether')\n\n\n",
        ">>> print(str(Web3.fromWei(123456789012345, 'ether')))\n0.000123456789012345\n>>> print(str(Web3.fromWei(123456789012345.123, 'ether')))\n0.000123456789012345125\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in https://github.com/nopslip/gtc-request-signer/pull/4/ , by using the sanitized integer value in the code flow."
    ],
    "Description": [
        "In the Signer service, values are properly checked, however the checked values are not preserved and the user input is passed down in the function.",
        "The values are sanitized here:",
        "code/gtc-request-signer-main-5eb22e882e28e6f3192b80f237f7a3bcd15b1ee9/app.py:L98-L108",
        "But the original user inputs are being used here:",
        "code/gtc-request-signer-main-5eb22e882e28e6f3192b80f237f7a3bcd15b1ee9/app.py:L110-L113",
        "code/gtc-request-signer-main-5eb22e882e28e6f3192b80f237f7a3bcd15b1ee9/app.py:L128-L131"
    ],
    "Examples": [
        "if a float amount is passed for user_amount, all checks will pass, however the final amount will be slightly different that what it is intended:"
    ],
    "Recommendation": [
        "After the sanity check, use the sanitized value for the rest of the code flow."
    ]
}
----End JSON----

https://solodit.xyz/issues/prefer-using-abiencode-in-tokendistributor-fixed-consensys-gitcoin-token-distribution-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// can we repoduce leaf hash included in the claim?\nrequire(\\_hashLeaf(user\\_id, user\\_amount, leaf), 'TokenDistributor: Leaf Hash Mismatch.');\n\n",
        "/\\*\\*\n\\* @notice hash user\\_id + claim amount together & compare results to leaf hash \n\\* @return boolean true on match\n\\*/\nfunction \\_hashLeaf(uint32 user\\_id, uint256 user\\_amount, bytes32 leaf) private returns (bool) {\n\n",
        "bytes32 leaf\\_hash = keccak256(abi.encodePacked(keccak256(abi.encodePacked(user\\_id, user\\_amount))));\n\n",
        "return leaf == leaf\\_hash;\n\n",
        "library Encode {\n    function encode32Plus256(uint32 \\_a, uint256 \\_b) public pure returns (bytes memory) {\n        return abi.encodePacked(\\_a, \\_b);\n    }\n   \n    function encode256Plus32(uint256 \\_a, uint32 \\_b) public pure returns (bytes memory) {\n        return abi.encodePacked(\\_a, \\_b);\n    }\n}\n\ncontract Hash {\n    function checkEqual() public pure returns (bytes32, bytes32) {\n        // Pack 1\n        uint32  a1 = 0x12345678;\n        uint256 b1 = 0x99999999999999999999999999999999999999999999999999999999FFFFFFFF;\n       \n        // Pack 2\n        uint256 a2 = 0x1234567899999999999999999999999999999999999999999999999999999999;\n        uint32  b2 = 0xFFFFFFFF;\n       \n        // Encode these 2 different values\n        bytes memory packed1 = Encode.encode32Plus256(a1, b1);\n        bytes memory packed2 = Encode.encode256Plus32(a2, b2);\n       \n        // Check if the packed encodings match\n        require(keccak256(packed1) == keccak256(packed2), \"Hash of representation should match\");\n       \n        // The hashes are the same\n        // 0x9e46e582607c5c6e05587dacf66d311c4ced0819378a41d4b4c5adf99d72408e\n        return (\n            keccak256(packed1),\n            keccak256(packed2)\n        );\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in gitcoinco/governance#7"
    ],
    "Description": [
        "The method _hashLeaf is called when a user claims their airdrop.",
        "code/governance-main-ee5e45a008d65021831de9f3e83053026f2a4dd2/contracts/TokenDistributor.sol:L128-L129",
        "This method receives the user_id and the user_amount as arguments.",
        "code/governance-main-ee5e45a008d65021831de9f3e83053026f2a4dd2/contracts/TokenDistributor.sol:L253-L257",
        "These arguments are abi encoded and hashed together to produce a unique hash.",
        "code/governance-main-ee5e45a008d65021831de9f3e83053026f2a4dd2/contracts/TokenDistributor.sol:L258",
        "This hash is checked against the third argument for equality.",
        "code/governance-main-ee5e45a008d65021831de9f3e83053026f2a4dd2/contracts/TokenDistributor.sol:L259",
        "If the hash matches the third argument, it returns true and considers the provided user_id and user_amount are correct.",
        "However, packing differently sized arguments may produce collisions.",
        "The Solidity documentation states that packing dynamic types will produce collisions, but this is also the case if packing uint32 and uint256."
    ],
    "Examples": [
        "Below there\u2019s an example showing that packing uint32 and uint256 in both orders can produce collisions with carefully picked values.",
        "Changing abi.encodePacked to abi.encode in the library will make the transaction fail with error message Hash of representation should match."
    ],
    "Recommendation": [
        "Unless there\u2019s a specific use case to use abi.encodePacked, you should always use abi.encode. You might need a few more bytes in the transaction data, but it prevents collisions. Similar fix can be achieved by using unit256 for both values to be packed to prevent any possible collisions."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaonodetrusted-dao-takeover-during-deploymentbootstrapping-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\\*\\* Recovery \\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*/\n   \n// In an explicable black swan scenario where the DAO loses more than the min membership required (3), this method can be used by a regular node operator to join the DAO\n// Must have their ID, email, current RPL bond amount available and must be called by their current registered node account\nfunction memberJoinRequired(string memory \\_id, string memory \\_email) override public onlyLowMemberMode onlyRegisteredNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrusted\", address(this)) {\n    // Ok good to go, lets add them\n    (bool successPropose, bytes memory responsePropose) = getContractAddress('rocketDAONodeTrustedProposals').call(abi.encodeWithSignature(\"proposalInvite(string,string,address)\", \\_id, \\_email, msg.sender));\n    // Was there an error?\n    require(successPropose, getRevertMsg(responsePropose));\n    // Get the to automatically join as a member (by a regular proposal, they would have to manually accept, but this is no ordinary situation)\n    (bool successJoin, bytes memory responseJoin) = getContractAddress(\"rocketDAONodeTrustedActions\").call(abi.encodeWithSignature(\"actionJoinRequired(address)\", msg.sender));\n    // Was there an error?\n    require(successJoin, getRevertMsg(responseJoin));\n}\n\n",
        "setSettingBool(\"node.registration.enabled\", true);     \n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The node registration is enabled by default (node.registration.enabled) but the client intends to change this to disabling the registration until bootstrap mode finished."
    ],
    "Description": [
        "The initial deployer of the RocketStorage contract is set as the Guardian/Bootstrapping role. This guardian can bootstrap the TrustedNode and Protocol DAO, add members, upgrade components, change settings.",
        "Right after deploying the DAO contract the member count is zero. The Guardian can now begin calling any of the bootstrapping functions to add members, change settings, upgrade components, interact with the treasury, etc. The bootstrapping configuration by the Guardian is unlikely to all happen within one transaction which might allow other parties to interact with the system while it is being set up.",
        "RocketDaoNodeTrusted also implements a recovery mode that allows any registered node to invite themselves directly into the DAO without requiring approval from the Guardian or potential other DAO members as long as the total member count is below daoMemberMinCount (3). The Guardian itself is not counted as a DAO member as it is a supervisory role.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrusted.sol:L202-L215",
        "This opens up a window during the bootstrapping phase where any Ethereum Address might be able to register as a node (RocketNodeManager.registerNode) if node registration is enabled (default=true) rushing into RocketDAONodeTrusted.memberJoinRequired adding themselves (up to 3 nodes) as trusted nodes to the DAO. The new DAO members can now take over the DAO by issuing proposals, waiting 2 blocks to vote/execute them (upgrade, change settings while Guardian is changing settings, etc.). The Guardian role can kick the new DAO members, however, they can invite themselves back into the DAO.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/protocol/settings/RocketDAOProtocolSettingsNode.sol:L19-L19"
    ],
    "Recommendation": [
        "Disable the DAO recovery mode during bootstrapping. Disable node registration by default and require the guardian to enable it. Ensure that bootstrapDisable (in both DAO contracts) performs sanity checks as to whether the DAO bootstrapping finished and permissions can effectively be revoked without putting the DAO at risk or in an irrecoverable state (enough members bootstrapped, vital configurations like registration and other settings are configured, \u2026)."
    ]
}
----End JSON----

https://solodit.xyz/issues/rockettokenreth-sandwiching-opportunity-on-price-updates-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    // This is called by the base ERC20 contract before all transfer, mint, and burns\n    function \\_beforeTokenTransfer(address from, address, uint256) internal override {\n        // Don't run check if this is a mint transaction\n        if (from != address(0)) {\n            // Check which block the user's last deposit was\n            bytes32 key = keccak256(abi.encodePacked(\"user.deposit.block\", from));\n            uint256 lastDepositBlock = getUint(key);\n            if (lastDepositBlock > 0) {\n                // Ensure enough blocks have passed\n                RocketDAOProtocolSettingsNetworkInterface rocketDAOProtocolSettingsNetwork = RocketDAOProtocolSettingsNetworkInterface(getContractAddress(\"rocketDAOProtocolSettingsNetwork\"));\n                uint256 blocksPassed = block.number.sub(lastDepositBlock);\n                require(blocksPassed > rocketDAOProtocolSettingsNetwork.getRethDepositDelay(), \"Not enough time has passed since deposit\");\n                // Clear the state as it's no longer necessary to check this until another deposit is made\n                deleteUint(key);\n            }\n        }\n    }\n\n",
        "require(rocketDAOProtocolSettingsDeposit.getDepositEnabled(), \"Deposits into Rocket Pool are currently disabled\");\nrequire(msg.value >= rocketDAOProtocolSettingsDeposit.getMinimumDeposit(), \"The deposited amount is less than the minimum deposit size\");\nrequire(getBalance().add(msg.value) <= rocketDAOProtocolSettingsDeposit.getMaximumDepositPoolSize(), \"The deposit pool size after depositing exceeds the maximum size\");\n// Mint rETH to user account\nrocketTokenRETH.mint(msg.value, msg.sender);\n\n",
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n    updatePrices(\\_block, \\_rplPrice);\n}\n\n",
        "function burn(uint256 \\_rethAmount) override external {\n    // Check rETH amount\n    require(\\_rethAmount > 0, \"Invalid token burn amount\");\n    require(balanceOf(msg.sender) >= \\_rethAmount, \"Insufficient rETH balance\");\n    // Get ETH amount\n    uint256 ethAmount = getEthValue(\\_rethAmount);\n    // Get & check ETH balance\n    uint256 ethBalance = getTotalCollateral();\n    require(ethBalance >= ethAmount, \"Insufficient ETH balance for exchange\");\n    // Update balance & supply\n    \\_burn(msg.sender, \\_rethAmount);\n    // Withdraw ETH from deposit pool if required\n    withdrawDepositCollateral(ethAmount);\n    // Transfer ETH to sender\n    msg.sender.transfer(ethAmount);\n    // Emit tokens burned event\n    emit TokensBurned(msg.sender, \\_rethAmount, ethAmount, block.timestamp);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue is being addressed in a currently pending pull request. By introducing a delay between an rETH deposit and a subsequent transfer or burn, sandwiching a price update transaction is not possible anymore. Specifically, a deposit delay of circa one day is introduced:",
        "https://github.com/rocket-pool/rocketpool/pull/201/files#diff-0387338dc5dd7edd0a03766cfdaaee42d021d4e781239d5ebbff359c81497839R146-R150",
        "In the current version, it is correctly enforced that a deposit delay of zero is not possible."
    ],
    "Description": [
        "The rETH token price is not coupled to the amount of rETH tokens in circulation on the Ethereum chain. The price is reported by oracle nodes and committed to the system via a voting process. The price of rETH changes If 51% of nodes observe and submit the same price information. If nodes fail to find price consensus for a block, then the rETH price might be stale.",
        "There is an opportunity for the user to front-run the price update right before it is committed. If the next price is higher than the previous (typical case), this gives an instant opportunity to perform a risk-free ETH -> rETH -> ETH exchange for profit. In the worst case, one could drain all the ETH held by the RocketTokenRETH contract + excess funds stored in the vault.",
        "Note: there seems to be a \"network.submit.balances.frequency\" price and balance submission frequency of 24hrs. However, this frequency is not enforced, and it is questionable if it makes sense to pin the price for 24hrs.",
        "Note: the total supply of the RocketTokenRETH contract may be completely disconnected from the reported total supply for RETH via oracle nodes."
    ],
    "Examples": [
        "A user observes a price update for rETH submitted to RocketNetworkPrices, resulting in an increased price for rETH. The user front-runs the effective price update (51% consensus reached on submission) by rETH at the current, discounted rate. Ideally, the user checks that none of the funds will be assigned to minipools in the queue (empty queue, disabled assignment, ..) and that the expected amount of ETH returned is available RocketTokenRETH and RocketDeposit (excess funds) contracts. The user then waits for the price update and back-runs it with a call burning all the rETH obtained at a discount for ETH, realizing an immediate profit.",
        "The amount of ETH was only staked during this one process for the price update duration and unlikely to be useful to the system. This way, a whale (only limited by the max deposit amount set on deposit) can drain the RocketTokenRETH contract from all its ETH and excess eth funds.",
        "mempool observed: submitPrice tx (an effective transaction that changes the price) wrapped with buying rETH and selling rETH for ETH:",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/deposit/RocketDepositPool.sol:L63-L67",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/network/RocketNetworkPrices.sol:L69-L72",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/token/RocketTokenRETH.sol:L107-L124"
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaonodetrustedactions-incomplete-implementation-of-member-challenge-process-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "setSettingUint('members.challenge.cooldown', 6172);              // How long a member must wait before performing another challenge, approx. 1 day worth of blocks\nsetSettingUint('members.challenge.window', 43204);               // How long a member has to respond to a challenge. 7 days worth of blocks\nsetSettingUint('members.challenge.cost', 1 ether);               // How much it costs a non-member to challenge a members node. It's free for current members to challenge other members.\n\n",
        "// In the event that the majority/all of members go offline permanently and no more proposals could be passed, a current member or a regular node can 'challenge' a DAO members node to respond\n// If it does not respond in the given window, it can be removed as a member. The one who removes the member after the challenge isn't met, must be another node other than the proposer to provide some oversight\n// This should only be used in an emergency situation to recover the DAO. Members that need removing when consensus is still viable, should be done via the 'kick' method.\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "As of the Smartnode\u2019s v1.0.0-rc1 release, its watchtower process supports challenge detection and responses. It should be noted that a node\u2019s challenge state is extracted from the respective storage key. This means that no process currently makes use of the emitted ActionChallengeMade event. It can potentially be removed to optimize gas cost."
    ],
    "Description": [
        "Any registered (even untrusted) node can challenge a trusted DAO node to respond. The challenge is initiated by calling actionChallengeMake. Trusted nodes can challenge for free, other nodes have to provide members.challenge.cost as a tribute to the Ethereum gods. The challenged node must call actionChallengeDecide before challengeStartBlock + members.challenge.window blocks are over (default approx 7 days). However, the Golang codebase does not actively monitor for the ActionChallengeMade event, nor does the node - regularly - check if it is being challenged. Means to respond to the challenge (calling actionChallengeDecide to stop the challenge) are not implemented.",
        "A minority of trusted nodes may use this functionality to boot other trusted node members off the DAO issuing challenges once a day until the DAO member number is low enough to allow them to reach quorum for their own proposals or until the member threshold allows them to add new nodes without having to go through the proposal process at all."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/settings/RocketDAONodeTrustedSettingsMembers.sol:L22-L24",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrustedActions.sol:L204-L206"
    ],
    "Recommendation": [
        "Implement the challenge-response process before enabling users to challenge other nodes. Implement means to detect misuse of this feature for griefing e.g. when one trusted node member forces another trusted node to defeat challenges over and over again (technical controls, monitoring)."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaoprotocolsettingsrocketdaonodetrustedsettings-anyone-can-setoverwrite-settings-until-contract-is-declared-deployed-acknowledged-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier onlyDAOProtocolProposal() {\n    // If this contract has been initialised, only allow access from the proposals contract\n    if(getBool(keccak256(abi.encodePacked(settingNameSpace, \"deployed\")))) require(getContractAddress('rocketDAOProtocolProposals') == msg.sender, \"Only DAO Protocol Proposals contract can update a setting\");\n    \\_;\n}\n\n\n",
        "modifier onlyDAONodeTrustedProposal() {\n    // If this contract has been initialised, only allow access from the proposals contract\n    if(getBool(keccak256(abi.encodePacked(settingNameSpace, \"deployed\")))) require(getContractAddress('rocketDAONodeTrustedProposals') == msg.sender, \"Only DAO Node Trusted Proposals contract can update a setting\");\n    \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client is aware of and acknowledges this potential issue. As with the current contracts the deployed flag is always set in the constructor and there will be no window for someone else to interact with the contract before this flag is set. The following statement was provided:",
        "Additionally, it was suggested to add safeguards to the access restricting modifier, to only allowing the guardian to change settings if a settings contract \u201cforgets\u201d to set the deployed flag in the constructor (Note: the deployed flag must be set with the deploing transaction or else there might be a window for someone to interact with the contract before it is fully configured)."
    ],
    "Description": [
        "The onlyDAOProtocolProposal modifier guards all state-changing methods in this contract. However, analog to https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/7, the access control is disabled until the variable settingsNameSpace.deployed is set. If this contract is not deployed and configured in one transaction, anyone can update the contract while left unprotected on the blockchain.",
        "See issue 6.5 for a similar issue."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/protocol/settings/RocketDAOProtocolSettings.sol:L18-L23",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/settings/RocketDAONodeTrustedSettings.sol:L18-L22",
        "There are at least 9 more occurrences of this pattern."
    ],
    "Recommendation": [
        "Restrict access to the methods to a temporary trusted account (e.g. guardian) until the system bootstrapping phase ends by setting deployed to true."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketstorage-anyone-can-setupdate-values-before-the-contract-is-initialized-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier onlyLatestRocketNetworkContract() {\n    // The owner and other contracts are only allowed to set the storage upon deployment to register the initial contracts/settings, afterwards their direct access is disabled\n    if (boolStorage[keccak256(abi.encodePacked(\"contract.storage.initialised\"))] == true) {\n        // Make sure the access is permitted to only contracts in our Dapp\n        require(boolStorage[keccak256(abi.encodePacked(\"contract.exists\", msg.sender))], \"Invalid or outdated network contract\");\n    }\n    \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by restricting access to the guardian while the contract is not yet initialized. The relevant changeset is rocket-pool/[email\u00a0protected]495a51f. The client provided the following statement:",
        "The client is aware of the implication of using tx.origin and that the guardian should never be used to interact with third-party contracts as the contract may be able to impersonate the guardian changing settings in the storage contract during that transaction.",
        "https://github.com/ConsenSys/rocketpool-audit-2021-03/blob/0a5f680ae0f4da0c5639a241bd1605512cba6004/rocketpool-rp3.0-updates/contracts/contract/RocketStorage.sol#L31-L32"
    ],
    "Description": [
        "According to the deployment script, the contract is deployed, and settings are configured in multiple transactions. This also means that for a period of time, the contract is left unprotected on the blockchain. Anyone can delete/set any value in the centralized data store. An attacker might monitor the mempool for new deployments of the RocketStorage contract and front-run calls to contract.storage.initialised setting arbitrary values in the system."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/RocketStorage.sol:L24-L31"
    ],
    "Recommendation": [
        "Restrict access to the methods to a temporary trusted account (e.g. guardian) until the system bootstrapping phase ends by setting initialised to true."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaoproposals-unpredictable-behavior-due-to-short-vote-delay-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\\_startBlock > block.number, \"Proposal start block must be in the future\");\nrequire(\\_durationBlocks > 0, \"Proposal cannot have a duration of 0 blocks\");\nrequire(\\_expiresBlocks > 0, \"Proposal cannot have a execution expiration of 0 blocks\");\nrequire(\\_votesRequired > 0, \"Proposal cannot have a 0 votes required to be successful\");\n\n",
        "setSettingUint('proposal.vote.delay.blocks', 1);                 // How long before a proposal can be voted on after it is created. Approx. Next Block\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed in branch rp3.0-updates (rocket-pool/[email\u00a0protected]b424ca1) by changing the default delay proposal.vote.delay.blocks to one week."
    ],
    "Description": [
        "A proposal can be voted and passed when it enters the ACTIVE state. Voting starts when the current block.number is greater than the startBlock configured in the proposal (up until the endBlock). The requirement for the startBlock is to be at least greater than block.number when the proposal is submitted.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/RocketDAOProposal.sol:L167-L170",
        "The default vote delay configured in the system is 1 block.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/settings/RocketDAONodeTrustedSettingsProposals.sol:L21-L21",
        "A vote is immediately passed when the required quorum is reached which allows it to be executed. This means that a group that is holding enough voting power can propose a change, wait for two blocks (block.number (of time of proposal creation) + configuredDelay (1) + 1 (for ACTIVE state), then vote and execute for the proposal to pass for it to take effect almost immediately after only 2 blocks (<30seconds).",
        "Settings can be changed after 30 seconds which might be unpredictable for other DAO members and not give them enough time to oppose and leave the DAO."
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change after two blocks. The only guarantee is that users can be sure the settings don\u2019t change for the next block if no proposal is active.",
        "We recommend giving the user advance notice of changes with a delay. For example, all upgrades should require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketnodestaking-node-operators-can-reduce-slashing-impact-by-withdrawing-excess-staked-rpl-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "rocketMinipoolManager.setMinipoolWithdrawalBalances(\\_minipoolAddress, \\_stakingEndBalance, nodeAmount);\n// Apply node penalties by liquidating RPL stake\nif (\\_stakingEndBalance < userDepositBalance) {\n    RocketNodeStakingInterface rocketNodeStaking = RocketNodeStakingInterface(getContractAddress(\"rocketNodeStaking\"));\n    rocketNodeStaking.slashRPL(minipool.getNodeAddress(), userDepositBalance - \\_stakingEndBalance);\n}\n\n",
        "uint256 rplSlashAmount = calcBase.mul(\\_ethSlashAmount).div(rocketNetworkPrices.getRPLPrice());\n// Cap slashed amount to node's RPL stake\nuint256 rplStake = getNodeRPLStake(\\_nodeAddress);\nif (rplSlashAmount > rplStake) { rplSlashAmount = rplStake; }\n// Transfer slashed amount to auction contract\nrocketVault.transferToken(\"rocketAuctionManager\", getContractAddress(\"rocketTokenRPL\"), rplSlashAmount);\n// Update RPL stake amounts\ndecreaseTotalRPLStake(rplSlashAmount);\ndecreaseNodeRPLStake(\\_nodeAddress, rplSlashAmount);\n\n",
        "    // Calculate minimum RPL stake\n    return rocketDAOProtocolSettingsMinipool.getHalfDepositUserAmount()\n        .mul(rocketDAOProtocolSettingsNode.getMinimumPerMinipoolStake())\n        .mul(rocketMinipoolManager.getNodeMinipoolCount(\\_nodeAddress))\n        .div(rocketNetworkPrices.getRPLPrice());\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The RocketNodeStaking.withdrawRPL method now reverts if a node operator attempts to withdraw an RPL amount that results in the leftover RPL stake being smaller than the maximum required stake. This prevents operators from withdrawing excess RPL to avoid the impact of a slashing.",
        "https://github.com/rocket-pool/rocketpool/blob/rp3.0-updates/contracts/contract/node/RocketNodeStaking.sol#L187"
    ],
    "Description": [
        "Oracle nodes update the Minipools' balance and progress it to the withdrawable state when they observe the minipools stake to become withdrawable. If the observed stakingEndBalance is less than the user deposit for that pool, the node operator is punished for the difference.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolStatus.sol:L89-L94",
        "The amount slashed is at max userDepositBalance - stakingEndBalance. The userDepositBalance is at least 16 ETH (minipool.half/.full) and at max 32 ETH (minipool.empty). The maximum amount to be slashed is therefore 32 ETH (endBalance = 0, minipool.empty).",
        "The slashing amount is denoted in ETH. The RPL price (in ETH) is updated regularly by oracle nodes (see related issue https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/32; note that the RPL token is potentially affected by a similar issue as one can stake RPL, wait for the cooldown period & wait for the price to change, and withdraw stake at higher RPL price/ETH). The ETH amount to be slashed is converted to RPL, and the corresponding RPL stake is slashed.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/node/RocketNodeStaking.sol:L188-L196",
        "If the node does not have a sufficient RPL stake to cover the losses, the slashing amount is capped at whatever amount of RPL the node has left staked.",
        "The minimum amount of RPL a node needs to have staked if it operates minipools is calculated as follows:",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/node/RocketNodeStaking.sol:L115-L120",
        "With the current configuration, this would resolve in a minimum stake of 16 ETH * 0.1 (10% collateralization) * 1 (nr_minipools) * RPL_Price for a node operating 1 minipool. This means a node operator basically only needs to have 10% of 16 ETH staked to operate one minipool.",
        "An operator can withdraw their stake at any time, but they have to wait at least 14 days after the last time they staked (cooldown period). They can, at max, withdraw all but the minimum stake required to run the pools (nr_of_minipools * 16 ETH * 10%). This also means that after the cooldown period, they can reduce their stake to 10% of the half deposit amount (16ETH), then perform a voluntary exit on ETH2 so that the minipool becomes withdrawable. If they end up with less than the userDepositBalance in staking rewards, they would only get slashed the 1.6 ETH at max (10% of 16ETH half deposit amount for 1 minipool) even though they incurred a loss that may be up to 32 ETH (empty Minipool empty amount).",
        "Furthermore, if a node operator runs multiple minipools, let\u2019s say 5, then they would have to provide at least 5*16ETH*0.1 = 8ETH as a security guarantee in the form of staked RPL. If the node operator incurs a loss with one of their minipools, their 8 ETH RPL stake will likely be slashed in full. Their other - still operating - minipools are not backed by any RPL anymore, and they effectively cannot be slashed anymore. This means that a malicious node operator can create multiple minipools, stake the minimum amount of RPL, get slashed for one minipool, and still operate the others without having the minimum RPL needed to run the minipools staked (getNodeMinipoolLimit).",
        "The RPL stake is donated to the RocketAuctionManager, where they can attempt to buy back RPL potentially at a discount.",
        "Note: Staking more RPL (e.g., to add another Minipool) resets the cooldown period for the total RPL staked (not only for the newly added)"
    ],
    "Recommendation": [
        "It is recommended to redesign the withdrawal process to prevent users from withdrawing their stake while slashable actions can still occur. A potential solution may be to add a locking period in the process. A node operator may schedule the withdrawal of funds, and after a certain time has passed, may withdraw them. This prevents the immediate withdrawal of funds that may need to be reduced while slashable events can still occur. E.g.:"
    ]
}
----End JSON----

https://solodit.xyz/issues/rockettokenrpl-inaccurate-inflation-rate-and-potential-for-manipulation-lowering-the-real-apy-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getInlfationIntervalsPassed() override public view returns(uint256) {\n    // The block that inflation was last calculated at\n    uint256 inflationLastCalculatedBlock = getInflationCalcBlock();\n    // Get the daily inflation in blocks\n    uint256 inflationInterval = getInflationIntervalBlocks();\n    // Calculate now if inflation has begun\n    if(inflationLastCalculatedBlock > 0) {\n        return (block.number).sub(inflationLastCalculatedBlock).div(inflationInterval);\n    }else{\n        return 0;\n    }\n}\n\n",
        "function inflationCalculate() override public view returns (uint256) {\n    // The inflation amount\n    uint256 inflationTokenAmount = 0;\n    // Optimisation\n    uint256 inflationRate = getInflationIntervalRate();\n    // Compute the number of inflation intervals elapsed since the last time we minted infation tokens\n    uint256 intervalsSinceLastMint = getInlfationIntervalsPassed();\n    // Only update if last interval has passed and inflation rate is > 0\n    if(intervalsSinceLastMint > 0 && inflationRate > 0) {\n        // Our inflation rate\n        uint256 rate = inflationRate;\n        // Compute inflation for total inflation intervals elapsed\n        for (uint256 i = 1; i < intervalsSinceLastMint; i++) {\n            rate = rate.mul(inflationRate).div(10 \\*\\* 18);\n        }\n        // Get the total supply now\n        uint256 totalSupplyCurrent = totalSupply();\n        // Return inflation amount\n        inflationTokenAmount = totalSupplyCurrent.mul(rate).div(10 \\*\\* 18).sub(totalSupplyCurrent);\n    }\n    // Done\n    return inflationTokenAmount;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The main issue was addressed in branch rp3.0-updates (rocket-pool/[email\u00a0protected]b424ca1) by recording the timestamp up to when inflation was updated to instead of the current block timestamp (lastTimeOfInflationMint + interval * inflationIntervals)."
    ],
    "Description": [
        "RocketTokenRPL allows users to swap their fixed-rate tokens to the inflationary RocketTokenRPL ERC20 token via a swapToken function. The DAO defines the inflation rate of this token and is initially set to be 5% APY. This APY is configured as a daily inflation rate (APD) with the corresponding 1 day in blocks inflation interval in the rocketDAOProtocolSettingsInflation contract. The DAO members control the inflation settings.",
        "Anyone can call inflationMintTokens to inflate the token, which mints tokens to the contracts RocketVault. Tokens are minted for discreet intervals since the last time inflationMintTokens was called (recorded as inflationCalcBlock). The inflation is then calculated for the passed intervals without taking the current not yet completed interval. However, the inflationCalcBlock is set to the current block.number, effectively skipping some \u201ctime\u201d/blocks of the APY calculation.",
        "The more often inflationMintTokens is called, the higher the APY likelihood dropping below the configured 5%. In the worst case, one could manipulate the APY down to 2.45% (assuming that the APD for a 5% APY was configured) by calling inflationMintTokens close to the end of every second interval. This would essentially restart the APY interval at block.number, skipping blocks of the current interval that have not been accounted for.",
        "The following diagram illustrates the skipped blocks due to the incorrect recording of inflationCalcBlock as block.number. The example assumes that we are in interval 4 but have not completed it. 3 APD intervals have passed, and this is what the inflation rate is based on. However, the inflationCalcBlock is updated to the current block.number, skipping some time/blocks that are now unaccounted in the APY restarting the 4th interval at block.number.",
        ""
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/token/RocketTokenRPL.sol:L108-L119",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/token/RocketTokenRPL.sol:L126-L148"
    ],
    "Recommendation": [
        "Properly track inflationCalcBlock as the end of the previous interval, as this is up to where the inflation was calculated, instead of the block at which the method was invoked.",
        "Ensure APY/APD and interval configuration match up. Ensure the interval is not too small (potential gas DoS blocking inflation mint and RocketRewardsPool.claim)."
    ]
}
----End JSON----

https://solodit.xyz/issues/trusted-node-participation-risk-and-potential-client-optimizations-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The development team considers this issue fixed as monitoring on the correct behaviour of node software is added to the system."
    ],
    "Description": [
        "The system might end up in a stale state with minipools never being setWithdrawable or network and prices being severely outdated because trusted nodes don\u2019t fulfill their duty of providing oracle values. Minipools not being able to advance to the Withdrawable state will severely harm the system as no rewards can be paid out. Outdated balances and prices may affect token economics around the tokens involved (specifically rETH price depends on oracle observations).",
        "There is an incentive to be an oracle node as you get paid to provide oracle node duties when enrolled with the DAO. However, it is not enforced that nodes actually fulfill their duty of calling the respective onlyTrustedNode oracle functions to submit prices/balances/minipool rewards.",
        "Therefore, a smart Rocket Pool trusted node operator might consider patching their client software to not or only sporadically fulfill their duties to save considerable amounts of gas, making more profit than other trusted nodes would.",
        "There is no means to directly incentivize trusted nodes to call certain functions as they get their rewards anyway. The only risk they run is that other trusted nodes might detect their antisocial behavior and attempt to kick them out of the DAO. To detect this, monitoring tools and processes need to be established; it is questionable whether users would participate in high maintenance DAO operators.",
        "Furthermore, trusted nodes might choose to gas optimize their submissions to avoid calling the actual action once quorum was established. They can, for example, attempt to submit prices as early as possible, avoiding that they\u2019re the first to hit the 51% threshold."
    ],
    "Recommendation": [
        "Create monitoring tools and processes to detect participants that do not fulfill their trusted DAO duties. Create direct incentives for trusted nodes to provide oracle services by, e.g., recording their participation rate and only payout rewards based on how active they are."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaonodetrustedupgrade-upgrade-does-not-prevent-the-use-of-the-same-address-multiple-times-creating-an-inconsistency-where-getcontractaddress-returns-outdated-information-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " sets contract.exists.0xfefe=true\r\n sets contract.name.0xfefe=test\r\n sets contract.address.test=0xfefe\r\n sets contract.abi.test=abi\r\n\n",
        "sets contract.exists.0xbadbad=true\r\nsets contract.name.0xbadbad=badcontract\r\nsets contract.address.badcontract=0xbadbad\r\nsets contract.abi.badcontract=abi\r\n\n",
        "overwrites contract.exists.0xbadbad=true` (even though its already true)\r\nupdates contract.name.0xbadbad=test (overwrites the reference to badcontract; badcontracts config is now inconsistent)\r\nupdates contract.address.test=0xbadbad (ok, expected)\r\nupdates contract.abi.test=abi (ok, expected)\r\nremoves contract.name.0xfefe (ok)\r\nremoves contract.exists.0xfefe (ok)\r\n\n",
        "sets contract.exists.0xc0c0=true\r\nsets contract.name.0xc0c0=test (ok, expected)\r\nupdates contract.address.test=0xc0c0 (ok, expected)\r\nupdates contract.abi.test=abi (ok, expected)\r\nremoves contract.name.0xbadbad (the contract is still registered as badcontract, but is indirectly removed now)\r\nremoves contract.exists.0xbadbad (the contract is still registered as badcontract, but is indirectly removed now)\r\n\n",
        "(removed) contract.exists.0xbadbad\r\n(removed) contract.name.0xbadbad=badcontract\r\nsets contract.address.badcontract=0xbadbad\r\nsets contract.abi.badcontract=abi\r\n\n",
        "require(\\_contractAddress != address(0x0), \"Invalid contract address\");\n\n",
        "require(\\_contractAddress != address(0x0), \"Invalid contract address\");\nrequire(\\_contractAddress != oldContractAddress, \"The contract address cannot be set to its current address\");\n// Register new contract\nsetBool(keccak256(abi.encodePacked(\"contract.exists\", \\_contractAddress)), true);\nsetString(keccak256(abi.encodePacked(\"contract.name\", \\_contractAddress)), \\_name);\nsetAddress(keccak256(abi.encodePacked(\"contract.address\", \\_name)), \\_contractAddress);\nsetString(keccak256(abi.encodePacked(\"contract.abi\", \\_name)), \\_contractAbi);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "A check has been introduced to make sure that the new contract address is not already in use by checking against the corresponding contract.exists storage key."
    ],
    "Description": [
        "When adding a new contract, it is checked whether the address is already in use. This check is missing when upgrading a named contract to a new implementation, potentially allowing someone to register one address to multiple names creating an inconsistent configuration.",
        "The crux of this is, that, getContractAddress() will now return a contract address that is not registered anymore (while getContractName may throw). getContractAddress can therefore not relied upon when checking ACL.",
        "After this, badcontract is partially cleared, getContractName(0xbadbad) throws while getContractAddress(badcontract) returns 0xbadbad which is already unregistered (contract.exists.0xbadbad=false)"
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrustedUpgrade.sol:L76-L76",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrustedUpgrade.sol:L53-L59"
    ],
    "Recommendation": [
        "Check that the address being upgraded to is not yet registered and properly clean up contract.address.<name|abi>."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketpool-cli-lax-data-validation-and-output-sanitation-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    wg.Go(func() error {\n        var err error\n        timezoneLocation, err = GetNodeTimezoneLocation(rp, nodeAddress, opts)\n        return err\n    })\n\n    // Wait for data\n    if err := wg.Wait(); err != nil {\n        return NodeDetails{}, err\n    }\n\n    // Return\n    return NodeDetails{\n        Address: nodeAddress,\n        Exists: exists,\n        WithdrawalAddress: withdrawalAddress,\n        TimezoneLocation: timezoneLocation,\n    }, nil\n\n}\n\n",
        "for \\_, member := range members.Members {\n    fmt.Printf(\"--------------------\\n\")\n    fmt.Printf(\"\\n\")\n    fmt.Printf(\"Member ID: %s\\n\", member.ID)\n    fmt.Printf(\"Email address: %s\\n\", member.Email)\n    fmt.Printf(\"Joined at block: %d\\n\", member.JoinedBlock)\n    fmt.Printf(\"Last proposal block: %d\\n\", member.LastProposalBlock)\n    fmt.Printf(\"RPL bond amount: %.6f\\n\", math.RoundDown(eth.WeiToEth(member.RPLBondAmount), 6))\n    fmt.Printf(\"Unbonded minipools: %d\\n\", member.UnbondedValidatorCount)\n    fmt.Printf(\"\\n\")\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with v1.0.0-rc1 by sanitizing non-printables from strings stored in the smart contract.",
        "This effectively mitigates terminal-based control character injection attacks. However, might still be used to inject context-sensitive information that may be consumed by different protocols/presentation layers (web, terminal by displaying falsified information next to fields).",
        "E-mail and timezone format validation was introduced with https://github.com/rocket-pool/rocketpool-go/blob/c8738633ab973503b79c7dee5c2f78d7e44e48ae/dao/trustednode/proposals.go#L22 and rocket-pool/[email\u00a0protected]6e72501.",
        "It is recommended to further tighten the checks on untrusted information enforcing an expected format of information and reject to interact with nodes/data that does not comply with the expected formats (e.g. email being in an email format, timezone information is a valid timezone, and does not contain extra information, \u2026)."
    ],
    "Description": [
        "ValidateTimezoneLocation and ValidateDAOMemberEmail are only used to validate user input from the command line. Timezone location information and member email addresses are stored in the smart contract\u2019s string storage, e.g., using the setTimezoneLocation function of the RocketNodeManager contract. This function only validates that a minimum length of 4 has been given.",
        "Through direct interaction with the contract, an attacker can submit arbitrary information, which is not validated on the CLI\u2019s side. With additional integrations of the Rocketpool smart contracts, the timezone location field may be used by an attacker to inject malicious code (e.g., for cross-site scripting attacks) or injecting false information (e.g. Balance: 1000 RPL or Status: Trusted), which is directly displayed on a user-facing application.",
        "On the command line, control characters such as newline characters can be injected to alter how text is presented to the user, effectively exploiting user trust in the official application."
    ],
    "Examples": [
        "rocketpool-go-2.5-Tokenomics/node/node.go:L134-L153",
        "smartnode-2.5-Tokenomics/rocketpool-cli/odao/members.go:L34-L44"
    ],
    "Recommendation": [
        "Validate user input before storing it on the blockchain. Validate and sanitize stored user tainted data before presenting it. Establish a register of data validation rules (e.g., email format, timezone format, etc.). Reject nodes operating with nodes that do not honor data validation rules.",
        "Validate the correct format of variables (e.g., timezone location, email, name, \u2026) on the storage level (if applicable) and the lowest level of the go library to offer developers a strong foundation to build on and mitigate the risk in future integrations. Furthermore, on-chain validation might not be implemented (due to increased gas consumption) should be mentioned in the developer documentation security section as they need to be handled with special caution by consumer applications. Sanitize output before presenting it to avoid control character injections in terminal applications or other presentation technologies (e.g., SQL or HTML).",
        "Review all usage of the fmt lib (especially Sprintf and string handling/concatenating functions). Ensure only sanitized data can reach this sink. Review the logging library and ensure it is hardened against control character injection by encoding non-printables and CR-LF."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketpool-cli-various-command-injection-vectors-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Initially, the client implemented the suggested fix using %q to dblquot user-provided data. While this recommendation mitigates some vectors it might still be susceptible to command injection attacks using backticks (as in bash dblquots do not prevent subcommand from being executed - backticks/$(cmd)) and the dblquot sequence may be terminated injecting a \" which is turned into a \\\". This was later changed to using golang shellEscape in https://github.com/rocket-pool/smartnode/compare/extra-escapes."
    ],
    "Description": [
        "Various commands in the Rocketpool CLI make use of the readOutput and printOutput functions. These do not perform sanitization of user-supplied inputs and allow an attacker to supply malicious values which can be used to execute arbitrary commands on the user\u2019s system."
    ],
    "Examples": [
        "All commands using the Client.readOutput, Client.printOutput and Client.compose functions are affected.",
        "",
        "Furthermore, Client.callAPI is used for API-related calls throughout the Rocketpool service. However, it does not validate that the values passed into it are valid API commands. This can lead to arbitrary command execution, also inside the container using docker exec."
    ],
    "Recommendation": [
        "Perform strict validation on all user-supplied parameters. If parameter values need to be inserted into a command template string, the %q format string or other restrictive equivalents should be used."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketstorage-risk-concentration-by-giving-all-registered-contracts-permissions-to-change-any-settings-in-rocketstorage-acknowledged-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier onlyLatestRocketNetworkContract() {\n    // The owner and other contracts are only allowed to set the storage upon deployment to register the initial contracts/settings, afterwards their direct access is disabled\n    if (boolStorage[keccak256(abi.encodePacked(\"contract.storage.initialised\"))] == true) {\n        // Make sure the access is permitted to only contracts in our Dapp\n        require(boolStorage[keccak256(abi.encodePacked(\"contract.exists\", msg.sender))], \"Invalid or outdated network contract\");\n    }\n    \\_;\n}\n\n\n",
        "function setAddress(bytes32 \\_key, address \\_value) onlyLatestRocketNetworkContract override external {\n    addressStorage[\\_key] = \\_value;\n}\n\n/// @param \\_key The key for the record\nfunction setUint(bytes32 \\_key, uint \\_value) onlyLatestRocketNetworkContract override external {\n    uIntStorage[\\_key] = \\_value;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client provided the following statement:"
    ],
    "Description": [
        "The ACL for changing settings in the centralized RocketStorage allows any registered contract (listed under contract.exists) to change settings that belong to other parts of the system.",
        "The concern is that if someone finds a way to add their malicious contract to the registered contact list, they will override any setting in the system. The storage is authoritative when checking certain ACLs. Being able to set any value might allow an attacker to gain control of the complete system. Allowing any contract to overwrite other contracts' settings dramatically increases the attack surface."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/RocketStorage.sol:L24-L32",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/RocketStorage.sol:L78-L85"
    ],
    "Recommendation": [
        "Allow contracts to only change settings related to their namespace."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaoproposals-require-a-minimum-participation-quorum-for-dao-proposals-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\\_votesRequired > 0, \"Proposal cannot have a 0 votes required to be successful\");\n\n",
        "function propose(string memory \\_proposalMessage, bytes memory \\_payload) override public onlyTrustedNode(msg.sender) onlyLatestContract(\"rocketDAONodeTrustedProposals\", address(this)) returns (uint256) {\n    // Load contracts\n    RocketDAOProposalInterface daoProposal = RocketDAOProposalInterface(getContractAddress('rocketDAOProposal'));\n    RocketDAONodeTrustedInterface daoNodeTrusted = RocketDAONodeTrustedInterface(getContractAddress('rocketDAONodeTrusted'));\n    RocketDAONodeTrustedSettingsProposalsInterface rocketDAONodeTrustedSettingsProposals = RocketDAONodeTrustedSettingsProposalsInterface(getContractAddress(\"rocketDAONodeTrustedSettingsProposals\"));\n    // Check this user can make a proposal now\n    require(daoNodeTrusted.getMemberLastProposalBlock(msg.sender).add(rocketDAONodeTrustedSettingsProposals.getCooldown()) <= block.number, \"Member has not waited long enough to make another proposal\");\n    // Record the last time this user made a proposal\n    setUint(keccak256(abi.encodePacked(daoNameSpace, \"member.proposal.lastblock\", msg.sender)), block.number);\n    // Create the proposal\n    return daoProposal.add(msg.sender, 'rocketDAONodeTrustedProposals', \\_proposalMessage, block.number.add(rocketDAONodeTrustedSettingsProposals.getVoteDelayBlocks()), rocketDAONodeTrustedSettingsProposals.getVoteBlocks(), rocketDAONodeTrustedSettingsProposals.getExecuteBlocks(), daoNodeTrusted.getMemberQuorumVotesRequired(), \\_payload);\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed by requiring the DAO minimum viable user count as the minium quorum with rocket-pool/[email\u00a0protected]11bc18c (in bootstrap mode). The check for the bootstrap mode has since been removed following our remark",
        "And the following feedback from the client:"
    ],
    "Description": [
        "If the DAO falls below the minimum viable membership threshold, voting for proposals still continues as DAO proposals do not require a minimum participation quorum. In the worst case, this would allow the last standing DAO member to create a proposal that would be passable with only one vote even if new members would be immediately ready to join via the recovery mode (which has its own risks) as the minimum votes requirement for proposals is set as >0.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/RocketDAOProposal.sol:L170-L170",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrustedProposals.sol:L57-L69",
        "Sidenote: Since a proposals acceptance quorum is recorded on proposal creation, this may lead to another scenario where proposals acceptance quorum may never be reached if members leave the DAO. This would require a re-submission of the proposal."
    ],
    "Recommendation": [
        "Do not accept proposals if the member count falls below the minimum DAO membercount threshold."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdaonodetrustedupgrade-inconsistent-upgrade-blacklist-addressed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_upgradeContract(string memory \\_name, address \\_contractAddress, string memory \\_contractAbi) internal {\n    // Check contract being upgraded\n    bytes32 nameHash = keccak256(abi.encodePacked(\\_name));\n    require(nameHash != keccak256(abi.encodePacked(\"rocketVault\")),        \"Cannot upgrade the vault\");\n    require(nameHash != keccak256(abi.encodePacked(\"rocketPoolToken\")),    \"Cannot upgrade token contracts\");\n    require(nameHash != keccak256(abi.encodePacked(\"rocketTokenRETH\")),     \"Cannot upgrade token contracts\");\n    require(nameHash != keccak256(abi.encodePacked(\"rocketTokenNETH\")), \"Cannot upgrade token contracts\");\n    require(nameHash != keccak256(abi.encodePacked(\"casperDeposit\")),      \"Cannot upgrade the casper deposit contract\");\n    // Get old contract address & check contract exists\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed in branch rp3.0-updates (rocket-pool/[email\u00a0protected]b424ca1) by updating the blacklist."
    ],
    "Description": [
        "upgradeContract defines a hardcoded list of contracts that cannot be upgraded because they manage their own settings (statevars) or they hold value in the system."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrustedUpgrade.sol:L41-L49"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/rocketdaonodetrustedactions-member-cannot-be-kicked-if-the-vault-does-not-hold-enough-rpl-to-cover-the-bond-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Addressed in branch rp3.0-updates (rocket-pool/[email\u00a0protected]b424ca1) by returning the bond if enough RPL is in the treasury and else continue without returning the bond. This way the member kick action does not block and the member can be kicked regardless of the RPL balance."
    ],
    "Description": [
        "If a DAO member behaves badly other DAO members may propose the node be evicted from the DAO. If for some reason, RocketVault does not hold enough RPL to pay back the DAO member bond actionKick will throw. The node is not evicted.",
        "Now this is a somewhat exotic scenario as the vault should always hold the bond for the members in the system. However, if the node was kicked for stealing RPL (e.g. passing an upgrade proposal to perform an attack) it might be impossible to execute the eviction."
    ],
    "Recommendation": [
        "Ensure that there is no way a node can influence a succeeded kick proposal to fail. Consider burning the bond (by keeping it) as there is a reason for evicting the node or allow them to redeem it in a separate step."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketminipoolstatus-dao-membership-changes-can-result-in-votes-getting-stuck-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n    setMinipoolWithdrawable(\\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance);\n}\n\n",
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n    updateBalances(\\_block, \\_totalEth, \\_stakingEth, \\_rethSupply);\n}\n\n",
        "RocketDAONodeTrustedInterface rocketDAONodeTrusted = RocketDAONodeTrustedInterface(getContractAddress(\"rocketDAONodeTrusted\"));\nif (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n    updatePrices(\\_block, \\_rplPrice);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been fixed in PR https://github.com/ConsenSys/rocketpool-audit-2021-03/issues/204 by introducing a public method that allows anyone to manually trigger a DAO consensus threshold check and a subsequent balance update in case the issue\u2019s example scenario occurs."
    ],
    "Description": [
        "Changes in the DAO\u2019s trusted node members are reflected in the RocketDAONodeTrusted.getMemberCount() function. When compared with the vote on consensus threshold, a DAO-driven decision is made, e.g., when updating token price feeds and changing Minipool states.",
        "Especially in the early phase of the DAO, the functions below can get stuck as execution is restricted to DAO members who have not voted yet. Consider the following scenario:",
        "Note: votes of members that are kicked/leave are still count towards the quorum!"
    ],
    "Examples": [
        "Setting a Minipool into the withdrawable state:",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolStatus.sol:L62-L65",
        "Submitting a block\u2019s network balances:",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/network/RocketNetworkBalances.sol:L94-L97",
        "Submitting a block\u2019s RPL price information:",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/network/RocketNetworkPrices.sol:L69-L72"
    ],
    "Recommendation": [
        "The conditional check and update of price feed information, Minipool state transition, etc., should be externalized into a separate public function. This function is also called internally in the existing code. In case the DAO gets into the scenario above, anyone can call the function to trigger a reevaluation of the condition with updated membership numbers and thus get the process unstuck."
    ]
}
----End JSON----

https://solodit.xyz/issues/trustedoracle-nodes-can-vote-multiple-times-for-different-outcomes-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Get submission keys\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, \\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance));\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.count\", \\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance));\n// Check & update node submission status\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\nsetBool(nodeSubmissionKey, true);\nsetBool(keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, \\_minipoolAddress)), true);\n// Increment submission count\nuint256 submissionCount = getUint(submissionCountKey).add(1);\nsetUint(submissionCountKey, submissionCount);\n\n",
        "// Get submission keys\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"network.balances.submitted.node\", msg.sender, \\_block, \\_totalEth, \\_stakingEth, \\_rethSupply));\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"network.balances.submitted.count\", \\_block, \\_totalEth, \\_stakingEth, \\_rethSupply));\n// Check & update node submission status\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\nsetBool(nodeSubmissionKey, true);\nsetBool(keccak256(abi.encodePacked(\"network.balances.submitted.node\", msg.sender, \\_block)), true);\n// Increment submission count\nuint256 submissionCount = getUint(submissionCountKey).add(1);\nsetUint(submissionCountKey, submissionCount);\n// Emit balances submitted event\nemit BalancesSubmitted(msg.sender, \\_block, \\_totalEth, \\_stakingEth, \\_rethSupply, block.timestamp);\n// Check submission count & update network balances\n\n",
        "// Get submission keys\nbytes32 nodeSubmissionKey = keccak256(abi.encodePacked(\"network.prices.submitted.node\", msg.sender, \\_block, \\_rplPrice));\nbytes32 submissionCountKey = keccak256(abi.encodePacked(\"network.prices.submitted.count\", \\_block, \\_rplPrice));\n// Check & update node submission status\nrequire(!getBool(nodeSubmissionKey), \"Duplicate submission from node\");\nsetBool(nodeSubmissionKey, true);\nsetBool(keccak256(abi.encodePacked(\"network.prices.submitted.node\", msg.sender, \\_block)), true);\n// Increment submission count\nuint256 submissionCount = getUint(submissionCountKey).add(1);\nsetUint(submissionCountKey, submissionCount);\n// Emit prices submitted event\nemit PricesSubmitted(msg.sender, \\_block, \\_rplPrice, block.timestamp);\n// Check submission count & update network prices\n\n"
    ],
    "preamble": [],
    "Description": [
        "Trusted/oracle nodes submit various ETH2 observations to the RocketPool contracts. When 51% of nodes submitted the same observation, the result is stored in the contract. However, while it is recorded that a node already voted for a specific minipool (being withdrawable & balance) or block (price/balance), a re-submission with different parameters for the same minipool/block is not rejected.",
        "Since the oracle values should be distinct, clear, and there can only be one valid value, it should not be allowed for trusted nodes to change their mind voting for multiple different outcomes within one block or one minipool"
    ],
    "Examples": [
        "Note that setBool(keccak256(abi.encodePacked(\"minipool.withdrawable.submitted.node\", msg.sender, _minipoolAddress)), true);  is recorded but never checked. (as for the other two instances)",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolStatus.sol:L48-L57",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/network/RocketNetworkBalances.sol:L80-L92",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/network/RocketNetworkPrices.sol:L55-L67"
    ],
    "Recommendation": [
        "Only allow one vote per minipool/block. Don\u2019t give nodes the possibility to vote multiple times for different outcomes."
    ]
}
----End JSON----

https://solodit.xyz/issues/rockettokenneth-pot-discrepancy-between-minted-tokens-and-deposited-collateral-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (calcBase.mul(submissionCount).div(rocketDAONodeTrusted.getMemberCount()) >= rocketDAOProtocolSettingsNetwork.getNodeConsensusThreshold()) {\n    setMinipoolWithdrawable(\\_minipoolAddress, \\_stakingStartBalance, \\_stakingEndBalance);\n}\n\n",
        "uint256 nodeAmount = getMinipoolNodeRewardAmount(\n    minipool.getNodeFee(),\n    userDepositBalance,\n    minipool.getStakingStartBalance(),\n    minipool.getStakingEndBalance()\n);\n// Mint nETH to minipool contract\nif (nodeAmount > 0) { rocketTokenNETH.mint(nodeAmount, \\_minipoolAddress); }\n\n",
        "receive() external payable {\n    (bool success, bytes memory data) = getContractAddress(\"rocketMinipoolDelegate\").delegatecall(abi.encodeWithSignature(\"receiveValidatorBalance()\"));\n    if (!success) { revert(getRevertMessage(data)); }\n}\n\n",
        "require(msg.sender == rocketDAOProtocolSettingsNetworkInterface.getSystemWithdrawalContractAddress(), \"The minipool's validator balance can only be sent by the eth1 system withdrawal contract\");\n// Set validator balance withdrawn status\nvalidatorBalanceWithdrawn = true;\n// Process validator withdrawal for minipool\nrocketNetworkWithdrawal.processWithdrawal{value: msg.value}();\n\n",
        "uint256 totalShare = rocketMinipoolManager.getMinipoolWithdrawalTotalBalance(msg.sender);\nuint256 nodeShare = rocketMinipoolManager.getMinipoolWithdrawalNodeBalance(msg.sender);\nuint256 userShare = totalShare.sub(nodeShare);\n// Get withdrawal amounts based on shares\nuint256 nodeAmount = 0;\nuint256 userAmount = 0;\nif (totalShare > 0) {\n    nodeAmount = msg.value.mul(nodeShare).div(totalShare);\n    userAmount = msg.value.mul(userShare).div(totalShare);\n}\n// Set withdrawal processed status\nrocketMinipoolManager.setMinipoolWithdrawalProcessed(msg.sender);\n// Transfer node balance to nETH contract\nif (nodeAmount > 0) { rocketTokenNETH.depositRewards{value: nodeAmount}(); }\n// Transfer user balance to rETH contract or deposit pool\n\n",
        "uint256 nethBalance = rocketTokenNETH.balanceOf(address(this));\nif (nethBalance > 0) {\n    // Get node withdrawal address\n    RocketNodeManagerInterface rocketNodeManager = RocketNodeManagerInterface(getContractAddress(\"rocketNodeManager\"));\n    address nodeWithdrawalAddress = rocketNodeManager.getNodeWithdrawalAddress(nodeAddress);\n    // Transfer\n    require(rocketTokenNETH.transfer(nodeWithdrawalAddress, nethBalance), \"nETH balance was not successfully transferred to node operator\");\n    // Emit nETH withdrawn event\n    emit NethWithdrawn(nodeWithdrawalAddress, nethBalance, block.timestamp);\n}\n\n",
        "function depositRewards() override external payable onlyLatestContract(\"rocketNetworkWithdrawal\", msg.sender) {\n    // Emit ether deposited event\n    emit EtherDeposited(msg.sender, msg.value, block.timestamp);\n}\n\n// Mint nETH\n// Only accepts calls from the RocketMinipoolStatus contract\nfunction mint(uint256 \\_amount, address \\_to) override external onlyLatestContract(\"rocketMinipoolStatus\", msg.sender) {\n    // Check amount\n    require(\\_amount > 0, \"Invalid token mint amount\");\n    // Update balance & supply\n    \\_mint(\\_to, \\_amount);\n    // Emit tokens minted event\n    emit TokensMinted(\\_to, \\_amount, block.timestamp);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue is obsoleted by the fact that the nETH contract was removed completely. The client provided the following statement:"
    ],
    "Description": [
        "The nETH token is paid to node operators when minipool becomes withdrawable. nETH is supposed to be backed by ETH 1:1. However, in most cases, this will not be the case.",
        "The nETH minting and deposition of collateral happens in two different stages of a minipool. nETH is minted in the minipool state transition from Staking to Withdrawable when the trusted/oracle nodes find consensus on the fact that the minipool became withdrawable (submitWinipoolWithdrawable).",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolStatus.sol:L63-L65",
        "When consensus is found on the state of the minipool, nETH tokens are minted to the minipool address according to the withdrawal amount observed by the trusted/oracle nodes. At this stage, ETH backing the newly minted nETH was not yet provided.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolStatus.sol:L80-L87",
        "The nETH token contract now holds more nETH.totalsupply than actual ETH collateral. It is out of sync with the ETH reserve and therefore becomes undercollateralized. This should generally be avoided as the security guarantees that for every nETH someone deposited, ETH does not hold. However, the newly minted nETH is locked to the minipoolAddress, and the minipool has no means of redeeming the nETH for ETH directly (via nETH.burn()).",
        "The transition from Withdrawable to Destroyed the actual collateral for the previously minted nETH (still locked to minipoolAddress) is provided by the Eth2 withdrawal contract. There is no specification for the withdrawal contract as of now. Still, it is assumed that some entity triggers the payout for the Eth2 rewards on the withdrawal contract, which sends the amount of ETH to the configured withdrawal address (the minipoolAddress).",
        "The minipool.receive() function receives the ETH",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipool.sol:L109-L112",
        "and forwards it to minipooldelegate.receiveValidatorBalance",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolDelegate.sol:L227-L231",
        "Which calculates the nodeAmount based on the ETH received and submits it as collateral to back the previously minted nodeAmount of nETH.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/network/RocketNetworkWithdrawal.sol:L46-L60",
        "Looking at how the nodeAmount of nETH that was minted was calculated and comparing it to how nodeAmount of ETH is calculated, we can observe the following:",
        "The nETH minted is initially uncollateralized and locked to the minipoolAddress, which cannot directly redeem it for ETH. The next step (next stage) is collateralized with the staking rewards (which, as noted, might not always completely add up to the minted nETH). At the last step in withdraw(), the nETH is transferred to the withdrawalAddress of the minipool.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolDelegate.sol:L201-L210",
        "Since the nETH initially minted can never take part in the nETH token market (as it is locked to the minipool address, which can only transfer it to the withdrawal address in the last step), the question arises why it is actually minted early in the lifecycle of the minipool. At the same time, it could as well be just directly minted to withdrawalAddress when providing the right amount of collateral in the last step of the minipool lifecycle. Furthermore, if nETH is minted at this stage, it should be questioned why nETH is actually needed when you can directly forward the nodeAmount to the withdrawalAddress instead of minting an intermediary token that is pegged 1:1 to ETH.",
        "For reference, depositRewards (providing collateral) and mint are not connected at all, hence the risk of nETH being an undercollateralized token.",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/token/RocketTokenNETH.sol:L28-L42"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/rocketminipooldelegate-on-destroy-leftover-eth-is-sent-to-rocketvault-where-it-cannot-be-recovered-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Destroy the minipool\nfunction destroy() private {\n    // Destroy minipool\n    RocketMinipoolManagerInterface rocketMinipoolManager = RocketMinipoolManagerInterface(getContractAddress(\"rocketMinipoolManager\"));\n    rocketMinipoolManager.destroyMinipool();\n    // Self destruct & send any remaining ETH to vault\n    selfdestruct(payable(getContractAddress(\"rocketVault\")));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Leftover ETH is now sent to the node operator address as expected.",
        "https://github.com/ConsenSys/rocketpool-audit-2021-03/blob/0a5f680ae0f4da0c5639a241bd1605512cba6004/rocketpool-rp3.0-updates/contracts/contract/minipool/RocketMinipoolDelegate.sol#L294"
    ],
    "Description": [
        "When destroying the MiniPool, leftover ETH is sent to the RocketVault. Since RocketVault has no means to recover \u201cunaccounted\u201d ETH (not deposited via depositEther), funds forcefully sent to the vault will end up being locked."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolDelegate.sol:L314-L321"
    ],
    "Recommendation": [
        "Implement means to recover and reuse ETH that was forcefully sent to the contract by MiniPool instances."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketdao-personally-identifiable-member-information-pii-stored-on-chain-acknowledged-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Return\nreturn MemberDetails{\n    Address: memberAddress,\n    Exists: exists,\n    ID: id,\n    Email: email,\n    JoinedBlock: joinedBlock,\n    LastProposalBlock: lastProposalBlock,\n    RPLBondAmount: rplBondAmount,\n    UnbondedValidatorCount: unbondedValidatorCount,\n}, nil\n\n",
        "function getMemberEmail(address \\_nodeAddress) override public view returns (string memory) {\n    return getString(keccak256(abi.encodePacked(daoNameSpace, \"member.email\", \\_nodeAddress))); \n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Acknowledged with the following statement:"
    ],
    "Description": [
        "Like a DAO user\u2019s e-mail address, PII is stored on-chain and can, therefore, be accessed by anyone. This may allow de-pseudonymize users (and correlate Ethereum addresses to user email addresses) and be used for spamming or targeted phishing campaigns putting the DAO users at risk."
    ],
    "Examples": [
        "rocketpool-go-2.5-Tokenomics/dao/trustednode/dao.go:L173-L183",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/dao/node/RocketDAONodeTrusted.sol:L110-L112"
    ],
    "Recommendation": [
        "Avoid storing PII on-chain where it is readily available for anyone."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketpool-cli-insecure-ssh-hostkeycallback-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "HostKeyCallback: ssh.InsecureIgnoreHostKey(),\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "A proper host key callback function to validate the remote party\u2019s authenticity is now defined.",
        "https://github.com/ConsenSys/rocketpool-audit-2021-03/blob/0a5f680ae0f4da0c5639a241bd1605512cba6004/smartnode-1.0.0-rc1/shared/services/rocketpool/client.go#L114-L117"
    ],
    "Description": [
        "The SSH client factory returns instances that have an insecure HostKeyCallback set. This means that SSH servers' public key will not be validated and thus initialize a potentially insecure connection. The function should not be used for production code."
    ],
    "Examples": [
        "smartnode-2.5-Tokenomics/shared/services/rocketpool/client.go:L87"
    ]
}
----End JSON----

https://solodit.xyz/issues/deployment-docker-containers-running-as-root-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "# Start from ubuntu image\nFROM ubuntu:20.10\n\n# Install OS dependencies\nRUN apt-get update && apt-get install -y ca-certificates\n\n# Copy binary\nCOPY --from=builder /go/bin/rocketpool /go/bin/rocketpool\n\n# Container entry point\nENTRYPOINT [\"/go/bin/rocketpool\"]\n\n\n",
        "# Start from ubuntu image\nFROM ubuntu:20.10\n\n# Install OS dependencies\nRUN apt-get update && apt-get install -y ca-certificates\n\n# Copy binary\nCOPY --from=builder /go/bin/rocketpool-pow-proxy /go/bin/rocketpool-pow-proxy\n\n# Container entry point\nENTRYPOINT [\"/go/bin/rocketpool-pow-proxy\"]\n\n\n"
    ],
    "preamble": [],
    "Description": [
        "By default, Docker containers run commands as the root user. This means that there is little to no resistance for an attacker who has managed to break into the container and execute commands. This effectively negates file permissions already set into the system, such as storing wallet-related information with 0600 as an attacker will most likely drop into the container as root already."
    ],
    "Examples": [
        "Missing USER instructions affect both SmartNode Dockerfiles:",
        "smartnode-2.5-Tokenomics/docker/rocketpool-dockerfile:L25-L36",
        "smartnode-2.5-Tokenomics/docker/rocketpool-pow-proxy-dockerfile:L24-L35"
    ],
    "Recommendation": [
        "In the Dockerfiles, create an unprivileged user and use the USER instruction to switch. Only then, the entrypoint launching the SmartNode or the POW Proxy should be defined."
    ]
}
----End JSON----

https://solodit.xyz/issues/rocketpoolminipool-should-check-for-address0x0-fixed-consensys-rocketpool-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getContractAddress(string memory \\_contractName) private view returns (address) {\n    return rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\n}\n\n",
        "function getContractAddress(string memory \\_contractName) private view returns (address) {\n    return rocketStorage.getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\n}\n\n",
        "function getContractAddress(string memory \\_contractName) internal view returns (address) {\n    // Get the current contract address\n    address contractAddress = getAddress(keccak256(abi.encodePacked(\"contract.address\", \\_contractName)));\n    // Check it\n    require(contractAddress != address(0x0), \"Contract not found\");\n    // Return\n    return contractAddress;\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed in branch rp3.0-updates (rocket-pool/[email\u00a0protected]b424ca1) by changing requiring that the contract address is not 0x0."
    ],
    "Description": [
        "The two implementations for getContractAddress() in Minipool/Delegate are not checking whether the requested contract\u2019s address was ever set before. If it were never set, the method would return address(0x0), which would silently make all delegatecalls succeed without executing any code. In contrast, RocketBase.getContractAddress() fails if the requested contract is not known.",
        "It should be noted that this can happen if rocketMinipoolDelegate is not set in global storage, or it was cleared afterward, or if _rocketStorageAddress points to a contract that implements a non-throwing fallback function (may not even be storage at all)."
    ],
    "Examples": [
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipool.sol:L170-L172",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/minipool/RocketMinipoolDelegate.sol:L91-L93",
        "rocketpool-2.5-Tokenomics-updates/contracts/contract/RocketBase.sol:L84-L92"
    ],
    "Recommendation": [
        "Similar to RocketBase.getContractAddress() require that the contract is set."
    ]
}
----End JSON----

https://solodit.xyz/issues/esms-use-of-sanitized-user_amount-user_id-values-fixed-consensys-none-gitcoin-token-distribution-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "try:\n    int(user_id)\nexcept ValueError:\n    gtc_sig_app.logger.error('Invalid user_id received!')\n    return Response('{\"message\":\"ESMS error\"}', status=400, mimetype='application/json')\n# make sure it's an int\ntry:\n    int(user_amount)\nexcept ValueError:\n    gtc_sig_app.logger.error('Invalid user_amount received!')\n    return Response('{\"message\":\"ESMS error\"}', status=400, mimetype='application/json')\n\n",
        "try:\n    leaf = proofs[str(user_id)]['leaf']\n    proof = proofs[str(user_id)]['proof']\n    leaf_bytes = Web3.toBytes(hexstr=leaf)\n\n",
        "# this is a bit of hack to avoid bug in old web3 on frontend\n# this means that user_amount is not converted back to wei before tx is broadcast! \nuser_amount_in_eth = Web3.fromWei(user_amount, 'ether')\n\n",
        ">>> print(str(Web3.fromWei(123456789012345, 'ether')))\n0.000123456789012345\n>>> print(str(Web3.fromWei(123456789012345.123, 'ether')))\n0.000123456789012345125\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in https://github.com/nopslip/gtc-request-signer/pull/4/ , by using the sanitized integer value in the code flow."
    ],
    "Description": [
        "In the Signer service, values are properly checked, however the checked values are not preserved and the user input is passed down in the function.",
        "The values are sanitized here:",
        "code/gtc-request-signer-main-5eb22e882e28e6f3192b80f237f7a3bcd15b1ee9/app.py:L98-L108",
        "But the original user inputs are being used here:",
        "code/gtc-request-signer-main-5eb22e882e28e6f3192b80f237f7a3bcd15b1ee9/app.py:L110-L113",
        "code/gtc-request-signer-main-5eb22e882e28e6f3192b80f237f7a3bcd15b1ee9/app.py:L128-L131"
    ],
    "Examples": [
        "if a float amount is passed for user_amount, all checks will pass, however the final amount will be slightly different that what it is intended:"
    ],
    "Recommendation": [
        "After the sanity check, use the sanitized value for the rest of the code flow."
    ]
}
----End JSON----

https://solodit.xyz/issues/re-entrancy-issue-for-erc1155-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function distributeAllNFT() external {\n    require(block.timestamp > getEndLMTime(),\n        \"2 weeks after liquidity mining time has not expired\");\n    require(!isNFTDistributed, \"NFT is already distributed\");\n\n    for (uint256 i = 0; i < leaderboard.length; i++) {\n        address[] memory \\_groupLeaders = groupsLeaders[leaderboard[i]];\n\n        for (uint256 j = 0; j < \\_groupLeaders.length; j++) {\n            \\_sendNFT(j, \\_groupLeaders[j]);\n        }\n    }\n\n    for (uint256 i = 0; i < topUsers.length; i++) {\n        address \\_currentAddress = topUsers[i];\n        LMNFT.safeTransferFrom(address(this), \\_currentAddress, 1, 1, \"\");\n        emit NFTSent(\\_currentAddress, 1);\n    }\n\n    isNFTDistributed = true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed by moving isNFTDistributed = true; before the token transfers and only transferring tokens to the message sender."
    ],
    "Description": [
        "ERC1155 tokens have callback functions on some of the transfers, like safeTransferFrom, safeBatchTransferFrom. During these transfers, the IERC1155ReceiverUpgradeable(to).onERC1155Received function is called in the to address.",
        "For example, safeTransferFrom is used in the LiquidityMining contract:",
        "code/contracts/LiquidityMining.sol:L204-L224",
        "During that transfer, the distributeAllNFT  function can be called again and again. So multiple transfers will be done for each user.",
        "In addition to that, any receiver of the tokens can revert the transfer. If that happens, nobody will be able to receive their tokens."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/winning-pods-can-be-frontrun-with-large-deposits-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function depositTo(address to, uint256 tokenAmount)\n    external\n    override\n    returns (uint256)\n{\n    require(tokenAmount > 0, \"Pod:invalid-amount\");\n\n    // Allocate Shares from Deposit To Amount\n    uint256 shares = \\_deposit(to, tokenAmount);\n\n    // Transfer Token Transfer Message Sender\n    IERC20Upgradeable(token).transferFrom(\n        msg.sender,\n        address(this),\n        tokenAmount\n    );\n\n    // Emit Deposited\n    emit Deposited(to, tokenAmount, shares);\n\n    // Return Shares Minted\n    return shares;\n}\n\n",
        "modifier pauseDepositsDuringAwarding() {\n    require(\n        !IPrizeStrategyMinimal(\\_prizePool.prizeStrategy()).isRngRequested(),\n        \"Cannot deposit while prize is being awarded\"\n    );\n    \\_;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Pod.depositTo() grants users shares of the pod pool in exchange for tokenAmount of token.",
        "code/pods-v3-contracts/contracts/Pod.sol:L266-L288",
        "The winner of a prize pool is typically determined by an off-chain random number generator, which requires a request to first be made on-chain. The result of this RNG request can be seen in the mempool and frontrun. In this case, an attacker could identify a winning Pod contract and make a large deposit, diluting existing user shares and claiming the entire prize."
    ],
    "Recommendation": [
        "The modifier pauseDepositsDuringAwarding is included in the Pod contract but is unused.",
        "code/pods-v3-contracts/contracts/Pod.sol:L142-L148",
        "Add this modifier to the depositTo() function along with corresponding test cases."
    ]
}
----End JSON----

https://solodit.xyz/issues/token-transfers-may-return-false-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "There are a lot of token transfers in the code, and most of them are just calling transfer or transferFrom without checking the return value. Ideally, due to the ERC-20 token standard, these functions should always return True or False (or revert). If a token returns False, the code will process the transfer as if it succeeds."
    ],
    "Recommendation": [
        "Use the safeTransfer and the safeTransferFrom versions of transfers from OZ."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokendrop-unprotected-initialize-function-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function initialize(address \\_measure, address \\_asset) external {\n    measure = IERC20Upgradeable(\\_measure);\n    asset = IERC20Upgradeable(\\_asset);\n\n    // Set Factory Deployer\n    factory = msg.sender;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The TokenDrop.initialize() function is unprotected and can be called multiple times.",
        "code/pods-v3-contracts/contracts/TokenDrop.sol:L81-L87",
        "Among other attacks, this would allow an attacker to re-initialize any TokenDrop with the same asset and a malicious measure token. By manipulating the balance of a user in this malicious measure token, the entire asset token balance of the TokenDrop contract could be drained."
    ],
    "Recommendation": [
        "Add the initializer modifier to the initialize() function and include an explicit test that every initialization function in the system can be called once and only once."
    ]
}
----End JSON----

https://solodit.xyz/issues/pod-re-entrancy-during-deposit-or-withdrawal-can-lead-to-stealing-funds-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 shares = \\_deposit(to, tokenAmount);\n\n// Transfer Token Transfer Message Sender\nIERC20Upgradeable(token).transferFrom(\n    msg.sender,\n    address(this),\n    tokenAmount\n);\n\n"
    ],
    "preamble": [],
    "Description": [
        "During the deposit, the token transfer is made after the Pod shares are minted:",
        "code/pods-v3-contracts/contracts/Pod.sol:L274-L281",
        "That means that if the token allows re-entrancy, the attacker can deposit one more time inside the token transfer. If that happens, the second call will mint more tokens than it is supposed to, because the first token transfer will still not be finished.\nBy doing so with big amounts, it\u2019s possible to drain the pod."
    ],
    "Recommendation": [
        "Add re-entrancy guard to the external functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokendrop-re-entrancy-in-the-claim-function-can-cause-to-draining-funds-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function claim(address user) external returns (uint256) {\n    drop();\n    \\_captureNewTokensForUser(user);\n    uint256 balance = userStates[user].balance;\n    userStates[user].balance = 0;\n    totalUnclaimed = uint256(totalUnclaimed).sub(balance).toUint112();\n\n    // Transfer asset/reward token to user\n    asset.transfer(user, balance);\n\n    // Emit Claimed\n    emit Claimed(user, balance);\n\n    return balance;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "If the asset token is making a call before the transfer to the receiver or to any other 3-d party contract (like it\u2019s happening in the Pod token using the _beforeTokenTransfer function), the attacker can call the drop function inside the transfer call here:",
        "code/pods-v3-contracts/contracts/TokenDrop.sol:L139-L153",
        "Because the totalUnclaimed is already changed, but the current balance is not, the drop function will consider the funds from the unfinished transfer as the new tokens. These tokens will be virtually redistributed to everyone.",
        "After that, the transfer will still happen, and further calls of the drop() function will fail because the following line will revert:",
        "uint256 newTokens = assetTotalSupply.sub(totalUnclaimed);",
        "That also means that any transfers of the Pod token will fail because they all are calling the drop function.\nThe TokenDrop will \u201cunfreeze\u201d only if someone transfers enough tokens to the TokenDrop contract.",
        "The severity of this issue is hard to evaluate because, at the moment, there\u2019s not a lot of tokens that allow this kind of re-entrancy."
    ],
    "Recommendation": [
        "Simply adding re-entrancy guard to the drop and the claim function won\u2019t help because the drop function is called from the claim. For that, the transfer can be moved to a separate function, and this function can have the re-entrancy guard as well as the drop function.",
        "Also, it\u2019s better to make sure that _beforeTokenTransfer will not revert to prevent the token from being frozen."
    ]
}
----End JSON----

https://solodit.xyz/issues/pod-having-multiple-token-drops-is-inconsistent-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setTokenDrop(address \\_token, address \\_tokenDrop)\n    external\n    returns (bool)\n{\n    require(\n        msg.sender == factory || msg.sender == owner(),\n        \"Pod:unauthorized-set-token-drop\"\n    );\n\n    // Check if target<>tokenDrop mapping exists\n    require(\n        drops[\\_token] == TokenDrop(0),\n        \"Pod:target-tokendrop-mapping-exists\"\n    );\n\n    // Set TokenDrop Referance\n    drop = TokenDrop(\\_tokenDrop);\n\n    // Set target<>tokenDrop mapping\n    drops[\\_token] = drop;\n\n    return true;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The Pod contract had the drop storage field and mapping of different TokenDrops (token => TokenDrop). When adding a new TokenDrop in the mapping, the drop field is also changed to the added _tokenDrop:",
        "code/pods-v3-contracts/contracts/Pod.sol:L455-L477",
        "On the other hand, the measure token and the asset token of the drop are strictly defined by the Pod contract. They cannot be changed, so all TokenDrops are supposed to have the same asset and measure tokens. So it is useless to have different TokenDrops."
    ],
    "Recommendation": [
        "The mapping seems to be unused, and only one TokenDrop will normally be in the system. If that code is not used, it should be deleted."
    ]
}
----End JSON----

https://solodit.xyz/issues/pod-fees-are-not-limited-by-a-user-during-the-withdrawal-consensys-pooltogether-pods-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (amount > currentBalance) {\n    // Calculate Withdrawl Amount\n    uint256 \\_withdraw = amount.sub(currentBalance);\n\n    // Withdraw from Prize Pool\n    uint256 exitFee = \\_withdrawFromPool(\\_withdraw);\n\n    // Add Exit Fee to Withdrawl Amount\n    amount = amount.sub(exitFee);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "When withdrawing from the Pod, the shares are burned, and the deposit is removed from the Pod. If there are not enough deposit tokens in the contract, the remaining tokens are withdrawn from the pool contract:",
        "code/pods-v3-contracts/contracts/Pod.sol:L523-L532",
        "These tokens are withdrawn with a fee from the pool, which is not controlled or limited by the user."
    ],
    "Recommendation": [
        "Allow users to pass a maxFee parameter to control fees."
    ]
}
----End JSON----

https://solodit.xyz/issues/random-task-execution-fixed-consensys-defi-saver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function executeOperation(\n    address[] memory \\_assets,\n    uint256[] memory \\_amounts,\n    uint256[] memory \\_fees,\n    address \\_initiator,\n    bytes memory \\_params\n) public returns (bool) {\n    require(msg.sender == AAVE\\_LENDING\\_POOL, ERR\\_ONLY\\_AAVE\\_CALLER);\n    require(\\_initiator == address(this), ERR\\_SAME\\_CALLER);\n\n    (Task memory currTask, address proxy) = abi.decode(\\_params, (Task, address));\n\n    // Send FL amounts to user proxy\n    for (uint256 i = 0; i < \\_assets.length; ++i) {\n        \\_assets[i].withdrawTokens(proxy, \\_amounts[i]);\n    }\n\n    address payable taskExecutor = payable(registry.getAddr(TASK\\_EXECUTOR\\_ID));\n\n    // call Action execution\n    IDSProxy(proxy).execute{value: address(this).balance}(\n        taskExecutor,\n        abi.encodeWithSelector(CALLBACK\\_SELECTOR, currTask, bytes32(\\_amounts[0] + \\_fees[0]))\n    );\n\n    // return FL\n    for (uint256 i = 0; i < \\_assets.length; i++) {\n        \\_assets[i].approveToken(address(AAVE\\_LENDING\\_POOL), \\_amounts[i] + \\_fees[i]);\n    }\n\n    return true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in DecenterApps/[email\u00a0protected]478e9cd by adding ReentrancyGuard to the executeOperation function."
    ],
    "Description": [
        "In a scenario where user takes a flash loan, _parseFLAndExecute() gives the flash loan wrapper contract (FLAaveV2, FLDyDx) the permission to execute functions on behalf of the user\u2019s DSProxy. This execution permission is revoked only after the entire recipe execution is finished, which means that in case that any of the external calls along the recipe execution is malicious, it might call executeAction() back and inject any task it wishes (e.g. take user\u2019s funds out, drain approved tokens, etc)"
    ],
    "Examples": [
        "code/contracts/actions/flashloan/FLAaveV2.sol:L105-L136"
    ],
    "Recommendation": [
        "A reentrancy guard (mutex) that covers the entire content of FLAaveV2.executeOperation/FLDyDx.callFunction should be used to prevent such attack."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokens-with-more-than-18-decimal-points-will-cause-issues-fixed-consensys-defi-saver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function getSellRate(address \\_srcAddr, address \\_destAddr, uint \\_srcAmount, bytes memory) public override view returns (uint rate) {\n        (rate, ) = KyberNetworkProxyInterface(KYBER\\_INTERFACE)\n            .getExpectedRate(IERC20(\\_srcAddr), IERC20(\\_destAddr), \\_srcAmount);\n\n        // multiply with decimal difference in src token\n        rate = rate \\* (10\\*\\*(18 - getDecimals(\\_srcAddr)));\n        // divide with decimal difference in dest token\n        rate = rate / (10\\*\\*(18 - getDecimals(\\_destAddr)));\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in DecenterApps/[email\u00a0protected]de22007 by using SafeMath.sub to revert on tokens with Decimal > 18"
    ],
    "Description": [
        "It is assumed that the maximum number of decimals for each token is 18. However uncommon, but it is possible to have tokens with more than 18 decimals, as an Example YAMv2 has 24 decimals. This can result in broken code flow and unpredictable outcomes (e.g. an underflow will result with really high rates)."
    ],
    "Examples": [],
    "Recommendation": [
        "Make sure the code won\u2019t fail in case the token\u2019s decimals is more than 18."
    ]
}
----End JSON----

https://solodit.xyz/issues/error-codes-of-compounds-comptrollerentermarket-comptrollerexitmarket-are-not-checked-fixed-consensys-defi-saver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function enterMarket(address \\_cTokenAddr) public {\n    address[] memory markets = new address[](1);\n    markets[0] = \\_cTokenAddr;\n\n    IComptroller(COMPTROLLER\\_ADDR).enterMarkets(markets);\n}\n\n/// @notice Exits the Compound market\n/// @param \\_cTokenAddr CToken address of the token\nfunction exitMarket(address \\_cTokenAddr) public {\n    IComptroller(COMPTROLLER\\_ADDR).exitMarket(\\_cTokenAddr);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in DecenterApps/[email\u00a0protected]7075e49 by reverting in the case the return value is non zero."
    ],
    "Description": [
        "Compound\u2019s enterMarket/exitMarket functions return an error code instead of reverting in case of failure.\nDeFi Saver smart contracts never check for the error codes returned from Compound smart contracts, although the code flow might revert due to unavailability of the CTokens, however early on checks for Compound errors are suggested."
    ],
    "Examples": [
        "code/contracts/actions/compound/helpers/CompHelper.sol:L26-L37"
    ],
    "Recommendation": [
        "Caller contract should revert in case the error code is not 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/reversed-order-of-parameters-in-allowance-function-call-fixed-consensys-defi-saver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function pullTokens(\n    address \\_token,\n    address \\_from,\n    uint256 \\_amount\n) internal returns (uint256) {\n    // handle max uint amount\n    if (\\_amount == type(uint256).max) {\n        uint256 allowance = IERC20(\\_token).allowance(address(this), \\_from);\n        uint256 balance = getBalance(\\_token, \\_from);\n\n        \\_amount = (balance > allowance) ? allowance : balance;\n    }\n\n    if (\\_from != address(0) && \\_from != address(this) && \\_token != ETH\\_ADDR && \\_amount != 0) {\n        IERC20(\\_token).safeTransferFrom(\\_from, address(this), \\_amount);\n    }\n\n    return \\_amount;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in DecenterApps/[email\u00a0protected]8b5657b by swapping the order of function call parameters."
    ],
    "Description": [
        "When trying to pull the maximum amount of tokens from an approver to the allowed spender, the parameters that are used for the allowance function call are not in the same order that is used later in the call to safeTransferFrom."
    ],
    "Examples": [
        "code/contracts/utils/TokenUtils.sol:L26-L44"
    ],
    "Recommendation": [
        "Reverse the order of parameters in allowance function call to fit the order that is in the safeTransferFrom function call."
    ]
}
----End JSON----

https://solodit.xyz/issues/full-test-suite-is-recommended-pending-consensys-defi-saver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "The test suite at this stage is not complete and many of the tests fail to execute. For complicated systems such as DeFi Saver, which uses many different modules and interacts with different DeFi protocols, it is crucial to have a full test coverage that includes the edge cases and failed scenarios. Especially this helps with safer future development and upgrading each modules.",
        "As we\u2019ve seen in some smart contract incidents, a complete test suite can prevent issues that might be hard to find with manual reviews.",
        "Some issues such as issue 5.4 could be caught by a full coverage test suite."
    ]
}
----End JSON----

https://solodit.xyz/issues/anyone-is-able-to-mint-nfts-by-calling-mintnftsforlm-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function mintNFTsForLM(address \\_liquidiyMiningAddr) external {\n    uint256[] memory \\_ids = new uint256[](NFT\\_TYPES\\_COUNT);\n    uint256[] memory \\_amounts = new uint256[](NFT\\_TYPES\\_COUNT);\n\n    \\_ids[0] = 1;\n    \\_amounts[0] = 5;\n\n    \\_ids[1] = 2;\n    \\_amounts[1] = 1 \\* LEADERBOARD\\_SIZE;\n\n    \\_ids[2] = 3;\n    \\_amounts[2] = 3 \\* LEADERBOARD\\_SIZE;\n\n    \\_ids[3] = 4;\n    \\_amounts[3] = 6 \\* LEADERBOARD\\_SIZE;\n\n    \\_mintBatch(\\_liquidiyMiningAddr, \\_ids, \\_amounts, \"\");\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed. Not an issue, as the contract is meant to be used as a mock."
    ],
    "Description": [
        "The contract LiquidityMiningNFT has the method mintNFTsForLM.",
        "code/contracts/LiquidityMiningNFT.sol:L12-L29",
        "However, this contract does not have any kind of special permissions to limit who is able to mint tokens.",
        "An attacker could call LiquidityMiningNFT.mintNFTsForLM(0xhackerAddress) to mint tokens for their address and sell them on the marketplace. They are also allowed to mint as many tokens as they want by calling the method multiple times."
    ],
    "Recommendation": [
        "Add some permissions to limit only some actors to mint tokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/liquidity-providers-can-create-deficit-of-dai-tokens-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Fixed by keeping all the DAI inside the PolicyBook."
    ],
    "Description": [
        "The current staking system is built in a way that a liquidity provider can stake DAIx tokens to the staking contract. By doing so, DAI tokens are getting withdrawn from the PolicyBook and there may be not enough funds to fulfill claims."
    ],
    "Recommendation": [
        "This issue requires major changes in the logic of the system."
    ]
}
----End JSON----

https://solodit.xyz/issues/profit-and-loss-distribution-mechanism-is-not-working-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Fixed by updating the totalLiquidity during claims and premium distribution."
    ],
    "Description": [
        "Liquidity providers should deposit DAI and receive DAIx in return; the initial rate of DAI to DAIx is 1. If claims are happening, the price of DAIx should decrease, and the loss should be distributed proportionally across the liquidity providers. If the policy is bought, the DAIx price should increase. Currently, it seems like the getDAIToDAIxRatio will always be zero because it\u2019s based on the totalLiquidity to the totalSupply() ratio. While the totalSupply() remains correct, the totalLiquidity is only modified when adding/removing liquidity. The totalLiquidity should represent the amount of DAI in the smart contract, which is the added liquidity + premium - claims. But the claims and premiums are not changing the totalLiquidity value.",
        "That error may also lead to the deficit of funds during withdrawals or claims."
    ],
    "Recommendation": [
        "Properly keep track of the totalLiquidity."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-liquidity-provider-can-withdraw-all-his-funds-anytime-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\n  WithdrawalStatus \\_status = getWithdrawalStatus(msg.sender);\n\n  require(\\_status == WithdrawalStatus.NONE || \\_status == WithdrawalStatus.EXPIRED,\n    \"PB: Can't request withdrawal\");\n\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n  uint256 \\_availableDaiBalance = balanceOf(msg.sender).mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n\n  if (block.timestamp < liquidityMining.getEndLMTime().add(neededTimeAfterLM)) {\n    \\_availableDaiBalance = \\_availableDaiBalance.sub(liquidityFromLM[msg.sender]);\n  }\n\n  require(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\n    \"PB: Not enough liquidity\");\n\n  require(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\n\n  WithdrawalInfo memory \\_newWithdrawalInfo;\n  \\_newWithdrawalInfo.amount = \\_tokensToWithdraw;\n  \\_newWithdrawalInfo.readyToWithdrawDate = block.timestamp.add(withdrawalPeriod);\n\n  withdrawalsInfo[msg.sender] = \\_newWithdrawalInfo;\n  emit RequestWithdraw(msg.sender, \\_tokensToWithdraw, \\_newWithdrawalInfo.readyToWithdrawDate);\n}\n\n",
        "function withdrawLiquidity() external override {\n  require(getWithdrawalStatus(msg.sender) == WithdrawalStatus.READY,\n    \"PB: Withdrawal is not ready\");\n\n  uint256 \\_tokensToWithdraw = withdrawalsInfo[msg.sender].amount;\n  uint256 \\_daiTokensToWithdraw = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n\n  if (withdrawalQueue.length != 0 || totalLiquidity.sub(\\_daiTokensToWithdraw) < totalCoverTokens) {\n    withdrawalQueue.push(msg.sender);\n  } else {\n    \\_withdrawLiquidity(msg.sender, \\_tokensToWithdraw);\n  }\n}\n\n",
        "require(totalLiquidity >= totalCoverTokens.add(\\_daiTokensToWithdraw),\n  \"PB: Not enough liquidity\");\n\nrequire(\\_availableDaiBalance >= \\_daiTokensToWithdraw, \"PB: Wrong announced amount\");\n\n",
        "withdrawalPeriod = 1 weeks;\nwithdrawalExpirePeriod = 2 days;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The funds are now locked when the withdrawal is requested, so funds cannot be transferred after the request, and this bug cannot be exploited anymore."
    ],
    "Description": [
        "Since some users provide liquidity to sell the insurance policies, it is important that these providers cannot withdraw their funds when the security breach happens and the policyholders are submitting claims. The liquidity providers can only request their funds first and withdraw them later (in a week).",
        "code/contracts/PolicyBook.sol:L358-L382",
        "code/contracts/PolicyBook.sol:L384-L396",
        "There is a restriction in requestWithdrawal that requires the liquidity provider to have enough funds at the moment of request:",
        "code/contracts/PolicyBook.sol:L371-L374",
        "But after the request is created, these funds can then be transferred to another address. When the request is created, the provider should wait for 7 days, and then there will be 2 days to withdraw the requested amount:",
        "code/contracts/PolicyBook.sol:L113-L114",
        "The attacker would have 4 addresses that will send the pool tokens to each other and request withdrawal of the full amount one by one every 2 days. So at least one of the addresses can withdraw all of the funds at any point in time. If the liquidity provider needs to withdraw funds immediately, he should transfer all funds to that address and execute the withdrawal."
    ],
    "Recommendation": [
        "One of the solutions would be to block the DAIx tokens from being transferred after the withdrawal request."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-buypolicyforaddliquidityfor-should-transfer-funds-from-msgsender-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function buyPolicyFor(\n  address \\_policyHolderAddr,\n  uint256 \\_epochsNumber,\n  uint256 \\_coverTokens   \n) external override {\n  \\_buyPolicyFor(\\_policyHolderAddr, \\_epochsNumber, \\_coverTokens);\n}\n\n",
        "function addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount) external override {\n  \\_addLiquidityFor(\\_liquidityHolderAddr, \\_liquidityAmount, false);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed by removing the buyPolicyFor function. And the addLiquidityFor function can only be called by the LiquidityMining contract."
    ],
    "Description": [
        "When calling the buyPolicyFor/addLiquidityFor functions, are called with the parameter _policyHolderAddr/_liquidityHolderAddr who is going to be the beneficiary in buying policy/adding liquidity:",
        "code/contracts/PolicyBook.sol:L183-L189",
        "code/contracts/PolicyBook.sol:L264-L266",
        "During the execution, the funds for the policy/liquidity are transferred from the _policyHolderAddr/_liquidityHolderAddr, while it\u2019s usually expected that they should be transferred from msg.sender. Because of that, anyone can call a function on behalf of a user that gave the allowance to the PolicyBook.",
        "For example, a user(victim) wants to add some DAI to the liquidity pool and gives allowance to the PolicyBook. After that, the user should call addLiquidity, but the attacker can front-run this transaction and buy a policy on behalf of the victim instead.",
        "Also, there is a curious edge case that makes this issue Critical: _policyHolderAddr/_liquidityHolderAddr parameters can be equal to the address of the PolicyBook contract. That may lead to multiple different dangerous attack vectors."
    ],
    "Recommendation": [
        "Make sure that nobody can transfer funds on behalf of the users if it\u2019s not intended."
    ]
}
----End JSON----

https://solodit.xyz/issues/liquiditymining-cant-accept-single-erc1155-tokens-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "contract LiquidityMining is ILiquidityMining, ERC1155Receiver, Ownable {\n\n",
        "function onERC1155Received(\n\n",
        "function onERC1155BatchReceived(\n\n",
        "function onERC1155Received(\n    address operator,\n    address from,\n    uint256 id,\n    uint256 value,\n    bytes memory data\n)\n    external\n    pure\n    override\n    returns(bytes4)\n{\n    return bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by properly implementing the ERC1155TokenReceiver  interface."
    ],
    "Description": [
        "The contract LiquidityMining is also defined as an ERC1155Receiver",
        "code/contracts/LiquidityMining.sol:L19",
        "The finalized EIP-1155 standard states that a contract which acts as an EIP-1155 Receiver must implement all the functions in the ERC1155TokenReceiver interface to be able to accept transfers.",
        "These are indeed implemented here:",
        "code/contracts/LiquidityMining.sol:L502",
        "code/contracts/LiquidityMining.sol:L517",
        "The standard states that they will be called and they MUST return a specific byte4 value, otherwise the transfer will fail.",
        "However one of the methods returns an incorrect value. This seems to an error generated by a copy/paste action.",
        "code/contracts/LiquidityMining.sol:L502-L515",
        "The value returned is equal to",
        "bytes4(keccak256(\"onERC1155BatchReceived(address,address,uint256[],uint256[],bytes)\"));",
        "But it should be",
        "bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\")).",
        "On top of this, the contract MUST implement the ERC-165 standard to correctly respond to supportsInterface."
    ],
    "Recommendation": [
        "Change the return value of onERC1155Received to be equal to 0xf23a6e61 which represents bytes4(keccak256(\"onERC1155Received(address,address,uint256,uint256,bytes)\")).",
        "Also, make sure to implement supportsInterface to signify support of ERC1155TokenReceiver to accept transfers.",
        "Add tests to check the functionality is correct and make sure these kinds of bugs do not exist in the future.",
        "Make sure to read the EIP-1155 and EIP-165 standards in detail and implement them correctly."
    ]
}
----End JSON----

https://solodit.xyz/issues/dai-is-assumed-to-have-the-same-price-as-daix-in-the-staking-contract-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_stakeDAIx(address \\_user, uint256 \\_amount, address \\_policyBookAddr) internal {\n    require (\\_amount > 0, \"BMIDAIStaking: Can't stake zero tokens\");\n\n    PolicyBook \\_policyBook = PolicyBook(\\_policyBookAddr);\n    // transfer DAI from PolicyBook to yield generator\n    daiToken.transferFrom(\\_policyBookAddr, address(defiYieldGenerator), \\_amount);            \n\n    // transfer bmiDAIx from user to staking\n    \\_policyBook.transferFrom(\\_user, address(this), \\_amount);       \n\n    \\_mintNFT(\\_user, \\_amount, \\_policyBook);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by not transferring DAI anymore."
    ],
    "Description": [
        "When a liquidity provider stakes tokens to the BMIDAIStaking contract, the equal amount of DAI and DAIx are transferred from the pool contract.",
        "code/contracts/BMIDAIStaking.sol:L113-L124"
    ],
    "Recommendation": [
        "Only the corresponding amount of DAI should be transferred to the pool."
    ]
}
----End JSON----

https://solodit.xyz/issues/updatewithdrawalqueue-can-run-out-of-gas-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_updateWithdrawalQueue() internal {\n  uint256 \\_availableLiquidity = totalLiquidity.sub(totalCoverTokens);\n  uint256 \\_countToRemoveFromQueue;\n\n  for (uint256 i = 0; i < withdrawalQueue.length; i++) {     \n    uint256 \\_tokensToWithdraw = withdrawalsInfo[withdrawalQueue[i]].amount;\n    uint256 \\_amountInDai = \\_tokensToWithdraw.mul(getDAIToDAIxRatio()).div(PERCENTAGE\\_100);\n\n    if (balanceOf(withdrawalQueue[i]) < \\_tokensToWithdraw) {\n      \\_countToRemoveFromQueue++;\n      continue;\n    }\n\n    if (\\_availableLiquidity >= \\_amountInDai) {\n      \\_withdrawLiquidity(withdrawalQueue[i], \\_tokensToWithdraw);\n      \\_availableLiquidity = \\_availableLiquidity.sub(\\_amountInDai);\n      \\_countToRemoveFromQueue++;\n    } else {\n      break;\n    }\n  }\n\n  \\_removeFromQueue(\\_countToRemoveFromQueue);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The updateWithdrawalQueuefunction is now limiting the number of processed withdrawals."
    ],
    "Description": [
        "When there\u2019s not enough collateral to withdraw liquidity from a policy book, the withdrawal request is added to a queue. The queue is supposed to be processed and cleared once there are enough funds for that. The only way to do so is the _updateWithdrawalQueue function that is caller when new liquidity is added:",
        "code/contracts/PolicyBook.sol:L315-L338",
        "The problem is that this function can only process all queue until the pool run out of available funds or the whole queue is going to be processed. If the queue is big enough, this process can be stuck."
    ],
    "Recommendation": [
        "Pass the parameter to the _updateWithdrawalQueue that defines how many requests to process in the queue per one call."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-policybook-should-make-dai-transfers-inside-the-contract-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function approveAllDaiTokensForStakingAndVotingAndTransferOwnership() internal {\n  daiToken.approve(address(bmiDaiStaking), MAX\\_INT);   \n  daiToken.approve(address(claimVoting), MAX\\_INT);    \n\n  transferOwnership(address(bmiDaiStaking));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The PolicyBook contract does not give the DAI allowance to anyone and token transfers are now done from the PolicyBook contract."
    ],
    "Description": [
        "The PolicyBook contract gives full allowance over DAI tokens to the other contracts:",
        "code/contracts/PolicyBook.sol:L120-L125",
        "That behavior is dangerous because it\u2019s hard to keep track of and control the contract\u2019s DAI balance. And it\u2019s also hard to track in the code where the balance of the PolicyBook can be changed from."
    ],
    "Recommendation": [
        "It\u2019s better to perform all the transfers inside the PolicyBook contract. So if the bmiDaiStaking and the claimVoting contracts need DAI tokens from the PolicyBook, they should call some function of the PolicyBook to perform transfers."
    ]
}
----End JSON----

https://solodit.xyz/issues/premium-is-payed-instantly-to-the-liquidity-providers-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The premium is now distributed on a daily basis."
    ],
    "Description": [
        "When the policy is bought, the premium is transferred to the PolicyBook instantly. Currently, these funds are not going to the liquidity providers as a reward due to the issue 5.3. But when the issue is fixed, it seems like the premium is paid and distributed as a reward instantly when the policy is purchased.",
        "The problem is that if someone buys the policy for a long period of time, every liquidity provider instantly gets the premium from the full period. If there\u2019s enough liquidity, any provider can withdraw the funds after that without taking a risk for this period."
    ],
    "Recommendation": [
        "Distribute the premium over time. For example, increase the reward after each epoch."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-totalcovertokens-is-only-updated-when-the-policy-is-bought-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_updateEpochsInfo() internal {\n  uint256 \\_totalEpochTime = block.timestamp.sub(epochStartTime);\n  uint256 \\_countOfPassedEpoch = \\_totalEpochTime.div(epochDuration);\n\n  uint256 \\_lastEpochUpdate = currentEpochNumber;\n  currentEpochNumber = \\_countOfPassedEpoch.add(1);\n\n  for (uint256 i = \\_lastEpochUpdate; i < currentEpochNumber; i++) {\n    totalCoverTokens = totalCoverTokens.sub(epochAmounts[i]);\n    delete epochAmounts[i];\n  }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The updateEpochsInfo function is now public and can be called by anyone."
    ],
    "Description": [
        "The totalCoverTokens value represents the amount of collateral that needs to be locked in the policy book. It should be changed either by buying a new policy or when an old policy expires. The problem is that when the old policy expires, this value is not updated; it is only updated when someone buys a policy by calling the _updateEpochsInfo  function:",
        "code/contracts/PolicyBook.sol:L240-L251",
        "Users waiting to withdraw liquidity should wait for someone to buy the policy to update the totalCoverTokens."
    ],
    "Recommendation": [
        "Make sure it\u2019s possible to call the _updateEpochsInfo function without buying a new policy."
    ]
}
----End JSON----

https://solodit.xyz/issues/unbounded-loops-in-liquiditymining-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < \\_teamsNumber; i++) {\n\n",
        "for (uint256 i = 0; i < \\_membersNumber; i++) {\n\n",
        "for (uint256 i = 0; i < \\_usersNumber; i++) {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by adding the limits."
    ],
    "Description": [
        "There are some methods that have unbounded loops and will fail when enough items exist in the arrays.",
        "code/contracts/LiquidityMining.sol:L83",
        "code/contracts/LiquidityMining.sol:L97",
        "code/contracts/LiquidityMining.sol:L110",
        "These methods will fail when lots of items will be added to them."
    ],
    "Recommendation": [
        "Consider adding limits (from, to) when requesting the items."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-_removefromqueue-is-very-gas-greedy-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_removeFromQueue(uint256 \\_countToRemove) internal {\n  for (uint256 i = 0; i < \\_countToRemove; i++) {\n    delete withdrawalsInfo[withdrawalQueue[i]];\n  }   \n\n  if (\\_countToRemove == withdrawalQueue.length) {\n    delete withdrawalQueue;\n  } else {\n    uint256 \\_remainingArrLength = withdrawalQueue.length.sub(\\_countToRemove);\n    address[] memory \\_remainingArr = new address[](\\_remainingArrLength);\n\n    for (uint256 i = 0; i < \\_remainingArrLength; i++) {\n      \\_remainingArr[i] = withdrawalQueue[i.add(\\_countToRemove)];\n    }\n\n    withdrawalQueue = \\_remainingArr;\n  }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The queue structure has changed significantly and became more optimized. On the other hand, the new structure has some overhead and can be simplified to optimize more gas."
    ],
    "Description": [
        "The _removeFromQueue function is supposed to remove _countToRemove elements from the queue:",
        "code/contracts/PolicyBook.sol:L296-L313",
        "This function uses too much gas, which makes it easier to make attacks on the system. Even if only one request is removed and executed, this function rewrites all the requests to the storage."
    ],
    "Recommendation": [
        "The data structure should be changed so this function shouldn\u2019t rewrite the requests that did not change.\nFor example, it can be a mapping (unit => address) with 2 indexes (start, end) that are only increasing."
    ]
}
----End JSON----

https://solodit.xyz/issues/withdrawal-with-zero-amount-is-possible-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function requestWithdrawal(uint256 \\_tokensToWithdraw) external override {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The _tokensToWithdraw  can now only be >0."
    ],
    "Description": [
        "When creating a withdrawal request, the amount of tokens to withdraw is passed as a parameter:",
        "code/contracts/PolicyBook.sol:L358",
        "The problem is that this parameter can be zero, and the function will be successfully executed. Moreover, this request can then be added to the queue, and the actual withdrawal will also be executed with zero value. Addresses that never added any liquidity could spam the system with these requests."
    ],
    "Recommendation": [
        "Do not allow withdrawals of zero tokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-withdrawal-queue-is-only-updated-when-the-liquidity-is-added-fixed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_addLiquidityFor(address \\_liquidityHolderAddr, uint256 \\_liquidityAmount, bool \\_isLM) internal {\n  daiToken.transferFrom(\\_liquidityHolderAddr, address(this), \\_liquidityAmount);   \n  \n  uint256 \\_amountToMint = \\_liquidityAmount.mul(PERCENTAGE\\_100).div(getDAIToDAIxRatio());\n  totalLiquidity = totalLiquidity.add(\\_liquidityAmount);\n  \\_mintERC20(\\_liquidityHolderAddr, \\_amountToMint);\n\n  if (\\_isLM) {\n    liquidityFromLM[\\_liquidityHolderAddr] = liquidityFromLM[\\_liquidityHolderAddr].add(\\_liquidityAmount);\n  }\n\n  \\_updateWithdrawalQueue();\n\n  emit AddLiquidity(\\_liquidityHolderAddr, \\_liquidityAmount, totalLiquidity);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The queue is now updated via the external function updateWithdrawalQueue but can only be called separately."
    ],
    "Description": [
        "Sometimes when the amount of liquidity is not much higher than the number of tokens locked for the collateral, it\u2019s impossible to withdraw liquidity. For a user that wants to withdraw liquidity, a withdrawal request is created. If the request can\u2019t be executed, it\u2019s added to the withdrawal queue, and the user needs to wait until there\u2019s enough collateral for withdrawal. There are potentially 2 ways to achieve that: either someone adds more liquidity or some existing policies expire.",
        "Currently, the queue can only be cleared when the internal _updateWithdrawalQueue  function is called. And it is only called in one place while adding liquidity:",
        "code/contracts/PolicyBook.sol:L276-L290"
    ],
    "Recommendation": [
        "It would be better if the queue could be processed when some policies expire without adding new liquidity. For example, there may be an external function that allows users to process the queue."
    ]
}
----End JSON----

https://solodit.xyz/issues/anyone-can-win-all-the-funds-from-the-liquiditymining-without-investing-any-dai-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function investDAI(uint256 \\_tokensAmount, address \\_policyBookAddr) external override {\n\n",
        "IPolicyBook(\\_policyBookAddr).addLiquidityFromLM(msg.sender, \\_tokensAmount);\n\n"
    ],
    "preamble": [],
    "Description": [
        "When a user decides to investDAI in the LiquidityMining contract, the policy book address is passed as a parameter:",
        "code_new/contracts/LiquidityMining.sol:L198",
        "But this parameter is never checked and only used at the end of the function:",
        "code_new/contracts/LiquidityMining.sol:L223",
        "The attacker can pass the address of a simple multisig that will process this transaction successfully without doing anything. And pretend to invest a lot of DAI without actually doing that to win all the rewards in the LiquidityMining contract."
    ],
    "Recommendation": [
        "Check that the pool address is valid."
    ]
}
----End JSON----

https://solodit.xyz/issues/liquidity-withdrawal-can-be-blocked-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "address \\_currentAddr = withdrawalQueue.head();\nuint256 \\_tokensToWithdraw = withdrawalsInfo[\\_currentAddr].withdrawalAmount;\n \nuint256 \\_amountInDAI = convertDAIXtoDAI(\\_tokensToWithdraw);\n \nif (\\_availableLiquidity < \\_amountInDAI) {\n  break;\n}\n\n",
        "} else if (\\_availableLiquidity < convertDAIXtoDAI(\\_tokensToWithdraw)) {\n  uint256 \\_availableDAIxTokens = convertDAIToDAIx(\\_availableLiquidity);\n  uint256 \\_currentWithdrawalAmount = \\_tokensToWithdraw.sub(\\_availableDAIxTokens);\n  withdrawalsInfo[\\_msgSender()].withdrawalAmount = \\_currentWithdrawalAmount;\n \n  aggregatedQueueAmount = aggregatedQueueAmount.add(\\_currentWithdrawalAmount);\n  withdrawalQueue.push(\\_msgSender());\n \n  \\_withdrawLiquidity(\\_msgSender(), \\_availableDAIxTokens);\n} else {\n\n"
    ],
    "preamble": [],
    "Description": [
        "The main problem in that issue is that the liquidity provider may face many potential issues when withdrawing the liquidity. Under some circumstances, a normal user will never be able to withdraw the liquidity. This issue consists of multiple factors that are interconnected and share the same solution.",
        "code_new/contracts/PolicyBook.sol:L444-L451",
        "But when the request is not in the queue, it can still be processed partially, and the rest of the locked tokens will wait in the queue.",
        "code_new/contracts/PolicyBook.sol:L581-L590",
        "If there\u2019s a huge request in the queue, it can become a bottleneck that does not allow others to withdraw even if there is enough free liquidity.",
        "The withdrawal can only be requested if there are enough free funds in the contract. But once these funds appear, the bots can instantly buy a policy, and for the normal users, it will be impossible to request the withdrawal. Even when a withdrawal is requested and then in the queue, the same problem appears at that stage."
    ],
    "Recommendation": [
        "One of the solutions would be to implement the following changes, but the team should thoroughly consider them:"
    ]
}
----End JSON----

https://solodit.xyz/issues/the-totalcovertokens-can-be-decreased-before-the-claim-is-committed-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "policyHolders[\\_msgSender()] = PolicyHolder(\\_coverTokens, currentEpochNumber,\n  \\_endEpochNumber, \\_totalPrice, \\_reinsurancePrice);\n\nepochAmounts[\\_endEpochNumber] = epochAmounts[\\_endEpochNumber].add(\\_coverTokens);\n\n",
        "uint256 \\_countOfPassedEpoch = block.timestamp.sub(epochStartTime).div(EPOCH\\_DURATION);\n\nnewTotalCoverTokens = totalCoverTokens;\nlastEpochUpdate = currentEpochNumber;\nnewEpochNumber = \\_countOfPassedEpoch.add(1);\n\nfor (uint256 i = lastEpochUpdate; i < newEpochNumber; i++) {\n  newTotalCoverTokens = newTotalCoverTokens.sub(epochAmounts[i]);     \n}\n\n",
        "function isPolicyActive(address \\_userAddr, address \\_policyBookAddr) public override view returns (bool) {\n  PolicyInfo storage \\_currentInfo = policyInfos[\\_userAddr][\\_policyBookAddr];\n\n  if (\\_currentInfo.endTime == 0) {\n    return false;\n  }\n\n  return \\_currentInfo.endTime.add(STILL\\_CLAIMABLE\\_FOR) > block.timestamp;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The totalCoverTokens is decreased right after the policy duration ends (_endEpochNumber). When that happens, the liquidity providers can withdraw their funds:",
        "code_new/contracts/PolicyBook.sol:L262-L265",
        "code_new/contracts/PolicyBook.sol:L343-L351",
        "On the other hand, the claim can be created while the policy is still \u201cactive\u201d. And is considered active until one week after the policy expired:",
        "code_new/contracts/PolicyRegistry.sol:L50-L58",
        "By the time when the claim is created + voted, the liquidity provider can potentially withdraw all of their funds already, and the claim will fail."
    ],
    "Recommendation": [
        "Make sure that there will always be enough funds for the claim."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-totalcovertokens-is-not-decreased-after-the-claim-happened-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "PolicyHolder storage holder = policyHolders[claimer];\n\nepochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\ntotalLiquidity = totalLiquidity.sub(claimAmount);\n\ndaiToken.transfer(claimer, claimAmount);\n               \ndelete policyHolders[claimer];\npolicyRegistry.removePolicy(claimer);\n\n"
    ],
    "preamble": [],
    "Description": [
        "When the claim happens and the policy is removed, the totalCoverTokens should be decreased instantly, that\u2019s why the scheduled reduction value is removed:",
        "code_new/contracts/PolicyBook.sol:L228-L236",
        "But the totalCoverTokens is not changed and will have the coverage from the removed policy forever."
    ],
    "Recommendation": [
        "Decrease the totalCoverTokens inside the commitClaim function."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-queue-remove-function-does-not-remove-the-item-completely-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function remove(UniqueAddressQueue storage baseQueue, address addrToRemove) internal returns (bool) {\n    if (!contains(baseQueue, addrToRemove)) {\n        return false;\n    }\n\n    if (baseQueue.HEAD == addrToRemove) {\n        return removeFirst(baseQueue);\n    }\n\n    if (baseQueue.TAIL == addrToRemove) {\n        return removeLast(baseQueue);\n    }\n\n    address prevAddr = baseQueue.queue[addrToRemove].prev;\n    address nextAddr = baseQueue.queue[addrToRemove].next;\n    baseQueue.queue[prevAddr].next = nextAddr;\n    baseQueue.queue[nextAddr].prev = prevAddr;\n    baseQueue.queueLength--;\n\n    return true;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "When removing an item in a queue, the following function is used:",
        "code_new/contracts/helpers/Queue.sol:L78-L98",
        "As the result, the baseQueue.queue[addrToRemove] is not deleted, so the contains function will still return True after the removal."
    ],
    "Recommendation": [
        "Remove the element from the queue completely."
    ]
}
----End JSON----

https://solodit.xyz/issues/optimization-issue-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 \\_tmpIndex = \\_currentIndex - 1;\nuint256 \\_currentUserAmount = usersTeamInfo[msg.sender].stakedAmount;\n \nwhile (\\_currentUserAmount > usersTeamInfo[topUsers[\\_tmpIndex]].stakedAmount) {\n    address \\_tmpAddr = topUsers[\\_tmpIndex];\n    topUsers[\\_tmpIndex] = msg.sender;\n    topUsers[\\_tmpIndex + 1] = \\_tmpAddr;\n \n    if (\\_tmpIndex == 0) {\n        break;\n    }\n \n    \\_tmpIndex--;\n}\n\n",
        "function \\_getAvailableMonthForReward(address \\_userAddr) internal view returns (uint256) {\n    uint256 \\_oneMonth = 30 days;\n    uint256 \\_startRewardTime = getEndLMTime();\n \n    uint256 \\_countOfRewardedMonth = countsOfRewardedMonth[usersTeamInfo[\\_userAddr].teamAddr][\\_userAddr];\n    uint256 \\_numberOfMonthForReward;\n \n    for (uint256 i = \\_countOfRewardedMonth; i < MAX\\_MONTH\\_TO\\_GET\\_REWARD; i++) {\n        if (block.timestamp > \\_startRewardTime.add(\\_oneMonth.mul(i))) {\n        \\_numberOfMonthForReward++;\n        } else {\n            break;\n        }\n    }\n \n    return \\_numberOfMonthForReward;\n}\n\n",
        "// Referral link => Address => count of rewarded month\nmapping (address => mapping (address => uint256)) public countsOfRewardedMonth;\n\n",
        "struct UserTeamInfo {\n    string teamName;\n    address teamAddr;\n \n    uint256 stakedAmount;\n    bool isNFTDistributed;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The codebase is huge, and there are still a lot of places where these complications and gas efficiency can be improved."
    ],
    "Examples": [
        "code_new/contracts/LiquidityMining.sol:L473-L486",
        "Instead of doing 2 operations per item that is lower than the new_item, same can be done with one operation: while topUsers[_tmpIndex] is lower than the new itemtopUsers[_tmpIndex + 1] = topUsers[_tmpIndex].",
        "code_new/contracts/LiquidityMining.sol:L351-L367",
        "code_new/contracts/LiquidityMining.sol:L60-L61",
        "code_new/contracts/LiquidityMining.sol:L42-L48",
        "Here the structure is created for every team member, duplicating the team name for each member."
    ],
    "Recommendation": [
        "Optimize and simplify the code."
    ]
}
----End JSON----

https://solodit.xyz/issues/proper-usage-of-the-transfer-and-the-transferfrom-functions-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "daiToken.transferFrom(\\_msgSender(), reinsurancePoolAddress, \\_reinsurancePrice);\ndaiToken.transferFrom(\\_msgSender(), address(this), \\_price);   \n\n",
        "function \\_unlockTokens(uint256 \\_amountToUnlock) internal {\n  this.transfer(\\_msgSender(), \\_amountToUnlock);\n  delete withdrawalsInfo[\\_msgSender()];\n}\n\n",
        "bmiToken.transfer(msg.sender, \\_userReward);\n\n"
    ],
    "preamble": [],
    "Description": [
        "Many ERC-20 transfers in the code are just called without checking the return values:",
        "code_new/contracts/PolicyBook.sol:L269-L270",
        "code_new/contracts/PolicyBook.sol:L556-L559",
        "code_new/contracts/LiquidityMining.sol:L278",
        "Even though the tokens in these calls are not arbitrary (DAI, BMI, DAIx, stkBMIToken) and probably always return True or call revert, it\u2019s still better to comply with the ERC-20 standard and make sure that the transfer went well."
    ],
    "Recommendation": [
        "The best solution would be better to always use the safe version of the transfers from openzeppelin/contracts/token/ERC20/SafeERC20.sol."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-price-and-the-duration-of-a-policy-may-be-unpredictable-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "When the user is buying a policy, the price is calculated based on the current liquidity/coverage ratio, and the duration is calculated based on the current timestamp. A malicious actor can front-run the buyer (e.g., buy short-term insurance with a huge coverage) and increase the policy\u2019s price. Or the transaction can be executed much later for some reason, and the number of the totalSeconds may be larger, the coverage period can be between _epochsNumber - 1 and _epochsNumber."
    ],
    "Recommendation": [
        "Given the unpredictability of the price, it\u2019s better to pass the hard limit for the insurance price as a parameter. Also, as an opinion, you can add a deadline for the transaction as a parameter."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-aggregatedqueueamount-value-is-used-inconsistently-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(\\_daiTokensToWithdraw),\n  \"PB: Not enough available liquidity\");\n\n"
    ],
    "preamble": [],
    "Description": [
        "The aggregatedQueueAmount variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal. When requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different:",
        "code_new/contracts/PolicyBook.sol:L539-L540",
        "That may lead to allowing the withdrawal request even if it shouldn\u2019t be allowed and the opposite."
    ],
    "Recommendation": [
        "Convert aggregatedQueueAmount to DAI in the _requestWithdrawal."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-claim-can-only-be-done-once-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function commitClaim(address claimer, uint256 claimAmount)\n  external \n  override\n  onlyClaimVoting\n  updateBMIDAIXStakingReward\n{\n  PolicyHolder storage holder = policyHolders[claimer];\n\n  epochAmounts[holder.endEpochNumber] = epochAmounts[holder.endEpochNumber].sub(holder.coverTokens);\n  totalLiquidity = totalLiquidity.sub(claimAmount);\n \n  daiToken.transfer(claimer, claimAmount);\n                 \n  delete policyHolders[claimer];\n  policyRegistry.removePolicy(claimer);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "When the claim happens, the policy is removed afterward:",
        "code_new/contracts/PolicyBook.sol:L222-L237",
        "If the claim amount is much lower than the coverage, the users are incentivized not to submit it and wait until the end of the coverage period to accumulate all the claims into one."
    ],
    "Recommendation": [
        "Allow the policyholders to submit multiple claims until the coverTokens is not reached."
    ]
}
----End JSON----

https://solodit.xyz/issues/users-are-incentivised-to-invest-right-before-the-getendlmtime-to-join-the-winning-team-consensys-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "When investing, there are 3 types of rewards in the LiquidityMining contracts: for the top users, for the top teams, for the group leaders in the top teams. EVERY member from the top teams is getting a reward proportional to the provided stake. Only the final snapshot of the stakes is used to determine the leaderboard which is right after the getEndLMTime.",
        "Everyone can join any team, and everyone\u2019s goal is to go to the winning teams. The best way to do so is to wait right until the end of the period and join the most beneficial team."
    ],
    "Recommendation": [
        "It\u2019s better to avoid extra incentives that create race conditions."
    ]
}
----End JSON----

https://solodit.xyz/issues/iethexchangeratestored-may-not-be-accurate-when-invoked-from-external-contracts-consensys-dforce-lending-protocol-review-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Gets balance of this contract in terms of the underlying\n \\*/\nfunction \\_getCurrentCash() internal view override returns (uint256) {\n    return address(this).balance.sub(msg.value);\n}\n\n",
        "// Check the iToken's supply capacity, -1 means no limit\nuint256 \\_totalSupplyUnderlying =\n    IERC20Upgradeable(\\_iToken).totalSupply().rmul(\n        IiToken(\\_iToken).exchangeRateStored()\n    );\nrequire(\n    \\_totalSupplyUnderlying.add(\\_mintAmount) <= \\_market.supplyCapacity,\n    \"Token supply capacity reached\"\n);\n\n",
        "(, uint256 \\_shortfall, , ) = calcAccountEquity(\\_borrower);\n\nrequire(\\_shortfall > 0, \"Account does not have shortfall\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed in commit 9876e3a by using a modifier to track the current msg.value of payable functions."
    ],
    "Description": [
        "iETH.exchangeRateStored returns the exchange rate of the contract as a function of the current cash of the contract. In the case of iETH, current cash is calculated as the contract\u2019s ETH balance minus msg.value:",
        "code/contracts/iETH.sol:L54-L59",
        "msg.value is subtracted because the majority of iETH methods are payable, and msg.value is implicitly added to a contract\u2019s balance before execution begins. If msg.value were not subtracted, the value sent with a call could be used to inflate the contract\u2019s exchange rate artificially.",
        "As part of execution, iETH makes calls to the Controller, which performs important checks using (among other things) the stored exchange rate. When exchangeRateStored is invoked from the Controller, the call context has a msg.value of 0. However, the msg.value sent by the initial iETH execution is still included in the contract\u2019s balance. This means that the Controller receives an exchange rate inflated by the initial call\u2019s msg.value."
    ],
    "Examples": [
        "This problem occurs in multiple locations in the Controller:",
        "code/contracts/Controller.sol:L670-L678",
        "code/contracts/Controller.sol:L917-L919"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/unbounded-loop-in-controllercalcaccountequity-allows-dos-on-liquidation-consensys-dforce-lending-protocol-review-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Calculate value of all collaterals\n// collateralValuePerToken = underlyingPrice \\* exchangeRate \\* collateralFactor\n// collateralValue = balance \\* collateralValuePerToken\n// sumCollateral += collateralValue\nuint256 \\_len = \\_accountData.collaterals.length();\nfor (uint256 i = 0; i < \\_len; i++) {\n    IiToken \\_token = IiToken(\\_accountData.collaterals.at(i));\n\n",
        "// Calculate all borrowed value\n// borrowValue = underlyingPrice \\* underlyingBorrowed / borrowFactor\n// sumBorrowed += borrowValue\n\\_len = \\_accountData.borrowed.length();\nfor (uint256 i = 0; i < \\_len; i++) {\n    IiToken \\_token = IiToken(\\_accountData.borrowed.at(i));\n\n"
    ],
    "preamble": [],
    "Description": [
        "Controller.calcAccountEquity calculates the relative value of a user\u2019s supplied collateral and their active borrow positions. Users may mark an arbitrary number of assets as collateral, and may borrow from an arbitrary number of assets. In order to calculate the value of both of these positions, this method performs two loops.",
        "First, to calculate the sum of the value of a user\u2019s collateral:",
        "code/contracts/Controller.sol:L1227-L1233",
        "Second, to calculate the sum of the value of a user\u2019s borrow positions:",
        "code/contracts/Controller.sol:L1263-L1268",
        "From dForce, we learned that 200 or more assets would be supported by the Controller. This means that a user with active collateral and borrow positions on all 200 supported assets could force any calcAccountEquity action to perform some 400 iterations of these loops, each with several expensive external calls."
    ],
    "Examples": [
        "By modifying dForce\u2019s unit test suite, we showed that an attacker could force the cost of calcAccountEquity above the block gas limit. This would prevent all of the following actions, as each relies on calcAccountEquity:",
        "The following actions would still be possible:",
        "As a result, an attacker may abuse the unbounded looping in calcAccountEquity to prevent the liquidation of underwater positions. We provided dForce with a PoC here: gist."
    ],
    "Recommendation": [
        "There are many possible ways to address this issue. Some ideas have been outlined below, and it may be that a combination of these ideas is the best approach:",
        "In general, cap the number of markets and borrowed assets a user may have: The primary cause of the DoS is that the number of collateral and borrow positions held by a user is only restricted by the number of supported assets. The PoC provided above showed that somewhere around 150 collateral positions and 150 borrow positions, the gas costs of calcAccountEquity use most of the gas in a block. Given that gas prices often spike along with turbulent market conditions and that liquidations are far more likely in turbulent market conditions, a cap on active markets / borrows should be much lower than 150 each so as to keep the cost of liquidations as low as possible.",
        "dForce should perform their own gas cost estimates to determine a cap, and choose a safe, low value. Estimates should be performed on the high-level liquidateBorrow method, so as to simulate an actual liquidation event. Additionally, estimates should factor in a changing block gas limit, and the possibility of opcode gas costs changing in future forks. It may be wise to make this cap configurable, so that the limits may be adjusted for future conditions."
    ]
}
----End JSON----

https://solodit.xyz/issues/fix-utilization-rate-computation-and-respect-reserves-when-lending-consensys-dforce-lending-protocol-review-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Calculate the utilization rate: `\\_borrows / (\\_cash + \\_borrows - \\_reserves)`\n \\* @param \\_cash Asset balance\n \\* @param \\_borrows Asset borrows\n \\* @param \\_reserves Asset reserves\n \\* @return Asset utilization [0, 1e18]\n \\*/\nfunction utilizationRate(\n    uint256 \\_cash,\n    uint256 \\_borrows,\n    uint256 \\_reserves\n) internal pure returns (uint256) {\n    // Utilization rate is 0 when there are no borrows\n    if (\\_borrows == 0) return 0;\n\n    return \\_borrows.mul(BASE).div(\\_cash.add(\\_borrows).sub(\\_reserves));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The dForce team has informed us that the only two interest rate models that are still in use are StablecoinInterestRateModel and StandardInterestRateModel. For these, recommendation 2 has been addressed in commits 2a0e974 and c11fa9b."
    ],
    "Description": [
        "The utilization rate UR of an asset forms the basis for interest calculations and is defined as borrows / ( borrows + cash - reserves).",
        "code/contracts/InterestRateModel/InterestRateModel.sol:L72-L88",
        "The implicit assumption here is that reserves <= cash; in this case \u2014 and if we define UR as 0 for borrows == 0 \u2014 we have 0 <= UR <=1. We can view cash - reserves as \u201cavailable cash\u201d.\nHowever, the system does not guarantee that reserves never exceeds cash. If reserves > cash (and borrows + cash - reserves > 0), the formula for UR above gives a utilization rate above 1. This doesn\u2019t make much sense conceptually and has undesirable technical consequences; an especially severe one is analyzed in issue 4.4."
    ],
    "Recommendation": [
        "If reserves > cash \u2014 or, in other words, available cash is negative \u2014 this means part of the reserves have been borrowed, which ideally shouldn\u2019t happen in the first place. However, the reserves grow automatically over time, so it might be difficult to avoid this entirely. We recommend (1) avoiding this situation whenever it is possible and (2) fixing the UR computation such that it deals more gracefully with this scenario. More specifically:"
    ],
    "Remark": [
        "Internally, the utilization rate and other fractional values are scaled by 1e18. The discussion above has a more conceptual than technical perspective, so we used unscaled numbers. When making changes to the code, care must be taken to apply the scaling."
    ]
}
----End JSON----

https://solodit.xyz/issues/if-base_updateinterest-fails-the-entire-system-will-halt-consensys-dforce-lending-protocol-review-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_updateInterest() internal virtual override {\n    InterestLocalVars memory \\_vars;\n    \\_vars.currentCash = \\_getCurrentCash();\n    \\_vars.totalBorrows = totalBorrows;\n    \\_vars.totalReserves = totalReserves;\n\n    // Gets the current borrow interest rate.\n    \\_vars.borrowRate = interestRateModel.getBorrowRate(\n        \\_vars.currentCash,\n        \\_vars.totalBorrows,\n        \\_vars.totalReserves\n    );\n    require(\n        \\_vars.borrowRate <= maxBorrowRate,\n        \"\\_updateInterest: Borrow rate is too high!\"\n    );\n\n",
        "/\\*\\*\n \\* @dev Sets a new interest rate model.\n \\* @param \\_newInterestRateModel The new interest rate model.\n \\*/\nfunction \\_setInterestRateModel(\n    IInterestRateModelInterface \\_newInterestRateModel\n) external virtual onlyOwner settleInterest {\n    // Gets current interest rate model.\n    IInterestRateModelInterface \\_oldInterestRateModel = interestRateModel;\n\n    // Ensures the input address is the interest model contract.\n    require(\n        \\_newInterestRateModel.isInterestRateModel(),\n        \"\\_setInterestRateModel: This is not the rate model contract!\"\n    );\n\n    // Set to the new interest rate model.\n    interestRateModel = \\_newInterestRateModel;\n\n",
        "baseInterestPerBlock: 0\r\ninterestPerBlock: 5.074e10\r\nhighInterestPerBlock: 4.756e11\r\nhigh: 0.75e18\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "dForce removed settleInterest from TokenAdmin._setInterestRateModel and MSDS._setInterestRateModel in commit 27f9a28."
    ],
    "Description": [
        "Before executing most methods, the iETH and iToken contracts update interest accumulated on borrows via the method Base._updateInterest. This method uses the contract\u2019s interest rate model to calculate the borrow interest rate. If the calculated value is above maxBorrowRate (0.001e18), the method will revert:",
        "code/contracts/TokenBase/Base.sol:L92-L107",
        "If this method reverts, the entire contract may halt and be unrecoverable. The only ways to change the values used to calculate this interest rate lie in methods that must first call Base._updateInterest. In this case, those methods would fail.",
        "One other potential avenue for recovery exists: the Owner role may update the interest rate calculation contract via TokenAdmin._setInterestRateModel:",
        "code/contracts/TokenBase/TokenAdmin.sol:L46-L63",
        "However, this method also calls Base._updateInterest before completing the upgrade, so it would fail as well."
    ],
    "Examples": [
        "We used interest rate parameters taken from dForce\u2019s unit tests to determine whether any of the interest rate models could return a borrow rate that would cause this failure. The default InterestRateModel is deployed using these values:",
        "Plugging these values in to their borrow rate calculations, we determined that the utilization rate of the contract would need to be 2103e18 in order to reach the max borrow rate and trigger a failure. Plugging this in to the formula for utilization rate, we derived the following ratio:",
        "reserves >= (2102/2103)*borrows + cash",
        "With the given interest rate parameters, if token reserves, total borrows, and underlying cash meet the above ratio, the interest rate model would return a borrow rate above the maximum, leading to the failure conditions described above."
    ],
    "Recommendation": [
        "Note that the examples above depend on the specific interest rate parameters configured by dForce. In general, with reasonable interest rate parameters and a reasonable reserve ratio, it seems unlikely that the maximum borrow rate will be reached. Consider implementing the following changes as a precaution:"
    ]
}
----End JSON----

https://solodit.xyz/issues/rewarddistributor-requirement-prevents-transition-of-owner-role-to-smart-contract-consensys-dforce-lending-protocol-review-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Update each iToken's distribution speed according to current global speed\n \\* @dev Only EOA can call this function\n \\*/\nfunction updateDistributionSpeed() public override {\n    require(msg.sender == tx.origin, \"only EOA can update speeds\");\n    require(!paused, \"Can not update speeds when paused\");\n\n    // Do the actual update\n    \\_updateDistributionSpeed();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed in commit 4f1e31b by invoking _updateDistributionSpeed directly."
    ],
    "Description": [
        "From dForce, we learned that the eventual plan for the system Owner role is to use a smart contract (a multisig or DAO). However, a requirement in RewardDistributor would prevent the onlyOwner method _setDistributionFactors from working in this case.",
        "_setDistributionFactors calls updateDistributionSpeed, which requires that the caller is an EOA:",
        "code/contracts/RewardDistributor.sol:L179-L189",
        "In the event the Owner role is a smart contract, this statement would necessitate a complicated upgrade to restore full functionality."
    ],
    "Recommendation": [
        "Rather than invoking updateDistributionSpeed, have _setDistributionFactors directly call the internal helper _updateDistributionSpeed, which does not require the caller is an EOA."
    ]
}
----End JSON----

https://solodit.xyz/issues/msdcontroller_withdrawreserves-does-not-update-interest-before-withdrawal-consensys-dforce-lending-protocol-review-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_withdrawReserves(address \\_token, uint256 \\_amount)\n    external\n    onlyOwner\n    onlyMSD(\\_token)\n{\n    (uint256 \\_equity, ) = calcEquity(\\_token);\n\n    require(\\_equity >= \\_amount, \"Token do not have enough reserve\");\n\n    // Increase the token debt\n    msdTokenData[\\_token].debt = msdTokenData[\\_token].debt.add(\\_amount);\n\n    // Directly mint the token to owner\n    MSD(\\_token).mint(owner, \\_amount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed in commit 2b5946e by changing calcEquity to update the interest of each MSDMinter assigned to an MSD asset.",
        "Note that this method iterates over each MSDMinter, which may cause out-of-gas issues if the number of MSDMinters grows. dForce has informed us that the MSDMinter role will only be held by two contracts per asset (iMSD and MSDS)."
    ],
    "Description": [
        "MSDController._withdrawReserves allows the Owner to mint the difference between an MSD asset\u2019s accumulated debt and earnings:",
        "code/contracts/msd/MSDController.sol:L182-L195",
        "Debt and earnings are updated each time the asset\u2019s iMSD and MSDS contracts are used for the first time in a given block. Because _withdrawReserves does not force an update to these values, it is possible for the withdrawal amount to be calculated using stale values."
    ],
    "Recommendation": [
        "Ensure _withdrawReserves invokes iMSD.updateInterest() and MSDS.updateInterest()."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-aggregatedqueueamount-value-is-used-inconsistently-consensys-none-bridge-mutual-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(totalLiquidity >= totalCoverTokens.add(aggregatedQueueAmount).add(_daiTokensToWithdraw),\n  \"PB: Not enough available liquidity\");\n\n"
    ],
    "preamble": [],
    "Description": [
        "The aggregatedQueueAmount variable represents the cumulative DAIx amount in the queue that is waiting for the withdrawal. When requesting the withdrawal, this value is used as the amount of DAI that needs to be withdrawn, which may be significantly different:",
        "code_new/contracts/PolicyBook.sol:L539-L540",
        "That may lead to allowing the withdrawal request even if it shouldn\u2019t be allowed and the opposite."
    ],
    "Recommendation": [
        "Convert aggregatedQueueAmount to DAI in the _requestWithdrawal."
    ]
}
----End JSON----

https://solodit.xyz/issues/token-approvals-can-be-stolen-in-daofiv1router01addliquidity-consensys-daofi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addLiquidity(\n    LiquidityParams calldata lp,\n    uint deadline\n) external override ensure(deadline) returns (uint256 amountBase) {\n    if (IDAOfiV1Factory(factory).getPair(\n        lp.tokenBase,\n        lp.tokenQuote,\n        lp.slopeNumerator,\n        lp.n,\n        lp.fee\n    ) == address(0)) {\n        IDAOfiV1Factory(factory).createPair(\n            address(this),\n            lp.tokenBase,\n            lp.tokenQuote,\n            msg.sender,\n            lp.slopeNumerator,\n            lp.n,\n            lp.fee\n        );\n    }\n    address pair = DAOfiV1Library.pairFor(\n        factory, lp.tokenBase, lp.tokenQuote, lp.slopeNumerator, lp.n, lp.fee\n    );\n\n    TransferHelper.safeTransferFrom(lp.tokenBase, lp.sender, pair, lp.amountBase);\n    TransferHelper.safeTransferFrom(lp.tokenQuote, lp.sender, pair, lp.amountQuote);\n    amountBase = IDAOfiV1Pair(pair).deposit(lp.to);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "DAOfiV1Router01.addLiquidity() creates the desired pair contract if it does not already exist, then transfers tokens into the pair and calls DAOfiV1Pair.deposit(). There is no validation of the address to transfer tokens from, so an attacker could pass in any address with nonzero token approvals to DAOfiV1Router. This could be used to add liquidity to a pair contract for which the attacker is the pairOwner, allowing the stolen funds to be retrieved using DAOfiV1Pair.withdraw().",
        "code/daofi-v1-periphery/contracts/DAOfiV1Router01.sol:L57-L85"
    ],
    "Recommendation": [
        "Transfer tokens from msg.sender instead of lp.sender."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-deposit-of-a-new-pair-can-be-stolen-consensys-daofi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function addLiquidity(\n    LiquidityParams calldata lp,\n    uint deadline\n) external override ensure(deadline) returns (uint256 amountBase) {\n    if (IDAOfiV1Factory(factory).getPair(\n        lp.tokenBase,\n        lp.tokenQuote,\n        lp.slopeNumerator,\n        lp.n,\n        lp.fee\n    ) == address(0)) {\n        IDAOfiV1Factory(factory).createPair(\n            address(this),\n            lp.tokenBase,\n            lp.tokenQuote,\n            msg.sender,\n            lp.slopeNumerator,\n            lp.n,\n            lp.fee\n        );\n    }\n    address pair = DAOfiV1Library.pairFor(\n        factory, lp.tokenBase, lp.tokenQuote, lp.slopeNumerator, lp.n, lp.fee\n    );\n\n    TransferHelper.safeTransferFrom(lp.tokenBase, lp.sender, pair, lp.amountBase);\n    TransferHelper.safeTransferFrom(lp.tokenQuote, lp.sender, pair, lp.amountQuote);\n    amountBase = IDAOfiV1Pair(pair).deposit(lp.to);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "To create a new pair, a user is expected to call the same addLiquidity() (or the addLiquidityETH()) function of the router contract seen above:",
        "code/daofi-v1-periphery/contracts/DAOfiV1Router01.sol:L57-L85",
        "This function checks if the pair already exists and creates a new one if it does not. After that, the first and only deposit is made to that pair.",
        "The attacker can front-run that call and create a pair with the same parameters (thus, with the same address) by calling the createPair function of the DAOfiV1Factory contract. By calling that function directly, the attacker does not have to make the deposit when creating a new pair. The initial user will make this deposit, whose funds can now be withdrawn by the attacker."
    ],
    "Recommendation": [
        "There are a few factors/bugs that allowed this attack. All or some of them should be fixed:"
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-token-decimal-conversions-can-lead-to-loss-of-funds-consensys-daofi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_convert(address token, uint256 amount, uint8 resolution, bool to) private view returns (uint256 converted) {\n    uint8 decimals = IERC20(token).decimals();\n    uint256 diff = 0;\n    uint256 factor = 0;\n    converted = 0;\n    if (decimals > resolution) {\n        diff = uint256(decimals.sub(resolution));\n        factor = 10 \\*\\* diff;\n        if (to && amount >= factor) {\n            converted = amount.div(factor);\n        } else if (!to) {\n            converted = amount.mul(factor);\n        }\n    } else if (decimals < resolution) {\n        diff = uint256(resolution.sub(decimals));\n        factor = 10 \\*\\* diff;\n        if (to) {\n            converted = amount.mul(factor);\n        } else if (!to && amount >= factor) {\n            converted = amount.div(factor);\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The _convert() function in DAOfiV1Pair is used to accommodate tokens with varying decimals() values. There are three cases in which it implicitly returns 0 for any amount, the most notable of which is when token.decimals() == resolution.",
        "As a result of this, getQuoteOut() reverts any time either baseToken or quoteToken have decimals == INTERNAL_DECIMALS (currently hardcoded to 8).",
        "getBaseOut() also reverts in most cases when either baseToken or quoteToken have decimals() == INTERNAL_DECIMALS. The exception is when getBaseOut() is called while supply is 0, as is the case in deposit(). This causes getBaseOut() to succeed, returning an incorrect value.",
        "The result of this is that no swaps can be performed in one of these pools, and the deposit() function will return an incorrect amountBaseOut of baseToken to the depositor, the balance of which can then be withdrawn by the pairOwner.",
        "code/daofi-v1-core/contracts/DAOfiV1Pair.sol:L108-L130"
    ],
    "Recommendation": [
        "The _convert() function should return amount when token.decimals() == resolution. Additionally, implicit return values should be avoided whenever possible, especially in functions that implement complex mathematical operations.",
        "BancorFormula.power(baseN, baseD, _, _) does not support baseN < baseD, and checks should be added to ensure that any call to the BancorFormula conforms to the expected input ranges."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-swapexacttokensforeth-checks-the-wrong-return-value-consensys-daofi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint amountOut = IWETH10(WETH).balanceOf(address(this));\nrequire(\n    IWETH10(sp.tokenOut).balanceOf(address(this)).sub(balanceBefore) >= sp.amountOut,\n    'DAOfiV1Router: INSUFFICIENT\\_OUTPUT\\_AMOUNT'\n);\n\n"
    ],
    "preamble": [],
    "Description": [
        "The following lines are intended to check that the amount of tokens received from a swap is greater than the minimum amount expected from this swap (sp.amountOut):",
        "code/daofi-v1-periphery/contracts/DAOfiV1Router01.sol:L341-L345",
        "Instead, it calculates the difference between the initial receiver\u2019s balance and the balance of the router."
    ],
    "Recommendation": [
        "Check the intended value."
    ]
}
----End JSON----

https://solodit.xyz/issues/daofiv1pairdeposit-accepts-deposits-of-zero-blocking-the-pool-consensys-daofi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function deposit(address to) external override lock returns (uint256 amountBaseOut) {\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_DEPOSIT');\n    require(deposited == false, 'DAOfiV1: DOUBLE\\_DEPOSIT');\n    reserveBase = IERC20(baseToken).balanceOf(address(this));\n    reserveQuote = IERC20(quoteToken).balanceOf(address(this));\n    // this function is locked and the contract can not reset reserves\n    deposited = true;\n    if (reserveQuote > 0) {\n        // set initial supply from reserveQuote\n        supply = amountBaseOut = getBaseOut(reserveQuote);\n        if (amountBaseOut > 0) {\n            \\_safeTransfer(baseToken, to, amountBaseOut);\n            reserveBase = reserveBase.sub(amountBaseOut);\n        }\n    }\n    emit Deposit(msg.sender, reserveBase, reserveQuote, amountBaseOut, to);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "DAOfiV1Pair.deposit() is used to deposit liquidity into the pool. Only a single deposit can be made, so no liquidity can ever be added to a pool where deposited == true. The deposit() function does not check for a nonzero deposit amount in either token, so a malicious user that does not hold any of the baseToken or quoteToken can lock the pool by calling deposit() without first transferring any funds to the pool.",
        "code/daofi-v1-core/contracts/DAOfiV1Pair.sol:L223-L239"
    ],
    "Recommendation": [
        "Require a minimum deposit amount in both baseToken and quoteToken, and do not rely on any assumptions about the distribution of baseToken as part of the security model."
    ]
}
----End JSON----

https://solodit.xyz/issues/restricting-daofiv1pair-functions-to-calls-from-router-makes-daofiv1router01-security-critical-consensys-daofi-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function deposit(address to) external override lock returns (uint256 amountBaseOut) {\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_DEPOSIT');\n\n",
        "function withdraw(address to) external override lock returns (uint256 amountBase, uint256 amountQuote) {\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_WITHDRAW');\n\n",
        "function swap(address tokenIn, address tokenOut, uint256 amountIn, uint256 amountOut, address to) external override lock {\n    require(msg.sender == router, 'DAOfiV1: FORBIDDEN\\_SWAP');\n\n"
    ],
    "preamble": [],
    "Description": [
        "The DAOfiV1Pair functions deposit(), withdraw(), and swap() are all restricted to calls from the router in order to avoid losses from user error. However, this means that any unidentified issue in the Router could render all pair contracts unusable, potentially locking the pair owner\u2019s funds.",
        "Additionally, DAOfiV1Factory.createPair() allows any nonzero address to be provided as the router, so pairs can be initialized with a malicious router that users would be forced to interact with to utilize the pair contract.",
        "code/daofi-v1-core/contracts/DAOfiV1Pair.sol:L223-L224",
        "code/daofi-v1-core/contracts/DAOfiV1Pair.sol:L250-L251",
        "code/daofi-v1-core/contracts/DAOfiV1Pair.sol:L292-L293"
    ],
    "Recommendation": [
        "Do not restrict DAOfiV1Pair functions to calls from router, but encourage users to use a trusted router to avoid losses from user error. If this restriction is kept, consider including the router address in the deployment salt for the pair or hardcoding the address of a trusted router in DAOfiV1Factory instead of taking the router as a parameter to createPair()."
    ]
}
----End JSON----

https://solodit.xyz/issues/users-can-withdraw-their-funds-immediately-when-they-are-over-leveraged-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdraw(address \\_accountAddr, address \\_token, uint256 \\_amount) external onlyAuthorized returns(uint256) {\n\n    // Check if withdraw amount is less than user's balance\n    require(\\_amount <= getDepositBalanceCurrent(\\_token, \\_accountAddr), \"Insufficient balance.\");\n    uint256 borrowLTV = globalConfig.tokenInfoRegistry().getBorrowLTV(\\_token);\n\n",
        "// This if condition is to deal with the withdraw of collateral token in liquidation.\n// As the amount if borrowed asset is already large than the borrow power, we don't\n// have to check the condition here.\nif(getBorrowETH(\\_accountAddr) <= getBorrowPower(\\_accountAddr))\n    require(\n        getBorrowETH(\\_accountAddr) <= getBorrowPower(\\_accountAddr).sub(\n            \\_amount.mul(globalConfig.tokenInfoRegistry().priceFromAddress(\\_token))\n            .mul(borrowLTV).div(Utils.getDivisor(address(globalConfig), \\_token)).div(100)\n        ), \"Insufficient collateral when withdraw.\");\n\n"
    ],
    "preamble": [],
    "Description": [
        "Accounts.withdraw makes two checks before processing a withdrawal.",
        "First, the method checks that the amount requested for withdrawal is not larger than the user\u2019s balance for the asset in question:",
        "code/contracts/Accounts.sol:L197-L201",
        "Second, the method checks that the withdrawal will not over-leverage the user. The amount to be withdrawn is subtracted from the user\u2019s current \u201cborrow power\u201d at the current price. If the user\u2019s total value borrowed exceeds this new borrow power, the method fails, as the user no longer has sufficient collateral to support their borrow positions. However, this require is only checked if a user is not already over-leveraged:",
        "code/contracts/Accounts.sol:L203-L211",
        "If the user has already borrowed more than their \u201cborrow power\u201d allows, they are allowed to withdraw regardless. This case may arise in several circumstances; the most common being price fluctuation."
    ],
    "Recommendation": [
        "Disallow withdrawals if the user is already over-leveraged.",
        "From the comment included in the code sample above, this condition is included to support the liquidate method, but its inclusion creates an attack vector that may allow users to withdraw when they should not be able to do so. Consider adding an additional method to support liquidate, so that users may not exit without repaying debts."
    ]
}
----End JSON----

https://solodit.xyz/issues/users-can-borrow-funds-deposit-them-then-borrow-more-wont-fix-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* Calculate an account's borrow power based on token's LTV\n \\*/\nfunction getBorrowPower(address \\_borrower) public view returns (uint256 power) {\n    for(uint8 i = 0; i < globalConfig.tokenInfoRegistry().getCoinLength(); i++) {\n        if (isUserHasDeposits(\\_borrower, i)) {\n            address token = globalConfig.tokenInfoRegistry().addressFromIndex(i);\n            uint divisor = INT\\_UNIT;\n            if(token != ETH\\_ADDR) {\n                divisor = 10\\*\\*uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));\n            }\n            // globalConfig.bank().newRateIndexCheckpoint(token);\n            power = power.add(getDepositBalanceCurrent(token, \\_borrower)\n                .mul(globalConfig.tokenInfoRegistry().priceFromIndex(i))\n                .mul(globalConfig.tokenInfoRegistry().getBorrowLTV(token)).div(100)\n                .div(divisor)\n            );\n        }\n    }\n    return power;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from DeFiner team:"
    ],
    "Description": [
        "Users may deposit and borrow funds denominated in any asset supported by the TokenRegistry. Each time a user deposits or borrows a token, they earn FIN according to the difference in deposit / borrow rate indices maintained by Bank.",
        "When users borrow funds, they may only borrow up to a certain amount: the user\u2019s \u201cborrow power.\u201d As long as the user is not requesting to borrow an amount that would cause their resulting borrowed asset value to exceed their available borrow power, the borrow is successful and the user receives the assets immediately. A user\u2019s borrow power is calculated in the following function:",
        "code/contracts/Accounts.sol:L333-L353",
        "For each asset, borrow power is calculated from the user\u2019s deposit size, multiplied by the current chainlink price, multiplied and that asset\u2019s \u201cborrow LTV.\u201d",
        "After a user borrows tokens, they can then deposit those tokens, increasing their deposit balance for that asset. As a result, their borrow power increases, which allows the user to borrow again.",
        "By continuing to borrow, deposit, and borrow again, the user can repeatedly borrow assets. Essentially, this creates positions for the user where the collateral for their massive borrow position is entirely made up of borrowed assets."
    ],
    "Conclusion": [
        "There are several potential side-effects of this behavior.",
        "First, as described in https://github.com/ConsenSys/definer-audit-2021-02/issues/3, the system is comprised of many different tokens, each of which is subject to price fluctuation. By borrowing and depositing repeatedly, a user may establish positions across all supported tokens. At this point, if price fluctuations cause the user\u2019s account to cross the liquidation threshold, their positions can be liquidated.",
        "Liquidation is a complicated function of the protocol, but in essence, the liquidator purchases a target\u2019s collateral at a discount, and the resulting sale balances the account somewhat. However, when a user repeatedly deposits borrowed tokens, their collateral is made up of borrowed tokens: the system\u2019s liquidity! As a result, this may allow an attacker to intentionally create a massively over-leveraged account on purpose, liquidate it, and exit with a chunk of the system liquidity.",
        "Another potential problem with this behavior is FIN token mining. When users borrow and deposit, they earn FIN according to the size of the deposit / borrow, and the difference in deposit / borrow rate indices since the last deposit / borrow. By repeatedly depositing / borrowing, users are able to artificially deposit and borrow far more often than normal, which may allow them to generate FIN tokens at will. This additional strategy may make attacks like the one described above much more economically feasible."
    ],
    "Recommendation": [
        "Due to the limited time available during this engagement, these possibilities and potential mitigations were not fully explored. Definer is encouraged to investigate this behavior more carefully."
    ]
}
----End JSON----

https://solodit.xyz/issues/stale-oracle-prices-might-affect-the-rates-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function priceFromAddress(address tokenAddress) public view returns(uint256) {\n        if(Utils.\\_isETH(address(globalConfig), tokenAddress)) {\n            return 1e18;\n        }\n        return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));\n    }\n\n"
    ],
    "preamble": [],
    "Description": [
        "It\u2019s possible that due to network congestion or other reasons, the price that the ChainLink oracle returns is old and not up to date. This is more extreme in lesser known tokens that have fewer ChainLink Price feeds to update the price frequently.\nThe codebase as is, relies on chainLink().getLatestAnswer() and does not check the timestamp of the price."
    ],
    "Examples": [
        "/contracts/registry/TokenRegistry.sol#L291-L296"
    ],
    "Recommendation": [
        "Do a sanity check on the price returned from the oracle. If the price is older than a threshold, revert or handle in other means."
    ]
}
----End JSON----

https://solodit.xyz/issues/overcomplicated-unit-conversions-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    function getBorrowRatePerBlock(address \\_token) public view returns(uint) {\n        if(!globalConfig.tokenInfoRegistry().isSupportedOnCompound(\\_token))\n        // If the token is NOT supported by the third party, borrowing rate = 3% + U \\* 15%.\n            return getCapitalUtilizationRatio(\\_token).mul(globalConfig.rateCurveSlope()).div(INT\\_UNIT).add(globalConfig.rateCurveConstant()).div(BLOCKS\\_PER\\_YEAR);\n\n        // if the token is suppored in third party, borrowing rate = Compound Supply Rate \\* 0.4 + Compound Borrow Rate \\* 0.6\n        return (compoundPool[\\_token].depositRatePerBlock).mul(globalConfig.compoundSupplyRateWeights()).\n            add((compoundPool[\\_token].borrowRatePerBlock).mul(globalConfig.compoundBorrowRateWeights())).div(10);\n    }\n\n",
        "                compoundPool[\\_token].depositRatePerBlock = cTokenExchangeRate.mul(UNIT).div(lastCTokenExchangeRate[cToken])\n                    .sub(UNIT).div(blockNumber.sub(lastCheckpoint[\\_token]));\n\n",
        "        return lastDepositeRateIndex.mul(getBlockNumber().sub(lcp).mul(depositRatePerBlock).add(INT\\_UNIT)).div(INT\\_UNIT);\n\n\n"
    ],
    "preamble": [],
    "Description": [
        "There are many instances of unit conversion in the system that are implemented in a confusing way. This could result in mistakes in the conversion and possibly failure in correct accounting. It\u2019s been seen in the ecosystem that these type of complicated unit conversions could result in calculation mistake and loss of funds."
    ],
    "Examples": [
        "Here are a few examples:"
    ],
    "Recommendation": [
        "Simplify the unit conversions in the system. This can be done either by using a function wrapper for units to convert all values to the same unit before including them in any calculation or by better documenting every line of unit conversion"
    ]
}
----End JSON----

https://solodit.xyz/issues/commented-out-code-in-the-codebase-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    struct LiquidationVars {\n        // address token;\n        // uint256 tokenPrice;\n        // uint256 coinValue;\n        uint256 borrowerCollateralValue;\n        // uint256 tokenAmount;\n        // uint256 tokenDivisor;\n        uint256 msgTotalBorrow;\n\n",
        "                if(token != ETH\\_ADDR) {\n                    divisor = 10\\*\\*uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(token));\n                }\n                // globalConfig.bank().newRateIndexCheckpoint(token);\n                power = power.add(getDepositBalanceCurrent(token, \\_borrower)\n\n",
        "// import \"@nomiclabs/buidler/console.sol\";\n...\n//console.log(\"tokenNum\", tokenNum);\n\n",
        "        // require(\n        // totalBorrow.mul(100) <= totalCollateral.mul(liquidationDiscountRatio),\n        // \"Collateral is not sufficient to be liquidated.\"\n        // );\n\n",
        "    // function \\_isETH(address \\_token) public view returns (bool) {\n    // return globalConfig.constants().ETH\\_ADDR() == \\_token;\n    // }\n\n    // function getDivisor(address \\_token) public view returns (uint256) {\n    // if(\\_isETH(\\_token)) return INT\\_UNIT;\n    // return 10 \\*\\* uint256(getTokenDecimals(\\_token));\n    // }\n\n\n",
        "        // require(\\_borrowLTV != 0, \"Borrow LTV is zero\");\n        require(\\_borrowLTV < SCALE, \"Borrow LTV must be less than Scale\");\n        // require(liquidationThreshold > \\_borrowLTV, \"Liquidation threshold must be greater than Borrow LTV\");\n\n\n"
    ],
    "preamble": [],
    "Description": [
        "There are many instances of code lines (and functions) that are commented out in the code base. Having commented out code increases the cognitive load on an already complex system. Also, it hides the important parts of the system that should get the proper attention, but that attention gets to be diluted.",
        "The main problem is that commented code adds confusion with no real benefit. Code should be code, and comments should be comments."
    ],
    "Examples": [
        "Here\u2019s a few examples of such lines of code, note that there are more."
    ],
    "Recommendation": [
        "In many of the above examples, it\u2019s not clear if the commented code is for testing or obsolete code (e.g. in the last example, can _borrowLTV ==0?) . All these instances should be reviewed and the system should be fully tested for all edge cases after the code changes."
    ]
}
----End JSON----

https://solodit.xyz/issues/price-volatility-may-compromise-system-integrity-wont-fix-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function borrow(address \\_token, uint256 \\_amount) external onlySupportedToken(\\_token) onlyEnabledToken(\\_token) whenNotPaused nonReentrant {\n\n    require(\\_amount != 0, \"Borrow zero amount of token is not allowed.\");\n\n    globalConfig.bank().borrow(msg.sender, \\_token, \\_amount);\n\n    // Transfer the token on Ethereum\n    SavingLib.send(globalConfig, \\_amount, \\_token);\n\n    emit Borrow(\\_token, msg.sender, \\_amount);\n}\n\n",
        "// globalConfig.bank().newRateIndexCheckpoint(token);\npower = power.add(getDepositBalanceCurrent(token, \\_borrower)\n    .mul(globalConfig.tokenInfoRegistry().priceFromIndex(i))\n    .mul(globalConfig.tokenInfoRegistry().getBorrowLTV(token)).div(100)\n    .div(divisor)\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from DeFiner team:"
    ],
    "Description": [
        "SavingAccount.borrow allows users to borrow funds from the bank. The funds borrowed may be denominated in any asset supported by the system-wide TokenRegistry. Borrowed funds come from the system\u2019s existing liquidity: other users' deposits.",
        "Borrowing funds is an instant process. Assuming the user has sufficient collateral to service the borrow request (as well as any existing loans), funds are sent to the user immediately:",
        "code/contracts/SavingAccount.sol:L130-L140",
        "Users may borrow up to their \u201cborrow power\u201d, which is the sum of their deposit balance for each token, multiplied by each token\u2019s borrowLTV, multiplied by the token price (queried from a chainlink oracle):",
        "code/contracts/Accounts.sol:L344-L349",
        "If users borrow funds, their position may be liquidated via SavingAccount.liquidate. An account is considered liquidatable if the total value of borrowed funds exceeds the total value of collateral (multiplied by some liquidation threshold ratio). These values are calculated similarly to \u201cborrow power:\u201d the sum of the deposit balance for each token, multiplied by each token\u2019s borrowLTV, multiplied by the token price as determined by chainlink."
    ],
    "Conclusion": [
        "The instant-borrow approach, paired with the chainlink oracle represents a single point of failure for the Definer system. When the price of any single supported asset is sufficiently volatile, the entire liquidity held by the system is at risk as borrow power and collateral value become similarly volatile.",
        "Some users may find their borrow power skyrocket and use this inflated value to drain large amounts of system liquidity they have no intention of repaying. Others may find their held collateral tank in value and be subject to sudden liquidations."
    ]
}
----End JSON----

https://solodit.xyz/issues/emergency-withdrawal-code-present-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "    // ============================================\n    // EMERGENCY WITHDRAWAL FUNCTIONS\n    // Needs to be removed when final version deployed\n    // ============================================\n    function emergencyWithdraw(GlobalConfig globalConfig, address \\_token) public {\n        address cToken = globalConfig.tokenInfoRegistry().getCToken(\\_token);\n...\n\n",
        "    function emergencyWithdraw(address \\_token) external onlyEmergencyAddress {\n        SavingLib.emergencyWithdraw(globalConfig, \\_token);\n    }\n\n",
        "...\n    address payable public constant EMERGENCY\\_ADDR = 0xc04158f7dB6F9c9fFbD5593236a1a3D69F92167c;\n...\n\n"
    ],
    "preamble": [],
    "Description": [
        "Code and functionality for emergency stop and withdrawal is present in this code base."
    ],
    "Examples": [
        "/contracts/lib/SavingLib.sol#L43-L48",
        "/contracts/SavingAccount.sol#L307-L309",
        "/contracts/config/Constant.sol#L7-L8"
    ],
    "Recommendation": [
        "To remove the emergency code and fully test all the affected contracts."
    ]
}
----End JSON----

https://solodit.xyz/issues/accounts-contains-expensive-looping-consensys-definer-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getBorrowETH(\n    address \\_accountAddr\n) public view returns (uint256 borrowETH) {\n    uint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();\n    //console.log(\"tokenNum\", tokenNum);\n    for(uint i = 0; i < tokenNum; i++) {\n        if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\n            address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);\n            uint divisor = INT\\_UNIT;\n            if(tokenAddress != ETH\\_ADDR) {\n                divisor = 10 \\*\\* uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));\n            }\n            borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));\n        }\n    }\n    return borrowETH;\n}\n\n",
        "function priceFromIndex(uint index) public view returns(uint256) {\n    require(index < tokens.length, \"coinIndex must be smaller than the coins length.\");\n    address tokenAddress = tokens[index];\n    // Temp fix\n    if(Utils.\\_isETH(address(globalConfig), tokenAddress)) {\n        return 1e18;\n    }\n    return uint256(globalConfig.chainLink().getLatestAnswer(tokenAddress));\n}\n\n",
        "function getBorrowBalanceCurrent(\n    address \\_token,\n    address \\_accountAddr\n) public view returns (uint256 borrowBalance) {\n    AccountTokenLib.TokenInfo storage tokenInfo = accounts[\\_accountAddr].tokenInfos[\\_token];\n    uint accruedRate;\n    if(tokenInfo.getBorrowPrincipal() == 0) {\n        return 0;\n    } else {\n        if(globalConfig.bank().borrowRateIndex(\\_token, tokenInfo.getLastBorrowBlock()) == 0) {\n            accruedRate = INT\\_UNIT;\n        } else {\n            accruedRate = globalConfig.bank().borrowRateIndexNow(\\_token)\n            .mul(INT\\_UNIT)\n            .div(globalConfig.bank().borrowRateIndex(\\_token, tokenInfo.getLastBorrowBlock()));\n        }\n        return tokenInfo.getBorrowBalance(accruedRate);\n    }\n}\n\n",
        "uint tokenNum = globalConfig.tokenInfoRegistry().getCoinLength();\nfor(uint i = 0; i < tokenNum; i++) {\n  if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\n    address tokenAddress = globalConfig.tokenInfoRegistry().addressFromIndex(i);\n    uint divisor = INT\\_UNIT;\n    if(tokenAddress != ETH\\_ADDR) {\n      divisor = 10 \\*\\* uint256(globalConfig.tokenInfoRegistry().getTokenDecimals(tokenAddress));\n    }\n    borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(globalConfig.tokenInfoRegistry().priceFromIndex(i)).div(divisor));\n  }\n}\n\n",
        "TokenRegistry registry = globalConfig.tokenInfoRegistry();\nuint tokenNum = registry.getCoinLength();\nfor(uint i = 0; i < tokenNum; i++) {\n  if(isUserHasBorrows(\\_accountAddr, uint8(i))) {\n    // here, getPriceFromIndex(i) performs all of the steps as the code above, but with only 1 ext call\n    borrowETH = borrowETH.add(getBorrowBalanceCurrent(tokenAddress, \\_accountAddr).mul(registry.getPriceFromIndex(i)).div(divisor));\n  }\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Accounts.getBorrowETH performs multiple external calls to GlobalConfig and TokenRegistry within a for loop:",
        "code/contracts/Accounts.sol:L381-L397",
        "The loop also makes additional external calls and delegatecalls from:",
        "code/contracts/registry/TokenRegistry.sol:L281-L289",
        "code/contracts/Accounts.sol:L313-L331",
        "In a worst case scenario, each iteration may perform a maximum of 25+ calls/delegatecalls. Assuming a maximum tokenNum of 128 (TokenRegistry.MAX_TOKENS), the gas cost for this method may reach upwards of 2 million for external calls alone.",
        "Given that this figure would only be a portion of the total transaction gas cost, getBorrowETH may represent a DoS risk within the Accounts contract."
    ],
    "Recommendation": [
        "Instead of this:",
        "Modify TokenRegistry to support a single call, and cache intermediate results like this:"
    ]
}
----End JSON----

https://solodit.xyz/issues/tokenfaucet-refill-can-have-an-unexpected-outcome-consensys-pooltogether-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 assetTotalSupply = asset.balanceOf(address(this));\nuint256 availableTotalSupply = assetTotalSupply.sub(totalUnclaimed);\nuint256 newSeconds = currentTimestamp.sub(lastDripTimestamp);\nuint256 nextExchangeRateMantissa = exchangeRateMantissa;\nuint256 newTokens;\nuint256 measureTotalSupply = measure.totalSupply();\n\nif (measureTotalSupply > 0 && availableTotalSupply > 0 && newSeconds > 0) {\n  newTokens = newSeconds.mul(dripRatePerSecond);\n  if (newTokens > availableTotalSupply) {\n    newTokens = availableTotalSupply;\n  }\n  uint256 indexDeltaMantissa = measureTotalSupply > 0 ? FixedPoint.calculateMantissa(newTokens, measureTotalSupply) : 0;\n  nextExchangeRateMantissa = nextExchangeRateMantissa.add(indexDeltaMantissa);\n\n  emit Dripped(\n    newTokens\n  );\n}\n\n\n"
    ],
    "preamble": [],
    "Description": [
        "The TokenFaucet contract can only disburse tokens to the users if it has enough balance. When the contract is running out of tokens, it stops dripping.",
        "code/pool-contracts/contracts/token-faucet/TokenFaucet.sol:L119-L138",
        "The owners of the faucet can decide to refill the contract so it can disburse tokens again. If there\u2019s been a lot of time since the faucet was drained, the lastDripTimestamp value can be far behind the currentTimestamp. In that case, the users can instantly withdraw some amount (up to all the balance) right after the refill."
    ],
    "Recommendation": [
        "To avoid uncertainty, it\u2019s essential to call the drip function before the refill. If this call is made in a separate transaction, the owner should make sure that this transaction was successfully mined before sending tokens for the refill."
    ]
}
----End JSON----

https://solodit.xyz/issues/genesisgroupcommit-overwrites-previously-committed-values-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function commit(address from, address to, uint amount) external override onlyGenesisPeriod {\n\tburnFrom(from, amount);\n\n\tcommittedFGEN[to] = amount;\n\ttotalCommittedFGEN += amount;\n\n\temit Commit(from, to, amount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#16."
    ],
    "Description": [
        "commit allows anyone to commit purchased FGEN to a swap that will occur once the genesis group is launched. This commitment may be performed on behalf of other users, as long as the calling account has sufficient allowance:",
        "code/contracts/genesis/GenesisGroup.sol:L87-L94",
        "The amount stored in the recipient\u2019s committedFGEN balance overwrites any previously-committed value. Additionally, this also allows anyone to commit an amount of \u201c0\u201d to any account, deleting their commitment entirely."
    ],
    "Recommendation": [
        "Ensure the committed amount is added to the existing commitment."
    ]
}
----End JSON----

https://solodit.xyz/issues/purchasing-and-committing-still-possible-after-launch-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#11."
    ],
    "Description": [
        "Even after GenesisGroup.launch has successfully been executed, it is still possible to invoke GenesisGroup.purchase and GenesisGroup.commit."
    ],
    "Recommendation": [
        "Consider adding validation in GenesisGroup.purchase and GenesisGroup.commit to make sure that these functions cannot be called after the launch."
    ]
}
----End JSON----

https://solodit.xyz/issues/uniswapincentive-overflow-on-pre-transfer-hooks-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function incentivize(\n\taddress sender,\n\taddress receiver, \n\taddress operator,\n\tuint amountIn\n) external override onlyFei {\n    updateOracle();\n\n\tif (isPair(sender)) {\n\t\tincentivizeBuy(receiver, amountIn);\n\t}\n\n\tif (isPair(receiver)) {\n        require(isSellAllowlisted(sender) || isSellAllowlisted(operator), \"UniswapIncentive: Blocked Fei sender or operator\");\n\t\tincentivizeSell(sender, amountIn);\n\t}\n}\n\n",
        "function incentivizeBuy(address target, uint amountIn) internal ifMinterSelf {\n\tif (isExemptAddress(target)) {\n\t\treturn;\n\t}\n\n    (uint incentive, uint32 weight,\n    Decimal.D256 memory initialDeviation,\n    Decimal.D256 memory finalDeviation) = getBuyIncentive(amountIn);\n\n    updateTimeWeight(initialDeviation, finalDeviation, weight);\n    if (incentive != 0) {\n        fei().mint(target, incentive);        \n    }\n}\n\n",
        "function getBuyIncentive(uint amount) public view override returns(\n    uint incentive,\n    uint32 weight,\n    Decimal.D256 memory initialDeviation,\n    Decimal.D256 memory finalDeviation\n) {\n    (initialDeviation, finalDeviation) = getPriceDeviations(-1 \\* int256(amount));\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#15."
    ],
    "Description": [
        "Before a token transfer is performed, Fei performs some combination of mint/burn operations via UniswapIncentive.incentivize:",
        "code/contracts/token/UniswapIncentive.sol:L49-L65",
        "Both incentivizeBuy and incentivizeSell calculate buy/sell incentives using overflow-prone math, then mint / burn from the target according to the results. This may have unintended consequences, like allowing a caller to mint tokens before transferring them, or burn tokens from their recipient."
    ],
    "Examples": [
        "incentivizeBuy calls getBuyIncentive to calculate the final minted value:",
        "code/contracts/token/UniswapIncentive.sol:L173-L186",
        "getBuyIncentive calculates price deviations after casting amount to an int256, which may overflow:",
        "code/contracts/token/UniswapIncentive.sol:L128-L134"
    ],
    "Recommendation": [
        "Ensure casts in getBuyIncentive and getSellPenalty do not overflow."
    ]
}
----End JSON----

https://solodit.xyz/issues/bondingcurve-allows-users-to-acquire-fei-before-launch-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice if window has passed, reward caller and reset window\nfunction \\_incentivize() internal virtual {\n    if (isTimeEnded()) {\n        \\_initTimed(); // reset window\n        fei().mint(msg.sender, incentiveAmount);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#59"
    ],
    "Description": [
        "BondingCurve.allocate allocates the protocol\u2019s held PCV, then calls _incentivize, which rewards the caller with FEI if a certain amount of time has passed:",
        "code-update/contracts/bondingcurve/BondingCurve.sol:L180-L186",
        "allocate can be called before genesis launch, as long as the contract holds some nonzero PCV. By force-sending the contract 1 wei, anyone can bypass the majority of checks and actions in allocate, and mint themselves FEI each time the timer expires."
    ],
    "Recommendation": [
        "Prevent allocate from being called before genesis launch."
    ]
}
----End JSON----

https://solodit.xyz/issues/timedistimeended-returns-true-if-the-timer-has-not-been-initialized-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#62"
    ],
    "Description": [
        "Timed initialization is a 2-step process:",
        "Before this second method is called, isTimeEnded() calculates remaining time using a startTime of 0, resulting in the method returning true for most values, even though the timer has not technically been started."
    ],
    "Recommendation": [
        "If Timed has not been initialized, isTimeEnded() should return false, or revert"
    ]
}
----End JSON----

https://solodit.xyz/issues/overflowunderflow-protection-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint totalGenesisTribe = tribeBalance() - totalCommittedTribe;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was partially addressed in fei-protocol/fei-protocol-core#17 by using SafeMath for the specific example given in the description."
    ],
    "Description": [
        "Having overflow/underflow vulnerabilities is very common for smart contracts. It is usually mitigated by using SafeMath or using solidity version ^0.8 (after solidity 0.8 arithmetical operations already have default overflow/underflow protection).",
        "In this code, many arithmetical operations are used without the \u2018safe\u2019 version. The reasoning behind it is that all the values are derived from the actual ETH values, so they can\u2019t overflow.",
        "On the other hand, some operations can\u2019t be checked for overflow/underflow without going much deeper into the codebase that is out of scope:",
        "code/contracts/genesis/GenesisGroup.sol:L131"
    ],
    "Recommendation": [
        "In our opinion, it is still safer to have these operations in a safe mode. So we recommend using SafeMath or solidity version ^0.8 compiler."
    ]
}
----End JSON----

https://solodit.xyz/issues/unchecked-return-value-for-iwethtransfer-call-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "weth.transfer(address(pair), amount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#12."
    ],
    "Description": [
        "In EthUniswapPCVController, there is a call to IWETH.transfer that does not check the return value:",
        "code/contracts/pcv/EthUniswapPCVController.sol:L122",
        "It is usually good to add a require-statement that checks the return value or to use something like safeTransfer; unless one is sure the given token reverts in case of a failure."
    ],
    "Recommendation": [
        "Consider adding a require-statement or using safeTransfer."
    ]
}
----End JSON----

https://solodit.xyz/issues/genesisgroupemergencyexit-remains-functional-after-launch-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "burnFrom(from, amountFGEN);\ncommittedFGEN[from] = 0;\n\npayable(to).transfer(total);\n\n",
        "uint amountFei = feiBalance() \\* totalCommittedFGEN / (totalSupply() + totalCommittedFGEN);\nif (amountFei != 0) {\n\ttotalCommittedTribe = ido.swapFei(amountFei);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was partially addressed in fei-protocol/fei-protocol-core#14 and fei-protocol/fei-protocol-core#13 by addressing the last two recommendations."
    ],
    "Description": [
        "emergencyExit is intended as an escape mechanism for users in the event the genesis launch method fails or is frozen. emergencyExit becomes callable 3 days after launch is callable. These two methods are intended to be mutually-exclusive, but are not: either method remains callable after a successful call to the other.",
        "This may result in accounting edge cases. In particular, emergencyExit fails to decrease totalCommittedFGEN by the exiting user\u2019s commitment:",
        "code/contracts/genesis/GenesisGroup.sol:L185-L188",
        "As a result, calling launch after a user performs an exit will incorrectly calculate the amount of FEI to swap:",
        "code/contracts/genesis/GenesisGroup.sol:L165-L168"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/unchecked-return-value-for-transferfrom-calls-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "stakedToken.transferFrom(from, address(this), amount);\n\n",
        "fei().transferFrom(msg.sender, address(pair), amountFei);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in fei-protocol/fei-protocol-core#12."
    ],
    "Description": [
        "There are two transferFrom calls that do not check the return value (some tokens signal failure by returning false):",
        "code/contracts/pool/Pool.sol:L121",
        "code/contracts/genesis/IDO.sol:L58",
        "It is usually good to add a require-statement that checks the return value or to use something like safeTransferFrom; unless one is sure the given token reverts in case of a failure."
    ],
    "Recommendation": [
        "Consider adding a require-statement or using safeTransferFrom."
    ]
}
----End JSON----

https://solodit.xyz/issues/clickjacking-and-missing-content-security-policy-fixed-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "default-src 'self';\r\nscript-src 'self' 'unsafe-inline' https://www.googletagmanager.com;\r\nobject-src 'none';\r\nstyle-src 'self' 'unsafe-inline';\r\nimg-src 'self';\r\nmedia-src 'none';\r\nframe-src 'none';\r\nfont-src 'self';\r\nconnect-src 'self'\r\n  https://api.amplitude.com\r\n  https://eth-ropsten.alchemyapi.io\r\n  https://eth-mainnet.alchemyapi.io\r\n  https://api.thegraph.com;\r\nframe-ancestors 'none'\r\n\n",
        "<script>\r\n if (self == top) {\r\n   document.documentElement.style.display = 'block ';\r\n } else {\r\n   top.location = self.location;\r\n }\r\n</script>\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "After multiple iterations, the following Content Security Policy has been put into effect:",
        "The CSP is transmitted through the following headers:",
        "as well as through corresponding meta HTML tags. Additionally, the following frame-busting JavaScript code has been added to prevent Clickjacking attacks in the unlikely event that existing CSP measures fail or are bypassed:"
    ],
    "Description": [
        "A content security policy (CSP) provides an added layer of protection against cross-site scripting (XSS), clickjacking, and other client-side attacks that rely on executing malicious content in the context of the website.",
        "Specifically, the lack of a content security policy allows an adversary to perform a clickjacking attack by including the target URL (such as app.fei.money) in an iframe element on their site. The attacker then uses one or more transparent layers on top of the embedded site to trick a user into performing a click action on a different element.",
        "This technique can be used to spawn malicious Metamask dialogues, tricking users into thinking that they are signing a legitimate transaction."
    ],
    "Affected Assets": [
        "All S3-hosted web sites."
    ],
    "Recommendation": [
        "It is recommended to add content security policy headers to the served responses to prevent browsers from embedding Fei-owned sites into malicious parent sites. Furthermore, CSP can be used to limit the permissions of JavaScript and CSS on the page, which can be used to further harden the deployment against a potential compromise of script dependencies.",
        "It should be noted that security headers should not only be served from Cloudfront but any public-facing endpoint. Otherwise, it will be trivial for an attacker to circumvent the security headers added by Cloudfront, e.g. by embedding the index.html file directly from the public-facing S3 bucket URL.",
        "Besides CSP headers, clickjacking can also be mitigated by directly including frame-busting JavaScript code into the served page."
    ]
}
----End JSON----

https://solodit.xyz/issues/s3-buckets-cleartext-communication-fixed-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "$ curl -v http://fei.money.s3.amazonaws.com/index.html\r\n*   Trying 52.219.112.162:80...\r\n* TCP_NODELAY set\r\n* Connected to fei.money.s3.amazonaws.com (52.219.112.162) port 80 (https://github.com/ConsenSys/fei-protocol-audit-2021-01/issues/0)\r\n> GET /index.html HTTP/1.1\r\n> Host: fei.money.s3.amazonaws.com\r\n> User-Agent: curl/7.68.0\r\n> Accept: */*\r\n> \r\n* Mark bundle as not supporting multiuse\r\n< HTTP/1.1 200 OK\r\n< x-amz-id-2: 0QtzqEhGn7gHUjjiAxpniOMXKQ1O1ouT6Tp8iQG2EfvlKbg0ZgEbDdkQrJrJL2OyJF1VyZkPjjU=\r\n< x-amz-request-id: D6250FE8F76E84F0\r\n< Date: Tue, 09 Feb 2021 13:07:54 GMT\r\n< Last-Modified: Mon, 11 Jan 2021 20:38:09 GMT\r\n< ETag: \"ec826fa83693f3db3a989fcbeb5adef1\"\r\n< Accept-Ranges: bytes\r\n< Content-Type: text/html\r\n< Content-Length: 3675\r\n< Server: AmazonS3\r\n< \r\n< ...\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Direct access to S3 buckets through s3.amazonaws.com is now rejected, while unencrypted HTTP traffic to the previously affected assets now consistently redirects to the HTTPS equivalents."
    ],
    "Description": [
        "The system\u2019s S3 buckets are configured to allow unencrypted traffic:"
    ],
    "Affected Assets": [],
    "Recommendation": [
        "It is recommended to enforce encryption of data in transit using TLS certificates. To accomplish this, the aws:SecureTransport can be set in the S3 bucket\u2019s policies."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-log-aggregation-fixed-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "CloudFrond and CloudTrail have been enabled. These components send endpoint-related and organizational log messages into S3 buckets where they can be queried using AWS Athena. The security review process section of this report contains sample queries for Athena."
    ],
    "Description": [
        "There is no centralized system that gathers operational events of AWS stack components. This includes S3 server access logs, configuration changes, as well as Cloudfront-related logging."
    ],
    "Recommendation": [
        "It is recommended to enable CloudTrail for internal log aggregation as it integrates seamlessly with S3, Cloudfront, and IAM. Furthermore, regular reviews should be set up where system activity is checked to detect suspicious activity as soon as possible."
    ]
}
----End JSON----

https://solodit.xyz/issues/enforce-strict-transport-security-fixed-consensys-fei-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "strict-transport-security: max-age=63072000; includeSubdomains\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "All domains in scope now ship with the following header:"
    ],
    "Description": [
        "The HTTP Strict-Transport-Security response header (often abbreviated as HSTS) lets a web site tell browsers that it should only be accessed using HTTPS, instead of using HTTP. This prevents attackers from stripping TLS certificates from connections and removing encryption."
    ],
    "Recommendation": [
        "It is recommended to deliver all responses with the Strict-Transport-Security header. In an S3-Cloudfront setup, this can be achieved using [email\u00a0protected] lambda functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/out-of-scope-referralfeereceiver-anyone-can-steal-all-the-funds-that-belong-to-referralfeereceiver-fix-unverified-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (path[0].isETH()) {\n    tx.origin.transfer(availableBalance);  // solhint-disable-line avoid-tx-origin\n} else {\n    path[0].safeTransfer(address(mooniswap), availableBalance);\n}\n\n",
        "IERC20[] memory tokens = mooniswap.getTokens();\nuint256 token0Balance = tokens[0].uniBalanceOf(address(this));\nuint256 token1Balance = tokens[1].uniBalanceOf(address(this));\n\n",
        "function unwrapLPTokens(Mooniswap mooniswap) external validSpread(mooniswap) {\n    mooniswap.withdraw(mooniswap.balanceOf(address(this)), new uint256[](0));\n}\n\nfunction swap(IERC20[] memory path) external validPath(path) {\n    (uint256 amount,) = \\_maxAmountForSwap(path, path[0].uniBalanceOf(address(this)));\n    uint256 result = \\_swap(path, amount, payable(address(rewards)));\n    rewards.notifyRewardAmount(result);\n}\n\n",
        "function updateReward(address referral, uint256 amount) external override {\n    Mooniswap mooniswap = Mooniswap(msg.sender);\n    TokenInfo storage token = tokenInfo[mooniswap];\n    UserInfo storage user = userInfo[referral];\n    uint256 currentEpoch = token.currentEpoch;\n\n    // Add new reward to current epoch\n    user.share[mooniswap][currentEpoch] = user.share[mooniswap][currentEpoch].add(amount);\n    token.epochBalance[currentEpoch].totalSupply = token.epochBalance[currentEpoch].totalSupply.add(amount);\n\n    // Collect all processed epochs and advance user token epoch\n    \\_collectProcessedEpochs(user, token, mooniswap, currentEpoch);\n}\n\n",
        "function freezeEpoch(Mooniswap mooniswap) external validSpread(mooniswap) {\n    TokenInfo storage token = tokenInfo[mooniswap];\n    uint256 currentEpoch = token.currentEpoch;\n    require(token.firstUnprocessedEpoch == currentEpoch, \"Previous epoch is not finalized\");\n\n    IERC20[] memory tokens = mooniswap.getTokens();\n    uint256 token0Balance = tokens[0].uniBalanceOf(address(this));\n    uint256 token1Balance = tokens[1].uniBalanceOf(address(this));\n    mooniswap.withdraw(mooniswap.balanceOf(address(this)), new uint256[](0));\n    token.epochBalance[currentEpoch].token0Balance = tokens[0].uniBalanceOf(address(this)).sub(token0Balance);\n    token.epochBalance[currentEpoch].token1Balance = tokens[1].uniBalanceOf(address(this)).sub(token1Balance);\n    token.currentEpoch = currentEpoch.add(1);\n}\n\n",
        "if (share > 0) {\n    EpochBalance storage epochBalance = token.epochBalance[firstUnprocessedEpoch];\n    uint256 totalSupply = epochBalance.totalSupply;\n    user.share[mooniswap][firstUnprocessedEpoch] = 0;\n    epochBalance.totalSupply = totalSupply.sub(share);\n\n    IERC20[] memory tokens = mooniswap.getTokens();\n    epochBalance.token0Balance = \\_transferTokenShare(tokens[0], epochBalance.token0Balance, share, totalSupply);\n    epochBalance.token1Balance = \\_transferTokenShare(tokens[1], epochBalance.token1Balance, share, totalSupply);\n    epochBalance.inchBalance = \\_transferTokenShare(inchToken, epochBalance.inchBalance, share, totalSupply);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "According to the client, this issue is addressed in 1inch-exchange/1inch-liquidity-protocol#2 and the reentrancy in FeeReceiver in 1inch-exchange/[email\u00a0protected]e9c6a03",
        "(This fix is as reported by the developer team, but has not been verified by Diligence)."
    ],
    "Description": [
        "Note: This issue was raised in components that were being affected by the scope reduction as outlined in the section \u201cScope\u201d and are, therefore, only shallowly validated. Nevertheless, we find it important to communicate such potential findings and ask the client to further investigate.",
        "The ReferralFeeReceiver receives pool shares when users swap() tokens in the pool. A ReferralFeeReceiver may be used with multiple pools and, therefore, be a lucrative target as it is holding pool shares.",
        "Any token or ETH that belongs to the ReferralFeeReceiver is at risk and can be drained by any user by providing a custom mooniswap pool contract that references existing token holdings.",
        "It should be noted that none of the functions in ReferralFeeReceiver verify that the user-provided mooniswap pool address was actually deployed by the linked MooniswapFactory. The factory provides certain security guarantees about mooniswap pool contracts (e.g. valid mooniswap contract, token deduplication, tokenA!=tokenB, enforced token sorting, \u2026), however, since the ReferralFeeReceiver does not verify the user-provided mooniswap address they are left unchecked.",
        "code/contracts/ReferralFeeReceiver.sol:L91-L95",
        "code/contracts/ReferralFeeReceiver.sol:L57-L59",
        "code/contracts/governance/GovernanceFeeReceiver.sol:L18-L26"
    ],
    "Examples": [
        "A malicious user can drain all token by calling claimFrozenEpoch with a custom contract as mooniswap that returns a token address the ReferralFeeReceiver contracts holds token from in IERC20[] memory tokens = mooniswap.getTokens();. A subsequent call to _transferTokenShare() will then send out any amount of token requested by the attacker to the attacker-controlled address (msg.sender).",
        "Let\u2019s assume the following scenario:",
        "An attacker may be able to drain the contract from DAI token via claimFrozenToken if",
        "The following steps outline the attack:",
        "code/contracts/ReferralFeeReceiver.sol:L38-L50",
        "code/contracts/ReferralFeeReceiver.sol:L52-L64",
        "code/contracts/ReferralFeeReceiver.sol:L153-L162"
    ],
    "Recommendation": [
        "Enforce that the user-provided mooniswap contract was actually deployed by the linked factory. Other contracts cannot be trusted. Consider implementing token sorting and de-duplication (tokenA!=tokenB) in the pool contract constructor as well. Consider employing a reentrancy guard to safeguard the contract from reentrancy attacks.",
        "Improve testing. The methods mentioned here are not covered at all. Improve documentation and provide a specification that outlines how this contract is supposed to be used.",
        "Review the \u201cadditional notes\u201d provided with this issue."
    ]
}
----End JSON----

https://solodit.xyz/issues/governancemothership-notifyfor-allows-to-arbitrarily-create-new-or-override-other-users-stake-in-governance-modules-fix-unverified-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function notifyFor(address account) external {\n    \\_notifyFor(account, balanceOf(msg.sender));\n}\n\n",
        "function \\_notifyFor(address account, uint256 balance) private {\n    uint256 modulesLength = \\_modules.length();\n    for (uint256 i = 0; i < modulesLength; ++i) {\n        IGovernanceModule(\\_modules.at(i)).notifyStakeChanged(account, balance);\n    }\n}\n\n",
        "function notifyStakeChanged(address account, uint256 newBalance) external override onlyMothership {\n    \\_notifyStakeChanged(account, newBalance);\n}\n\n",
        "function \\_notifyStakeChanged(address account, uint256 newBalance) internal override {\n    uint256 balance = balanceOf(account);\n    if (newBalance > balance) {\n        \\_mint(account, newBalance.sub(balance));\n    } else if (newBalance < balance) {\n        \\_burn(account, balance.sub(newBalance));\n    } else {\n        return;\n    }\n    uint256 newTotalSupply = totalSupply();\n\n    \\_defaultFee.updateBalance(account, \\_defaultFee.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_FEE, \\_emitDefaultFeeVoteUpdate);\n    \\_defaultSlippageFee.updateBalance(account, \\_defaultSlippageFee.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_SLIPPAGE\\_FEE, \\_emitDefaultSlippageFeeVoteUpdate);\n    \\_defaultDecayPeriod.updateBalance(account, \\_defaultDecayPeriod.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_DECAY\\_PERIOD, \\_emitDefaultDecayPeriodVoteUpdate);\n    \\_referralShare.updateBalance(account, \\_referralShare.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_REFERRAL\\_SHARE, \\_emitReferralShareVoteUpdate);\n    \\_governanceShare.updateBalance(account, \\_governanceShare.votes[account], balance, newBalance, newTotalSupply, \\_DEFAULT\\_GOVERNANCE\\_SHARE, \\_emitGovernanceShareVoteUpdate);\n}\n\n",
        "function \\_notifyStakeChanged(address account, uint256 newBalance) internal override updateReward(account) {\n    uint256 balance = balanceOf(account);\n    if (newBalance > balance) {\n        \\_mint(account, newBalance.sub(balance));\n    } else if (newBalance < balance) {\n        \\_burn(account, balance.sub(newBalance));\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "According to the client, this issue is addressed in 1inch-exchange/[email\u00a0protected]2ce549d and added tests with 1inch-exchange/[email\u00a0protected]e0dc46b",
        "(This fix is as reported by the developer team, but has not been verified by Diligence)."
    ],
    "Description": [
        "The notify* methods are called to update linked governance modules when an accounts stake changes in the Mothership. The linked modules then update their own balances of the user to accurately reflect the account\u2019s real stake in the Mothership.",
        "Besides notify there\u2019s also a method named notifyFor which is publicly accessible. It is assumed that the method should be used similar to notify to force an update for another account\u2019s balance.",
        "However, invoking the method forces an update in the linked modules for the provided address, but takes balanceOf(msg.sender) instead of balanceOf(account). This allows malicious actors to:"
    ],
    "Examples": [
        "code/contracts/inch/GovernanceMothership.sol:L48-L50",
        "code/contracts/inch/GovernanceMothership.sol:L73-L78",
        "code/contracts/governance/BaseGovernanceModule.sol:L29-L31",
        "code/contracts/governance/MooniswapFactoryGovernance.sol:L144-L160",
        "code/contracts/governance/GovernanceRewards.sol:L72-L79"
    ],
    "Recommendation": [
        "Remove notifyFor or change it to take the balance of the correct account _notifyFor(account, balanceOf(msg.sender)).",
        "It is questionable whether the public notify*() family of methods is actually needed as stake should only change - and thus an update of linked modules should only be required - if an account calls stake() or unstake(). It should therefore be considered to remove notify(), notifyFor and batchNotifyFor."
    ]
}
----End JSON----

https://solodit.xyz/issues/users-can-increase-their-voting-power-by-voting-for-the-maxmin-values-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "Many parameters in the system are determined by the complicated governance mechanism. These parameters are calculated as a result of the voting process and are equal to the weighted average of all the votes that stakeholders make. The idea is that every user is voting for the desired value. But if the result value is smaller (larger) than the desired, the user can change the vote for the max (min) possible value. That would shift the result towards the desired one and basically \u201cincrease\u201d this stakeholder\u2019s voting power. So every user is more incentivized to vote for the min/max value than for the desired one.",
        "The issue\u2019s severity is not high because all parameters have reasonable max value limitations, so it\u2019s hard to manipulate the system too much."
    ],
    "Recommendation": [
        "Reconsider the voting mechanism."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-unitransferfrom-function-can-potentially-be-used-with-invalid-params-fix-unverified-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function uniTransferFrom(IERC20 token, address payable from, address to, uint256 amount) internal {\n    if (amount > 0) {\n        if (isETH(token)) {\n            require(msg.value >= amount, \"UniERC20: not enough value\");\n            if (msg.value > amount) {\n                // Return remainder if exist\n                from.transfer(msg.value.sub(amount));\n            }\n        } else {\n            token.safeTransferFrom(from, to, amount);\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "According to the client, this issue is addressed in 1inch-exchange/[email\u00a0protected]d0ffb6f.",
        "(This fix is as reported by the developer team, but has not been verified by Diligence)."
    ],
    "Description": [
        "The system is using the UniERC20 contract to incapsulate transfers of both ERC-20 tokens and ETH. This contract has uniTransferFrom function that can be used for any ERC-20 or ETH:",
        "code/contracts/libraries/UniERC20.sol:L36-L48",
        "In case if the function is called for the normal ERC-20 token, everything works as expected. The tokens are transferred from the from address to the to address. If the token is ETH - the transfer is expected to be from the msg.sender to this contract. Even if the to and from parameters are different.",
        "This issue\u2019s severity is not high because the function is always called with the proper parameters in the current codebase."
    ],
    "Recommendation": [
        "Make sure that the uniTransferFrom function is always called with expected parameters."
    ]
}
----End JSON----

https://solodit.xyz/issues/mooniswapgovernance-votingpower-is-not-accurately-reflected-when-minting-pool-tokens-fix-unverified-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_beforeTokenTransfer(address from, address to, uint256 amount) internal override {\n    uint256 balanceFrom = (from != address(0)) ? balanceOf(from) : 0;\n    uint256 balanceTo = (from != address(0)) ? balanceOf(to) : 0;\n    uint256 newTotalSupply = totalSupply()\n        .add(from == address(0) ? amount : 0)\n        .sub(to == address(0) ? amount : 0);\n\n    ParamsHelper memory params = ParamsHelper({\n        from: from,\n        to: to,\n        amount: amount,\n        balanceFrom: balanceFrom,\n        balanceTo: balanceTo,\n        newTotalSupply: newTotalSupply\n    });\n\n",
        "\nif (params.to != address(0)) {\n    votingData.updateBalance(params.to, voteTo, params.balanceTo, params.balanceTo.add(params.amount), params.newTotalSupply, defaultValue, emitEvent);\n}\n\n",
        "uint256 balanceTo = (to != address(0)) ? balanceOf(to) : 0;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "According to the client, this issue is addressed in 1inch-exchange/[email\u00a0protected]eb869fd",
        "(This fix is as reported by the developer team, but has not been verified by Diligence)."
    ],
    "Description": [
        "When a user provides liquidity to the pool, pool-tokens are minted. The minting event triggers the _beforeTokenTransfer callback in MooniswapGovernance which updates voting power reflecting the newly minted stake for the user.",
        "There seems to be a copy-paste error in the way balanceTo is determined that sets balanceTo to zero if new token were minted (from==address(0)). This means, that in a later call to _updateOnTransfer only the newly minted amount is considered when adjusting voting power."
    ],
    "Examples": [
        "code/contracts/governance/MooniswapGovernance.sol:L100-L114",
        "code/contracts/governance/MooniswapGovernance.sol:L150-L153"
    ],
    "Recommendation": [
        "balanceTo should be zero when burning (to == address(0)) and balanceOf(to) when minting.",
        "e.g. like this:"
    ]
}
----End JSON----

https://solodit.xyz/issues/mooniswapgovernance-_beforetokentransfer-should-not-update-voting-power-on-transfers-to-self-fix-unverified-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_beforeTokenTransfer(address from, address to, uint256 amount) internal override {\n    uint256 balanceFrom = (from != address(0)) ? balanceOf(from) : 0;\n    uint256 balanceTo = (from != address(0)) ? balanceOf(to) : 0;\n    uint256 newTotalSupply = totalSupply()\n        .add(from == address(0) ? amount : 0)\n        .sub(to == address(0) ? amount : 0);\n\n    ParamsHelper memory params = ParamsHelper({\n        from: from,\n        to: to,\n        amount: amount,\n        balanceFrom: balanceFrom,\n        balanceTo: balanceTo,\n        newTotalSupply: newTotalSupply\n    });\n\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultFee, \\_emitFeeVoteUpdate, \\_fee);\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultSlippageFee, \\_emitSlippageFeeVoteUpdate, \\_slippageFee);\n    \\_updateOnTransfer(params, mooniswapFactoryGovernance.defaultDecayPeriod, \\_emitDecayPeriodVoteUpdate, \\_decayPeriod);\n}\n\n",
        "if (params.from != address(0)) {\n    votingData.updateBalance(params.from, voteFrom, params.balanceFrom, params.balanceFrom.sub(params.amount), params.newTotalSupply, defaultValue, emitEvent);\n}\n\nif (params.to != address(0)) {\n    votingData.updateBalance(params.to, voteTo, params.balanceTo, params.balanceTo.add(params.amount), params.newTotalSupply, defaultValue, emitEvent);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed 1inch-exchange/[email\u00a0protected]7c7126d",
        "(This fix is as reported by the developer team, but has not been verified by Diligence)."
    ],
    "Description": [
        "Mooniswap governance is based on the liquidity voting system that is also employed by the mothership or for factory governance. In contrast to traditional voting systems where users vote for discrete values, the liquidity voting system derives a continuous weighted averaged \u201cconsensus\u201d value from all the votes. Thus it is required that whenever stake changes in the system, all the parameters that can be voted upon are updated with the new weights for a specific user.",
        "The Mooniswap pool is governed by liquidity providers and liquidity tokens are the stake that gives voting rights in MooniswapGovernance. Thus whenever liquidity tokens are transferred to another address, stake and voting values need to be updated. This is handled by MooniswapGovernance._beforeTokenTransfer().",
        "In the special case where someone triggers a token transfer where the from address equals the to address, effectively sending the token to themselves, no update on voting power should be performed. Instead, voting power is first updated with balance - amount and then with balance + amount which in the worst case means it is updating first to a zero balance and then to 2x the balance.",
        "Ultimately this should not have an effect on the overall outcome but is unnecessary and wasting gas."
    ],
    "Examples": [
        "code/contracts/governance/MooniswapGovernance.sol:L100-L119",
        "code/contracts/governance/MooniswapGovernance.sol:L147-L153"
    ],
    "Recommendation": [
        "Do not update voting power on LP token transfers where from == to."
    ]
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-for-users-due-to-admin-front-running-or-general-bad-timing-consensys-1inch-liquidity-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setReferralFeeReceiver(address newReferralFeeReceiver) external onlyOwner {\n    referralFeeReceiver = newReferralFeeReceiver;\n    emit ReferralFeeReceiverUpdate(newReferralFeeReceiver);\n}\n\n",
        "if (referral != address(0)) {\n    referralShare = invIncrease.mul(referralShare).div(\\_FEE\\_DENOMINATOR);\n    if (referralShare > 0) {\n        if (referralFeeReceiver != address(0)) {\n            \\_mint(referralFeeReceiver, referralShare);\n            IReferralFeeReceiver(referralFeeReceiver).updateReward(referral, referralShare);\n\n",
        "function addModule(address module) external onlyOwner {\n    require(\\_modules.add(module), \"Module already registered\");\n    emit AddModule(module);\n}\n\n",
        "function \\_notifyFor(address account, uint256 balance) private {\n    uint256 modulesLength = \\_modules.length();\n    for (uint256 i = 0; i < modulesLength; ++i) {\n        IGovernanceModule(\\_modules.at(i)).notifyStakeChanged(account, balance);\n    }\n}\n\n",
        "function removeModule(address module) external onlyOwner {\n    require(\\_modules.remove(module), \"Module was not registered\");\n    emit RemoveModule(module);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to the unfortunate timing of changes.",
        "In general users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "code/contracts/governance/MooniswapFactoryGovernance.sol:L92-L95",
        "code/contracts/Mooniswap.sol:L281-L286",
        "At any point in time and without prior notice to users an admin may accidentally or intentionally add a broken governance sub-module to the system that blocks all users from unstaking their 1INCH token. An admin can recover from this by removing the broken sub-module, however, with malicious intent tokens may be locked forever.",
        "Since 1INCH token gives voting power in the system, tokens are considered to hold value for other users and may be traded on exchanges. This raises concerns if tokens can be locked in a contract by one actor.",
        "code/contracts/inch/GovernanceMothership.sol:L63-L66",
        "code/contracts/inch/GovernanceMothership.sol:L73-L78",
        "An admin may front-run users while staking in an attempt to prevent submodules from being notified of the stake update. This is unlikely to happen as it incurs costs for the attacker (front-back-running) to normal users but may be an interesting attack scenario to exclude a whale\u2019s stake from voting.",
        "For example, an admin may front-run stake() or notoify*() by briefly removing all governance submodules from the mothership and re-adding them after the users call succeeded. The stake-update will not be propagated to the sub-modules. A user may only detect this when they are voting (if they had no stake before) or when they actually check their stake. Such an attack might likely stay unnoticed unless someone listens for addmodule removemodule events on the contract.",
        "code/contracts/inch/GovernanceMothership.sol:L68-L71",
        "An admin may choose to front-run their own unstake(), temporarily removing all governance sub-modules, preventing unstake() from syncing the action to sub-modules while still getting their previously staked tokens out. The governance sub-modules can be re-added right after unstaking. Due to double-accounting of the stake (in governance and in every sub-module) their stake will still be exercisable in the sub-module even though it was removed from the mothership. Users can only prevent this by manually calling a state-sync on the affected account(s)."
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately.",
        "Furthermore, users should be guaranteed to be able to redeem their staked tokens. An entity - even though trusted - in the system should not be able to lock tokens indefinitely."
    ]
}
----End JSON----

https://solodit.xyz/issues/potentially-dangerous-use-of-a-cached-exchange-rate-from-compound-consensys-growth-defi-v1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "GPortfolioReserveManager.adjustReserve performs reserve adjustment calculations based on Compound\u2019s cached exchange rate values (using CompoundLendingMarketAbstraction.getExchangeRate()) then triggers operations on managed tokens based on up-to-date values (using CompoundLendingMarketAbstraction.fetchExchangeRate()) . Significant deviation between the cached and up-to-date values may make it difficult to predict the outcome of reserve adjustments."
    ],
    "Recommendation": [
        "Use getExchangeRate() consistently, or ensure fetchExchangeRate() is used first, and getExchangeRate() afterward."
    ]
}
----End JSON----

https://solodit.xyz/issues/potential-resource-exhaustion-by-external-calls-performed-within-an-unbounded-loop-consensys-growth-defi-v1-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 \\_numMarkets = SoloMargin(\\_solo).getNumMarkets();\nfor (uint256 \\_i = 0; \\_i < \\_numMarkets; \\_i++) {\n\taddress \\_address = SoloMargin(\\_solo).getMarketTokenAddress(\\_i);\n\tif (\\_address == \\_token) {\n\t\t\\_marketId = \\_i;\n\t\tbreak;\n\t}\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "DydxFlashLoanAbstraction._requestFlashLoan performs external calls in a potentially-unbounded loop. Depending on changes made to DyDx\u2019s SoloMargin, this may render this flash loan provider prohibitively expensive. In the worst case, changes to SoloMargin could make it impossible to execute this code due to the block gas limit.",
        "code/contracts/modules/DydxFlashLoanAbstraction.sol:L62-L69"
    ]
}
----End JSON----

https://solodit.xyz/issues/ether-temporarily-held-during-transactions-can-be-stolen-via-reentrancy-fixed-consensys-0x-exchange-v4-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @dev Refunds up to `msg.value` leftover ETH at the end of the call.\nmodifier refundsAttachedEth() {\n    \\_;\n    uint256 remainingBalance =\n        LibSafeMathV06.min256(msg.value, address(this).balance);\n    if (remainingBalance > 0) {\n        msg.sender.transfer(remainingBalance);\n    }\n}\n\n",
        "if (inputToken == ETH\\_TOKEN\\_ADDRESS) {\n    provider.transfer(sellAmount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is addressed in 0xProject/[email\u00a0protected]437a3b0 by transferring exactly msg.value in sellToLiquidityProvider(). This adequately protects against this specific vulnerability.",
        "The client team decided to leave the accounting in MetaTransactionsFeature as-is due to the complexity/expense of tracking ether consumption more strictly."
    ],
    "Description": [
        "The exchange proxy typically holds no ether balance, but it can temporarily hold a balance during a transaction. This balance is vulnerable to theft if the following conditions are met:",
        "We found one example where these conditions are met, but it\u2019s possible that more exist."
    ],
    "Example": [
        "MetaTransactionsFeature.executeMetaTransaction() accepts ether, which is used to pay protocol fees. It\u2019s possible for less than the full amount in msg.value to be consumed, which is why the function uses the refundsAttachedEth modifier to return any remaining ether to the caller:",
        "code/contracts/zero-ex/contracts/src/features/MetaTransactionsFeature.sol:L98-L106",
        "Notice that this modifier just returns the remaining ether balance (up to msg.value). It does not check for a specific amount of remaining ether. This meets condition (1) above.",
        "It\u2019s impossible to reenter the system with a second metatransaction because executeMetaTransaction() uses the modifier nonReentrant, but there\u2019s nothing preventing reentrancy via a different feature. We can achieve reentrancy by trading a token that uses callbacks (e.g. ERC777\u2019s hooks) during transfers. This meets condition (2).",
        "To find a full exploit, we also need a way to extract the ether held by the exchange proxy. LiquidityProviderFeature.sellToLiquidityProvider() provides such a mechanism. By passing ETH_TOKEN_ADDRESS as the inputToken and an address in the attacker\u2019s control as the provider, an attacker can transfer out any ether held by the exchange proxy. Note that sellToLiquidityProvider() can transfer any amount of ether, not limited to the amount sent via msg.value:",
        "code/contracts/zero-ex/contracts/src/features/LiquidityProviderFeature.sol:L114-L115",
        "This meets condition (3).",
        "The full steps to exploit this vulnerability are as follows:"
    ],
    "Recommendation": [
        "In general, we recommend using strict accounting of ether throughout the system. If there\u2019s ever a temporary balance, it should be accurately resolved at the end of the transaction, after any potential reentrancy opportunities.",
        "For the example we specifically found, we recommend doing strict accounting in the metatransactions feature. This means features called via a metatransaction would need to return how much ether was consumed. The metatransactions feature could then refund exactly msg.value - <consumed ether>. The transaction should be reverted if this fails because it means ether went missing during the transaction.",
        "We also recommend limiting sellToLiquidityProvider() to only transfer up to msg.value. This is a form of defense in depth in case other vectors for a similar attack exist."
    ]
}
----End JSON----

https://solodit.xyz/issues/periodicprizestrategy-rng-failure-can-lock-user-funds-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function beforeTokenTransfer(address from, address to, uint256 amount, address controlledToken) external override onlyPrizePool {\n  if (controlledToken == address(ticket)) {\n    \\_requireNotLocked();\n  }\n\n",
        "function \\_requireNotLocked() internal view {\n  uint256 currentBlock = \\_currentBlock();\n  require(rngRequest.lockBlock == 0 || currentBlock < rngRequest.lockBlock, \"PeriodicPrizeStrategy/rng-in-flight\");\n}\n\n",
        "function setRngService(RNGInterface rngService) external onlyOwner {\n  require(!isRngRequested(), \"PeriodicPrizeStrategy/rng-in-flight\");\n\n"
    ],
    "preamble": [],
    "Description": [
        "To prevent manipulation of the SortitionSumTree after a requested random number enters the mempool, users are unable to withdraw funds while the strategy contract waits on a random number request between execution of startAward() and completeAward().",
        "If an rng request fails, however, there is no way to exit this locked state. After an rng request times out, only startAward() can be called, which will make another rng request and re-enter the same locked state. The rng provider can also not be updated while the contract is in this state. If the rng provider fails permanently, user funds are permanently locked."
    ],
    "Examples": [
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L282-L285",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L528-L531",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L413-L414"
    ],
    "Recommendation": [
        "Instead of forcing the pending award phase to be re-entered in the event of an rng request time-out, provide an exitAwardPhase() function that ends the award phase without paying out the award. This will at least allow users to withdraw their funds in the event of a catastrophic failure of the rng service. It may also be prudent to allow the rng service to be updated in the event of an rng request time out."
    ]
}
----End JSON----

https://solodit.xyz/issues/lootbox-unprotected-selfdestruct-in-proxy-implementation-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "constructor () public {\n  lootBoxActionInstance = new LootBox();\n  lootBoxActionBytecode = MinimalProxyLibrary.minimalProxy(address(lootBoxActionInstance));\n}\n\n",
        "/// @notice Destroys this contract using `selfdestruct`\n/// @param to The address to send remaining Ether to\nfunction destroy(address payable to) external {\n  selfdestruct(to);\n}\n\n",
        "\ncontract CounterfactualAction {\n  function depositTo(address payable user, PrizePool prizePool, address output, address referrer) external {\n    IERC20 token = IERC20(prizePool.token());\n    uint256 amount = token.balanceOf(address(this));\n    token.approve(address(prizePool), amount);\n    prizePool.depositTo(user, amount, output, referrer);\n    selfdestruct(user);\n  }\n\n  function cancel(address payable user, PrizePool prizePool) external {\n    IERC20 token = IERC20(prizePool.token());\n    token.transfer(user, token.balanceOf(address(this)));\n    selfdestruct(user);\n  }\n\n"
    ],
    "preamble": [],
    "Description": [
        "When the LootBoxController is deployed, it also deploys an instance of LootBox. When someone calls LootBoxController.plunder() or LootBoxController.executeCall() the controller actually deploys a temporary proxy contract to a deterministic address using create2, then calls out to it to collect the loot.",
        "The LootBox implementation contract is completely unprotected, exposing all its functionality to any actor on the blockchain. The most critical functionality is actually the LootBox.destroy() method that calls selfdestruct() on the implementation contract.",
        "Therefore, an unauthenticated user can selfdestruct the LootBox proxy implementation and cause the complete system to become dysfunctional. As an effect, none of the AirDrops that were delivered based on this contract will be redeemable (Note: create2 deploy address is calculated from the current contract address and salt). Funds may be lost."
    ],
    "Examples": [
        "code/loot-box/contracts/LootBoxController.sol:L28-L31",
        "code/loot-box/contracts/LootBox.sol:L86-L90",
        "code/pool/contracts/counterfactual-action/CounterfactualAction.sol:L7-L21"
    ],
    "Recommendation": [
        "Enforce that only the deployer of the contract can call functionality in the contract. Make sure that nobody can destroy the implementation of proxy contracts."
    ]
}
----End JSON----

https://solodit.xyz/issues/ticket-duplication-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (from != address(0)) {\n  uint256 fromBalance = balanceOf(from).sub(amount);\n  sortitionSumTrees.set(TREE\\_KEY, fromBalance, bytes32(uint256(from)));\n}\n\nif (to != address(0)) {\n  uint256 toBalance = balanceOf(to).add(amount);\n  sortitionSumTrees.set(TREE\\_KEY, toBalance, bytes32(uint256(to)));\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Ticket._beforeTokenTransfer() contains logic to update the SortitionSumTree from which prize winners are drawn. In the case where the from address is the same as the to address, tickets are duplicated rather than left unchanged. This allows any attacker to duplicate their tickets with no limit and virtually guarantee that they will win all awarded prizes.",
        "code/pool/contracts/token/Ticket.sol:L71-L79",
        "This code was outside the scope of our review but was live on mainnet at the time the issue was disovered. We immediately made the client aware of the issue and an effort was made to mitigate the impact on the existing deployment."
    ]
}
----End JSON----

https://solodit.xyz/issues/periodicpricestrategy-trustedforwarder-can-impersonate-any-msgsender-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier onlyPrizePool() {\n  require(\\_msgSender() == address(prizePool), \"PeriodicPrizeStrategy/only-prize-pool\");\n  \\_;\n}\n\n",
        "modifier onlyOwnerOrListener() {\n  require(\\_msgSender() == owner() || \\_msgSender() == address(periodicPrizeStrategyListener), \"PeriodicPrizeStrategy/only-owner-or-listener\");\n  \\_;\n}\n\n",
        "emit PrizePoolOpened(\\_msgSender(), prizePeriodStartedAt);\n\n",
        "emit PrizePoolAwardStarted(\\_msgSender(), address(prizePool), requestId, lockBlock);\n\n",
        "emit PrizePoolAwarded(\\_msgSender(), randomNumber);\nemit PrizePoolOpened(\\_msgSender(), prizePeriodStartedAt);\n\n",
        "/// @dev Provides information about the current execution context for GSN Meta-Txs.\n/// @return The payable address of the message sender\nfunction \\_msgSender()\n  internal\n  override(BaseRelayRecipient, ContextUpgradeSafe)\n  virtual\n  view\n  returns (address payable)\n{\n  return BaseRelayRecipient.\\_msgSender();\n}\n\n",
        "// File: @opengsn/gsn/contracts/BaseRelayRecipient.sol\n\n...\n\n   /\\*\\*\n \\* return the sender of this call.\n \\* if the call came through our trusted forwarder, return the original sender.\n \\* otherwise, return `msg.sender`.\n \\* should be used in the contract anywhere instead of msg.sender\n \\*/\n    function \\_msgSender() internal override virtual view returns (address payable ret) {\n        if (msg.data.length >= 24 && isTrustedForwarder(msg.sender)) {\n            // At this point we know that the sender is a trusted forwarder,\n            // so we trust that the last bytes of msg.data are the verified sender address.\n            // extract sender address from the end of msg.data\n            assembly {\n                ret := shr(96,calldataload(sub(calldatasize(),20)))\n            }\n        } else {\n            return msg.sender;\n        }\n    }\n\n"
    ],
    "preamble": [],
    "Description": [
        "The trustedForwarder undermines the trust assumptions in the system. For example, one would assume that the access control modifier onlyPrizePool would only allow the configured PrizePool to call certain methods. However, in reality, the trustedForwarder can assume this position as well. The same is true for the onlyOwnerOrListener modifier. One would assume msg.sender must either be periodicPrizeStrategyListener or owner (the initial deployer) while the trustedForwarder can assume any of the administrative roles.",
        "The centralization of power to allow one account to impersonate other components and roles (owner, listener, prizePool) in the system is a concern by itself and may give users pause when deciding whether to trust the contract system. The fact that the trustedForwarder can spoof events for any msg.sender may also make it hard to keep an accurate log trail of events in case of a security incident.",
        "Note: The same functionality seems to be used in ControlledToken and other contracts which allows the trustedForwarder to assume any tokenholder in ERC20UpgradeSafe. There is practically no guarantee to ControlledToken holders.",
        "Note: The trustedForwarder/msgSender() pattern is used in multiple contracts, many of which are not in the scope of this assessment."
    ],
    "Examples": [
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L588-L591",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L565-L568",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L164-L164",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L340-L340",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L356-L357",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L541-L551"
    ],
    "Recommendation": [
        "Remove the trustedForwarder or restrict the type of actions the forwarder can perform and don\u2019t allow it to impersonate other components in the system. Make sure users understand the trust assumptions and who has what powers in the system. Make sure to keep an accurate log trail of who performed which action on whom\u2019s behalf."
    ]
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-for-users-due-to-admin-front-running-or-general-bad-timing-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setNumberOfWinners(uint256 count) external onlyOwner {\n  \\_\\_numberOfWinners = count;\n\n  emit NumberOfWinnersSet(count);\n}\n\n",
        "function setRngService(RNGInterface rngService) external onlyOwner {\n  require(!isRngRequested(), \"PeriodicPrizeStrategy/rng-in-flight\");\n\n  rng = rngService;\n  emit RngServiceUpdated(address(rngService));\n}\n\n",
        "function setRngRequestTimeout(uint32 \\_rngRequestTimeout) external onlyOwner {\n  \\_setRngRequestTimeout(\\_rngRequestTimeout);\n}\n\n",
        "function setTokenListener(TokenListenerInterface \\_tokenListener) external onlyOwner {\n  tokenListener = \\_tokenListener;\n\n  emit TokenListenerUpdated(address(tokenListener));\n}\n\n",
        "function setPeriodicPrizeStrategyListener(address \\_periodicPrizeStrategyListener) external onlyOwner {\n  periodicPrizeStrategyListener = PeriodicPrizeStrategyListener(\\_periodicPrizeStrategyListener);\n\n  emit PeriodicPrizeStrategyListenerSet(\\_periodicPrizeStrategyListener);\n}\n\n",
        "/// @notice Sets the prize strategy of the prize pool. Only callable by the owner.\n/// @param \\_prizeStrategy The new prize strategy\nfunction setPrizeStrategy(address \\_prizeStrategy) external override onlyOwner {\n  \\_setPrizeStrategy(TokenListenerInterface(\\_prizeStrategy));\n}\n\n\n",
        "function removeExternalErc20Award(address \\_externalErc20, address \\_prevExternalErc20) external onlyOwner {\n  externalErc20s.removeAddress(\\_prevExternalErc20, \\_externalErc20);\n  emit ExternalErc20AwardRemoved(\\_externalErc20);\n}\n\n",
        "function removeExternalErc721Award(address \\_externalErc721, address \\_prevExternalErc721) external onlyOwner {\n  externalErc721s.removeAddress(\\_prevExternalErc721, \\_externalErc721);\n  delete externalErc721TokenIds[\\_externalErc721];\n  emit ExternalErc721AwardRemoved(\\_externalErc721);\n}\n\n",
        "function transferExternalERC20(\n  address to,\n  address externalToken,\n  uint256 amount\n)\n  external\n  onlyOwner\n{\n  prizePool.transferExternalERC20(to, externalToken, amount);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.",
        "In general users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "An administrator (deployer) of MultipleWinners can change the number of winners in the system without warning. This has the potential to violate a security goal of the system.",
        "code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L38-L42",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L413-L418",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L420-L422",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L175-L179",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L360-L364",
        "code/pool/contracts/prize-pool/PrizePool.sol:L1003-L1008",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L461-L464",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L506-L510",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L517-L526"
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all system-parameter and upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period. This allows users that do not accept the change to withdraw immediately."
    ]
}
----End JSON----

https://solodit.xyz/issues/periodicpricestrategy-addexternalerc721award-duplicate-or-invalid-tokenids-may-block-award-phase-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Adds an external ERC721 token as an additional prize that can be awarded\n/// @dev Only the Prize-Strategy owner/creator can assign external tokens,\n/// and they must be approved by the Prize-Pool\n/// NOTE: The NFT must already be owned by the Prize-Pool\n/// @param \\_externalErc721 The address of an ERC721 token to be awarded\n/// @param \\_tokenIds An array of token IDs of the ERC721 to be awarded\nfunction addExternalErc721Award(address \\_externalErc721, uint256[] calldata \\_tokenIds) external onlyOwnerOrListener {\n  // require(\\_externalErc721.isContract(), \"PeriodicPrizeStrategy/external-erc721-not-contract\");\n  require(prizePool.canAwardExternal(\\_externalErc721), \"PeriodicPrizeStrategy/cannot-award-external\");\n \n  if (!externalErc721s.contains(\\_externalErc721)) {\n    externalErc721s.addAddress(\\_externalErc721);\n  }\n\n  for (uint256 i = 0; i < \\_tokenIds.length; i++) {\n    uint256 tokenId = \\_tokenIds[i];\n    require(IERC721(\\_externalErc721).ownerOf(tokenId) == address(prizePool), \"PeriodicPrizeStrategy/unavailable-token\");\n    externalErc721TokenIds[\\_externalErc721].push(tokenId);\n  }\n\n  emit ExternalErc721AwardAdded(\\_externalErc721, \\_tokenIds);\n}\n\n",
        "/// @notice Awards all external ERC721 tokens to the given user.\n/// The external tokens must be held by the PrizePool contract.\n/// @dev The list of ERC721s is reset after every award\n/// @param winner The user to transfer the tokens to\nfunction \\_awardExternalErc721s(address winner) internal {\n  address currentToken = externalErc721s.start();\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\n    if (balance > 0) {\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\n      delete externalErc721TokenIds[currentToken];\n    }\n    currentToken = externalErc721s.next(currentToken);\n  }\n  externalErc721s.clearAll();\n}\n\n",
        "/// @notice Called by the prize strategy to award external ERC721 prizes\n/// @dev Used to award any arbitrary NFTs held by the Prize Pool\n/// @param to The address of the winner that receives the award\n/// @param externalToken The address of the external NFT token being awarded\n/// @param tokenIds An array of NFT Token IDs to be transferred\nfunction awardExternalERC721(\n  address to,\n  address externalToken,\n  uint256[] calldata tokenIds\n)\n  external override\n  onlyPrizeStrategy\n{\n  require(\\_canAwardExternal(externalToken), \"PrizePool/invalid-external-token\");\n\n  if (tokenIds.length == 0) {\n    return;\n  }\n\n  for (uint256 i = 0; i < tokenIds.length; i++) {\n    IERC721(externalToken).transferFrom(address(this), to, tokenIds[i]);\n  }\n\n  emit AwardedExternalERC721(to, externalToken, tokenIds);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The prize-strategy owner (or a listener) can add ERC721 token awards by calling addExternalErc721Award providing the ERC721 token address and a list of tokenIds owned by the prizePool.",
        "The method does not check if duplicate tokenIds or tokenIds that are not owned by the contract are provided. This may cause an exception when _awardExternalErc721s calls prizePool.awardExternalERC721 to transfer an invalid or previously transferred token, blocking the award phase.",
        "Note: An admin can recover from this situation by removing and re-adding the ERC721 token from the awards list."
    ],
    "Examples": [
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L478-L499",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L248-L263",
        "code/pool/contracts/prize-pool/PrizePool.sol:L582-L606"
    ],
    "Recommendation": [
        "Ensure that no duplicate token-ids were provided or skip over token-ids that are not owned by prize-pool (anymore)."
    ]
}
----End JSON----

https://solodit.xyz/issues/periodicprizestrategy-token-with-callback-related-warnings-erc777-ao-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_awardExternalErc721s(address winner) internal {\n  address currentToken = externalErc721s.start();\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\n    if (balance > 0) {\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\n      delete externalErc721TokenIds[currentToken];\n    }\n    currentToken = externalErc721s.next(currentToken);\n  }\n  externalErc721s.clearAll();\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "This issue is highly dependent on the configuration of the system. If an admin decides to allow callback enabled token (e.g. ERC20 compliant ERC777 or other ERC721/ERC20 extensions) as awards then one recipient may be able to"
    ],
    "Examples": [
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L252-L263"
    ],
    "Recommendation": [
        "It is highly recommended to not allow tokens with callback functionality into the system. Document and/or implement safeguards that disallow the use of callback enabled tokens. Consider implementing means for the \u201cother winners\u201d to withdraw their share of the rewards independently from others."
    ]
}
----End JSON----

https://solodit.xyz/issues/periodicprizestrategy-unbounded-external-tokens-linked-list-may-be-used-to-force-a-gas-dos-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Adds an external ERC20 token type as an additional prize that can be awarded\n/// @dev Only the Prize-Strategy owner/creator can assign external tokens,\n/// and they must be approved by the Prize-Pool\n/// @param \\_externalErc20 The address of an ERC20 token to be awarded\nfunction addExternalErc20Award(address \\_externalErc20) external onlyOwnerOrListener {\n  \\_addExternalErc20Award(\\_externalErc20);\n}\n\nfunction \\_addExternalErc20Award(address \\_externalErc20) internal {\n  require(prizePool.canAwardExternal(\\_externalErc20), \"PeriodicPrizeStrategy/cannot-award-external\");\n  externalErc20s.addAddress(\\_externalErc20);\n  emit ExternalErc20AwardAdded(\\_externalErc20);\n}\n\n",
        "/// @param newAddress The address to shift to the front of the list\nfunction addAddress(Mapping storage self, address newAddress) internal {\n  require(newAddress != SENTINEL && newAddress != address(0), \"Invalid address\");\n  require(self.addressMap[newAddress] == address(0), \"Already added\");\n  self.addressMap[newAddress] = self.addressMap[SENTINEL];\n  self.addressMap[SENTINEL] = newAddress;\n  self.count = self.count + 1;\n}\n\n",
        "/// @notice Awards all external ERC721 tokens to the given user.\n/// The external tokens must be held by the PrizePool contract.\n/// @dev The list of ERC721s is reset after every award\n/// @param winner The user to transfer the tokens to\nfunction \\_awardExternalErc721s(address winner) internal {\n  address currentToken = externalErc721s.start();\n  while (currentToken != address(0) && currentToken != externalErc721s.end()) {\n    uint256 balance = IERC721(currentToken).balanceOf(address(prizePool));\n    if (balance > 0) {\n      prizePool.awardExternalERC721(winner, currentToken, externalErc721TokenIds[currentToken]);\n      delete externalErc721TokenIds[currentToken];\n    }\n    currentToken = externalErc721s.next(currentToken);\n  }\n  externalErc721s.clearAll();\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The size of the linked list of ERC20/ERC721 token awards is not limited. This fact may be exploited by an administrative account by adding an excessive number of external token addresses.",
        "The winning user might want to claim their win by calling completeAward() which fails in one of the _distribute() -> _awardAllExternalTokens() -> _awardExternalErc20s/_awardExternalErc721s while loops if too many token addresses are configured and gas consumption hits the block gas limit (or it just gets too expensive for the user to call).",
        "Note: an admin can recover from this situation by removing items from the list."
    ],
    "Examples": [
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L436-L448",
        "code/pool/contracts/utils/MappedSinglyLinkedList.sol:L46-L53",
        "code/pool/contracts/prize-strategy/PeriodicPrizeStrategy.sol:L248-L263"
    ],
    "Recommendation": [
        "Limit the number of tokens an admin can add. Consider implementing an interface that allows the user to claim tokens one-by-one or in user-configured batches."
    ]
}
----End JSON----

https://solodit.xyz/issues/multiplewinners-setnumberofwinners-does-not-enforce-count0-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\\_numberOfWinners > 0, \"MultipleWinners/num-gt-zero\");\n\n",
        "function setNumberOfWinners(uint256 count) external onlyOwner {\n  \\_\\_numberOfWinners = count;\n\n  emit NumberOfWinnersSet(count);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "The constructor of MultipleWinners enforces that the argument _numberOfWinners > 0 while setNumberOfWinners does not. A careless or malicious admin might set __numberOfWinners to zero to cause the distribute() method to throw and not pay out any winners."
    ],
    "Examples": [
        "code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L34-L34",
        "code/pool/contracts/prize-strategy/multiple-winners/MultipleWinners.sol:L38-L42"
    ],
    "Recommendation": [
        "Require that numberOfWinners > 0."
    ]
}
----End JSON----

https://solodit.xyz/issues/lootbox-plunder-should-disallow-plundering-to-address0-consensys-pooltogether-lootbox-and-multiplewinners-strategy-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function plunder(\n  address erc721,\n  uint256 tokenId,\n  IERC20[] calldata erc20s,\n  LootBox.WithdrawERC721[] calldata erc721s,\n  LootBox.WithdrawERC1155[] calldata erc1155s\n) external {\n  address payable owner = payable(IERC721(erc721).ownerOf(tokenId));\n\n",
        " \\* @dev See {IERC721-ownerOf}.\n \\*/\nfunction ownerOf(uint256 tokenId) public view override returns (address) {\n    return \\_tokenOwners[tokenId];\n}\n\n\n",
        "function plunder(\n  IERC20[] memory erc20,\n  WithdrawERC721[] memory erc721,\n  WithdrawERC1155[] memory erc1155,\n  address payable to\n) external {\n  \\_withdrawERC20(erc20, to);\n  \\_withdrawERC721(erc721, to);\n  \\_withdrawERC1155(erc1155, to);\n  transferEther(to, address(this).balance);\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "Anyone can call LootboxController.plunder() to plunder on behalf of a tokenId owner. If a LootBox received an AirDrop but no NFT was issued to an owner (yet) this might open up an opportunity for a malicious actor to call plunder() in an attempt to burn the ETH and any airdropped tokens that allow transfers to address(0).",
        "Note:"
    ],
    "Examples": [
        "code/loot-box/contracts/LootBoxController.sol:L49-L56",
        "code/loot-box/contracts/external/openzeppelin/ERC721.sol:L102-L107",
        "code/loot-box/contracts/LootBox.sol:L74-L84"
    ],
    "Recommendation": [
        "Require that the destination address to in plunder() and transferEther() is not address(0)."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc20-tokens-with-no-return-value-will-fail-to-transfer-fixed-consensys-bitbank-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (!instance.transfer(getSendAddress(), forwarderBalance)) {\n    revert('Could not gather ERC20');\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed using OpenZeppelin\u2019s SafeERC20."
    ],
    "Description": [
        "Although the ERC20 standard suggests that a transfer should return true on success, many tokens are non-compliant in this regard.",
        "In that case, the .transfer() call here will revert even if the transfer is successful, because solidity will check that the RETURNDATASIZE matches the ERC20 interface.",
        "code/contracts/ExchangeDeposit.sol:L229-L231"
    ],
    "Recommendation": [
        "Consider using OpenZeppelin\u2019s SafeERC20."
    ]
}
----End JSON----

https://solodit.xyz/issues/owners-can-never-be-removed-fixed-consensys-paxos-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < ownersArr.length; i++) {\n   isOwner[ownersArr[i]] = false;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This has been fixed in https://github.com/paxosglobal/simple-multisig/pull/5, and appropriate tests have been added."
    ],
    "Description": [
        "The intention of setOwners() is to replace the current set of owners with a new set of owners. However, the isOwner mapping is never updated, which means any address that was ever considered an owner is permanently considered an owner for purposes of signing transactions."
    ],
    "Recommendation": [
        "In setOwners_(), before adding new owners, loop through the current set of owners and clear their isOwner booleans, as in the following code:"
    ]
}
----End JSON----

https://solodit.xyz/issues/delegated-transactions-can-be-executed-for-multiple-accounts-fixed-consensys-none-pillar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "address sender = \\_hashPrimaryTypedData(\n \\_hashTypedData(\n nonce,\n to,\n data\n )\n).recoverAddress(senderSignature);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the client: The issue has been solved"
    ],
    "Description": [
        "The Gateway contract allows users to create meta transactions triggered by the system\u2019s backend. To do so, one of the owners of the account should sign the message in the following format:",
        "code/src/gateway/Gateway.sol:L125-L131",
        "The message includes a nonce, destination address, and call data. The problem is that this message does not include the account address. So if the sender is the owner of multiple accounts, this meta transaction can be called for multiple accounts."
    ],
    "Recommendation": [
        "Add the account field in the signed message or make sure that any address can be the owner of only one account."
    ]
}
----End JSON----

https://solodit.xyz/issues/removing-an-owner-does-not-work-in-personalaccountregistry-fixed-consensys-none-pillar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "accounts[account].owners[owner].removedAtBlockNumber = block.number;\n\nemit AccountOwnerRemoved(\n account,\n owner\n);\n\n",
        "function \\_verifySender(\n address account\n)\n private\n returns (address)\n{\n address sender = \\_getContextSender();\n\n if (!accounts[account].owners[sender].added) {\n require(\n accounts[account].salt == 0\n );\n\n bytes32 salt = keccak256(\n abi.encodePacked(sender)\n );\n\n require(\n account == \\_computeAccountAddress(salt)\n );\n\n accounts[account].salt = salt;\n accounts[account].owners[sender].added = true;\n\n emit AccountOwnerAdded(\n account,\n sender\n );\n }\n\n return sender;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the client: The issue has been solved"
    ],
    "Description": [
        "An owner of a personal account can be added/removed by other owners. When removing the owner, only removedAtBlockNumber value is updated. accounts[account].owners[owner].added remains true:",
        "code/src/personal/PersonalAccountRegistry.sol:L116-L121",
        "But when the account is checked whether this account is the owner, only accounts[account].owners[owner].added is actually checked:",
        "code/src/personal/PersonalAccountRegistry.sol:L255-L286",
        "So the owner will never be removed, because accounts[account].owners[owner].added will always be `true."
    ],
    "Recommendation": [
        "Properly check if the account is still the owner in the _verifySender  function."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-withdrawal-mechanism-is-overcomplicated-fixed-consensys-none-pillar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdrawDeposit(\n address token\n)\n external\n{\n address owner = \\_getContextAccount();\n uint256 lockedUntil = deposits[owner].withdrawalLockedUntil[token];\n\n /\\* solhint-disable not-rely-on-time \\*/\n\n if (lockedUntil != 0 && lockedUntil <= now) {\n deposits[owner].withdrawalLockedUntil[token] = 0;\n\n address depositAccount = deposits[owner].account;\n uint256 depositValue;\n\n if (token == address(0)) {\n depositValue = depositAccount.balance;\n } else {\n depositValue = ERC20Token(token).balanceOf(depositAccount);\n }\n\n \\_transferFromDeposit(\n depositAccount,\n owner,\n token,\n depositValue\n );\n\n emit DepositWithdrawn(\n depositAccount,\n owner,\n token,\n depositValue\n );\n } else {\n \\_deployDepositAccount(owner);\n\n lockedUntil = now.add(depositWithdrawalLockPeriod);\n\n deposits[owner].withdrawalLockedUntil[token] = lockedUntil;\n\n emit DepositWithdrawalRequested(\n deposits[owner].account,\n owner,\n token,\n lockedUntil\n );\n }\n /\\* solhint-enable not-rely-on-time \\*/\n}\n\n",
        "if (deposits[sender].withdrawalLockedUntil[token] > 0) {\n deposits[sender].withdrawalLockedUntil[token] = 0;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the client:",
        "The withdrawal mechanism has been refactored.\nIn current version user can withdraw funds from the deposit account in two ways:"
    ],
    "Description": [
        "To withdraw the funds, anyone who has the account in PaymentRegistry should call the withdrawDeposit function and go through the withdrawal process. After the lockdown period (30 days), the user will withdraw all the funds from the account.",
        "code/src/payment/PaymentRegistry.sol:L160-L210",
        "During that period, everyone who has a channel with the user is forced to commit their channels or lose money from that channel. When doing so, every user will reset the initial lockdown period and the withdrawer should start the process again.",
        "code/src/payment/PaymentRegistry.sol:L479-L480",
        "There is no way for the withdrawer to close the channel by himself. If the withdrawer has N channels, it\u2019s theoretically possible to wait for up to N*(30 days) period and make N+2 transactions."
    ],
    "Recommendation": [
        "There may be some minor recommendations on how to improve that without major changes:"
    ]
}
----End JSON----

https://solodit.xyz/issues/a-malicious-guardian-can-steal-funds-wont-fix-consensys-none-pillar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from the client: The etherspot payment system is semi-trusted by design."
    ],
    "Description": [
        "A guardian is signing every message that should be submitted as a payment channel update.\nA guardian\u2019s two main things to verify are: blockNumber and the fact that the sender has enough funds.",
        "There are two main attack vectors for the malicious guardian:"
    ],
    "Recommendation": [
        "Reduce the system\u2019s reliance on single points of failure like the guardians."
    ]
}
----End JSON----

https://solodit.xyz/issues/every-node-gets-a-full-validators-bounty-fixed-consensys-skale-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "return epochPoolSize\n    .add(\\_bountyWasPaidInCurrentEpoch)\n    .mul(\n        delegationController.getAndUpdateEffectiveDelegatedToValidator(\n            nodes.getValidatorId(nodeIndex),\n            currentMonth\n        )\n    )\n    .div(effectiveDelegatedSum);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue is addressed in Bug/skale 3273 formula fix 435 and SKALE-3273 Fix BountyV2 populating error 438.",
        "The main change is related to how bounties are calculated for each validator. Below are a few notes on these pull requests:"
    ],
    "Description": [
        "To get the bounty, every node calls the getBounty function of the SkaleManager contract. This function can be called once per month. The size of the bounty is defined in the BountyV2 contract in the _calculateMaximumBountyAmount function:",
        "code/contracts/BountyV2.sol:L213-L221",
        "The problem is that this amount actually represents the amount that should be paid to the validator of that node. But each node will get this amount. Additionally, the amount of validator\u2019s bounty should also correspond to the number of active nodes, while this formula only uses the amount of delegated funds."
    ],
    "Recommendation": [
        "Every node should get only their parts of the bounty."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-node-exit-prevents-some-other-nodes-from-exiting-for-some-period-pending-consensys-skale-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "known issue, acknowledged, assigned as the work for the next few months as an improvement. Please assign as \u201cPending\u201d.\r\n\n",
        "function freezeSchains(uint nodeIndex) external allow(\"SkaleManager\") {\n    SchainsInternal schainsInternal = SchainsInternal(contractManager.getContract(\"SchainsInternal\"));\n    bytes32[] memory schains = schainsInternal.getActiveSchains(nodeIndex);\n    for (uint i = 0; i < schains.length; i++) {\n        Rotation memory rotation = rotations[schains[i]];\n        if (rotation.nodeIndex == nodeIndex && now < rotation.freezeUntil) {\n            continue;\n        }\n        string memory schainName = schainsInternal.getSchainName(schains[i]);\n        string memory revertMessage = \"Node cannot rotate on Schain \";\n        revertMessage = revertMessage.strConcat(schainName);\n        revertMessage = revertMessage.strConcat(\", occupied by Node \");\n        revertMessage = revertMessage.strConcat(rotation.nodeIndex.uint2str());\n        string memory dkgRevert = \"DKG process did not finish on schain \";\n        ISkaleDKG skaleDKG = ISkaleDKG(contractManager.getContract(\"SkaleDKG\"));\n        require(\n            skaleDKG.isLastDKGSuccessful(keccak256(abi.encodePacked(schainName))),\n            dkgRevert.strConcat(schainName));\n        require(rotation.freezeUntil < now, revertMessage);\n        \\_startRotation(schains[i], nodeIndex);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Skale team\u2019s comment:"
    ],
    "Description": [
        "When a node wants to exit, the nodeExit function should be called as many times, as there are schains in the node. Each time one schain is getting removed from the node. During every call, all the active schains are getting frozen for 12 hours.",
        "code/contracts/NodeRotation.sol:L84-L105",
        "Because of that, no other node that is running one of these schains can exit during that period. In the worst-case scenario, one malicious node has 128 Schains and calls nodeExit every 12 hours. That means that some nodes will not be able to exit for 64 days."
    ],
    "Recommendation": [
        "Make node exiting process less synchronous."
    ]
}
----End JSON----

https://solodit.xyz/issues/removing-a-node-require-multiple-transactions-and-may-be-very-expensive-pending-consensys-skale-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Acknowledged, assigned as the work for the next few months  (improvement). Please assign it as \u201cPending\u201d.\r\n\n",
        "function \\_startRotation(bytes32 schainIndex, uint nodeIndex) private {\n    ConstantsHolder constants = ConstantsHolder(contractManager.getContract(\"ConstantsHolder\"));\n    rotations[schainIndex].nodeIndex = nodeIndex;\n    rotations[schainIndex].newNodeIndex = nodeIndex;\n    rotations[schainIndex].freezeUntil = now.add(constants.rotationDelay());\n    waitForNewNode[schainIndex] = true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Skale team\u2019s comment:"
    ],
    "Description": [
        "When removing a node from the network, the owner should redistribute all the schains that are currently on that node to the other nodes. To do so, the validator should call the nodeExit function of the SkaleManager contract. In this function, only one schain is going to be removed from the node. So the node would have to call the nodeExit function as many times as there are schains in the node. Every call iterates over every potential node that can be used as a replacement (like in https://github.com/ConsenSys/skale-network-audit-2020-10/issues/3).",
        "In addition to that, the first call will iterate over all schains in the node, make 4 SSTORE operations and external calls for each schain:",
        "code/contracts/NodeRotation.sol:L204-L210",
        "This may hit the block gas limit even easier than issue 5.4.",
        "If the first transaction does not hit the block\u2019s gas limit, the maximum price of deleting a node would be BLOCK_GAS_COST * 128. At the moment, it\u2019s around $50,000."
    ],
    "Recommendation": [
        "Optimize the process of deleting a node, so it can\u2019t hit the gas limit in one transaction, and the overall price should be cheaper."
    ]
}
----End JSON----

https://solodit.xyz/issues/adding-a-new-schain-may-potentially-hit-the-gas-limit-pending-consensys-skale-network-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Acknowledged, assigned as the work for the next few months (improvement) Please assign as \u201cPending\u201d.\r\n\n",
        "function \\_generateGroup(bytes32 schainId, uint numberOfNodes) private returns (uint[] memory nodesInGroup) {\n    Nodes nodes = Nodes(contractManager.getContract(\"Nodes\"));\n    uint8 space = schains[schainId].partOfNode;\n    nodesInGroup = new uint[](numberOfNodes);\n\n    uint[] memory possibleNodes = isEnoughNodes(schainId);\n    require(possibleNodes.length >= nodesInGroup.length, \"Not enough nodes to create Schain\");\n    uint ignoringTail = 0;\n    uint random = uint(keccak256(abi.encodePacked(uint(blockhash(block.number.sub(1))), schainId)));\n    for (uint i = 0; i < nodesInGroup.length; ++i) {\n        uint index = random % (possibleNodes.length.sub(ignoringTail));\n        uint node = possibleNodes[index];\n        nodesInGroup[i] = node;\n        \\_swap(possibleNodes, index, possibleNodes.length.sub(ignoringTail).sub(1));\n        ++ignoringTail;\n\n        \\_exceptionsForGroups[schainId][node] = true;\n        addSchainForNode(node, schainId);\n        require(nodes.removeSpaceFromNode(node, space), \"Could not remove space from Node\");\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Skale team\u2019s comment:"
    ],
    "Description": [
        "When adding a new schain, a group of random 16 nodes is randomly selected to run that schain. In order to do so, the _generateGroup function iterates over all the nodes that can be used for that purpose:",
        "code/contracts/SchainsInternal.sol:L522-L541",
        "If the total number of nodes exceeds around a few thousands, adding a schain may hit the block gas limit."
    ],
    "Recommendation": [
        "Avoid iterating over all nodes when selecting a random node for a schain."
    ]
}
----End JSON----

https://solodit.xyz/issues/attacker-can-abuse-swapliquidity-function-to-drain-users-funds-fixed-consensys-aave-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "vars.fromReserveAToken.burn(\n  msg.sender,\n  receiverAddress,\n  amountToSwap,\n  fromReserve.liquidityIndex\n);\n// Notifies the receiver to proceed, sending as param the underlying already transferred\nISwapAdapter(receiverAddress).executeOperation(\n  fromAsset,\n  toAsset,\n  amountToSwap,\n  address(this),\n  params\n);\n\nvars.amountToReceive = IERC20(toAsset).balanceOf(receiverAddress);\nif (vars.amountToReceive != 0) {\n  IERC20(toAsset).transferFrom(\n    receiverAddress,\n    address(vars.toReserveAToken),\n    vars.amountToReceive\n  );\n\n  if (vars.toReserveAToken.balanceOf(msg.sender) == 0) {\n    \\_usersConfig[msg.sender].setUsingAsCollateral(toReserve.id, true);\n  }\n\n  vars.toReserveAToken.mint(msg.sender, vars.amountToReceive, toReserve.liquidityIndex);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Solved by removing swapLiquidity functionality."
    ],
    "Description": [
        "The swapLiquidity function allows liquidity providers to atomically swap their collateral. The function takes\na receiverAddressargument that normally points to an ISwapAdapter implementation trusted by the user.",
        "code/contracts/lendingpool/LendingPoolCollateralManager.sol:L490-L517",
        "However, since an attacker can pass any address as the receiverAddress, they can arbitrarily transfer funds from other contracts that have given allowances to the LendingPool contract (for example, another ISwapAdapter).",
        "The amountToSwap is defined by the caller and can be very small. The attacker gets the difference between IERC20(toAsset).balanceOf(receiverAddress) value of toAsset and the amountToSwap of fromToken."
    ],
    "Remediation": [
        "Ensure that no funds can be stolen from contracts that have granted allowances to the LendingPool contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/griefing-attack-by-taking-flash-loan-on-behalf-of-user-consensys-aave-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function flashLoan(\n  address receiverAddress,\n  address asset,\n  uint256 amount,\n  uint256 mode,\n  bytes calldata params,\n  uint16 referralCode\n) external override {\n\n"
    ],
    "preamble": [],
    "Description": [
        "When taking a flash loan from the protocol, the arbitrary receiverAddress  address can be passed as the argument:",
        "code/contracts/lendingpool/LendingPool.sol:L547-L554",
        "That may allow anyone to execute a flash loan on behalf of other users. In order to make that attack, the receiverAddress should give the allowance to the LendingPool contract to make a transfer for the amount of currentAmountPlusPremium."
    ],
    "Example": [
        "If someone is giving the allowance to the LendingPool contract to make a deposit, the attacker can execute a flash loan on behalf of that user, forcing the user to pay fees from the flash loan. That will also prevent the victim from making a successful deposit transaction."
    ],
    "Remediation": [
        "Make sure that only the user can take a flash loan."
    ]
}
----End JSON----

https://solodit.xyz/issues/interest-rates-are-updated-incorrectly-consensys-aave-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "vars.collateralAtoken.burn(\n  user,\n  receiver,\n  vars.maxCollateralToLiquidate,\n  collateralReserve.liquidityIndex\n);\n\n",
        "//updating collateral reserve\ncollateralReserve.updateInterestRates(\n  collateral,\n  address(vars.collateralAtoken),\n  0,\n  vars.maxCollateralToLiquidate\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was independently discovered by the Aave developers and had already been fixed by the end of the audit.",
        "The function updateInterestRates() updates the borrow rates of a reserve. Since the rates depend on the available liquidity they must be recalculated each time liquidity changes. The function takes the amount of liquidity added or removed as the input and is called ahead of minting or burning ATokens. However, in LendingPoolCollateralManager an interest rate update is performed after aTokens have been burned, resulting in an incorrect interest rate.",
        "code/contracts/lendingpool/LendingPoolCollateralManager.sol:L377-L382",
        "code/contracts/lendingpool/LendingPoolCollateralManager.sol:L427-L433",
        "Recommendation",
        "Update interest rates before calling collateralAtoken.burn()."
    ]
}
----End JSON----

https://solodit.xyz/issues/unhandled-return-values-of-transfer-and-transferfrom-consensys-aave-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "IERC20(asset).transferFrom(receiverAddress, vars.aTokenAddress, vars.amountPlusPremium);\n\n",
        "IERC20(principal).transferFrom(receiver, vars.principalAToken, vars.actualAmountToLiquidate);\n\n",
        "IERC20(toAsset).transferFrom(\n  receiverAddress,\n  address(vars.toReserveAToken),\n  vars.amountToReceive\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "safeTransferFrom is now used instead of transferFrom in all locations.",
        "ERC20 implementations are not always consistent. Some implementations of transfer and transferFrom could return \u2018false\u2019 on failure instead of reverting. It is safer to wrap such calls into require() statements to these failures. Unsafe transferFrom calls were found in the following locations:",
        "code/contracts/lendingpool/LendingPool.sol:L578",
        "code/contracts/lendingpool/LendingPoolCollateralManager.sol:L407",
        "code/contracts/lendingpool/LendingPoolCollateralManager.sol:L507-L511",
        "Recommendation",
        "Check the return value and revert on 0/false or use OpenZeppelin\u2019s SafeERC20 wrapper functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/unhandled-return-values-of-transfer-and-transferfrom-fixed-consensys-aave-safety-module-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "IERC20(STAKED\\_TOKEN).transferFrom(msg.sender, address(this), amount);\n\n",
        "REWARD\\_TOKEN.transferFrom(REWARDS\\_VAULT, to, amountToWithdraw);\n\n",
        "IERC20(STAKED\\_TOKEN).transfer(to, amount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The issue was fixed by using OpenZeppelin\u2019s safeTransfer and safeTransferFrom wrappers.",
        "ERC20 implementations are not always consistent. Some implementations of transfer and transferFrom could return \u2018false\u2019 on failure instead of reverting. It is safer to wrap such calls into require() statements to these failures.",
        "code/contracts/stake/StakedToken.sol:L92",
        "code/contracts/stake/StakedToken.sol:L156",
        "code/contracts/stake/StakedToken.sol:L125"
    ]
}
----End JSON----

https://solodit.xyz/issues/attacker-can-abuse-swapliquidity-function-to-drain-users-funds-fixed-consensys-aave-protocol-v2-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [
        "vars.fromReserveAToken.burn(\n msg.sender,\n receiverAddress,\n amountToSwap,\n fromReserve.liquidityIndex\n);\n// Notifies the receiver to proceed, sending as param the underlying already transferred\nISwapAdapter(receiverAddress).executeOperation(\n fromAsset,\n toAsset,\n amountToSwap,\n address(this),\n params\n);\n\nvars.amountToReceive = IERC20(toAsset).balanceOf(receiverAddress);\nif (vars.amountToReceive != 0) {\n IERC20(toAsset).transferFrom(\n receiverAddress,\n address(vars.toReserveAToken),\n vars.amountToReceive\n );\n\n if (vars.toReserveAToken.balanceOf(msg.sender) == 0) {\n \\_usersConfig[msg.sender].setUsingAsCollateral(toReserve.id, true);\n }\n\n vars.toReserveAToken.mint(msg.sender, vars.amountToReceive, toReserve.liquidityIndex);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Solved by removing swapLiquidity functionality."
    ],
    "Description": [
        "The swapLiquidity function allows liquidity providers to atomically swap their collateral. The function takes\na receiverAddressargument that normally points to an ISwapAdapter implementation trusted by the user.",
        "code/contracts/lendingpool/LendingPoolCollateralManager.sol:L490-L517",
        "However, since an attacker can pass any address as the receiverAddress, they can arbitrarily transfer funds from other contracts that have given allowances to the LendingPool contract (for example, another ISwapAdapter).",
        "The amountToSwap is defined by the caller and can be very small. The attacker gets the difference between IERC20(toAsset).balanceOf(receiverAddress) value of toAsset and the amountToSwap of fromToken."
    ],
    "Remediation": [
        "Ensure that no funds can be stolen from contracts that have granted allowances to the LendingPool contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/votingmachine-trytomovetovalidating-can-lock-up-proposals-fixed-consensys-aave-governance-dao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "tryToMoveToValidating(\\_proposalId);\n\n",
        "/// @notice Function to move to Validating the proposal in the case the last vote action\n/// was done before the required votingBlocksDuration passed\n/// @param \\_proposalId The id of the proposal\nfunction tryToMoveToValidating(uint256 \\_proposalId) public {\n    Proposal storage \\_proposal = proposals[\\_proposalId];\n    require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"VOTING\\_STATUS\\_REQUIRED\");\n    if (\\_proposal.currentStatusInitBlock.add(\\_proposal.votingBlocksDuration) <= block.number) {\n        for (uint256 i = 0; i <= COUNT\\_CHOICES; i++) {\n            if (\\_proposal.votes[i] > \\_proposal.precReq) {\n                internalMoveToValidating(\\_proposalId);\n            }\n        }\n    }\n}\n\n",
        "/// @notice Internal function to change proposalStatus from Voting to Validating\n/// @param \\_proposalId The id of the proposal\nfunction internalMoveToValidating(uint256 \\_proposalId) internal {\n    Proposal storage \\_proposal = proposals[\\_proposalId];\n    require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"ONLY\\_ON\\_VOTING\\_STATUS\");\n    \\_proposal.proposalStatus = ProposalStatus.Validating;\n    \\_proposal.currentStatusInitBlock = block.number;\n    emit StatusChangeToValidating(\\_proposalId);\n}\n\n",
        "for (uint256 i = 0; i <= COUNT\\_CHOICES; i++) {\n    if (\\_proposal.votes[i] > \\_proposal.precReq) {\n        internalMoveToValidating(\\_proposalId);\n    }\n}\n\n",
        "require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"ONLY\\_ON\\_VOTING\\_STATUS\");\n\\_proposal.proposalStatus = ProposalStatus.Validating;\n\n",
        "function tryToMoveToValidating(uint256 \\_proposalId) public {\n    Proposal storage \\_proposal = proposals[\\_proposalId];\n    require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"VOTING\\_STATUS\\_REQUIRED\");\n    if (\\_proposal.currentStatusInitBlock.add(\\_proposal.votingBlocksDuration) <= block.number) {\n        for (uint256 i = 0; i <= COUNT\\_CHOICES; i++) {\n            if (\\_proposal.votes[i] > \\_proposal.precReq) {\n                internalMoveToValidating(\\_proposalId);\n                return; // <- this was added\n            }\n        }\n    }\n}\n\n",
        "/// @notice Internal function to change proposalStatus from Voting to Validating\n/// @param \\_proposalId The id of the proposal\nfunction internalMoveToValidating(uint256 \\_proposalId) internal {\n    Proposal storage \\_proposal = proposals[\\_proposalId];\n    // The line below can be removed\n    // require(\\_proposal.proposalStatus == ProposalStatus.Voting, \"ONLY\\_ON\\_VOTING\\_STATUS\");\n    \\_proposal.proposalStatus = ProposalStatus.Validating;\n    \\_proposal.currentStatusInitBlock = block.number;\n    emit StatusChangeToValidating(\\_proposalId);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed per our recommendation."
    ],
    "Description": [
        "After a vote was received, the proposal can move to a validating state if any of the votes pass the proposal\u2019s precReq value, referred to as the minimum threshold.",
        "code/contracts/governance/VotingMachine.sol:L391",
        "Inside the method tryToMoveToValidating each of the vote options are checked to see if they pass precReq. In case that happens, the proposal goes into the next stage, specifically Validating.",
        "code/contracts/governance/VotingMachine.sol:L394-L407",
        "The method internalMoveToValidating checks the proposal\u2019s status to be Voting and proceeds to moving the proposal into Validating state.",
        "code/contracts/governance/VotingMachine.sol:L270-L278",
        "The problem appears if multiple vote options go past the minimum threshold. This is because the loop does not stop after the first found option and the loop will fail when the method internalMoveToValidating is called a second time.",
        "code/contracts/governance/VotingMachine.sol:L401-L405",
        "The method internalMoveToValidating fails the second time because the first time it is called, the proposal goes into the Validating state and the second time it is called, the require check fails.",
        "code/contracts/governance/VotingMachine.sol:L274-L275",
        "This can lead to proposal lock-ups if there are enough votes to at least one option that pass the minimum threshold."
    ],
    "Recommendation": [
        "After moving to the Validating state return successfully.",
        "An additional change can be done to internalMoveToValidating because it is called only in tryToMoveToValidating and the parent method already does the check."
    ]
}
----End JSON----

https://solodit.xyz/issues/votingmachine-verifynonce-should-only-allow-the-next-nonce-fixed-consensys-aave-governance-dao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Verifies the nonce of a voter on a proposal\n/// @param \\_proposalId The id of the proposal\n/// @param \\_voter The address of the voter\n/// @param \\_relayerNonce The nonce submitted by the relayer\nfunction verifyNonce(uint256 \\_proposalId, address \\_voter, uint256 \\_relayerNonce) public view {\n    Proposal storage \\_proposal = proposals[\\_proposalId];\n    require(\\_proposal.voters[\\_voter].nonce < \\_relayerNonce, \"INVALID\\_NONCE\");\n}\n\n",
        "voter.nonce = voter.nonce.add(1);\n\n",
        "require(\\_proposal.voters[\\_voter].nonce + 1 == \\_relayerNonce, \"INVALID\\_NONCE\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed per our recommendation."
    ],
    "Description": [
        "When a relayer calls submitVoteByRelayer they also need to provide a nonce. This nonce is cryptographicly checked against the provided signature. It is also checked again to be higher than the previous nonce saved for that voter.",
        "code/contracts/governance/VotingMachine.sol:L232-L239",
        "When the vote is saved, the previous nonce is incremented.",
        "code/contracts/governance/VotingMachine.sol:L387",
        "This leaves the opportunity to use the same signature to vote multiple times, as long as the provided nonce is higher than the incremented nonce."
    ],
    "Recommendation": [
        "The check should be more restrictive and make sure the consecutive nonce was provided."
    ]
}
----End JSON----

https://solodit.xyz/issues/reentrancy-vulnerability-in-metaswapswap-fixed-consensys-metaswap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Transfer remaining balance of tokenTo to sender\nif (address(tokenTo) != Constants.ETH) {\n    uint256 balance = tokenTo.balanceOf(address(this));\n    require(balance >= amountTo, \"INSUFFICIENT\\_AMOUNT\");\n    \\_transfer(tokenTo, balance, recipient);\n} else {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/[email\u00a0protected]8de01f6."
    ],
    "Description": [
        "MetaSwap.swap() should have a reentrancy guard.",
        "The adapters use this general process:",
        "If an attacker is able to reenter swap() before step 3, they can execute their own trade using the same tokens and get all the tokens for themselves.",
        "This is partially mitigated by the check against amountTo in CommonAdapter, but note that the amountTo typically allows for slippage, so it may still leave room for an attacker to siphon off some amount while still returning the required minimum to the user.",
        "code/contracts/adapters/CommonAdapter.sol:L57-L62"
    ],
    "Examples": [
        "As an example of how this could be exploited, 0x supports an \u201cEIP1271Wallet\u201d signature type, which invokes an external contract to check whether a trade is allowed. A malicious maker might front run the swap to reduce their inventory. This way, the taker is sending more of the taker asset than necessary to MetaSwap. The excess can be stolen by the maker during the EIP1271 call."
    ],
    "Recommendation": [
        "Use a simple reentrancy guard, such as OpenZeppelin\u2019s ReentrancyGuard to prevent reentrancy in MetaSwap.swap(). It might seem more obvious to put this check in Spender.swap(), but the Spender contract intentionally does not use any storage to avoid interference between different adapters."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-new-malicious-adapter-can-access-users-tokens-fixed-consensys-metaswap-markdown_
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/[email\u00a0protected]8de01f6."
    ],
    "Description": [
        "The purpose of the MetaSwap contract is to save users gas costs when dealing with a number of different aggregators. They can just approve() their tokens to be spent by MetaSwap (or in a later architecture, the Spender contract). They can then perform trades with all supported aggregators without having to reapprove anything.",
        "A downside to this design is that a malicious (or buggy) adapter has access to a large collection of valuable assets. Even a user who has diligently checked all existing adapter code before interacting with MetaSwap runs the risk of having their funds intercepted by a new malicious adapter that\u2019s added later."
    ],
    "Recommendation": [
        "There are a number of designs that could be used to mitigate this type of attack. After discussion and iteration with the client team, we settled on a pattern where the MetaSwap contract is the only contract that receives token approval. It then moves tokens to the Spender contract before that contract DELEGATECALLs to the appropriate adapter. In this model, newly added adapters shouldn\u2019t be able to access users' funds."
    ]
}
----End JSON----

https://solodit.xyz/issues/owner-can-front-run-traders-by-updating-adapters-fixed-consensys-metaswap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/[email\u00a0protected]8de01f6."
    ],
    "Description": [
        "MetaSwap owners can front-run users to swap an adapter implementation. This could be used by a malicious or compromised owner to steal from users.",
        "Because adapters are DELEGATECALLed, they can modify storage. This means any adapter can overwrite the logic of another adapter, regardless of what policies are put in place at the contract level. Users must fully trust every adapter because just one malicious adapter could change the logic of all other adapters."
    ],
    "Recommendation": [
        "At a minimum, disallow modification of existing adapters. Instead, simply add new adapters and disable the old ones. (They should be deleted, but the aggregator IDs of deleted adapters should never be reused.)",
        "This is, however, insufficient. A new malicious adapter could still overwrite the adapter mapping to modify existing adapters. To fully address this issue, the adapter registry should be in a separate contract. Through discussion and iteration with the client team, we settled on the following pattern:"
    ]
}
----End JSON----

https://solodit.xyz/issues/attacker-can-abuse-gas-tokens-stored-in-metaswap-fixed-consensys-metaswap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This function was removed in ConsenSys/[email\u00a0protected]75c4454."
    ],
    "Description": [
        "MetaSwap.swapUsingGasToken() allows users to make use of gas tokens held by the MetaSwap contract itself to reduce the gas cost of trades.",
        "This mechanism is unsafe because any tokens held by the contract can be used by an attacker for other purposes."
    ],
    "Examples": [
        "If gas tokens are held by MetaSwap, an attacker can use them all up by performing a gas-heavy operation via a call to swapUsingGasToken(). For example, an attacker could create a token called EVIL and establish an ETH/EVIL pair on Uniswap. The implementation for EVIL\u2019s transfer() or transferFrom() method could do arbitrary gas-heavy operations. Finally, the attacker can invoke swapUsingGasToken(), using the Uniswap adapter and ETH/EVIL as the trading pair. When EVIL\u2019s transfer functions are called, they can consume a large amount of gas. When the operation is complete, swapUsingGasTokens() will burn as much CHI gas tokens as possible to help offset the gas use.",
        "An attack could also be made by using an existing token that makes external calls (e.g. an ERC777 token) or a mechanism in an aggregated exchange that makes external calls (e.g. wallet signatures in 0x)."
    ],
    "Recommendation": [
        "The simplest way to avoid this vulnerability is to never transfer CHI gas tokens to MetaSwap at all. An alternative would be to only allow gas tokens to be used by approved transactions from the MetaSwap API. A possible mechanism for that would be to require a signature from the MetaSwap API. If such a signature were only provided in known-good situations (which are admittedly hard to define), it wouldn\u2019t be possible for an attacker to misuse the tokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-new-malicious-adapter-can-access-users-tokens-fixed-consensys-metaswap-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/[email\u00a0protected]8de01f6."
    ],
    "Description": [
        "The purpose of the MetaSwap contract is to save users gas costs when dealing with a number of different aggregators. They can just approve() their tokens to be spent by MetaSwap (or in a later architecture, the Spender contract). They can then perform trades with all supported aggregators without having to reapprove anything.",
        "A downside to this design is that a malicious (or buggy) adapter has access to a large collection of valuable assets. Even a user who has diligently checked all existing adapter code before interacting with MetaSwap runs the risk of having their funds intercepted by a new malicious adapter that\u2019s added later."
    ],
    "Recommendation": [
        "There are a number of designs that could be used to mitigate this type of attack. After discussion and iteration with the client team, we settled on a pattern where the MetaSwap contract is the only contract that receives token approval. It then moves tokens to the Spender contract before that contract DELEGATECALLs to the appropriate adapter. In this model, newly added adapters shouldn\u2019t be able to access users\u2019 funds."
    ]
}
----End JSON----

https://solodit.xyz/issues/swap-fees-can-be-bypassed-using-redeemmasset-addressed-consensys-mstable-11-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_settleRedemption(\\_recipient, \\_mAssetQuantity, props.bAssets, bAssetQuantities, props.indexes, props.integrators, false);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was reported independently via the bug bounty program and was fixed early during the audit. The fix has already been deployed on mainnet using the upgrade mechanism"
    ],
    "Description": [
        "Part of the value proposition for liquidity providers is earning fees incurred for swapping between assets. However, traders can perform fee-less swaps by providing liquidity in one bAsset, followed by calling redeemMasset() to convert the resulting mAssets back into a proportional amount of bAssets. Since removing liquidity via redeemMasset() does not incur a fee this is equivalent to doing a swap with zero fees.",
        "As a very simple example, assuming a pool with 2 bAssets (say, DAI and USDT), it would be possible to swap 10 DAI to USDT as follows:"
    ],
    "Examples": [
        "The boolean argument applyFee is set to false in _redeemMasset:",
        "code/contracts/masset/Masset.sol:L569"
    ],
    "Recommendation": [
        "Charge a small redemption fee in redeemMasset()."
    ]
}
----End JSON----

https://solodit.xyz/issues/users-can-collect-interest-from-savingscontract-by-only-staking-mtokens-momentarily-addressed-consensys-mstable-11-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// 1. Only collect interest if it has been 30 mins\nuint256 timeSinceLastCollection = now.sub(previousCollection);\nif(timeSinceLastCollection > THIRTY\\_MINUTES) {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The blocker on collecting interest more than once in 30 minute period. A new APY bounds check has been added to verify that supply isn\u2019t inflated by more than 0.1% within a 30 minutes window."
    ],
    "Description": [
        "The SAVE contract allows users to deposit mAssets in return for lending yield and swap fees. When depositing mAsset, users receive a \u201ccredit\u201d tokens at the momentary credit/mAsset exchange rate which is updated at every deposit. However, the smart contract enforces a minimum timeframe of 30 minutes in which the interest rate will not be updated. A user who deposits shortly before the end of the timeframe will receive credits at the stale interest rate and can immediately trigger and update of the rate and withdraw at the updated (more favorable) rate after the 30 minutes window. As a result, it would be possible for users to benefit from interest payouts by only staking mAssets momentarily and using them for other purposes the rest of the time."
    ],
    "Examples": [
        "code/contracts/savings/SavingsManager.sol:L141-L143"
    ],
    "Recommendation": [
        "Remove the 30 minutes window such that every deposit also updates the exchange rate between credits and tokens. Note that this issue was reported independently during the bug bounty program and a fix is currently being worked on."
    ]
}
----End JSON----

https://solodit.xyz/issues/internal-accounting-of-vault-balance-may-diverge-from-actual-token-balance-in-lending-pool-wont-fix-consensys-mstable-11-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "quantityDeposited = \\_amount;\n\nif(\\_isTokenFeeCharged) {\n    // If we charge a fee, account for it\n    uint256 prevBal = \\_checkBalance(cToken);\n    require(cToken.mint(\\_amount) == 0, \"cToken mint failed\");\n    uint256 newBal = \\_checkBalance(cToken);\n    quantityDeposited = \\_min(quantityDeposited, newBal.sub(prevBal));\n} else {\n    // Else just execute the mint\n    require(cToken.mint(\\_amount) == 0, \"cToken mint failed\");\n}\n\nemit Deposit(\\_bAsset, address(cToken), quantityDeposited);\n\n",
        "basketManager.increaseVaultBalance(bInfo.index, integrator, quantityDeposited);\n\n",
        "uint256 deposited = IPlatformIntegration(\\_integrator).deposit(\\_bAsset, quantityTransferred, \\_erc20TransferFeeCharged);\n\n",
        "uint256 balance = IPlatformIntegration(integrations[i]).checkBalance(b.addr);\nuint256 oldVaultBalance = b.vaultBalance;\n\n// accumulate interest (ratioed bAsset)\nif(balance > oldVaultBalance && b.status == BassetStatus.Normal) {\n    // Update balance\n    basket.bassets[i].vaultBalance = balance;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "After discussion with the team the risk of this invariant violation was considered negligible as the gas cost increase for querying constantly querying the lending pool would outweigh the size of the accounting error of only 1 base unit."
    ],
    "Description": [
        "It is possible that the vault balance for a given bAsset is greater than the corresponding balance in the lending pool. This violates one of the correctness properties stated in the audit brief. Our Harvey fuzzer was able to generate a transaction that mints a small amount (0xf500) of mAsset. Due to the way that the lending pool integration (Compound in this case) updates the vault balance it ends up greater than the available balance in the lending pool.",
        "More specifically, the integration contract assumes that the amount deposited into the pool is equal to the amount received by the mAsset contract for the case where no transaction fees are charged for token transfers:",
        "code/contracts/masset/platform-integrations/CompoundIntegration.sol:L45-L58",
        "For illustration, consider the following scenario: assume your current balance in a lending pool is 0. When you deposit some amount X into the lending pool your balance after the deposit may be less than X (even if the underlying token does not charge transfer fees). One reason for this is rounding, but, in theory, a lending pool could also charge fees, etc.",
        "The vault balance is updated in function Masset._mintTo based on the amount returned by the integration.",
        "code/contracts/masset/Masset.sol:L189",
        "code/contracts/masset/Masset.sol:L274",
        "This violation of the correctness property is temporary since the vault balance is readjusted when interest is collected. However, the time frame of ca. 30 minutes between interest collections (may be longer if no continuous interest is distributed) means that it may be violated for substantial periods of time.",
        "code/contracts/masset/BasketManager.sol:L243-L249",
        "The regular updates due to interest collection should ensure that the difference stays relatively small. However, note that the following scenarios is feasible: assuming there is 0 DAI in the basket, a user mints X mUSD by depositing X DAI. While the interest collection hasn\u2019t been triggered yet, the user tries to redeem X mUSD for DAI. This may fail since the amount of DAI in the lending pool is smaller than X."
    ],
    "Recommendation": [
        "It seems like this issue could be fixed by using the balance increase from the lending pool to update the vault balance (much like for the scenario where transfer fees are charged) instead of using the amount received."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-validation-in-masset_redeemto-acknowledged-consensys-mstable-11-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 colRatio = StableMath.min(props.colRatio, StableMath.getFullScale());\n\n// Ensure payout is related to the collateralised mAsset quantity\nuint256 collateralisedMassetQuantity = \\_mAssetQuantity.mulTruncate(colRatio);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "An explicit check will be added with the next Masset proxy upgrade."
    ],
    "Description": [
        "In function _redeemTo the collateralisation ratio is not taken into account unlike in _redeemMasset:",
        "code/contracts/masset/Masset.sol:L558-L561",
        "It seems like _redeemTo should not be executed if the collateralisation ratio is below 100%. However, the contracts (that is, Masset and ForgeValidator) themselves don\u2019t seem to enforce this explicitly. Instead, the governor needs to ensure that the collateralisation ratio is only set to a value below 100% when the basket is not \u201chealthy\u201d (for instance, if it is considered \u201cfailed\u201d). Failing to ensure this may allow an attacker to redeem a disproportionate amount of assets. Note that the functionality for setting the collateralisation ratio is not currently implemented in the audited code."
    ],
    "Recommendation": [
        "Consider enforcing the intended use of _redeemTo more explicitly. For instance, it might be possible to introduce additional input validation by requiring that the collateralisation ratio is not below 100%."
    ]
}
----End JSON----

https://solodit.xyz/issues/oracle-updates-can-be-manipulated-to-perform-atomic-front-running-attack-addressed-consensys-bancor-v2-amm-security-audit-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The issue was mitigated by updating the Oracle price only once per block and consistently only using the old value throughout the block instead of querying the Oracle when adding or removing liquidity. Arbitrageurs can now no longer do the profitable trade within a single transaction which also precludes the possibility of using flash loans to amplify the attack."
    ],
    "Description": [
        "It is possible to atomically arbitrage rate changes in a risk-free way by \u201csandwiching\u201d the Oracle update between two transactions. The attacker would send the following 2 transactions at the moment the Oracle update appears in the mempool:",
        "The first transaction, which is sent with a higher gas price than the Oracle update transaction, converts a very small amount. This \u201clocks in\u201d the conversion weights for the block since handleExternalRateChange() only updates weights once per block. By doing this, the arbitrageur ensures that the stale Oracle price is initially used when doing the first conversion in the following transaction.",
        "The second transaction, which is sent at a slightly lower gas price than the transaction that updates the Oracle, does the following:",
        "The attacker can obtain liquidity for step 2 using a flash loan. The attack will deplete the reserves of the pool. An example is shown in section 5.4."
    ],
    "Recommendation": [
        "Do not allow users to trade at a stale Oracle rate and trigger an Oracle price update in the same transaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/slippage-and-fees-can-be-manipulated-by-a-trader-addressed-consensys-bancor-v2-amm-security-audit-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Initial state:\r\nconverter TKN balance = 10000000\r\nconverter TKN weight = 500000\r\nconverter BNT balance = 10000000\r\nconverter BNT weight = 500000\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The issue was addressed by introducing an exit fee mechanism. When a liquidity provider wants to withdraw some liquidity, the smart contract returns fewer tokens if the primary reserve is not in the balanced state. So in most cases, the manipulations described in the issue should potentially be non-profitable anymore. Although, in some cases, the traders still may have some incentive to add liquidity before making the trade and remove it after to get a part of the fees (i.e., if the pool is going to be in a balanced state after the trade)."
    ],
    "Description": [
        "Users are making trades against the liquidity pool (converter) with slippage and fees defined in the converter contract and Bancor formula.\nThe following steps can be done to optimize trading costs:",
        "Because the liquidity is increased on the first step, slippage is getting smaller for this trade. Additionally, the trader receives a part of the fees for this trade by providing liquidity.",
        "One of the reasons why this is possible is described in another issue issue 5.3.",
        "This technique of reducing slippage could be used by the trader to get more profit from any frontrunning/arbitrage opportunity and can help to deplete the reserves."
    ],
    "Example": [
        "Consider the initial state with an amplification factor of 20 and zero fees:",
        "Here a user can make a trade with the following rate:",
        "-> Convert 9000000 TKN into 8612440 BNT.",
        "But if the user adds 100% of the liquidity in both tokens before the trade, the slippage will be lower:",
        "-> Convert 9000000 TKN into 8801955 BNT."
    ],
    "Recommendation": [
        "Fixing this issue requires some modification of the algorithm."
    ]
}
----End JSON----

https://solodit.xyz/issues/loss-of-the-liquidity-pool-is-not-equally-distributed-addressed-consensys-bancor-v2-amm-security-audit-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        IPoolTokensContainer(anchor).burn(\\_poolToken, msg.sender, \\_amount);\n\n        // calculate how much liquidity to remove\n        // if the entire supply is liquidated, the entire staked amount should be sent, otherwise\n        // the price is based on the ratio between the pool token supply and the staked balance\n        uint256 reserveAmount = 0;\n        if (\\_amount == initialPoolSupply)\n            reserveAmount = balance;\n        else\n            reserveAmount = \\_amount.mul(balance).div(initialPoolSupply);\n\n        // sync the reserve balance / staked balance\n        reserves[reserveToken].balance = reserves[reserveToken].balance.sub(reserveAmount);\n        uint256 newStakedBalance = stakedBalances[reserveToken].sub(reserveAmount);\n        stakedBalances[reserveToken] = newStakedBalance;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The issue was addressed by adding a new fee mechanism called \u2018adjusted fees\u2019. This mechanism aims to decrease the deficit of the reserves over time. If there is a deficit of reserves, it is usually present on the secondary token side, because there is a strong incentive to bring the primary token to the balanced state. Roughly speaking, the idea is that if the secondary token has a deficit in reserves, there are additional fees for trading that token. These fees are not distributed across the liquidity providers like the regular fees. Instead, they are just populating the reserve, decreasing the existing deficit.",
        "Loss is still not distributed across the liquidity providers, and there is a possibility that there are not enough funds for everyone to withdraw them. In the case of a run on reserves, LPs will be able to withdraw funds on a first-come-first-serve basis."
    ],
    "Description": [
        "All stakeholders in the liquidity pool should be able to withdraw the same amount as they staked plus a share of fees that the converter earned during their staking period.",
        "code/contracts/converter/LiquidityPoolV2Converter.sol:L491-L505",
        "The problem is that sometimes there might not be enough funds in reserve (for example, due to this issue https://github.com/ConsenSys/bancor-audit-2020-06/issues/4). So the first ones who withdraw their stakes receive all the tokens they own. But the last stakeholders might not be able to get their funds back because the pool is empty already.",
        "So under some circumstances, there is a chance that users can lose all of their staked funds.",
        "This issue also has the opposite side: if the liquidity pool makes an extra profit, the stakers do not owe this profit and cannot withdraw it."
    ],
    "Recommendation": [
        "Distribute losses evenly across the liquidity providers."
    ]
}
----End JSON----

https://solodit.xyz/issues/oracle-front-running-could-deplete-reserves-over-time-addressed-consensys-bancor-v2-amm-security-audit-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "converter TKN balance = 100,000,000\r\nconverter TKN weight = 500,000\r\nconverter BNT balance = 100,000,000\r\nconverter BNT weight = 500,000\r\nfrontrunner TKN balance = 100,000,000\r\nfrontrunner BNT balance = 0\r\nOracle A rate = 10,000\r\nOracle B rate - 10,000\r\n\n",
        "converter TKN balance = 101,000,000\r\nconverter TKN weight = 500,000\r\nconverter BNT balance = 99,000,500\r\nconverter BNT weight = 500,000\r\nfrontrunner TKN balance = 99,000,000\r\nfrontrunner BNT balance = 999,500\r\n\n",
        "converter TKN balance = 99,995,006\r\nconverter TKN weight = 498,754\r\nconverter BNT balance = 100,000,000\r\nconverter BNT weight = 501,246\r\nfrontrunner TKN balance = 100,004,994\r\nfrontrunner BNT balance = 0\r\n\n",
        "converter TKN balance = 100,000,000\r\nconverter TKN weight = 498,754\r\nconverter BNT balance = 99,995,031\r\nconverter BNT weight = 501,246\r\nfrontrunner  TKN balance = 100,000,000\r\nfrontrunner BNT balance = 4,969\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "To mitigate this issue, the Bancor team has added a mechanism that adjusts the effective weights once per block based on its internal price feed. The conversion rate re-anchors to the external oracle price once the next oracle update comes in. This mechanism should help to cause the weight rebalancing caused by the external Oracle update to be less pronounced, thereby limiting the profitability of Oracle frontrunning. It should be noted that it also adds another layer of complexity to the system. It is difficult to predict the actual effectiveness and impact of this mitigation measure without simulating the system under real-world conditions."
    ],
    "Description": [
        "Bancor\u2019s weight rebalancing mechanism uses Chainlink price oracles to dynamically update the weights of the assets in the pool to track the market price. Due to Oracle price updates being visible in the mempool before they are included in a block, it is always possible to know about Oracle updates in advance and attempt to make a favourable conversion which takes the future rebalancing into account, followed by the reverse conversion after the rebalancing has occurred. This can be done with high liquidity and medium risk since transaction ordering on the Ethereum blockchain is largely predictable.",
        "Over time, this could deplete the secondary reserve as the formula compensates by rebalancing the weights such that the secondary token is sold slightly below its market rate (this is done to create an incentive to bring the primary reserve back to the amount staked by liquidity providers)."
    ],
    "Example": [
        "Consider the initial state with an amplification factor of 20 and zero fees:",
        "The frontrunner sees a Chainlink transaction in the mempool that changes Oracle B rate to 10,500. He sends a transaction with a slightly higher gas price than the Oracle update.",
        "The intermediate state:",
        "In the following block, the frontrunner sends another transaction with a high gas price (the goal is to be first to convert at the new rate set by the Oracle update):",
        "The state is:",
        "The frontrunner can now leverage the incentive created by the formula to bring back TKN reserve balance to staked TKN balance by converting TKN back to BNT:",
        "The final state is:",
        "The pool is now balanced and the frontrunner has gained 4,969 BNT."
    ],
    "Recommendation": [
        "This appears to be a fundamental problem caused by the fact that rebalancing is predictable. It is difficult to assess the actual impact of this issue without also reviewing components external to the scope of this audit (Chainlink) and extensively testing the system under real-world conditions."
    ]
}
----End JSON----

https://solodit.xyz/issues/use-of-external-calls-with-a-fixed-amount-of-gas-wont-fix-consensys-bancor-v2-amm-security-audit-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_to.transfer(address(this).balance);\n\n",
        "if (\\_targetToken == ETH\\_RESERVE\\_ADDRESS)\n\n",
        "msg.sender.transfer(reserveAmount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "It was decided to accept this minor risk as the usage of .call() might introduce other unexpected behavior."
    ],
    "Description": [
        "The converter smart contract uses the Solidity transfer() function to transfer Ether.",
        ".transfer() and .send() forward exactly 2,300 gas to the recipient. The goal of this hardcoded gas stipend was to prevent reentrancy vulnerabilities, but this only makes sense under the assumption that gas costs are constant. Recently EIP 1884 was included in the Istanbul hard fork. One of the changes included in EIP 1884 is an increase to the gas cost of the SLOAD operation, causing a contract\u2019s fallback function to cost more than 2300 gas."
    ],
    "Examples": [
        "code/contracts/converter/ConverterBase.sol:L228",
        "code/contracts/converter/LiquidityPoolV2Converter.sol:L370",
        "code/contracts/converter/LiquidityPoolV2Converter.sol:L509"
    ],
    "Recommendation": [
        "It\u2019s recommended to stop using .transfer() and .send() and instead use .call(). Note that .call() does nothing to mitigate reentrancy attacks, so other precautions must be taken. To prevent reentrancy attacks, it is recommended that you use the checks-effects-interactions pattern."
    ]
}
----End JSON----

https://solodit.xyz/issues/unexpected-response-in-an-assimilators-external-call-can-lock-up-the-whole-system-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:",
        "When this was brought to our attention, it made the most sense to look at it from a bird\u2019s eye view. In the event that an assimilator does seize up either due to smart contract malfunctioning or to some type of governance decision in one of our dependencies, then depending on the severity of the event, it could either make it so that that particular dependency is unable to be transacted with or it could brick the pool altogether.",
        "In the case of the latter severity where the pool is bricked altogether for an extended period of time, then this means the end of that particular pool\u2019s life. In this case, we find it prudent to allow for the withdrawal of any asset still functional from the pool. Should such an event transpire, we have instituted functionality to allow users to withdraw individually from the pool\u2019s assets according to their Shell balances without being exposed to the inertia of the incapacitated assets.",
        "In such an event, the owner of the pool can now trigger a partitioned state which is an end of life state for the pool in which users send Shells as normal until they decide to redeem any portion of them, after which they will only be able to redeem the portion of individual asset balances their Shell balance held claims on."
    ],
    "Description": [
        "The assimilators, being the \u201cmiddleware\u201d between a shell and all the external DeFi systems it interacts with, perform several external calls within their methods, as would be expected.",
        "An example of such a contract is mainnetSUsdToASUsdAssimilator.sol (the contract can be found here).",
        "The problem outlined in the title arises from the fact that Solidity automatically checks for the successful execution of the underlying message call (i.e., it bubbles up assertions and reverts) and, therefore, if any of these external systems changes in unexpected ways the call to the shell will revert itself.",
        "This problem is immensely magnified by the fact that all the external methods in Loihi dealing with deposits, withdraws, and swaps rebalance the pool and, as a consequence, all of the assimilators for the reserve tokens get called at some point.",
        "In summary, if any of the reserve tokens start, for some reason, refusing to complete a call to some of their methods, the whole protocol stops working, and the tokens are locked in forever (this is assuming the development team removes the safeApprove function from Loihi, v. https://github.com/ConsenSys/shell-protocol-audit-2020-06/issues/10)."
    ],
    "Recommendation": [
        "There is no easy solution to this problem since calls to these external systems cannot simply be ignored. Shell needs successful responses from the reserve assimilators to be able to function properly.",
        "One possible mitigation is to create a trustless mechanism based on repeated misbehavior by an external system to be able to remove a reserve asset from the pool.",
        "Such a design could consist of an external function accessible to all actors that needs X confirmations over a period of Y blocks (or days, for that matter) with even spacing between them to be able to remove a reserve asset.",
        "This means that no trust to the owners is implied (since this would require the extreme power to take user\u2019s tokens) and still maintains the healthy option of being able to remove faulty tokens from the pool."
    ]
}
----End JSON----

https://solodit.xyz/issues/certain-functions-lack-input-validation-routines-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function includeAsset (address \\_numeraire, address \\_nAssim, address \\_reserve, address \\_rAssim, uint256 \\_weight) public onlyOwner {\n    shell.includeAsset(\\_numeraire, \\_nAssim, \\_reserve, \\_rAssim, \\_weight);\n}\n\n",
        "function includeAsset (Shells.Shell storage shell, address \\_numeraire, address \\_numeraireAssim, address \\_reserve, address \\_reserveAssim, uint256 \\_weight) internal {\n\n    Assimilators.Assimilator storage \\_numeraireAssimilator = shell.assimilators[\\_numeraire];\n\n    \\_numeraireAssimilator.addr = \\_numeraireAssim;\n\n    \\_numeraireAssimilator.ix = uint8(shell.numeraires.length);\n\n    shell.numeraires.push(\\_numeraireAssimilator);\n\n    Assimilators.Assimilator storage \\_reserveAssimilator = shell.assimilators[\\_reserve];\n\n    \\_reserveAssimilator.addr = \\_reserveAssim;\n\n    \\_reserveAssimilator.ix = uint8(shell.reserves.length);\n\n    shell.reserves.push(\\_reserveAssimilator);\n\n    shell.weights.push(\\_weight.divu(1e18).add(uint256(1).divu(1e18)));\n\n}\n\n",
        "function includeAssimilator (address \\_numeraire, address \\_derivative, address \\_assimilator) public onlyOwner {\n    shell.includeAssimilator(\\_numeraire, \\_derivative, \\_assimilator);\n}\n\n",
        "function includeAssimilator (Shells.Shell storage shell, address \\_numeraire, address \\_derivative, address \\_assimilator) internal {\n\n    Assimilators.Assimilator storage \\_numeraireAssim = shell.assimilators[\\_numeraire];\n\n    shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix);\n    // shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix, 0, 0);\n\n}\n\n",
        "function swapByOrigin (address \\_o, address \\_t, uint256 \\_oAmt, uint256 \\_mTAmt, uint256 \\_dline) public notFrozen returns (uint256 tAmt\\_) {\n\n    return transferByOrigin(\\_o, \\_t, \\_dline, \\_mTAmt, \\_oAmt, msg.sender);\n\n}\n\n",
        "function transferByOrigin (address \\_origin, address \\_target, uint256 \\_dline, uint256 \\_mTAmt, uint256 \\_oAmt, address \\_rcpnt) public notFrozen nonReentrant returns (uint256 tAmt\\_) {\n\n    Assimilators.Assimilator memory \\_o = shell.assimilators[\\_origin];\n    Assimilators.Assimilator memory \\_t = shell.assimilators[\\_target];\n\n    // TODO: how to include min target amount\n    if (\\_o.ix == \\_t.ix) return \\_t.addr.outputNumeraire(\\_rcpnt, \\_o.addr.intakeRaw(\\_oAmt));\n\n",
        "// transfers raw amonut of dai in, wraps it in cDai, returns numeraire amount\nfunction intakeRaw (uint256 \\_amount) public returns (int128 amount\\_, int128 balance\\_) {\n\n    dai.transferFrom(msg.sender, address(this), \\_amount);\n\n    amount\\_ = \\_amount.divu(1e18);\n\n}\n\n",
        "// takes numeraire amount of dai, unwraps corresponding amount of cDai, transfers that out, returns numeraire amount\nfunction outputNumeraire (address \\_dst, int128 \\_amount) public returns (uint256 amount\\_) {\n\n    amount\\_ = \\_amount.mulu(1e18);\n\n    dai.transfer(\\_dst, amount\\_);\n\n    return amount\\_;\n\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:"
    ],
    "Description": [
        "The functions should first check if the passed arguments are valid first. The checks-effects-interactions pattern should be implemented throughout the code.",
        "These checks should include, but not be limited to:"
    ],
    "Examples": [
        "The function includeAsset does not do any checks before changing the contract state.",
        "src/Loihi.sol:L59-L61",
        "The internal function called by the public method includeAsset again doesn\u2019t check any of the data.",
        "src/Controller.sol:L77-L97",
        "Similar with includeAssimilator.",
        "src/Loihi.sol:L63-L65",
        "Again no checks are done in any function.",
        "src/Controller.sol:L99-L106",
        "Not only does the administrator functions not have any checks, but also user facing functions do not check the arguments.",
        "For example swapByOrigin does not check any of the arguments if you consider it calls MainnetDaiToDaiAssimilator.",
        "src/Loihi.sol:L85-L89",
        "It calls transferByOrigin and we simplify this example and consider we have _o.ix == _t.ix",
        "src/Loihi.sol:L181-L187",
        "In which case it can call 2 functions on an assimilatior such as MainnetDaiToDaiAssimilator.",
        "The first called function is intakeRaw.",
        "src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L42-L49",
        "And its result is used in outputNumeraire that again does not have any checks.",
        "src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L83-L92"
    ],
    "Recommendation": [
        "Implement the checks-effects-interactions as a pattern to write code. Add tests that check if all of the arguments have been validated.",
        "Consider checking arguments as an important part of writing code and developing the system."
    ]
}
----End JSON----

https://solodit.xyz/issues/remove-loihi-methods-that-can-be-used-as-backdoors-by-the-administrator-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function safeApprove(address \\_token, address \\_spender, uint256 \\_value) public onlyOwner {\n\n    (bool success, bytes memory returndata) = \\_token.call(abi.encodeWithSignature(\"approve(address,uint256)\", \\_spender, \\_value));\n\n    require(success, \"SafeERC20: low-level call failed\");\n\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue was partly addressed by the development team. However, the feature to add new assimilators is still present and that ultimately means that the administrators have power to run arbitrary bytecode.",
        "Updated remediation response\nSince the development team still hadn\u2019t fully settled on a strategy for a mainnet launch, this was left as a residue even after the audit mitigation phase. However, at launch time, this issue was no longer present and all the assimilators are now defined at deploy-time, it is fully resolved."
    ],
    "Description": [
        "There are several functions in Loihi that give extreme powers to the shell administrator. The most dangerous set of those is the ones granting the capability to add assimilators.",
        "Since assimilators are essentially a proxy architecture to delegate code to several different implementations of the same interface, the administrator could, intentionally or unintentionally, deploy malicious or faulty code in the implementation of an assimilator.\nThis means that the administrator is essentially totally trusted to not run code that, for example, drains the whole pool or locks up the users' and LPs' tokens.",
        "In addition to these, the function safeApprove allows the administrator to move any of the tokens the contract holds to any address regardless of the balances any of the users have.",
        "This can also be used by the owner as a backdoor to completely drain the contract.",
        "src/Loihi.sol:L643-L649"
    ],
    "Recommendation": [
        "Remove the safeApprove function and, instead, use a trustless escape-hatch mechanism like the one suggested in issue 6.1.",
        "For the assimilator addition functions, our recommendation is that they are made completely internal, only callable in the constructor, at deploy time.",
        "Even though this is not a big structural change (in fact, it reduces the attack surface), it is, indeed, a feature loss. However, this is the only way to make each shell a time-invariant system.",
        "This would not only increase Shell\u2019s security but also would greatly improve the trust the users have in the protocol since, after deployment, the code is now static and auditable."
    ]
}
----End JSON----

https://solodit.xyz/issues/assimilators-should-implement-an-interface-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function swapByOrigin (address \\_o, address \\_t, uint256 \\_oAmt, uint256 \\_mTAmt, uint256 \\_dline) public notFrozen returns (uint256 tAmt\\_) {\n\n    return transferByOrigin(\\_o, \\_t, \\_dline, \\_mTAmt, \\_oAmt, msg.sender);\n\n}\n\n",
        "if (\\_o.ix == \\_t.ix) return \\_t.addr.outputNumeraire(\\_rcpnt, \\_o.addr.intakeRaw(\\_oAmt));\n\n",
        "// takes raw cdai amount, transfers it in, calculates corresponding numeraire amount and returns it\nfunction intakeRaw (uint256 \\_amount) public returns (int128 amount\\_) {\n\n    bool success = cdai.transferFrom(msg.sender, address(this), \\_amount);\n\n    if (!success) revert(\"CDai/transferFrom-failed\");\n\n    uint256 \\_rate = cdai.exchangeRateStored();\n\n    \\_amount = ( \\_amount \\* \\_rate ) / 1e18;\n\n    cdai.redeemUnderlying(\\_amount);\n\n    amount\\_ = \\_amount.divu(1e18);\n\n}\n\n",
        "// transfers raw amonut of dai in, wraps it in cDai, returns numeraire amount\nfunction intakeRaw (uint256 \\_amount) public returns (int128 amount\\_, int128 balance\\_) {\n\n    dai.transferFrom(msg.sender, address(this), \\_amount);\n\n    amount\\_ = \\_amount.divu(1e18);\n\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:",
        "They now implement the interface in \u201csrc/interfaces/IAssimilator.sol\u201d."
    ],
    "Description": [
        "The Assimilators are one of the core components within the application. They are used to move the tokens and can be thought of as a \u201cmiddleware\u201d between the Shell Protocol application and any other supported tokens.",
        "The methods attached to the assimilators are called throughout the application and they are a critical component of the whole system. Because of this fact, it is extremely important that they behave correctly.",
        "A suggestion to restrict the possibility of errors when implementing them and when using them is to make all of the assimilators implement a unique specific interface. This way, any deviation would be immediately observed, right when the compilation happens."
    ],
    "Examples": [
        "Consider this example. The user calls swapByOrigin.",
        "src/Loihi.sol:L85-L89",
        "Which calls transferByOrigin. In transferByOrigin, if the origin index matches the target index, a different execution branch is activated.",
        "src/Loihi.sol:L187",
        "In this case we need the output of _o.addr.intakeRaw(_oAmt).",
        "If we pick a random assimilator and check the implementation, we see the function intakeRaw needs to return the transferred amount.",
        "src/assimilators/mainnet/daiReserves/mainnetCDaiToDaiAssimilator.sol:L52-L67",
        "However, with other implementations, the returns do not match. In the case of MainnetDaiToDaiAssimilator, it returns 2 values, which will make the Loihi contract work in this case but can misbehave in other cases, or even fail.",
        "src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L42-L49",
        "Making all the assimilators implement one unique interface will enforce the functions to look the same from the outside."
    ],
    "Recommendation": [
        "Create a unique interface for the assimilators and make all the contracts implement that interface."
    ]
}
----End JSON----

https://solodit.xyz/issues/assimilators-do-not-conform-to-the-erc20-specification-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "dai.transferFrom(msg.sender, address(this), \\_amount);\n\n",
        "dai.transfer(\\_dst, \\_amount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:",
        "All calls to compliant ERC20s now check for return booleans. Non compliant ERC20s are called with a function that checks for the success of the call."
    ],
    "Description": [
        "The assimilators in the codebase make heavy usage of both the transfer and transferFrom methods in the ERC20 standard.",
        "Quoting the relevant parts of the specification of the standard:",
        "We can see that, even though it is suggested that ERC20-compliant tokens do throw on the lack of authorization from the sender or lack of funds to complete the transfer, the standard does not enforce it.",
        "This means that, in order to make the system both more resilient and future-proof, code in each implementation of current and future assimilators should check for the return value of both transfer and transferFrom call instead of just relying on the external contract to revert execution.",
        "The extent of this issue is only mitigated by the fact that new assets are only added by the shell administrator and could, therefore, be audited prior to their addition."
    ],
    "Non-exhaustive Examples": [
        "src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L45",
        "src/assimilators/mainnet/daiReserves/mainnetDaiToDaiAssimilator.sol:L64"
    ],
    "Recommendation": [
        "Add a check for the return boolean of the function.",
        "Example:",
        "require(dai.transferFrom(msg.sender, address(this), _amount) == true);"
    ]
}
----End JSON----

https://solodit.xyz/issues/access-to-assimilators-does-not-check-for-existence-and-allows-delegation-to-the-zeroth-address-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\n\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\n\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\n\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\n\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:",
        "All retrieval of assimilators now check that the assimilators address is not the zeroth address."
    ],
    "Description": [
        "For every method that allows to selectively withdraw, deposit, or swap tokens in Loihi, the user is allowed to specify addresses for the assimilators of said tokens (by inputting the addresses of the tokens themselves).",
        "The shell then performs a lookup on a mapping called assimilators inside its main structure and uses the result of that lookup to delegate call the assimilator deployed by the shell administrator.",
        "However, there are no checks for prior instantiation of a specific, supported token, effectively meaning that we can do a lookup on an all-zeroed-out member of that mapping and delegate call execution to the zeroth address.",
        "The only thing preventing execution from going forward in this unwanted fashion is the fact that the ABI decoder expects a certain return data size from the interface implemented in Assimilator.sol.",
        "For example, the 32 bytes expected as a result of this call:",
        "src/Assimilators.sol:L58-L66",
        "This is definitely an insufficient check since the interface for the assimilators might change in the future to include functions that have no return values."
    ],
    "Recommendation": [
        "Check for the prior instantiation of assimilators by including the following requirement:",
        "require(shell.assimilators[<TOKEN_ADDRESS>].ix != 0);",
        "In all the functions that access the assimilators mapping and change the indexes to be 1-based instead pf 0-based."
    ]
}
----End JSON----

https://solodit.xyz/issues/math-librarys-fork-has-problematic-changes-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* Calculate x + y. Revert on overflow.\n \\*\n \\* @param x signed 64.64-bit fixed point number\n \\* @param y signed 64.64-bit fixed point number\n \\* @return signed 64.64-bit fixed point number\n \\*/\nfunction add (int128 x, int128 y) internal pure returns (int128) {\n  int256 result = int256(x) + y;\n  require (result >= MIN\\_64x64 && result <= MAX\\_64x64);\n  return int128 (result);\n}\n\n",
        "/\\*\\*\n \\* Calculate x + y. Revert on overflow.\n \\*\n \\* @param x signed 64.64-bit fixed point number\n \\* @param y signed 64.64-bit fixed point number\n \\* @return signed 64.64-bit fixed point number\n \\*/\nfunction unsafe\\_add (int128 x, int128 y) internal pure returns (int128) {\n  int256 result = int256(x) + y;\n  require (result >= MIN\\_64x64 && result <= MAX\\_64x64);\n  return int128 (result);\n}\n\n",
        "/\\*\\*\n \\* Calculate |x|. Revert on overflow.\n \\*\n \\* @param x signed 64.64-bit fixed point number\n \\* @return signed 64.64-bit fixed point number\n \\*/\nfunction abs (int128 x) internal pure returns (int128) {\n  require (x != MIN\\_64x64);\n  return x < 0 ? -x : x;\n}\n\n",
        "/\\*\\*\n \\* Calculate |x|. Revert on overflow.\n \\*\n \\* @param x signed 64.64-bit fixed point number\n \\* @return signed 64.64-bit fixed point number\n \\*/\nfunction unsafe\\_abs (int128 x) internal pure returns (int128) {\n  return x < 0 ? -x : x;\n}\n\n",
        "require (x != MIN\\_64x64);\n\n",
        "int128 private constant MIN\\_64x64 = -0x80000000000000000000000000000000;\n\n"
    ],
    "preamble": [],
    "Description": [
        "The math library ABDK Libraries for Solidity was forked and modified to add a few unsafe_* functions.",
        "The problem which was introduced is that unsafe_add ironically is not really unsafe, it is as safe as the original add function. It is, in fact, identical to the safe add function.",
        "src/ABDKMath64x64.sol:L102-L113",
        "src/ABDKMath64x64.sol:L115-L126",
        "Fortunately, unsafe_add is not used anywhere in the code.",
        "However, unsafe_abs was changed from this:",
        "src/ABDKMath64x64.sol:L322-L331",
        "To this:",
        "src/ABDKMath64x64.sol:L333-L341",
        "The check that was removed, is actually an important check:",
        "src/ABDKMath64x64.sol:L19",
        "The problem is that for an int128 variable that is equal to -0x80000000000000000000000000000000, there is no absolute value within the constraints of int128.",
        "Starting from int128 n = -0x80000000000000000000000000000000, the absolute value should be int128 abs_n = -n, however abs_n is equal to the initial value of n. The final value of abs_n is still -0x80000000000000000000000000000000. It\u2019s still not a positive or zero value. The operation 0 - n wraps back to the same initial value."
    ],
    "Recommendation": [
        "Remove unused unsafe_* functions and try to find other ways of doing unsafe math (if it is fundamentally important) without changing existing, trusted, already audited code."
    ]
}
----End JSON----

https://solodit.xyz/issues/use-one-file-for-each-contract-or-library-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "library SafeERC20Arithmetic {\n\n",
        "library Shells {\n\n",
        "contract ERC20Approve {\n    function approve (address spender, uint256 amount) public returns (bool);\n}\n\n",
        "contract Loihi is LoihiRoot {\n\n",
        "library Delegate {\n\n",
        "library Assimilators {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue fixed by the development team."
    ],
    "Description": [
        "The repository contains a lot of contracts and libraries that are added in the same file as another contract or library.",
        "Organizing the code in this manner makes it hard to navigate, develop and audit. It is a best practice to have each contract or library in its own file. The file also needs to bear the name of the hosted contract or library."
    ],
    "Examples": [
        "src/Shells.sol:L20",
        "src/Shells.sol:L32",
        "src/Loihi.sol:L26-L28",
        "src/Loihi.sol:L30",
        "src/Assimilators.sol:L19",
        "src/Assimilators.sol:L33"
    ],
    "Recommendation": [
        "Split up contracts and libraries in single files."
    ]
}
----End JSON----

https://solodit.xyz/issues/remove-debugging-code-from-the-repository-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "event log(bytes32);\nevent log\\_int(bytes32, int256);\nevent log\\_ints(bytes32, int256[]);\nevent log\\_uint(bytes32, uint256);\nevent log\\_uints(bytes32, uint256[]);\n\n",
        "event log(bytes32);\nevent log\\_uint(bytes32, uint256);\nevent log\\_int(bytes32, int256);\n\n",
        "event log(bytes32);\nevent log\\_int(bytes32, int128);\nevent log\\_int(bytes32, int);\nevent log\\_uint(bytes32, uint);\nevent log\\_addr(bytes32, address);\n\n",
        "event log(bytes32);\n\n",
        "event log(bytes32);\nevent log\\_int(bytes32, int256);\nevent log\\_ints(bytes32, int256[]);\nevent log\\_uint(bytes32, uint256);\nevent log\\_uints(bytes32, uint256[]);\n\n",
        "event log\\_int(bytes32, int);\nevent log\\_ints(bytes32, int128[]);\nevent log\\_uint(bytes32, uint);\nevent log\\_uints(bytes32, uint[]);\nevent log\\_addrs(bytes32, address[]);\n\n",
        "event log\\_uint(bytes32, uint256);\nevent log\\_int(bytes32, int256);\n\n",
        "event log\\_uint(bytes32, uint256);\n\n",
        "shell.testHalts = true;\n\n",
        "function setTestHalts (bool \\_testOrNotToTest) public {\n\n    shell.testHalts = \\_testOrNotToTest;\n\n}\n\n",
        "bool testHalts;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue fixed but he development team."
    ],
    "Description": [
        "Throughout the repository, there is source code from the development stage that was used for debugging the functionality and was not removed.",
        "This should not be present in the source code and even if they are used while functionality is developed, they should be removed after the functionality was implemented."
    ],
    "Examples": [
        "src/Shells.sol:L63-L67",
        "src/Assimilators.sol:L44-L46",
        "src/Controller.sol:L33-L37",
        "src/LoihiRoot.sol:L53",
        "src/Shells.sol:L63-L67",
        "src/Loihi.sol:L470-L474",
        "src/assimilators/mainnet/cdaiReserves/mainnetDaiToCDaiAssimilator.sol:L35-L36",
        "src/assimilators/mainnet/cusdcReserves/mainnetUsdcToCUsdcAssimilator.sol:L38",
        "src/Loihi.sol:L51",
        "src/LoihiRoot.sol:L79-L83",
        "src/Shells.sol:L60"
    ],
    "Recommendation": [
        "Remove the debug functionality at the end of the development cycle of each functionality."
    ]
}
----End JSON----

https://solodit.xyz/issues/tests-should-not-fail-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:",
        "The failing tests are because we made minute changes to our present model (changes in applying the base fee - \u201cepsilon\u201d), so in a sense, rather than failing they just need updating. Many of them are also an artifact of architecting the tests in such a way that they can be run against arbitrary parameter sets - or in different \u201csuites\u201d."
    ],
    "Description": [
        "The role of the tests should be to make sure the application behaves properly. This should include positive tests (functionality that should be implemented) and negative tests (behavior stopped or limited by the application).",
        "The test suite should pass 100% of the tests. After spending time with the development team, we managed to ask for the changes that allowed us to run the tests suite. This revealed that out of the 555 tests, 206 are failing. This staggering number does not allow us to check what the problem is and makes anybody running tests ignore them completely.",
        "Tests should be an integral part of the codebase, and they should be considered as important (or even more important) than the code itself. One should be able to recreate the whole codebase by just having the tests."
    ],
    "Recommendation": [
        "Update tests in order for the whole of the test suite to pass."
    ]
}
----End JSON----

https://solodit.xyz/issues/remove-commented-out-code-from-the-repository-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function viewRawAmount (address \\_assim, int128 \\_amt) internal returns (uint256 amount\\_) {\n\n    // amount\\_ = IAssimilator(\\_assim).viewRawAmount(\\_amt); // for production\n\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewRawAmount.selector, \\_amt.abs()); // for development\n\n    amount\\_ = abi.decode(\\_assim.delegate(data), (uint256)); // for development\n\n}\n\n",
        "function viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\n\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\n\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\n\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\n\n}\n\n",
        "function viewNumeraireAmount (address \\_assim, uint256 \\_amt) internal returns (int128 amt\\_) {\n\n    // amount\\_ = IAssimilator(\\_assim).viewNumeraireAmount(\\_amt); // for production\n\n    bytes memory data = abi.encodeWithSelector(iAsmltr.viewNumeraireAmount.selector, \\_amt); // for development\n\n    amt\\_ = abi.decode(\\_assim.delegate(data), (int128)); // for development\n\n}\n\n",
        "function includeAssimilator (Shells.Shell storage shell, address \\_numeraire, address \\_derivative, address \\_assimilator) internal {\n\n    Assimilators.Assimilator storage \\_numeraireAssim = shell.assimilators[\\_numeraire];\n\n    shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix);\n    // shell.assimilators[\\_derivative] = Assimilators.Assimilator(\\_assimilator, \\_numeraireAssim.ix, 0, 0);\n\n}\n\n",
        "function transfer (address \\_recipient, uint256 \\_amount) public nonReentrant returns (bool) {\n    // return shell.transfer(\\_recipient, \\_amount);\n}\n\nfunction transferFrom (address \\_sender, address \\_recipient, uint256 \\_amount) public nonReentrant returns (bool) {\n    // return shell.transferFrom(\\_sender, \\_recipient, \\_amount);\n}\n\nfunction approve (address \\_spender, uint256 \\_amount) public nonReentrant returns (bool success\\_) {\n    // return shell.approve(\\_spender, \\_amount);\n}\n\nfunction increaseAllowance(address \\_spender, uint256 \\_addedValue) public returns (bool success\\_) {\n    // return shell.increaseAllowance(\\_spender, \\_addedValue);\n}\n\nfunction decreaseAllowance(address \\_spender, uint256 \\_subtractedValue) public returns (bool success\\_) {\n    // return shell.decreaseAllowance(\\_spender, \\_subtractedValue);\n}\n\nfunction balanceOf (address \\_account) public view returns (uint256) {\n    // return shell.balances[\\_account];\n}\n\n",
        "// function test\\_s1\\_selectiveDeposit\\_noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_NO\\_HACK () public logs\\_gas {\n\n// uint256 newShells = super.noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD();\n\n// assertEq(newShells, 32499999216641686631);\n\n// }\n\n// function test\\_s1\\_selectiveDeposit\\_noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_HACK () public logs\\_gas {\n\n// uint256 newShells = super.noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_HACK();\n\n// assertEq(newShells, 32499999216641686631);\n\n// }\n\n",
        "// function noSlippage\\_balanced\\_10DAI\\_10USDC\\_10USDT\\_2p5SUSD\\_HACK () public returns (uint256 shellsMinted\\_) {\n\n// uint256 startingShells = l.proportionalDeposit(300e18);\n\n// uint256 gas = gasleft();\n\n// shellsMinted\\_ = l.depositHack(\n// address(dai), 10e18,\n// address(usdc), 10e6,\n// address(usdt), 10e6,\n// address(susd), 2.5e18\n// );\n\n// emit log\\_uint(\"gas for deposit\", gas - gasleft());\n\n\n// }\n\n"
    ],
    "preamble": [],
    "Description": [
        "Having commented out code increases the cognitive load on an already complex system. Also, it hides the important parts of the system that should get the proper attention, but that attention gets to be diluted.",
        "There is no code that is important enough to be left commented out in a repository. Git branching should take care of having different code versions or diffs should show what was before.",
        "If there is commented out code, this also has to be maintained; it will be out of date if other parts of the system are changed, and the tests will not pick that up.",
        "The main problem is that commented code adds confusion with no real benefit. Code should be code, and comments should be comments."
    ],
    "Examples": [
        "Commented out code should be removed or dealt with in a separate branch that is later included in the master branch.",
        "src/Assimilators.sol:L48-L56",
        "src/Assimilators.sol:L58-L66",
        "src/Assimilators.sol:L58-L66",
        "src/Controller.sol:L99-L106",
        "src/Loihi.sol:L596-L618",
        "src/test/deposits/suiteOne.t.sol:L15-L29",
        "src/test/deposits/depositsTemplate.sol:L40-L56"
    ],
    "Recommendation": [
        "Remove all the commented out code or transform it into comments."
    ]
}
----End JSON----

https://solodit.xyz/issues/should-check-if-the-asset-already-exists-when-adding-a-new-asset-fixed-consensys-shell-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function includeAsset (address \\_numeraire, address \\_nAssim, address \\_reserve, address \\_rAssim, uint256 \\_weight) public onlyOwner {\n    shell.includeAsset(\\_numeraire, \\_nAssim, \\_reserve, \\_rAssim, \\_weight);\n}\n\n",
        "function includeAsset (Shells.Shell storage shell, address \\_numeraire, address \\_numeraireAssim, address \\_reserve, address \\_reserveAssim, uint256 \\_weight) internal {\n\n",
        "shell.numeraires.push(\\_numeraireAssimilator);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from the development team:",
        "We have decided not to have dynamic adding/removing of assets in this release."
    ],
    "Description": [
        "The public function includeAsset",
        "src/Loihi.sol:L128-L130",
        "Calls the internal includeAsset implementation",
        "src/Controller.sol:L72",
        "But there is no check to see if the asset already exists in the list. Because the check was not done, shell.numeraires can contain multiple identical instances.",
        "src/Controller.sol:L80"
    ],
    "Recommendation": [
        "Check if the _numeraire already exists before invoking includeAsset."
    ]
}
----End JSON----

https://solodit.xyz/issues/eliminate-assembly-code-by-using-abi-decode-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "assembly {\n    flag := mload(add(\\_data, 32))\n}\nif (flag == CHANGE\\_PARTITION\\_FLAG) {\n    assembly {\n        toPartition := mload(add(\\_data, 64))\n\n",
        "assembly {\n    toPartition := mload(add(\\_data, 64))\n\n",
        "for (uint256 i = 116; i <= \\_operatorData.length; i = i + 32) {\n    bytes32 temp;\n    assembly {\n        temp := mload(add(\\_operatorData, i))\n    }\n    proof[index] = temp;\n    index++;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "All assembly code was replaced with proper use of abi.decode()."
    ],
    "Description": [
        "There are several locations where assembly code is used to access and decode byte arrays (including uses inside loops).\nEven though assembly code was used for gas optimization, it reduces the readability (and future updatability) of the code."
    ],
    "Examples": [
        "code/amp-contracts/contracts/partitions/PartitionsBase.sol:L39-L44",
        "code/amp-contracts/contracts/partitions/PartitionsBase.sol:L43-L44",
        "Same code as above is also present here:\n/flexa-collateral-manager/contracts/FlexaCollateralManager.sol#L1403\nflexa-collateral-manager/contracts/FlexaCollateralManager.sol#L1407",
        "code/flexa-collateral-manager/contracts/FlexaCollateralManager.sol:L1463-L1470"
    ],
    "Recommendation": [
        "As discussed in the mid-audit meeting, it is a good solution to use ABI decode since all uses of assembly simply access 32-byte chunks of data from user input. This should eliminate all assembly code and make the code significantly more clean.\nIn addition, it might allow for more compact encoding in some cases (for instance, by eliminating or reducing the size of the flags).",
        "This suggestion can be also applied to Merkle Root verifications/calculation code, which can reduce the for loops and complexity of these functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/ignored-return-value-for-transferfrom-call-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "swapToken.transferFrom(\\_from, swapTokenGraveyard, amount);\n\n\n",
        "require(swapToken.transferFrom(_from, swapTokenGraveyard, amount));\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by adding a require to validate the success/failure of transferFrom()."
    ],
    "Description": [
        "When burning swap tokens the return value of the transferFrom call is ignored. Depending on the token\u2019s implementation this could allow an attacker to mint an arbitrary amount of Amp tokens.",
        "Note that the severity of this issue could have been Critical if Flexa token was any arbitrarily tokens. We quickly verified that Flexa token implementation would revert if the amount exceeds the allowance, however it might not be the case for other token implementations.",
        "code/amp-contracts/contracts/Amp.sol:L619-L620"
    ],
    "Recommendation": [
        "The code should be changed like this:"
    ]
}
----End JSON----

https://solodit.xyz/issues/no-integration-tests-for-the-two-main-components-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "It is recommended to write test suites that achieve high code coverage to prevent missing obvious bugs that tests could cover."
    ],
    "Description": [
        "The existing tests cover each of the two main components and each set of tests mocks the other component. While this is good for unit testing some issues might be missed without proper system/integration tests that cover all components."
    ],
    "Recommendation": [
        "Consider adding system/integration tests for all components. As we\u2019ve seen in the recent issues in multi-contract smart contract systems, it\u2019s becoming more crucial to have a full test suits for future changes to the code base. Not having inter-component tests, could result in issues in the next development and deployment cycles."
    ]
}
----End JSON----

https://solodit.xyz/issues/potentially-insufficient-validation-for-operator-transfers-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\n    \\_isOperatorForPartition(\\_partition, msg.sender, \\_from) ||\n        (\\_value <= \\_allowedByPartition[\\_partition][\\_from][msg.sender]),\n    EC\\_53\\_INSUFFICIENT\\_ALLOWANCE\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "removing operatorTransferByPartition and simplifying the interfaces to only tranferByPartition"
    ],
    "Description": [
        "For operator transfers, the current validation does not require the sender to be an operator (as long as the transferred value does not exceed the allowance):",
        "code/amp-contracts/contracts/Amp.sol:L755-L759",
        "It is unclear if this is the intention or whether the logical or should be a logical and."
    ],
    "Recommendation": [
        "Confirm that the code matches the intention. If so, consider documenting the behavior (for instance, by changing the name of function operatorTransferByPartition."
    ]
}
----End JSON----

https://solodit.xyz/issues/potentially-missing-nonce-check-acknowledged-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "addressToWithdrawalNonce[\\_partition][supplier] = withdrawalRootNonce;\n\n\n",
        "addressToWithdrawalNonce[\\_partition][supplier] = maxWithdrawalRootNonce;\n\n\n",
        "maxWithdrawalRootNonce = \\_nonce;\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Nothing was done here, as Dave M writes:"
    ],
    "Description": [
        "When executing withdrawals in the collateral manager the per-address withdrawal nonce is simply updated without checking that the new nonce is one greater than the previous one (see Examples). It seems like without such a check it might be easy to make mistakes and causing issues with ordering of withdrawals."
    ],
    "Examples": [
        "code/flexa-collateral-manager/contracts/FlexaCollateralManager.sol:L663-L664",
        "code/flexa-collateral-manager/contracts/FlexaCollateralManager.sol:L845-L846",
        "code/flexa-collateral-manager/contracts/FlexaCollateralManager.sol:L1155-L1156"
    ],
    "Recommendation": [
        "Consider adding more validation and sanity checks for nonces on per-address withdrawals."
    ]
}
----End JSON----

https://solodit.xyz/issues/unbounded-loop-when-validating-merkle-proofs-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 proofNb = (\\_operatorData.length - 84) / 32;\nbytes32[] memory proof = new bytes32[](proofNb);\nuint256 index = 0;\nfor (uint256 i = 116; i <= \\_operatorData.length; i = i + 32) {\n    bytes32 temp;\n    assembly {\n        temp := mload(add(\\_operatorData, i))\n    }\n    proof[index] = temp;\n    index++;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The loop was removed by switching to abi.decode."
    ],
    "Description": [
        "It seems like the loop for validating Merkle proofs is unbounded. If possible it would be good to have an upper bound to prevent DoS-like attacks. It seems like the depth of the tree, and thus, the length of the proof could be bounded.",
        "This could also simplify the decoding and make it more robust. For instance, in _decodeWithdrawalOperatorData it is unclear what happens if the data length is not a multiple of 32.\nIt seems like it might result in out-of-bound reads.",
        "code/flexa-collateral-manager/contracts/FlexaCollateralManager.sol:L1460-L1470"
    ],
    "Recommendation": [
        "Consider enforcing a bound on the length of Merkle proofs.",
        "Also note that if similar mitigation method as issue 5.1 is used, this method can be replaced by a simpler function using ABI Decode, which does not have any unbounded issues as the sizes of the hashes are fixed (or can be indicated in the passed objects)"
    ]
}
----End JSON----

https://solodit.xyz/issues/mitigation-for-possible-reentrancy-in-token-transfers-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\n    \\_balanceOfByPartition[\\_from][\\_fromPartition] >= \\_value,\n    EC\\_52\\_INSUFFICIENT\\_BALANCE\n);\n\nbytes32 toPartition = \\_fromPartition;\nif (\\_data.length >= 64) {\n    toPartition = \\_getDestinationPartition(\\_fromPartition, \\_data);\n}\n\n\\_callPreTransferHooks(\n    \\_fromPartition,\n    \\_operator,\n    \\_from,\n    \\_to,\n    \\_value,\n    \\_data,\n    \\_operatorData\n);\n\n\\_removeTokenFromPartition(\\_from, \\_fromPartition, \\_value);\n\\_transfer(\\_from, \\_to, \\_value);\n\\_addTokenToPartition(\\_to, toPartition, \\_value);\n\n\\_callPostTransferHooks(\n    toPartition,\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed as recommended."
    ],
    "Description": [
        "ERC777 adds significant features to the token implementation, however there are some known risks associated with this token, such as possible reentrancy attack vector.\nGiven that the Amp token uses hooks to communicate to Collateral manager, it seems that the environment is trusted and safe.\nHowever, a minor modification to the implementation can result in safer implementation of the token transfer."
    ],
    "Examples": [
        "In Amp.sol --> _transferByPartition()",
        "code/amp-contracts/contracts/Amp.sol:L1152-L1177"
    ],
    "Recommendation": [
        "It is suggested to move any condition check that is checking the balance to after the external call. However _callPostTransferHooks needs to be called after the state changes, so the suggested mitigation here is to move the require at line 1152 to after _callPreTransferHooks() function (e.g. line 1171)."
    ]
}
----End JSON----

https://solodit.xyz/issues/potentially-inconsistent-input-validation-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(\\_isOperator(msg.sender, \\_from), EC\\_58\\_INVALID\\_OPERATOR);\n\n",
        "require(\\_operator != msg.sender);\n\n",
        "require(\\_operator != msg.sender);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "transferWithData was removed as a resolution of another filed issue, the rest are documented properly."
    ],
    "Description": [
        "There are some functions that might require additional input validation (similar to other functions):"
    ],
    "Examples": [
        "code/amp-contracts/contracts/Amp.sol:L699",
        "code/amp-contracts/contracts/Amp.sol:L789",
        "code/amp-contracts/contracts/Amp.sol:L800"
    ],
    "Recommendation": [
        "Consider adding additional input validation."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc20-compatibility-of-amp-token-using-defaultpartition-fixed-consensys-amp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "emit ApprovalByPartition(\\_partition, \\_tokenHolder, \\_spender, \\_amount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This fix resulted in significant changes to the token allowance work flow. The new implementation of balanceOf represents the total balance of tokens at that address (across any partition), instead of only default partition."
    ],
    "Description": [
        "It is somewhat unclear how the Amp token ensures ERC20 compatibility. While the default partition is used in some places (for instance, in function balanceOf) there are also separate fields for (aggregated) balances/allowances. This seems to introduce some redundancy and raises certain questions about when which fields are relevant."
    ],
    "Examples": [
        "code/amp-contracts/contracts/Amp.sol:L1494"
    ],
    "Recommendation": [
        "After the mid-audit discussion, it was clear that the general balanceOf method (with no partition) is not needed and can be replaced with a balanceOf function that returns balance of the default partition, similarly for allowance, the general increaseAllowance function can simply call increaseAllowanceByPartition using default partition (same for decreaseAllowance)."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc1400erc20-whitelist-circumvents-partition-restrictions-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Modifier to verify if sender and recipient are whitelisted.\n \\*/\nmodifier isWhitelisted(address recipient) {\n  require(\\_whitelisted[recipient], \"A3: Transfer Blocked - Sender lockup period not ended\");\n  \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/ERC1400#13."
    ],
    "Description": [
        "ERC1400/1410 enable \u201cpartially fungible tokens\u201d in that not all tokens are equivalent. A specific use case is placing restrictions on some tokens, such as lock-up periods.",
        "The whitelist in ERC1400ERC20 circumvents these restrictions. When a token holder uses the ERC20 transfer function, tokens are transferred from that user\u2019s \u201cdefault partitions\u201d, which a user can choose themselves by calling ERC1410.setDefaultPartitions. This means they can transfer tokens from any partition, and the only restriction that\u2019s placed on the transfer is that the recipient must be whitelisted.",
        "It should be noted that the comment and error message around the whitelisting feature suggests that it is meant to be applied to both the sender and recipient:",
        "code/contracts/token/ERC20/ERC1400ERC20.sol:L24-L30"
    ],
    "Remediation": [
        "There are many possibilities, but here are concrete suggestions for addressing this:"
    ]
}
----End JSON----

https://solodit.xyz/issues/certificate-controllers-do-not-always-constrain-the-last-argument-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes memory payload;\n\nassembly {\n  let payloadsize := sub(calldatasize, 160)\n  payload := mload(0x40) // allocate new memory\n  mstore(0x40, add(payload, and(add(add(payloadsize, 0x20), 0x1f), not(0x1f)))) // boolean trick for padding to 0x40\n  mstore(payload, payloadsize) // set length\n  calldatacopy(add(add(payload, 0x20), 4), 4, sub(payloadsize, 4))\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The existing back end already does its own ABI encoding, which means it\u2019s not vulnerable to this issue. Documentation has been added in https://gitlab.com/ConsenSys/client/fr/dauriel/smart-contracts/certificate-controller/merge_requests/9 to ensure future maintainers understand this potential issue."
    ],
    "Description": [
        "The certificate controllers (CertificateControllerNonce and CertificateControllerSalt) are used by passing a signature as a final argument in a function call. This signature is over the other arguments to the function. Specifically, the signature must match the call data that precedes the signature.",
        "The way this is implemented assumes standard ABI encoding of parameters, but there\u2019s actually some room for manipulation by a malicious user. This manipulation can allow the user to change some of the call data without invalidating the signature.",
        "The following code is from CertificateControllerNonce, but similar logic applies to CertificateControllerSalt:",
        "code2/contracts/CertificateControllerNonce.sol:L127-L134",
        "Here the signature is over all call data except the final 160 bytes. 160 bytes makes sense because the byte array is length 97, and it\u2019s preceded by a 32-byte size. This is a total of 129 bytes, and typical ABI encoded pads this to the next multiple of 32, which is 160.",
        "If an attacker does not pad their arguments, they can use just 129 bytes for the signature or even 128 bytes if the v value happens to be 0. This means that when checking the signature, not only will the signature be excluded, but also the 31 or 32 bytes that come before the signature. This means the attacker can call a function with a different final argument than the one that was signed.",
        "That final argument is, in many cases, the number of tokens to transfer, redeem, or issue."
    ],
    "Mitigating factors": [
        "For this to be exploitable, the attacker has to be able to obtain a signature over shortened call data.",
        "If the signer accepts raw arguments and does its own ABI encoding with standard padding, then there\u2019s likely no opportunity for an attacker to exploit this vulnerability. (They can shorten the call data length when they make the function call later, but the signature won\u2019t match.)"
    ],
    "Remediation": [
        "We have two suggestions for how to address this:"
    ]
}
----End JSON----

https://solodit.xyz/issues/salt-based-certificate-controller-is-subject-to-signature-replay-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "modifier isValidCertificate(bytes memory data) {\n\n  require(\n    \\_certificateSigners[msg.sender] || \\_checkCertificate(data, 0, 0x00000000),\n    \"A3: Transfer Blocked - Sender lockup period not ended\"\n  );\n\n  \\_usedCertificate[data] = true; // Use certificate\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in https://gitlab.com/ConsenSys/client/fr/dauriel/smart-contracts/certificate-controller/merge_requests/8."
    ],
    "Description": [
        "The salt-based certificate controller prevents signature replay by storing each full signature. Only a signature that is exactly identical to a previously-used signature will be rejected.",
        "For ECDSA signatures, each signature has a second S value (and flipped V to match) that will recover the same address. An attacker can produce such a second signature trivially without knowing the signer\u2019s private key. This gives an attacker a way to produce a new unique signature based on a previously used one. This effectively means every signature can be used twice.",
        "code2/contracts/CertificateControllerSalt.sol:L25-L32"
    ],
    "References": [
        "See https://smartcontractsecurity.github.io/SWC-registry/docs/SWC-117."
    ],
    "Remediation": [
        "Instead of rejecting used signatures based on the full signature value, keep track of used salts (which are then better referred to as \u201cnonces\u201d)."
    ]
}
----End JSON----

https://solodit.xyz/issues/eip-1400-is-missing-cantransfer-functions-acknowledged-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "  // Transfer Validity\n  function canTransfer(address \\_to, uint256 \\_value, bytes \\_data) external view returns (byte, bytes32);\n  function canTransferFrom(address \\_from, address \\_to, uint256 \\_value, bytes \\_data) external view returns (byte, bytes32);\n  function canTransferByPartition(address \\_from, address \\_to, bytes32 \\_partition, uint256 \\_value, bytes \\_data) external view returns (byte, bytes32, bytes32);   \n\n"
    ],
    "preamble": [],
    "Description": [
        "The EIP-1400 states defines the interface to be implemented containing the 3 functions:",
        "These functions were not implemented in ERC1400, thus making the implementation not completely compatible with EIP-1400.",
        "In case the deployed contract needs to be added as a \u201clego block\u201d part of a another application, there is a high chance that it will not correctly function. That external application could potentially call the EIP-1400 functions canTransfer, canTransferFrom or canTransferByPartition, in which case the transaction will likely fail.",
        "This means that the current implementation will not be able to become part of external markets, exchanges or applications that need to interact with a generic EIP-1400 implementation."
    ],
    "Remediation": [
        "Even if the functions do not correctly reflect the transfer possibility, their omission can break other contracts interacting with the implementation.",
        "A suggestion would be to add these functions and make them always return true. This way the contracts interacting with the current implementation do not break when they call these functions, while the actual transfer of the tokens is still limited by the current logic."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc777-incompatibilities-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/ERC1400#26."
    ],
    "Description": [
        "As noted in the README, the ERC777 contract is not actually compatible with ERC 777.",
        "Functions and events have been renamed, and the hooks ERC777TokensRecipient and ERC777TokensSender have been modified to add a partition parameter.",
        "This means no tools that deal with standard ERC 777 contracts will work with this code\u2019s tokens."
    ],
    "Remediation": [
        "We suggest renaming these contracts to not use the term \u201cERC777\u201d, as they lack compatibility. Most importantly, we recommend not using the interface names \u201cERC777TokensRecipient\u201d and \u201cERC777TokensSender\u201d when looking up the appropriate hook contracts via ERC 1820. Contracts that handle that interface will not be capable of handling the modified interface used here."
    ]
}
----End JSON----

https://solodit.xyz/issues/buffer-over-read-in-erc1410_getdestinationpartition-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_getDestinationPartition(bytes32 fromPartition, bytes memory data) internal pure returns(bytes32 toPartition) {\n  bytes32 changePartitionFlag = 0xffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffffff;\n  bytes32 flag;\n  assembly {\n    flag := mload(add(data, 32))\n  }\n  if(flag == changePartitionFlag) {\n    assembly {\n      toPartition := mload(add(data, 64))\n    }\n  } else {\n    toPartition = fromPartition;\n  }\n}\n\n",
        "if(operatorData.length != 0 && data.length != 0) {\n  toPartition = \\_getDestinationPartition(fromPartition, data);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/ERC1400#16."
    ],
    "Description": [
        "There\u2019s no check that data is at least 64 bytes long, so the following code can read past the end of data:",
        "code/contracts/token/ERC1410/ERC1410.sol:L348-L361",
        "The only caller is _transferByPartition, which only checks that data.length > 0:",
        "code/contracts/token/ERC1410/ERC1410.sol:L263-L264",
        "Depending on how the compiler chooses to lay out memory, the next data in memory is probably the operatorData buffer, so data may inadvertently be read from there."
    ],
    "Remediation": [
        "Check for sufficient length (at least 64 bytes) before attempting to read it."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc20erc777-compatibility-erc20-transfer-functions-should-not-revert-if-the-recipient-is-a-contract-without-a-registered-erc777tokensrecipient-implementation-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/ERC1400#17."
    ],
    "Description": [
        "The ERC20 functions ERC1400ERC20.transfer and ERC1400ERC20.transferFrom call ERC1410._transferByDefaultPartitions, which calls ERC1410._transferByPartition, which calls ERC777._transferWithData with the preventLocking argument of true.",
        "This will block transfers to a contract that doesn\u2019t have an ERC777TokensRecipient implementation. This is in violation of ERC 777, which says:"
    ],
    "Remediation": [
        "Make sure that ERC20-compatible transfer calls do not set preventLocking to true."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc777-compatibility-authorizeoperator-and-revokeoperator-should-revert-when-the-caller-and-operator-are-the-same-account-fixed-consensys-codefi-erc1400-assessment-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function authorizeOperator(address operator) external {\n  \\_authorizedOperator[operator][msg.sender] = true;\n  emit AuthorizedOperator(operator, msg.sender);\n}\n\n",
        "function revokeOperator(address operator) external {\n  \\_authorizedOperator[operator][msg.sender] = false;\n  emit RevokedOperator(operator, msg.sender);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in ConsenSys/ERC1400#19."
    ],
    "Description": [
        "From ERC 777:",
        "The autohrizeOperator implementation does not do that:",
        "code/contracts/token/ERC777/ERC777.sol:L144-L147",
        "The same holds for revokeOperator:",
        "code/contracts/token/ERC777/ERC777.sol:L155-L158"
    ],
    "Remediation": [
        "Add require(operator != msg.sender) to those two functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/a-reverting-fallback-function-will-lock-up-all-payouts-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_transferETH(address \\_recipient, uint256 \\_amount) private {\n    (bool success, ) = \\_recipient.call{value: \\_amount}(\n        abi.encodeWithSignature(\"\")\n    );\n    require(success, \"Transfer Failed\");\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Replace the push method to pull pattern."
    ],
    "Description": [
        "In BoxExchange.sol, the internal function _transferEth() reverts if the transfer does not succeed:",
        "code/Fairswap_iDOLvsETH/contracts/BoxExchange.sol:L958-L963",
        "The _payment() function processes a list of transfers to settle the transactions in an ExchangeBox. If any of the recipients of an Eth transfer is a smart contract that reverts, then the entire payout will fail and will be unrecoverable."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/force-traders-to-mint-gas-token-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_transferETH(address \\_recipient, uint256 \\_amount) private {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Replace push funds with Pull Pattern."
    ],
    "Description": [
        "Attack scenario:",
        "If Alice has $100 worth of ETH tied up in the exchange, you can basically ransom her for $99 of gas token or else she\u2019ll never see her funds again."
    ],
    "Examples": [
        "code/Fairswap_iDOLvsETH/contracts/BoxExchange.sol:L958"
    ],
    "Recommendation": [
        "When sending ETH, a pull-payment model is generally preferable.",
        "This would require setting up a queue, allowing users to call a function to initiate a withdrawal."
    ]
}
----End JSON----

https://solodit.xyz/issues/missing-proper-access-control-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        " \\*/\nfunction setIDOLContract(address contractAddress) public {\n    require(address(\\_IDOLContract) == address(0), \"IDOL contract is already registered\");\n    \\_setStableCoinContract(contractAddress);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from Lien Protocol:"
    ],
    "Description": [
        "Some functions do not have proper access control and are public, meaning that anyone can call them. This will result in system take over depending on how critical those functionalities are."
    ],
    "Examples": [
        "Anyone can set IDOLContract in MainContracts.Auction.sol, which is a critical aspect of the auction contract, and it cannot be changed after it is set:",
        "code/MainContracts/contracts/Auction.sol:L144-L148"
    ],
    "Recommendation": [
        "Make the setIDOLContract() function internal and call it from the constructor, or only allow the deployer to set the value."
    ]
}
----End JSON----

https://solodit.xyz/issues/code-is-not-production-ready-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\n// Indicates any auction has never held for a specified BondID\nfunction isNotStartedAuction(bytes32 auctionID) public virtual override returns (bool) {\n uint256 closingTime = \\_auctionClosingTime[auctionID];\n return closingTime == 0;\n}\n\n// Indicates if the auctionID is in bid acceptance status\nfunction inAcceptingBidsPeriod(bytes32 auctionID) public virtual override returns (bool) {\n uint256 closingTime = \\_auctionClosingTime[auctionID];\n\n",
        "// TEST\nfunction isNotStartedAuction(bytes32 auctionID)\n    public\n    virtual\n    override\n    returns (bool)\n{\n    return true;\n}\n\n// TEST\nfunction inAcceptingBidsPeriod(bytes32 auctionID)\n\n",
        "require(\n    inRevealingValuationPeriod(auctionID),\n    \"it is not the time to reveal the value of bids\"\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from Lien Protocol:"
    ],
    "Description": [
        "Similar to other discussed issues, several areas of the code suggest that the system is not production-ready. This results in narrow test scenarios that do not cover production code flow."
    ],
    "Examples": [
        "In MainContracts/contracts/AuctionTimeControl.sol the following functions are commented out and replaced with same name functions that simply return True for testing purposes:",
        "code/MainContracts/contracts/AuctionTimeControl.sol:L30-L39",
        "code/MainContracts/contracts/AuctionTimeControl.sol:L67-L78",
        "These commented-out functions contain essential functionality for the Auction contract. For example, inRevealingValuationPeriod is used to allow revealing of the bid price publicly:",
        "code/MainContracts/contracts/Auction.sol:L403-L406"
    ],
    "Recommendation": [
        "Remove the test functions and use the production code for testing. The tests must have full coverage of the production code to be considered complete."
    ]
}
----End JSON----

https://solodit.xyz/issues/unable-to-compile-contracts-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "Error: Member \"calculatePrice\" not found or not visible after argument-dependent lookup in contract CalculatorInterface.\r\n   --> contracts/BoxExchange.sol:821:36:\r\n    |\r\n821 |         uint256[5] memory Prices = calc.calculatePrice(\r\n    |                                    ^^^^^^^^^^^^^^^^^^^\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The related code was updated on the 7th day of the audit, and fixed this issue for Fairswap_iDOLvsImmortalOptions as far as we reviewed."
    ],
    "Description": [
        "In the Fairswap_iDOLvsImmortalOptionsrepository:",
        "Compilation with truffle fails due to a missing file: contracts/testTokens/TestBondMaker.sol.\nCompilation with solc fails due to an undefined interface function:",
        "In the Fairswap_iDOLvsLien repository:",
        "Compilation with truffle fails due to a missing file: ./ERC20RegularlyRecord.sol. The correct filename is ./TestERC20RegularlyRecord.sol."
    ],
    "Recommendation": [
        "Ensure all contracts are easily compilable by following simple instructions in the README."
    ]
}
----End JSON----

https://solodit.xyz/issues/unreachable-code-due-to-checked-conditions-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function revealBid(\n    bytes32 auctionID,\n    uint256 price,\n    uint256 targetSBTAmount,\n    uint256 random\n) public override {\n    require(\n        inRevealingValuationPeriod(auctionID),\n        \"it is not the time to reveal the value of bids\"\n    );\n\n",
        "/\\*\\*\n \\* @dev Penalties for revealing too early.\n \\* Some participants may not follow the rule and publicate their bid information before the reveal process.\n \\* In such a case, the bid price is overwritten by the bid with the strike price (slightly unfavored price).\n \\*/\nuint256 bidPrice = price;\n\n/\\*\\*\n \\* @dev FOR TEST CODE RUNNING: The following if statement in L533 should be replaced by the comment out\n \\*/\nif (inAcceptingBidsPeriod(auctionID)) {\n    // if (false) {\n    (, , uint256 solidStrikePriceE4, ) = \\_getBondFromAuctionID(auctionID);\n    bidPrice = \\_exchangeSBT2IDOL(solidStrikePriceE4.mul(10\\*\\*18));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from Lien Protocol:"
    ],
    "Description": [
        "The code flow in MainContracts.Auction.sol revealBid() is that it first checks if the function has been called during the reveal period, which means \u201cafter closing\u201d and \u201cbefore the end of the reveal period.\u201d",
        "code/MainContracts/contracts/Auction.sol:L508-L517",
        "However, later in the same function, code exists to introduce \u201cPenalties for revealing too early.\u201d This checks to see if the function was called before closing, which should not be possible given the previous check.",
        "code/MainContracts/contracts/Auction.sol:L523-L537"
    ],
    "Recommendation": [
        "Double-check the logic in these functions. If revealing should be allowed (but penalized in the earlier stage), the first check should be changed. However, based on our understanding, the first check is correct, and the second check for early reveal is redundant and should be removed."
    ]
}
----End JSON----

https://solodit.xyz/issues/todo-tags-present-in-the-code-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// require(strikePriceIDOLAmount > 10\\*\\*10, 'at least 100 iDOL is required for the bid Amount'); // require $100 for spam protection // TODO\nrequire(\n\n",
        "bytes32[] storage bondIDs = bondGroup.bondIDs;\n// require(msg.value.mul(998).div(1000) > amount, 'fail to transfer Ether'); // TODO\n\n\n",
        "    \\_issueNewBond(bondID, msg.sender, amount);\n    // transferETH(bondTokenAddress, msg.value - amount); // TODO\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Comment from Lien Protocol:"
    ],
    "Description": [
        "There are a few instances of TODO tags in the codebase that must be addressed before production as they correspond to commented-out code that makes up essential parts of the system."
    ],
    "Examples": [
        "code/MainContracts/contracts/Auction.sol:L310-L311",
        "code/MainContracts/contracts/BondMaker.sol:L392-L394",
        "code/MainContracts/contracts/BondMaker.sol:L402-L404"
    ]
}
----End JSON----

https://solodit.xyz/issues/documented-function-geterc20tokendividend-does-not-exist-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from Lien Protocol:"
    ],
    "Description": [
        "In the README of Fairswap_iDOLvsLien, a function is listed which is not implemented in the codebase:"
    ],
    "Recommendation": [
        "Implement the function, or update the documentation"
    ]
}
----End JSON----

https://solodit.xyz/issues/fairswap-interfaces-are-inconsistent-fixed-consensys-lien-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Comment from Lien Protocol:"
    ],
    "Description": [
        "There are unexpected inconsistencies between the three Fairswap contract interfaces, which may cause issues for composability with external contracts."
    ],
    "Examples": [
        "The function used to submit orders between the base and settlement currency has a different name across the three exchanges:"
    ],
    "Recommendation": [
        "Implement the desired interface in a separate file, and inherit it on the exchange contracts to ensure they are implemented as intended."
    ]
}
----End JSON----

https://solodit.xyz/issues/exchange-cancelorder-has-no-effect-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nfunction cancelOrder(LibOrder.Order memory order) public {\n    require(msg.sender == order.trader || msg.sender == order.broker, \"invalid caller\");\n\n    bytes32 orderHash = order.getOrderHash();\n    cancelled[orderHash] = true;\n\n    emit Cancel(orderHash);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been addressed with mai-protocol-v2/2fcbf4b44f4595e5879ff5efea4e42c529ef0ce1 by verifying that an order has not been cancelled in method validateOrderParam.",
        "cancelOrder still does not verify the order signature."
    ],
    "Description": [
        "The exchange provides means for the trader or broker to cancel the order. The cancelOrder method, however, only stores the hash of the canceled order in mapping but the mapping is never checked. It is therefore effectively impossible for a trader to cancel an order."
    ],
    "Examples": [
        "code/contracts/exchange/Exchange.sol:L179-L187"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/amm-funding-can-be-called-in-emergency-mode-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by silently skipping funding() if the status is not NORMAL."
    ],
    "Description": [
        "The specification for AMM.funding() states isEmergency==FALSE as a requirement. However, the state isEmergency does not exist (we assume EMERGENCY aka. SETTLING) and the implementation does not perform any state checks. This method is called by many other functions in AMM."
    ],
    "Recommendation": [
        "According to the specification, forceFunding should not be allowed in EMERGENCY mode. However, it is assumed that this method should only be callable in NORMAL mode.",
        "The assessment team would like to note that the specification appears to be inconsistent and dated (method names, variable names, \u2026)."
    ]
}
----End JSON----

https://solodit.xyz/issues/perpetual-withdraw-should-only-be-available-in-normal-state-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nfunction withdraw(uint256 amount) public {\n    withdrawFromAccount(msg.sender, amount);\n}\n\n",
        "function withdrawFromAccount(address payable guy, uint256 amount) private {\n    require(guy != address(0), \"invalid guy\");\n    require(status != LibTypes.Status.SETTLING, \"wrong perpetual status\");\n\n    uint256 currentMarkPrice = markPrice();\n    require(isSafeWithPrice(guy, currentMarkPrice), \"unsafe before withdraw\");\n    remargin(guy, currentMarkPrice);\n    address broker = currentBroker(guy);\n    bool forced = broker == address(amm.perpetualProxy()) || broker == address(0);\n    withdraw(guy, amount, forced);\n\n    require(isSafeWithPrice(guy, currentMarkPrice), \"unsafe after withdraw\");\n    require(availableMarginWithPrice(guy, currentMarkPrice) >= 0, \"withdraw margin\");\n}\n\n",
        "function withdrawFor(address payable guy, uint256 amount) public onlyWhitelisted {\n    require(status == LibTypes.Status.NORMAL, \"wrong perpetual status\");\n    withdrawFromAccount(guy, amount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was resolved by requiring status == LibTypes.Status.NORMAL."
    ],
    "Description": [
        "According to the specification withdraw can only be called in NORMAL state. However, the implementation allows it to be called in NORMAL and SETTLED mode."
    ],
    "Examples": [
        "Withdraw only checks for !SETTLING state which resolves to NORMAL and SETTLED.",
        "code/contracts/perpetual/Perpetual.sol:L175-L178",
        "code/contracts/perpetual/Perpetual.sol:L156-L169",
        "In contrast, withdrawFor requires the state to be NORMAL:",
        "code/contracts/perpetual/Perpetual.sol:L171-L174"
    ],
    "Recommendation": [
        "withdraw should only be available in the NORMAL operation mode."
    ]
}
----End JSON----

https://solodit.xyz/issues/perpetual-withdrawfrominsurancefund-should-check-wadamount-instead-of-rawamount-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function withdrawFromInsuranceFund(uint256 rawAmount) public onlyWhitelistAdmin {\n    require(rawAmount > 0, \"invalid amount\");\n    require(insuranceFundBalance > 0, \"insufficient funds\");\n    require(rawAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");\n\n    int256 wadAmount = toWad(rawAmount);\n    insuranceFundBalance = insuranceFundBalance.sub(wadAmount);\n    withdrawFromProtocol(msg.sender, rawAmount);\n\n    require(insuranceFundBalance >= 0, \"negtive insurance fund\");\n\n    emit UpdateInsuranceFund(insuranceFundBalance);\n}\n\n",
        "await perpetual.withdrawFromInsuranceFund(toWad(10.111));\nfund = await perpetual.insuranceFundBalance();\nassert.equal(fund.toString(), 0);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by checking wadBalance instead of the rawAmount against insuranceFundBalance. withdrawFromProtocol was renamed to pushCollateral which now forwards all gas to the recipient and does not check for amount==0 by itself anymore (which may be fine because the callers in the current code revision do). It should be noted that the unit-test cases still attempt to provide a WAD value instead of the raw token amount."
    ],
    "Description": [
        "withdrawFromInsurance checks that enough funds are in the insurance fund before allowing withdrawal by an admin by checking the provided rawAmount <= insuranceFundBalance.toUint256(). rawAmount is the ETH (18 digit precision) or collateral token amount (can be less than 18 digit precision) to be withdrawn while insuranceFundBalance is a WAD-denominated value (18 digit precision).",
        "The check does not hold if the configured collateral has different precision and may have unwanted consequences, e.g. the withdrawal of more funds than expected.",
        "Note: there is another check for insuranceFundBalance staying positive after the potential external call to collateral."
    ],
    "Examples": [
        "code/contracts/perpetual/Perpetual.sol:L204-L216",
        "When looking at the test-cases there seems to be a misconception about what unit of amount withdrawFromInsuranceFund is taking. For example, the insurance fund withdrawal and deposit are not tested for collateral that specifies a precision that is not 18. The test-cases falsely assume that the input to withdrawFromInsuranceFund is a WAD value, while it is taking the collateral\u2019s rawAmount which is then converted to a WAD number.",
        "code/test/test_perpetual.js:L471-L473"
    ],
    "Recommendation": [
        "Check that require(wadAmount <= insuranceFundBalance.toUint256(), \"insufficient funds\");, add a test-suite testing the insurance fund with collaterals with different precision and update existing tests that properly provide the expected input to withdraFromInsurance."
    ]
}
----End JSON----

https://solodit.xyz/issues/perpetual-liquidatefrom-should-not-have-public-visibility-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// safe for liquidation\nfunction isSafeWithPrice(address guy, uint256 currentMarkPrice) public returns (bool) {\n    return\n        marginBalanceWithPrice(guy, currentMarkPrice) >=\n        maintenanceMarginWithPrice(guy, currentMarkPrice).toInt256();\n}\n\n",
        "function liquidateFrom(address from, address guy, uint256 maxAmount) public returns (uint256, uint256) {\n\n",
        "function liquidate(address guy, uint256 maxAmount) public returns (uint256, uint256) {\n    require(status != LibTypes.Status.SETTLED, \"wrong perpetual status\");\n    return liquidateFrom(msg.sender, guy, maxAmount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been resolved by removing the liquidateFrom method entirely and refactoring liquidate. The method now enforces that status != LibTypes.Status.SETTLED. Additionally, the method now checks that msg.sender!=trader."
    ],
    "Description": [
        "Perpetual.liquidate is used to liquidate an account that is \u201cunsafe,\u201d determined by the relative sizes of marginBalanceWithPrice and maintenanceMarginWithPrice:",
        "code/contracts/perpetual/Perpetual.sol:L248-L253",
        "Perpetual.liquidate allows the caller to assume the liquidated account\u2019s position, as well as a small amount of \u201cpenalty collateral.\u201d The steps to liquidate are, roughly:",
        "We found several issues in Perpetual.liquidate:"
    ],
    "Examples": [
        "liquidateFrom has public visibility:",
        "code/contracts/perpetual/Perpetual.sol:L270",
        "Given that liquidate only calls liquidateFrom after checking the current contract\u2019s status, this oversight allows anyone to call liquidateFrom during the SETTLED stage:",
        "code/contracts/perpetual/Perpetual.sol:L291-L294",
        "Additionally, directly calling liquidateFrom allows anyone to liquidate on behalf of other users, forcing other accounts to assume liquidated positions.",
        "Finally, neither liquidate nor liquidateFrom check that the liquidated account and liquidator are the same. Though the liquidation accounting process is hard to follow, we believe this is unintended and could lead to large errors in internal contract accounting."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-due-to-front-running-or-general-bad-timing-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setGlobalParameter(bytes32 key, uint256 value) public onlyWhitelistAdmin {\n    if (key == \"withdrawalLockBlockCount\") {\n        withdrawalLockBlockCount = value;\n    } else if (key == \"brokerLockBlockCount\") {\n        brokerLockBlockCount = value;\n    } else {\n        revert(\"key not exists\");\n    }\n    emit UpdateGlobalParameter(key, value);\n}\n\n",
        "function setGovernanceParameter(bytes32 key, int256 value) public onlyWhitelistAdmin {\n    if (key == \"initialMarginRate\") {\n        governance.initialMarginRate = value.toUint256();\n        require(governance.initialMarginRate > 0, \"require im > 0\");\n        require(governance.initialMarginRate < 10\\*\\*18, \"require im < 1\");\n        require(governance.maintenanceMarginRate < governance.initialMarginRate, \"require mm < im\");\n    } else if (key == \"maintenanceMarginRate\") {\n        governance.maintenanceMarginRate = value.toUint256();\n        require(governance.maintenanceMarginRate > 0, \"require mm > 0\");\n        require(governance.maintenanceMarginRate < governance.initialMarginRate, \"require mm < im\");\n        require(governance.liquidationPenaltyRate < governance.maintenanceMarginRate, \"require lpr < mm\");\n        require(governance.penaltyFundRate < governance.maintenanceMarginRate, \"require pfr < mm\");\n    } else if (key == \"liquidationPenaltyRate\") {\n        governance.liquidationPenaltyRate = value.toUint256();\n        require(governance.liquidationPenaltyRate < governance.maintenanceMarginRate, \"require lpr < mm\");\n    } else if (key == \"penaltyFundRate\") {\n        governance.penaltyFundRate = value.toUint256();\n        require(governance.penaltyFundRate < governance.maintenanceMarginRate, \"require pfr < mm\");\n    } else if (key == \"takerDevFeeRate\") {\n        governance.takerDevFeeRate = value;\n    } else if (key == \"makerDevFeeRate\") {\n        governance.makerDevFeeRate = value;\n    } else if (key == \"lotSize\") {\n        require(\n            governance.tradingLotSize == 0 || governance.tradingLotSize.mod(value.toUint256()) == 0,\n            \"require tls % ls == 0\"\n        );\n        governance.lotSize = value.toUint256();\n    } else if (key == \"tradingLotSize\") {\n        require(governance.lotSize == 0 || value.toUint256().mod(governance.lotSize) == 0, \"require tls % ls == 0\");\n        governance.tradingLotSize = value.toUint256();\n    } else if (key == \"longSocialLossPerContracts\") {\n        require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");\n        socialLossPerContracts[uint256(LibTypes.Side.LONG)] = value;\n    } else if (key == \"shortSocialLossPerContracts\") {\n        require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");\n        socialLossPerContracts[uint256(LibTypes.Side.SHORT)] = value;\n    } else {\n        revert(\"key not exists\");\n    }\n    emit UpdateGovernanceParameter(key, value);\n}\n\n",
        "function setGovernanceAddress(bytes32 key, address value) public onlyWhitelistAdmin {\n    require(value != address(0x0), \"invalid address\");\n    if (key == \"dev\") {\n        devAddress = value;\n    } else if (key == \"amm\") {\n        amm = IAMM(value);\n    } else if (key == \"globalConfig\") {\n        globalConfig = IGlobalConfig(value);\n    } else {\n        revert(\"key not exists\");\n    }\n    emit UpdateGovernanceAddress(key, value);\n}\n\n",
        "function setGovernanceParameter(bytes32 key, int256 value) public onlyWhitelistAdmin {\n    if (key == \"poolFeeRate\") {\n        governance.poolFeeRate = value.toUint256();\n    } else if (key == \"poolDevFeeRate\") {\n        governance.poolDevFeeRate = value.toUint256();\n    } else if (key == \"emaAlpha\") {\n        require(value > 0, \"alpha should be > 0\");\n        governance.emaAlpha = value;\n        emaAlpha2 = 10\\*\\*18 - governance.emaAlpha;\n        emaAlpha2Ln = emaAlpha2.wln();\n    } else if (key == \"updatePremiumPrize\") {\n        governance.updatePremiumPrize = value.toUint256();\n    } else if (key == \"markPremiumLimit\") {\n        governance.markPremiumLimit = value;\n    } else if (key == \"fundingDampener\") {\n        governance.fundingDampener = value;\n    } else {\n        revert(\"key not exists\");\n    }\n    emit UpdateGovernanceParameter(key, value);\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by the client providing the following statement:"
    ],
    "Description": [
        "In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.",
        "Some instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "The deployer of the PerpetualGovernance, AMMGovernance, and GlobalConfig contracts are set as administrators for the contracts through WhitelistedRole. The WhitelistedAdminRole can whitelist other accounts at any time and allow them to perform actions protected by the onlyWhitelisted decorator.",
        "Updating governance and global configuration parameters are not protected by a time-lock and take effect immediately. This, therefore, creates an opportunity for administrators to front-run users on the exchange by changing parameters for orders. It may also allow an administrator to temporarily lift restrictions for themselves (e.g. withdrawalLockBlockCount).",
        "code/contracts/global/GlobalConfig.sol:L18-L27",
        "code/contracts/perpetual/PerpetualGovernance.sol:L39-L80",
        "code/contracts/perpetual/PerpetualGovernance.sol:L82-L94",
        "code/contracts/liquidity/AMMGovernance.sol:L22-L43"
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all updates to system parameters or upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period.",
        "Additionally, users should verify the whitelist setup before using the contract system and monitor it for new additions to the whitelist. Documentation should clearly outline what roles are owned by whom to support suitability. Sane parameter bounds should be enforced (e.g. min. disallow block delay of zero )"
    ]
}
----End JSON----

https://solodit.xyz/issues/amm-governance-is-able-to-set-an-invalid-alpha-value-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "} else if (key == \"emaAlpha\") {\n    require(value > 0, \"alpha should be > 0\");\n    governance.emaAlpha = value;\n    emaAlpha2 = 10\\*\\*18 - governance.emaAlpha;\n    emaAlpha2Ln = emaAlpha2.wln();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by checking that the provided emaAlpha <= 1 WAD. This would allow a data smoothing factor of 1 which causes emaAlpha2 and emaAlpha2Ln to go zero which should not be allowed. As outlined in the recommendation, check 0 < \u03b1 < 1 instead."
    ],
    "Description": [
        "According to https://en.wikipedia.org/wiki/Moving_average",
        "However, the code does not check upper bounds. An admin may, therefore, set an invalid alpha that puts emaAlpha2 out of bounds or negative."
    ],
    "Examples": [
        "code/contracts/liquidity/AMMGovernance.sol:L27-L31"
    ],
    "Recommendation": [
        "Ensure that the system configuration is always within safe bounds. Document expected system variable types and their safe operating ranges. Enforce that bounds are checked every time a value is set. Enforce safe defaults when deploying contracts.",
        "Ensure emaAlpha is 0 < value < 1 WAD"
    ]
}
----End JSON----

https://solodit.xyz/issues/amm-amount-of-collateral-spent-or-shares-received-may-be-unpredictable-for-liquidity-provider-acknowledged-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client acknowledges this issue without providing further information or implementing the recommended fixes."
    ],
    "Description": [
        "When providing liquidity with addLiquidity(), the amount of collateral required is based on the current price and the amount of shares received depends on the total amount of shares in circulation. This price can fluctuate at a moment\u2019s notice, making the behavior of the function unpredictable for the user.",
        "The same is true when removing liquidity via removeLiquidity()."
    ],
    "Recommendation": [
        "Unpredictability can be introduced by someone front-running the transaction, or simply by poor timing. For example, adjustments to global variable configuration by the system admin will directly impact subsequent actions by the user. In order to ensure users know what to expect:"
    ]
}
----End JSON----

https://solodit.xyz/issues/exchange-insufficient-input-validation-in-matchorders-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function matchOrders(\n    LibOrder.OrderParam memory takerOrderParam,\n    LibOrder.OrderParam[] memory makerOrderParams,\n    address \\_perpetual,\n    uint256[] memory amounts\n) public {\n\n",
        "function matchOrderWithAMM(LibOrder.OrderParam memory takerOrderParam, address \\_perpetual, uint256 amount) public {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by following the recommendation to verify that amounts.length > 0 && makerOrderParams.length == amounts.length. However, the code does not abort if one of the amounts is zero which should never happen and therefore raise an exception due to it likely being an erroneous call. Additionally, the method now enforces that only a broker can interact with the interface."
    ],
    "Description": [
        "matchOrders does not check that that the sender has provided the same number of amounts as makerOrderParams. When fewer amounts exist than makerOrderParams, the method will revert because of an out-of-bounds array access. When fewer makerOrderParams exist than amounts, the method will succeed, and the additional values in amounts will be ignored.",
        "Additionally, the method allows the sender to provide no makerOrderParams at all, resulting in no state changes.",
        "matchOrders also does not reject trades with an amount set to zero. Such orders should be rejected because they do not comply with the minimum tradingLotSize configured for the system. As a side-effect, events may be emitted for zero-amount trades and unexpected state changes may occur."
    ],
    "Examples": [
        "code/contracts/exchange/Exchange.sol:L34-L39",
        "code/contracts/exchange/Exchange.sol:L113-L113"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/amm-liquidity-provider-may-lose-up-to-lotsize-when-removing-liquidity-acknowledged-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 liquidatableAmount = totalPositionSize.sub(totalPositionSize.mod(governance.lotSize));\nliquidationAmount = liquidationAmount.ceil(governance.lotSize).min(maxAmount).min(liquidatableAmount);\n\n",
        "} else if (key == \"lotSize\") {\n    require(\n        governance.tradingLotSize == 0 || governance.tradingLotSize.mod(value.toUint256()) == 0,\n        \"require tls % ls == 0\"\n    );\n    governance.lotSize = value.toUint256();\n} else if (key == \"tradingLotSize\") {\n    require(governance.lotSize == 0 || value.toUint256().mod(governance.lotSize) == 0, \"require tls % ls == 0\");\n    governance.tradingLotSize = value.toUint256();\n\n",
        "uint256 amount = shareAmount.wmul(oldPoolPositionSize).wdiv(shareToken.totalSupply());\namount = amount.sub(amount.mod(perpetualProxy.lotSize()));\n\nperpetualProxy.transferBalanceOut(trader, price.wmul(amount).mul(2));\nburnShareTokenFrom(trader, shareAmount);\nuint256 opened = perpetualProxy.trade(trader, LibTypes.Side.LONG, price, amount);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client acknowledges this issue without providing further information."
    ],
    "Description": [
        "When removing liquidity, the amount of collateral received is calculated from the shareAmount (ShareToken) of the liquidity provider. The liquidity removal process registers a trade on the amount, with the liquidity provider and AMM taking opposite sides. Because trading only accepts multiple of the lotSize, the leftover is discarded. The amount discarded may be up to lotSize - 1.",
        "The expectation is that this value should not be too high, but as lotSize can be set to arbitrary values by an admin, it is possible that this step discards significant value. Additionally, see issue 6.6 for how this can be exploited by an admin.",
        "Note that similar behavior is present in Perpetual.liquidateFrom, where the liquidatableAmount calculated undergoes a similar modulo operation:",
        "code/contracts/perpetual/Perpetual.sol:L277-L278"
    ],
    "Examples": [
        "code/contracts/perpetual/PerpetualGovernance.sol:L61-L69",
        "code/contracts/liquidity/AMM.sol:L289-L294"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/oracle-unchecked-oracle-response-timestamp-and-integer-overunderflow-fixed-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "int256 public constant chainlinkDecimalsAdapter = 10\\*\\*10;\n\nconstructor(address \\_feeder) public {\n    feeder = IChainlinkFeeder(\\_feeder);\n}\n\nfunction price() public view returns (uint256 newPrice, uint256 timestamp) {\n    newPrice = (feeder.latestAnswer() \\* chainlinkDecimalsAdapter).toUint256();\n    timestamp = feeder.latestTimestamp();\n}\n\n",
        "int256 public constant chainlinkDecimalsAdapter = 10\\*\\*10;\n\nconstructor(address \\_feeder) public {\n    feeder = IChainlinkFeeder(\\_feeder);\n}\n\nfunction price() public view returns (uint256 newPrice, uint256 timestamp) {\n    newPrice = ONE.wdiv(feeder.latestAnswer() \\* chainlinkDecimalsAdapter).toUint256();\n    timestamp = feeder.latestTimestamp();\n}\n\n",
        "    timestamp = feeder.latestTimestamp();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was resolved by following the recommendations,",
        "The assessment team would like to note that the acceptable time-frame for answers can vary, the price may be outdated, and it is totally up to the deployer to configure the acceptable timeout. The timeout can be changed by the account deploying the oracle feed without a delay allowing the price-feed owner to arbitrarily make calls to AMM.indexPrice fail (front-running). A timeout may be set to an arbitrarily high value to bypass the check. User\u2019s of the system are advised to validate that they trust the account operating the feeder and that the timeout is set correctly."
    ],
    "Description": [
        "The external Chainlink oracle, which provides index price information to the system, introduces risk inherent to any dependency on third-party data sources. For example, the oracle could fall behind or otherwise fail to be maintained, resulting in outdated data being fed to the index price calculations of the AMM. Oracle reliance has historically resulted in crippled on-chain systems, and complications that lead to these outcomes can arise from things as simple as network congestion.",
        "Ensuring that unexpected oracle return values are properly handled will reduce reliance on off-chain components and increase the resiliency of the smart contract system that depends on them."
    ],
    "Examples": [
        "code/contracts/oracle/ChainlinkAdapter.sol:L10-L19",
        "code/contracts/oracle/InversedChainlinkAdapter.sol:L11-L20",
        "code/contracts/oracle/InversedChainlinkAdapter.sol:L19-L20"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/amm-liquidity-pools-can-be-initialized-with-zero-collateral-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by checking that amount > 0. The assessment team would like to note that;"
    ],
    "Description": [
        "createPool can be initialized with amount == 0. Because a subsequent call to initFunding can only happen once, the contract is now initialized with a zero size pool that does not allow any liquidity to be added.",
        "Trying to recover by calling createPool again fails as the funding state is already initialized. The specification also states the following about createPool:",
        "This is inaccurate, as createPool can only be called once due to a check in initFunding, but this call may leave the pool empty.",
        "Furthermore, the contract\u2019s liquidity management functionality (addLiquidity and removeLiquidity) allows adding zero liquidity (amount == 0) and removing zero shares (shareAmount == 0). As these actions do not change the liquidity of the pool, they should be rejected."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/perpetual-administrators-can-put-the-system-into-emergency-mode-indefinitely-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function beginGlobalSettlement(uint256 price) public onlyWhitelistAdmin {\n    require(status != LibTypes.Status.SETTLED, \"already settled\");\n    settlementPrice = price;\n    status = LibTypes.Status.SETTLING;\n    emit BeginGlobalSettlement(price);\n}\n\n",
        "function endGlobalSettlement() public onlyWhitelistAdmin {\n    require(status == LibTypes.Status.SETTLING, \"wrong perpetual status\");\n\n    address guy = address(amm.perpetualProxy());\n    settleFor(guy);\n    status = LibTypes.Status.SETTLED;\n\n    emit EndGlobalSettlement();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client provided the following statement addressing the issue:",
        "The duration of the emergency phase is still unrestricted."
    ],
    "Description": [
        "There is no limitation on how long an administrator can put the Perpetual contract into emergency mode. Users cannot trade or withdraw funds in emergency mode and are effectively locked out until the admin chooses to put the contract in SETTLED mode."
    ],
    "Examples": [
        "code/contracts/perpetual/PerpetualGovernance.sol:L96-L101",
        "code/contracts/perpetual/Perpetual.sol:L146-L154"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/signed-data-may-be-usable-cross-chain-fixed-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "struct Order {\n    address trader;\n    address broker;\n    address perpetual;\n    uint256 amount;\n    uint256 price;\n    /\\*\\*\n \\* Data contains the following values packed into 32 bytes\n \\* \u2554\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2564\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2557\n \\* \u2551 \u2502 length(bytes) desc \u2551\n \\* \u255f\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u253c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2562\n \\* \u2551 version \u2502 1 order version \u2551\n \\* \u2551 side \u2502 1 0: buy (long), 1: sell (short) \u2551\n \\* \u2551 isMarketOrder \u2502 1 0: limitOrder, 1: marketOrder \u2551\n \\* \u2551 expiredAt \u2502 5 order expiration time in seconds \u2551\n \\* \u2551 asMakerFeeRate \u2502 2 maker fee rate (base 100,000) \u2551\n \\* \u2551 asTakerFeeRate \u2502 2 taker fee rate (base 100,000) \u2551\n \\* \u2551 (d) makerRebateRate\u2502 2 rebate rate for maker (base 100) \u2551\n \\* \u2551 salt \u2502 8 salt \u2551\n \\* \u2551 isMakerOnly \u2502 1 is maker only \u2551\n \\* \u2551 isInversed \u2502 1 is inversed contract \u2551\n \\* \u2551 \u2502 8 reserved \u2551\n \\* \u255a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2567\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u255d\n \\*/\n    bytes32 data;\n}\n\n",
        "function isValidSignature(OrderSignature memory signature, bytes32 hash, address signerAddress)\n    internal\n    pure\n    returns (bool)\n{\n    uint8 method = uint8(signature.config[1]);\n    address recovered;\n    uint8 v = uint8(signature.config[0]);\n\n    if (method == uint8(SignatureMethod.ETH\\_SIGN)) {\n        recovered = ecrecover(\n            keccak256(abi.encodePacked(\"\\x19Ethereum Signed Message:\\n32\", hash)),\n            v,\n            signature.r,\n            signature.s\n        );\n    } else if (method == uint8(SignatureMethod.EIP712)) {\n        recovered = ecrecover(hash, v, signature.r, signature.s);\n    } else {\n        revert(\"invalid sign method\");\n    }\n\n    return signerAddress == recovered;\n}\n\n",
        "if (uint256(s) > 0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0) {\n      revert(\"ECDSA: invalid signature 's' value\");\n }\n\n",
        "if (v != 27 && v != 28) {\n     revert(\"ECDSA: invalid signature 'v' value\");\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by adding the chainId to the order data and verifying it as part of validateOrderParam. Additional checks were added to LibSignature to ensure s, v, and the result of ecrecover() are within valid bounds."
    ],
    "Description": [
        "Signed order data may be re-usable cross-chain as the chain-id is not explicitly part of the signed data.",
        "It is also recommended to further harden the signature verification and validate that v and s are within expected bounds. ecrecover() returns 0x0 to indicate an error condition, therefore, a signerAddress or recovered address of 0x0 should explicitly be disallowed."
    ],
    "Examples": [
        "The signed order data currently includes the EIP712 Domain Name Mai Protocol and the following information:",
        "code/contracts/lib/LibOrder.sol:L23-L48",
        "Signature verification:",
        "code/contracts/lib/LibSignature.sol:L24-L47"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/exchange-validateorderparam-does-not-check-against-supported_order_version-fixed-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function validateOrderParam(IPerpetual perpetual, LibOrder.OrderParam memory orderParam)\n    internal\n    view\n    returns (bytes32)\n{\n    address broker = perpetual.currentBroker(orderParam.trader);\n    require(broker == msg.sender, \"invalid broker\");\n    require(orderParam.getOrderVersion() == 2, \"unsupported version\");\n    require(orderParam.getExpiredAt() >= block.timestamp, \"order expired\");\n\n    bytes32 orderHash = orderParam.getOrderHash(address(perpetual), broker);\n    require(orderParam.signature.isValidSignature(orderHash, orderParam.trader), \"invalid signature\");\n    require(filled[orderHash] < orderParam.amount, \"fullfilled order\");\n\n    return orderHash;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was resolved by checking against SUPPORTED_ORDER_VERSION instead of the hardcoded value 2."
    ],
    "Description": [
        "validateOrderParam verifies the signature and version of a provided order. Instead of checking against the contract constant SUPPORTED_ORDER_VERSION it, however, checks against a hardcoded version 2 in the method itself.",
        "This might be a problem if SUPPORTED_ORDER_VERSION is seen as the configuration parameter for the allowed version. Changing it would not change the allowed order version for validateOrderParam as this constant literal is never used.",
        "At the time of this audit, however, the SUPPORTED_ORDER_VERSION value equals the hardcoded value in the validateOrderParam method."
    ],
    "Examples": [
        "code/contracts/exchange/Exchange.sol:L155-L170"
    ],
    "Recommendation": [
        "Check against SUPPORTED_ORDER_VERSION instead of the hardcoded value 2."
    ]
}
----End JSON----

https://solodit.xyz/issues/libmathsigned-wpowi-returns-an-invalid-result-for-a-negative-exponent-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// x ^ n\n// NOTE: n is a normal integer, do not shift 18 decimals\n// solium-disable-next-line security/no-assign-params\nfunction wpowi(int256 x, int256 n) internal pure returns (int256 z) {\n    z = n % 2 != 0 ? x : \\_WAD;\n\n    for (n /= 2; n != 0; n /= 2) {\n        x = wmul(x, x);\n\n        if (n % 2 != 0) {\n            z = wmul(z, x);\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by requiring that n is a positive signed integer (here). The method is still lacking proper natspec documentation outlining expected argument types and valid ranges. The client chose not to implement a check to detect the case where a user accidentally provides n  in WAD."
    ],
    "Description": [
        "LibMathSigned.wpowi(x,n) calculates Wad value x (base) to the power of n (exponent). The exponent is declared as a signed int, however, the method returns wrong results when calculating x ^(-n).",
        "The comment for the wpowi method suggests that n is a normal integer instead of a Wad-denominated value. This, however, is not being enforced."
    ],
    "Examples": [
        "code/contracts/lib/LibMath.sol:L103-L116"
    ],
    "Recommendation": [
        "Make wpowi support negative exponents or use the proper type for n (uint) and reject negative values.",
        "Enforce that the exponent bounds are within sane ranges and less than a Wad to detect potential misuse where someone accidentally provides a Wad value as n.",
        "Add positive and negative unit-tests to fully cover this functionality."
    ]
}
----End JSON----

https://solodit.xyz/issues/outdated-solidity-version-and-floating-pragma-pending-consensys-mcdex-mai-protocol-v2-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "pragma solidity ^0.5.2;\npragma experimental ABIEncoderV2; // to enable structure-type parameters\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed by removing the floating pragma and fixing the compiler version to v0.5.15. The assessment team would like to note, that the latest 0.5.x release of solidity is 0.5.17 with 0.5.16 addressing an ABIEncoder issue."
    ],
    "Description": [
        "Using an outdated compiler version can be problematic especially if there are publicly disclosed bugs and issues (see also https://github.com/ethereum/solidity/releases) that affect the current compiler version.",
        "The codebase specifies a floating version of ^0.5.2 and makes use of the experimental feature ABIEncoderV2.",
        "It should be noted, that ABIEncoderV2 was subject to multiple bug-fixes up until the latest 0.6.xversion and contracts compiled with earlier versions are - for example - susceptible to the following issues:"
    ],
    "Examples": [
        "Codebase declares compiler version ^0.5.2:",
        "code/contracts/liquidity/AMM.sol:L1-L2",
        "According to etherscan.io, the currently deployed main-net AMM contract is compiled with solidity version 0.5.8:",
        "https://etherscan.io/address/0xb95B9fb0539Ec84DeD2855Ed1C9C686Af9A4e8b3#code"
    ],
    "Recommendation": [
        "It is recommended to settle on the latest stable 0.6.x or 0.5.x version of the Solidity compiler and lock the pragma version to a specifically tested compiler release."
    ]
}
----End JSON----

https://solodit.xyz/issues/similar-token-to-token-swap-methods-can-yield-very-different-results-consensys-balancer-finance-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "BPool\u2019s interface exposes several methods to perform token swaps. Because the formula used to calculate trade values varies depending on the method, we compared token swaps performed using two different methods:",
        "While the latter method performs a swap by way of the pool\u2019s token as an intermediary, both methods can be used in order to perform a token-to-token swap. Our comparison between the two tested the relative amount tokenAmountOut of tokenOut between the two methods with a variety of different parameters."
    ],
    "Examples": [
        "Each example made use of a testing contract, found here: https://gist.github.com/wadeAlexC/12ee22438e8028f5439c5f0faaf9b7f7",
        "Additionally, BPool was modified; unneeded functions were removed so that deployment did not exceed the block gas limit.",
        "tokenIn weight: 25 BONE",
        "tokenOut weight: 25 BONE",
        "tokenIn, tokenOut at equal balances (50 BONE)",
        "tokenAmountIn: 1 BONE",
        "swapExactAmountIn tokenAmountOut: 980391195693945000",
        "joinswapExternAmountIn + exitSwapPoolAmountIn tokenAmountOut: 980391186207949598",
        "Result: swapExactAmountIn gives 1.00000001x more tokens",
        "tokenIn weight: 1 BONE",
        "tokenOut weight: 49 BONE",
        "tokenIn, tokenOut at equal balances (50 BONE)",
        "tokenAmountIn: 1 BONE",
        "swapExactAmountIn tokenAmountOut: 20202659955287800",
        "joinswapExternAmountIn + exitSwapPoolAmountIn tokenAmountOut: 20202659970818843",
        "Result: joinswap/exitswap gives 1.00000001x more tokens",
        "tokenIn weight: 25 BONE",
        "tokenOut weight: 25 BONE",
        "tokenIn, tokenOut at equal balances (1 BONE)",
        "tokenAmountIn: 0.5 BONE",
        "swapExactAmountIn tokenAmountOut: 333333111111037037",
        "joinswapExternAmountIn + exitSwapPoolAmountIn tokenAmountOut: 333333055579388951",
        "Result: swapExactAmountIn gives 1.000000167x more tokens",
        "tokenIn weight: 25 BONE",
        "tokenOut weight: 25 BONE",
        "tokenIn, tokenOut at equal balances (30 BONE)",
        "tokenAmountIn: 15 BONE",
        "swapExactAmountIn tokenAmountOut: 9999993333331111110",
        "joinswapExternAmountIn + exitSwapPoolAmountIn tokenAmountOut: 9999991667381668530",
        "Result: swapExactAmountIn gives 1.000000167x more tokens",
        "The final test raised the swap fee from MIN_FEE (0.0001%) to MAX_FEE (10%):",
        "tokenIn weight: 25 BONE",
        "tokenOut weight: 25 BONE",
        "tokenIn, tokenOut at equal balances (30 BONE)",
        "tokenAmountIn: 15 BONE",
        "swapExactAmountIn tokenAmountOut: 9310344827586206910",
        "joinswapExternAmountIn + exitSwapPoolAmountIn tokenAmountOut: 9177966102628338740",
        "Result: swapExactAmountIn gives 1.014423536x more tokens"
    ],
    "Recommendation": [
        "Our final test showed that with equivalent balances and weights, raising the swap fee to 10% had a drastic effect on relative tokenAmountOut received, with swapExactAmountIn yielding >1.44% more tokens than the joinswap/exitswap method.",
        "Reading through Balancer\u2019s provided documentation, our assumption was that these two swap methods were roughly equivalent. Discussion with Balancer clarified that the joinswap/exitswap method applied two swap fees: one for single asset deposit, and one for single asset withdrawal. With the minimum swap fee, this double application proved to have relatively little impact on the difference between the two methods. In fact, some parameters resulted in higher relative yield from the joinswap/exitswap method. With the maximum swap fee, the double application was distinctly noticeable.",
        "Given the relative complexity of the math behind BPools, there is much that remains to be tested. There are alternative swap methods, as well as numerous additional permutations of parameters that could be used; these tests were relatively narrow in scope.",
        "We recommend increasing the intensity of unit testing to cover a more broad range of interactions with BPool\u2019s various swap methods. In particular, the double application of the swap fee should be examined, as well as the differences between low and high swap fees.",
        "Those using BPool should endeavor to understand as much of the underlying math as they can, ensuring awareness of the various options available for performing trades."
    ]
}
----End JSON----

https://solodit.xyz/issues/test-code-present-in-the-code-base-fixed-consensys-rico-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "whitelistingAddress = \\_whitelistingAddress;\nprojectAddress = \\_projectAddress;\nfreezerAddress = \\_projectAddress; // TODO change, here only for testing\nrescuerAddress = \\_projectAddress; // TODO change, here only for testing\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in lukso-network/[email\u00a0protected]edb880c."
    ],
    "Description": [
        "Test code are present in the code base. This is mainly a reminder to fix those before production."
    ],
    "Examples": [
        "rescuerAddress and freezerAddress are not even in the function arguments.",
        "code/contracts/ReversibleICO.sol:L243-L247"
    ],
    "Recommendation": [
        "Make sure all the variable assignments are ready for production before deployment to production."
    ]
}
----End JSON----

https://solodit.xyz/issues/freezeraddress-has-more-power-than-required-acknowledged-consensys-rico-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This issue is acknowledged by the client and the behaviour has been documented in security measurements."
    ],
    "Description": [
        "FreezerAddress is designed to have the ability of freezing the contract in case of emergency. However, indirectly, there are other changes in the system that can result from the freeze."
    ],
    "Examples": [],
    "Recommendation": [
        "If these behaviors are intentional they should be well documented and specified. If not, they should be removed.",
        "In the case they are, indeed, intentional the audit team believes that, for Example 1., there should be some event fired to serve as notification for the participants (possibly followed by off-chain infrastructure to warn them through email or other communication channel)."
    ]
}
----End JSON----

https://solodit.xyz/issues/frozenperiod-is-subtracted-twice-for-calculating-the-current-price-fixed-consensys-rico-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getCurrentStage() public view returns (uint8) {\n    return getStageAtBlock(getCurrentBlockNumber());\n}\n\n",
        "function getCurrentBlockNumber() public view returns (uint256) {\n    return uint256(block.number)\n    .sub(frozenPeriod); // make sure we deduct any frozenPeriod from calculations\n}\n\n",
        "function getStageAtBlock(uint256 \\_blockNumber) public view returns (uint8) {\n\n    uint256 blockNumber = \\_blockNumber.sub(frozenPeriod); // adjust the block by the frozen period\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Found in parallel to the audit team and has been mitigated in lukso-network/[email\u00a0protected]ebc4bce . The issue was further simplified by adding getCurrentEffectiveBlockNumber() in lukso-network/[email\u00a0protected]e4c9ed5 to remove ambiguity when calculating current block number."
    ],
    "Description": [
        "If the contract had been frozen, the current stage price will calculate the price by subtracting the frozenPeriod twice and result in wrong calculation.",
        "getCurrentBlockNumber() subtracts frozenPeriod once, and then getStageAtBlock() will also subtract the same number again."
    ],
    "Examples": [
        "code/contracts/ReversibleICO.sol:L617-L619",
        "code/contracts/ReversibleICO.sol:L711-L714",
        "code/contracts/ReversibleICO.sol:L654-L656"
    ],
    "Recommendation": [
        "Make sure frozenPeriod calculation is done correctly. It could be solved by renaming getCurrentBlockNumber() to reflect the calculation done inside the function.",
        "e.g. :"
    ]
}
----End JSON----

https://solodit.xyz/issues/gold-order-size-should-be-limited-addressed-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Mint gold cards\nskyweaverAssets.batchMint(\\_order.cardRecipient, \\_ids, amounts, \"\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed in horizon-games/SkyWeaver-contracts#9 by adding a limit for cold cards amount in one order."
    ],
    "Description": [
        "When a user submits an order to buy gold cards, it\u2019s possible to buy a huge amount of cards. _commit function uses less gas than mineGolds, which means that the user can successfully commit to buying this amount of cards and when it\u2019s time to collect them, mineGolds function may run out of gas because it iterates over all card IDs and mints them:",
        "code/contracts/shop/GoldCardsFactory.sol:L375-L376"
    ],
    "Recommendation": [
        "Limit a maximum gold card amount in one order."
    ]
}
----End JSON----

https://solodit.xyz/issues/price-and-refund-changes-may-cause-failures-addressed-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_commit(uint256 \\_weaveAmount, GoldOrder memory \\_order)\n  internal\n{\n  // Check if weave sent is sufficient for order\n  uint256 total\\_cost = \\_order.cardAmount.mul(goldPrice).add(\\_order.feeAmount);\n  uint256 refund\\_amount = \\_weaveAmount.sub(total\\_cost); // Will throw if insufficient amount received\n\n",
        "// Burn the non-refundable weave\nuint256 weave\\_to\\_burn = (\\_order.cardAmount.mul(goldPrice)).sub(\\_order.cardAmount.mul(goldRefund));\nweaveContract.burn(weaveID, weave\\_to\\_burn);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed in horizon-games/SkyWeaver-contracts#3."
    ],
    "Description": [
        "Price and refund for gold cards are used in 3 different places: commit, mint, refund.",
        "Weave tokens spent during the commit phase",
        "code/contracts/shop/GoldCardsFactory.sol:L274-L279",
        "but they are burned rngDelay blocks after",
        "code/contracts/shop/GoldCardsFactory.sol:L371-L373",
        "If the price is increased between these transactions, mining cards may fail because it should burn more weave tokens than there are tokens in the smart contract. Even if there are enough tokens during this particular transaction, someone may fail to melt a gold card later.",
        "If the price is decreased, some weave tokens will be stuck in the contract forever without being burned."
    ],
    "Recommendation": [
        "Store goldPrice and goldRefund in GoldOrder."
    ]
}
----End JSON----

https://solodit.xyz/issues/re-entrancy-attack-allows-to-buy-eternalheroes-cheaper-addressed-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 refundAmount = \\_arcAmount.sub(total\\_cost);\nif (refundAmount > 0) {\n  arcadeumCoin.safeTransferFrom(address(this), \\_recipient, arcadeumCoinID, refundAmount, \"\");\n}\n\n// Mint tokens to recipient\nfactoryManager.batchMint(\\_recipient, \\_ids, amounts\\_to\\_mint, \"\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed in horizon-games/SkyWeaver-contracts#4.",
        "And re-entrancy guard added here: horizon-games/SkyWeaver-contracts#10"
    ],
    "Description": [
        "When buying eternal heroes in _buy  function of EternalHeroesFactory contract, a buyer can do re-entracy before items are minted.",
        "code/contracts/shop/EternalHeroesFactory.sol:L278-L284",
        "Since price should increase after every N items are minted, it\u2019s possible to buy more items with the old price."
    ],
    "Recommendation": [
        "Add re-entrancy protection or mint items before sending the refund."
    ]
}
----End JSON----

https://solodit.xyz/issues/supply-limitation-misbehaviors-addressed-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setMaxSupplies(uint256[] calldata \\_ids, uint256[] calldata \\_newMaxSupplies) external onlyOwner() {\n  require(\\_ids.length == \\_newMaxSupplies.length, \"SWSupplyManager#setMaxSupply: INVALID\\_ARRAYS\\_LENGTH\");\n\n  // Can only \\*decrease\\* a max supply\n  // Can't set max supply back to 0\n  for (uint256 i = 0; i < \\_ids.length; i++ ) {\n    if (maxSupply[\\_ids[i]] > 0) {\n      require(\n        0 < \\_newMaxSupplies[i] && \\_newMaxSupplies[i] < maxSupply[\\_ids[i]],\n        \"SWSupplyManager#setMaxSupply: INVALID\\_NEW\\_MAX\\_SUPPLY\"\n      );\n    }\n    maxSupply[\\_ids[i]] = \\_newMaxSupplies[i];\n  }\n\n  emit MaxSuppliesChanged(\\_ids, \\_newMaxSupplies);\n}\n\n",
        "function burn(\n  uint256 \\_id,\n  uint256 \\_amount)\n  external\n{\n  \\_burn(msg.sender, \\_id, \\_amount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Logic remains unchanged as it\u2019s the desired behaviour. But the issue is mitigated in horizon-games/SkyWeaver-contracts#5 by renaming the term \u201ccurrentSupply\u201d to \u201ccurrentIssuance\u201d and \u201cmaxSupply\u201d to \u201cmaxIssuance\u201d for maximum clarity."
    ],
    "Description": [
        "In SWSupplyManager contract, the owner can limit supply for any token ID by setting maxSupply:",
        "code/contracts/shop/SWSupplyManager.sol:L149-L165",
        "The problem is that you can set maxSupply that is lower than currentSupply, which would be an unexpected state to have.",
        "Also, if some tokens are burned, their currentSupply is not decreasing:",
        "code/contracts/shop/SWSupplyManager.sol:L339-L345",
        "This unexpected behaviour may lead to burning all of the tokens without being able to mint more."
    ],
    "Recommendation": [
        "Properly track currentSupply by modifying it in burn function.\nConsider having a following restriction require(_newMaxSupplies[i] > currentSupply[_ids[i]]) in setMaxSupplies function."
    ]
}
----End JSON----

https://solodit.xyz/issues/owner-can-modify-gold-cards-distribution-after-someone-committed-to-buy-wont-fix-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client decided not to fix this issue with the following comment:"
    ],
    "Description": [
        "When a user commits to buying a gold card (and sends weave), there is an expected distribution of possible outcomes. But the problem is that owner can change distribution by calling registerIDs and deregisterIDs  functions.",
        "Additionally, owner can buy any specific gold card avoiding RNG mechanism. It can be done by deleting all the unwanted cards, mining the card and then returning them back. And if owner removes every card from the list, nothing is going to be minted."
    ],
    "Recommendation": [
        "There are a few possible recommendations:"
    ]
}
----End JSON----

https://solodit.xyz/issues/a-buyer-of-a-gold-card-can-manipulate-randomness-wont-fix-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client decided not to fix this issue with the following comment:"
    ],
    "Description": [
        "When a user is buying a gold card, _commit function is called. After rngDelay number of blocks, someone should call mineGolds function to actually mint the card. If this function is not called during 255 blocks (around 1 hour), a user should call recommit to try to mint a gold card again with a new random seed.\nSo if the user doesn\u2019t like a card that\u2019s going to be minted (randomly), user can try again until a card is good.\nThe issue is medium because anyone can call mineGolds function in order to prevent this behaviour. But it costs money and there\u2019s no incentive for anyone to do so."
    ],
    "Recommendation": [
        "Create a mechanism to avoid this kind of manipulation. For example, make sure there is an incentive for someone to call mineGolds function"
    ]
}
----End JSON----

https://solodit.xyz/issues/a-refund-is-sent-to-recipient-wont-fix-consensys-skyweaver-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The client decided not to fix this issue with the following comment:"
    ],
    "Description": [
        "When a refund is sent, it\u2019s sent to recipient. In case if a user wants to keep game items and money separate, it makes sense to send a refund back to from address."
    ],
    "Recommendation": [
        "Since there may be different use cases, consider adding refundAddress to order structure."
    ]
}
----End JSON----

https://solodit.xyz/issues/system-deployer-is-fully-trusted-in-this-version-of-the-poco-system-acknowledged-consensys-iexec-poco-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Update from the iExec team:",
        "After deployment, ownership is planned to be transferred to a multisig.\nThis is just the first step towards a more decentralised governance on the protocol. We will consider adding an intermediary contract that enforces the lock period. This would however, prevent us from any kind of \u201cemergency\u201d update.\nThe long term goal is it involve the community in the process, using a DAO or a similar solution."
    ],
    "Description": [
        "The introduction of ERC1538-compliant proxies to construct the PoCo system has many benefits. It heightens modularity, reduces the number of external calls between the system\u2019s components and allows for easy expansion of the system\u2019s capabilities without disruption of the service or need for off-chain infrastructure upgrade.\nHowever, the last enumerated benefit is in fact a double-edged sword.",
        "Even though ERC1538 enables easy upgradeability it also completely strips the PoCo system of all of its prior trustless nature. In this version the iExec development team should be entirely trusted by every actor in the system not to change the deployed on-chain delegates for new ones.",
        "Also the deployer, owner, has permission to change some of the system variables, such as m_callbackgas for Oracle callback gas limit. This indirectly can lock the system, for example it could result in IexecPocoDelegate.executeCallback() reverting which prevents the finalization of corresponding task."
    ],
    "Recommendation": [
        "The best, easiest solution for the trust issue would be to immediately revoke ownership of the proxy right after deployment. This way the modular deployment would still be possible but no power to change the deployed on-chain code would exist.",
        "A second best solution would be to force a timespan period before any change to the proxy methods (and its delegates) is made effective. This way any actor in the system can still monitor for possible changes and \u201cleave\u201d the system before they are implemented.",
        "In this last option the \u201clock\u201d period should, obviously, be greater than the amount of time it takes to verify a Task of the bigger category but it is advisable to decide on it by anthropomorphic rules and use a longer, \u201chuman-friendly\u201d time lock of, for example, 72 hours."
    ]
}
----End JSON----

https://solodit.xyz/issues/importscore-in-iexecmaintenancedelegate-can-be-used-to-wrongfully-reset-worker-scores-acknowledged-consensys-iexec-poco-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function importScore(address \\_worker)\nexternal override\n{\n\trequire(!m\\_v3\\_scoreImported[\\_worker], \"score-already-imported\");\n\tm\\_workerScores[\\_worker] = m\\_workerScores[\\_worker].max(m\\_v3\\_iexecHub.viewScore(\\_worker));\n\tm\\_v3\\_scoreImported[\\_worker] = true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Update from the iExec team:",
        "In order to perform this attack, one would first have to gain reputation on the new version, and lose it. They would then be able to restore its score from the old version.",
        "We feel the risk is acceptable for a few reasons:",
        "We might force the import all 180 workers with reputation >0. A script to identify the relevant addresses is already available."
    ],
    "Description": [
        "The import of worker scores from the previous PoCo system deployed on chain is made to be asynchronous. And, even though the pull pattern usually makes a system much more resilient, in this case, it opens up the possibility for an attack that undermines the trust-based game-theoretical balance the PoCo system relies on. As can be seen in the following function:",
        "code/poco-dev/contracts/modules/delegates/IexecMaintenanceDelegate.sol:L51-L57",
        "A motivated attacker could attack the system providing bogus results for computation tasks therefore reducing his own reputation (mirrored by the low worker score that would follow).",
        "After the fact, the attacker could reset its score to the previous high value attained in the previously deployed PoCo system (v3) and undo all the wrongdoings he had done at no reputational cost."
    ],
    "Recommendation": [
        "Check that each worker interacting with the PoCo system has already imported his score. Otherwise import it synchronously with a call at the time of their first interaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/outdated-documentation-acknowledged-consensys-iexec-poco-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Update from the iExec team: Work in progress."
    ],
    "Description": [
        "There are many changes within the system from the initial version that are not reflected in the documentation.",
        "It is necessary to have updated documentation for the time of the audit, as the specification dictates the correct behaviour of the code base."
    ],
    "Examples": [
        "Entities such as iExecClerk are the main point of entry in the documentation, however they have been replaced by proxy implementation in the code base (V5)."
    ],
    "Recommendation": [
        "Up date documentation to reflect the recent changes and design in the code base."
    ]
}
----End JSON----

https://solodit.xyz/issues/domain-separator-in-iexecmaintenancedelegate-has-a-wrong-version-field-acknowledged-consensys-iexec-poco-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_domain()\ninternal view returns (IexecLibOrders\\_v5.EIP712Domain memory)\n{\n\treturn IexecLibOrders\\_v5.EIP712Domain({\n\t\tname:              \"iExecODB\"\n\t, version:           \"3.0-alpha\"\n\t, chainId:           \\_chainId()\n\t, verifyingContract: address(this)\n\t});\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue was fixed in iExecBlockchainComputing/[email\u00a0protected]ebee370"
    ],
    "Description": [
        "The domain separator used to comply with the EIP712 standard in iExecMaintenanceDelegate has a wrong version field.",
        "code/poco-dev/contracts/modules/delegates/IexecMaintenanceDelegate.sol:L77-L86",
        "In the above snippet we can see the code is still using the version field from an old version of the PoCo protocol, \"3.0-alpha\"."
    ],
    "Recommendation": [
        "Change the version field to: \"5.0-alpha\""
    ]
}
----End JSON----

https://solodit.xyz/issues/tokenstakingrecoverstake-allows-instant-stake-undelegation-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function recoverStake(address \\_operator) public {\n    uint256 operatorParams = operators[\\_operator].packedParams;\n    require(\n        block.number > operatorParams.getUndelegationBlock().add(undelegationPeriod),\n        \"Can not recover stake before undelegation period is over.\"\n    );\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with keep-network/keep-core#1521 by adding a non-zero check for the undelegation block."
    ],
    "Description": [
        "TokenStaking.recoverStake is used to recover stake that has been designated to be undelegated. It contains a single check to ensure that the undelegation period has passed:",
        "keep-core/contracts/solidity/contracts/TokenStaking.sol:L182-L187",
        "However, if an undelegation period is never set, this will always return true, allowing any operator to instantly undelegate stake at any time."
    ],
    "Recommendation": [
        "Require that the undelegation period is nonzero before allowing an operator to recover stake."
    ]
}
----End JSON----

https://solodit.xyz/issues/improper-length-validation-in-bls-signature-library-allows-rng-manipulation-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function relayEntry(bytes memory \\_groupSignature) public nonReentrant {\n    require(isEntryInProgress(), \"Entry was submitted\");\n    require(!hasEntryTimedOut(), \"Entry timed out\");\n\n    bytes memory groupPubKey = groups.getGroupPublicKey(signingRequest.groupIndex);\n\n    require(\n        BLS.verify(\n            groupPubKey,\n            signingRequest.previousEntry,\n            \\_groupSignature\n        ),\n        \"Invalid signature\"\n    );\n\n    emit RelayEntrySubmitted();\n\n",
        "function verify(\n    bytes memory publicKey,\n    bytes memory message,\n    bytes memory signature\n) public view returns (bool) {\n\n    AltBn128.G1Point memory \\_signature = AltBn128.g1Unmarshal(signature);\n\n",
        "/\\*\\*\n \\* @dev Unmarshals a point on G1 from bytes in an uncompressed form.\n \\*/\nfunction g1Unmarshal(bytes memory m) internal pure returns(G1Point memory) {\n    bytes32 x;\n    bytes32 y;\n\n    /\\* solium-disable-next-line \\*/\n    assembly {\n        x := mload(add(m, 0x20))\n        y := mload(add(m, 0x40))\n    }\n\n    return G1Point(uint256(x), uint256(y));\n}\n\n",
        "// Spend no more than groupSelectionGasEstimate + 40000 gas max\n// This will prevent relayEntry failure in case the service contract is compromised\nsigningRequest.serviceContract.call.gas(groupSelectionGasEstimate.add(40000))(\n    abi.encodeWithSignature(\n        \"entryCreated(uint256,bytes,address)\",\n        signingRequest.relayRequestId,\n        \\_groupSignature,\n        msg.sender\n    )\n);\n\nif (signingRequest.callbackFee > 0) {\n    executeCallback(signingRequest, uint256(keccak256(\\_groupSignature)));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with keep-network/keep-core#1523 by adding input length checks to g2Decompress, g2Unmarshal and g1Unmarshal."
    ],
    "Description": [
        "KeepRandomBeaconOperator.relayEntry(bytes memory _signature) is used to submit random beacon results:",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L418-L433",
        "The function calls BLS.verify, which validates that the submitted signature correctly signs the previous recorded random beacon entry. BLS.verify calls AltBn128.g1Unmarshal(signature):",
        "keep-core/contracts/solidity/contracts/cryptography/BLS.sol:L31-L37",
        "AltBn128.g1Unmarshal(signature) reads directly from memory without making any length checks:",
        "keep-core/contracts/solidity/contracts/cryptography/AltBn128.sol:L214-L228",
        "There are two potential issues with this:",
        "These issues are important because the hash of the signature is the \u201crandom number\u201d supplied to user contracts:",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L435-L448",
        "An attacker can use this behavior to game random number generation by frontrunning a valid signature submission with additional byte padding."
    ],
    "Recommendation": [
        "Ensure each function in BLS.sol properly validates input lengths for all parameters; the same length validation issue exists in BLS.verifyBytes."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-the-tecdsa-keep-is-never-closed-signer-bonds-are-not-released-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/tbtc/issues/473, https://github.com/keep-network/tbtc/issues/490, https://github.com/keep-network/tbtc/pull/534, and keep-network/tbtc#520."
    ],
    "Description": [
        "At the end of the TBTC deposit lifecycle happy path, the deposit is supposed to close the keep in order to release the signer bonds. However, there is no call to closeKeep in any of the code-bases under audit."
    ],
    "Recommendation": [
        "Close the keep releasing the signer bonds."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-no-access-control-in-tbtcsystemrequestnewkeep-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Request a new keep opening.\n/// @param \\_m Minimum number of honest keep members required to sign.\n/// @param \\_n Number of members in the keep.\n/// @return Address of a new keep.\nfunction requestNewKeep(uint256 \\_m, uint256 \\_n, uint256 \\_bond)\n    external\n    payable\n    returns (address)\n{\n    IBondedECDSAKeepVendor \\_keepVendor = IBondedECDSAKeepVendor(keepVendor);\n    IBondedECDSAKeepFactory \\_keepFactory = IBondedECDSAKeepFactory(\\_keepVendor.selectFactory());\n    return \\_keepFactory.openKeep.value(msg.value)(\\_n, \\_m, msg.sender, \\_bond);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue addressed in keep-network/tbtc#514. Each call to requestNewKeep makes a check that uint(msg.sender) is an existing TBTCDepositToken. Because these tokens are only minted in DepositFactory, msg.sender would have to be one of the cloned deposit contracts."
    ],
    "Description": [
        "TBTCSystem.requestNewKeep is used by each new Deposit contract on creation. It calls BondedECDSAKeepFactory.openKeep, which sets the Deposit contract as the \u201cowner,\u201d a permissioned role within the created keep. openKeep also automatically allocates bonds from members registered to the application. The \u201capplication\u201d from which member bonds are allocated is the tbtc system itself.",
        "Because requestNewKeep has no access controls, anyone can request that a keep be opened with msg.sender as the \u201cowner,\u201d and arbitrary signing threshold values:",
        "tbtc/implementation/contracts/system/TBTCSystem.sol:L231-L243",
        "Given that the owner of a keep is able to seize signer bonds, close the keep, and more, having control of this role could be detrimental to group members."
    ],
    "Recommendation": [
        "Add access control to requestNewKeep, so that it can only be called as a part of the Deposit creation and initialization process."
    ]
}
----End JSON----

https://solodit.xyz/issues/unpredictable-behavior-due-to-front-running-or-general-bad-timing-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Set the system signer fee divisor.\n/// @param \\_signerFeeDivisor The signer fee divisor.\nfunction setSignerFeeDivisor(uint256 \\_signerFeeDivisor)\n    external onlyOwner\n{\n    require(\\_signerFeeDivisor > 9, \"Signer fee divisor must be greater than 9, for a signer fee that is <= 10%.\");\n    signerFeeDivisor = \\_signerFeeDivisor;\n    emit SignerFeeDivisorUpdated(\\_signerFeeDivisor);\n}\n\n",
        "/\\*\\*\n \\* @dev Upgrade current implementation.\n \\* @param \\_implementation Address of the new implementation contract.\n \\*/\nfunction upgradeTo(address \\_implementation)\n    public\n    onlyOwner\n{\n    address currentImplementation = implementation();\n    require(\\_implementation != address(0), \"Implementation address can't be zero.\");\n    require(\\_implementation != currentImplementation, \"Implementation address must be different from the current one.\");\n    setImplementation(\\_implementation);\n    emit Upgraded(\\_implementation);\n}\n\n",
        "/// @notice Upgrades the current vendor implementation.\n/// @param \\_implementation Address of the new vendor implementation contract.\nfunction upgradeTo(address \\_implementation) public onlyOwner {\n    address currentImplementation = implementation();\n    require(\n        \\_implementation != address(0),\n        \"Implementation address can't be zero.\"\n    );\n    require(\n        \\_implementation != currentImplementation,\n        \"Implementation address must be different from the current one.\"\n    );\n    setImplementation(\\_implementation);\n    emit Upgraded(\\_implementation);\n}\n\n",
        "function registerFactory(address payable \\_factory) external onlyOperatorContractUpgrader {\n    require(\\_factory != address(0), \"Incorrect factory address\");\n    require(\n        registry.isApprovedOperatorContract(\\_factory),\n        \"Factory contract is not approved\"\n    );\n    keepFactory = \\_factory;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been addressed with https://github.com/keep-network/tbtc/issues/493 and the following set of PRs:",
        "The client also provided the following statements:"
    ],
    "Description": [
        "In a number of cases, administrators of contracts can update or upgrade things in the system without warning. This has the potential to violate a security goal of the system.",
        "Specifically, privileged roles could use front running to make malicious changes just ahead of incoming transactions, or purely accidental negative effects could occur due to unfortunate timing of changes.",
        "Some instances of this are more important than others, but in general users of the system should have assurances about the behavior of the action they\u2019re about to take."
    ],
    "Examples": [
        "System Parameters",
        "The owner of the TBTCSystem contract can change system parameters at any time with changes taking effect immediately.",
        "This also opens up an opportunity for malicious owner to:",
        "tbtc/implementation/contracts/system/TBTCSystem.sol:L113-L121",
        "Upgradables",
        "The proxy pattern used in many places throughout the system allows the operator to set a new implementation which takes effect immediately.",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconService.sol:L67-L80",
        "keep-tecdsa/solidity/contracts/BondedECDSAKeepVendor.sol:L57-L71",
        "Registry",
        "keep-tecdsa/solidity/contracts/BondedECDSAKeepVendorImplV1.sol:L43-L50"
    ],
    "Recommendation": [
        "The underlying issue is that users of the system can\u2019t be sure what the behavior of a function call will be, and this is because the behavior can change at any time.",
        "We recommend giving the user advance notice of changes with a time lock. For example, make all upgrades require two steps with a mandatory time window between them. The first step merely broadcasts to users that a particular change is coming, and the second step commits that change after a suitable waiting period."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-core-reportrelayentrytimeout-creates-an-incentive-for-nodes-to-race-for-rewards-potentially-wasting-gas-and-it-creates-an-opportunity-for-front-running-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Function used to inform about the fact the currently ongoing\n \\* new relay entry generation operation timed out. As a result, the group\n \\* which was supposed to produce a new relay entry is immediately\n \\* terminated and a new group is selected to produce a new relay entry.\n \\* All members of the group are punished by seizing minimum stake of\n \\* their tokens. The submitter of the transaction is rewarded with a\n \\* tattletale reward which is limited to min(1, 20 / group\\_size) of the\n \\* maximum tattletale reward.\n \\*/\nfunction reportRelayEntryTimeout() public {\n    require(hasEntryTimedOut(), \"Entry did not time out\");\n    groups.reportRelayEntryTimeout(signingRequest.groupIndex, groupSize, minimumStake);\n\n    // We could terminate the last active group. If that's the case,\n    // do not try to execute signing again because there is no group\n    // which can handle it.\n    if (numberOfGroups() > 0) {\n        signRelayEntry(\n            signingRequest.relayRequestId,\n            signingRequest.previousEntry,\n            signingRequest.serviceContract,\n            signingRequest.entryVerificationAndProfitFee,\n            signingRequest.callbackFee\n        );\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Following the discussion at https://github.com/keep-network/keep-core/issues/1404 it was verified that the method throws as early as possible in an attempt to safe gas in case many nodes call out the timeout in the same block. The client is currently comfortable with this tradeoff. We would like to note that this issue cannot easily be addressed (e.g. allowing nodes to disable calling out timeouts impacts the security of the system; a commit/reveal proxy adds overhead and is unlikely to make the situation better as nodes are programmed to call out timeouts) and we therefore recommend to monitor the network for this scenario."
    ],
    "Description": [
        "The incentive on reportRelayEntryTimeout for being rewarded with 5% of the seized amount creates an incentive to call the method but might also kick off a race for front-running this call. This method is being called from the keep node which is unlikely to adjust the gasPrice and might always lose the race against a front-running bot collecting rewards for all timeouts and fraud proofs (issue 5.7)"
    ],
    "Examples": [
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L600-L626"
    ],
    "Recommendation": [
        "Make sure that reportRelayEntryTimeout throws as early as possible if the group was previously terminated (isGroupTerminated) to avoid that keep-nodes spend gas on a call that will fail. Depending on the reward for calling out the timeout this might create a front-running opportunity that cannot be resolved."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-core-reportunauthorizedsigning-fraud-proof-is-not-bound-to-reporter-and-can-be-front-run-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Reports unauthorized signing for the provided group. Must provide\n \\* a valid signature of the group address as a message. Successful signature\n \\* verification means the private key has been leaked and all group members\n \\* should be punished by seizing\u00a0their tokens. The submitter of this proof is\n \\* rewarded with 5% of the total seized amount scaled by the reward adjustment\n \\* parameter and the rest 95% is burned.\n \\*/\nfunction reportUnauthorizedSigning(\n    uint256 groupIndex,\n    bytes memory signedGroupPubKey\n) public {\n    groups.reportUnauthorizedSigning(groupIndex, signedGroupPubKey, minimumStake);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/keep-core/issues/1405 by binding the proof to msg.sender."
    ],
    "Description": [
        "An attacker can monitor reportUnauthorizedSigning() for fraud reports and attempt to front-run the original call in an effort to be the first one reporting the fraud and be rewarded 5% of the total seized amount."
    ],
    "Examples": [
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L742-L755"
    ],
    "Recommendation": [
        "Require the reporter to include msg.sender in the signature proving the fraud or\nimplement a two-step commit/reveal scheme to counter front-running opportunities by forcing a reporter to secretly commit the fraud parameters in one block and reveal them in another."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-core-operator-contracts-disabled-via-panic-button-can-be-re-enabled-by-registrykeeper-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\nfunction approveOperatorContract(address operatorContract) public onlyRegistryKeeper {\n    operatorContracts[operatorContract] = 1;\n}\n\nfunction disableOperatorContract(address operatorContract) public onlyPanicButton {\n    operatorContracts[operatorContract] = 2;\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed by https://github.com/keep-network/keep-core/issues/1406 with changes from https://github.com/keep-network/keep-core/pull/1463:"
    ],
    "Description": [
        "The Registry contract defines three administrative accounts: Governance, registryKeeper, and panicButton. All permissions are initially assigned to the deployer when the contract is created. The account acting like a super-admin, being allowed to re-assign administrative accounts - is Governance. registryKeeper is a lower privileged account maintaining the registry and panicButton is an emergency account that can disable operator contracts.",
        "The keep specification states the following:",
        "It is assumed that the permissions are Governance > panicButton > registryKeeper, meaning that panicButton should be able to overrule registryKeeper, while registryKeeper cannot overrule panicButton.",
        "With the current implementation of the Registry the registryKeeper account can re-enable an operator contract that has previously been disabled by the panicButton account.",
        "We would also like to note the following:"
    ],
    "Examples": [
        "keep-core/contracts/solidity/contracts/Registry.sol:L67-L75"
    ],
    "Recommendation": [
        "The keep specification states:",
        "All three accounts are typically trusted. We recommend requiring the Governance or paniceButton accounts to reset the contract operator state before registryKeeper can change the state or disallow re-enabling of disabled operator contracts as stated in the specification."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-state-transitions-are-not-always-enforced-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice we poll the Keep contract to retrieve our pubkey\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\n/// @param \\_d deposit storage pointer\n/// @return True if successful, otherwise revert\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\n\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\n\n\n",
        "function provideBTCFundingProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public returns (bool) {\n\n    require(\\_d.inAwaitingBTCFundingProof(), \"Not awaiting funding\");\n\n    bytes8 \\_valueBytes;\n    bytes memory  \\_utxoOutpoint;\n\n",
        "/// @notice Goes from courtesy call to active\n/// @dev Only callable if collateral is sufficient and the deposit is not expiring\n/// @param \\_d deposit storage pointer\nfunction exitCourtesyCall(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inCourtesyCall(), \"Not currently in courtesy call\");\n    require(block.timestamp <= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit is expiring\");\n    require(getCollateralizationPercentage(\\_d) >= \\_d.undercollateralizedThresholdPercent, \"Deposit is still undercollateralized\");\n    \\_d.setActive();\n    \\_d.logExitedCourtesyCall();\n}\n\n",
        "/// @notice Notifies the contract that its term limit has been reached\n/// @dev This initiates a courtesy call\n/// @param \\_d deposit storage pointer\nfunction notifyDepositExpiryCourtesyCall(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inActive(), \"Deposit is not active\");\n    require(block.timestamp >= \\_d.fundedAt + TBTCConstants.getDepositTerm(), \"Deposit term not elapsed\");\n    \\_d.setCourtesyCall();\n    \\_d.logCourtesyCalled();\n    \\_d.courtesyCallInitiated = block.timestamp;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed with https://github.com/keep-network/tbtc/issues/494 and accepted by the client with the following statement. Deposits that are timed out can still be pushed to an active state."
    ],
    "Description": [
        "A deposit follows a complex state-machine that makes sure it is correctly funded before TBTC Tokens are minted. The deposit lifecycle starts with a set of states modeling a funding flow that - if successful - ultimately leads to the deposit being active, meaning that corresponding TBTC tokens exist for the deposits. A redemption flow allows to redeem TBTC for BTC and a liquidation flow handles fraud and abort conditions. Fraud cases in the funding flow are handled separately.",
        "State transitions from one deposit state to another require someone calling the corresponding transition method on the deposit and actually spend gas on it. The incentive to call a transition varies and is analyzed in more detail in the security-specification section of this report.",
        "This issue assumes that participants are not always pushing forward through the state machine as soon as a new state becomes available, opening up the possibility of having multiple state transitions being a valid option for a deposit (e.g. pushing a deposit to active state even though a timeout should have been called on it)."
    ],
    "Examples": [
        "This affects all states that can time out.",
        "There is no timeout check in retrieveSignerPubkey, provideBTCFundingProof.",
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L108-L117",
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L263-L278",
        "It should be noted that even after the fraud funding timeout passed the TDT holder could provideFraudBTCFundingProof as it does not check for the timeout.",
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L289-L298",
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L318-L327",
        "Allow exiting the courtesy call only if the deposit is not expired: block.timestamp < _d.fundedAt + TBTCConstants.getDepositTerm()"
    ],
    "Recommendation": [
        "Ensure that there are no competing interests between participants of the system to favor one transition over the other, causing race conditions, front-running opportunities or stale deposits that are not pushed to end-states.",
        "Note: Please find an analysis of incentives to call state transitions in the security section of this document."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-funder-loses-payment-to-keep-if-signing-group-is-not-established-in-time-pending-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice we poll the Keep contract to retrieve our pubkey\n/// @dev We store the pubkey as 2 bytestrings, X and Y.\n/// @param \\_d deposit storage pointer\n/// @return True if successful, otherwise revert\nfunction retrieveSignerPubkey(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inAwaitingSignerSetup(), \"Not currently awaiting signer setup\");\n\n    bytes memory \\_publicKey = IBondedECDSAKeep(\\_d.keepAddress).getPublicKey();\n    require(\\_publicKey.length == 64, \"public key not set or not 64-bytes long\");\n\n    \\_d.signingGroupPubkeyX = \\_publicKey.slice(0, 32).toBytes32();\n    \\_d.signingGroupPubkeyY = \\_publicKey.slice(32, 32).toBytes32();\n    require(\\_d.signingGroupPubkeyY != bytes32(0) && \\_d.signingGroupPubkeyX != bytes32(0), \"Keep returned bad pubkey\");\n    \\_d.fundingProofTimerStart = block.timestamp;\n\n    \\_d.setAwaitingBTCFundingProof();\n    \\_d.logRegisteredPubkey(\n        \\_d.signingGroupPubkeyX,\n        \\_d.signingGroupPubkeyY);\n}\n\n",
        "/// @notice Anyone may notify the contract that signing group setup has timed out\n/// @dev We rely on the keep system punishes the signers in this case\n/// @param \\_d deposit storage pointer\nfunction notifySignerSetupFailure(DepositUtils.Deposit storage \\_d) public {\n    require(\\_d.inAwaitingSignerSetup(), \"Not awaiting setup\");\n    require(\n        block.timestamp > \\_d.signingGroupRequestedAt + TBTCConstants.getSigningGroupFormationTimeout(),\n        \"Signing group formation timeout not yet elapsed\"\n    );\n    \\_d.setFailedSetup();\n    \\_d.logSetupFailed();\n\n    fundingTeardown(\\_d);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed with https://github.com/keep-network/tbtc/issues/495 by refunding the cost of creating a new keep. We recommend using the pull instead of a push payment pattern to avoid that the funder can block the call.",
        "Additionally, the client provided the following statement:"
    ],
    "Description": [
        "To create a new deposit, the funder has to pay for the creation of a keep. If establishing the keep does not succeed in time, fails or the signing group decides not to return a public key when retrieveSignerPubkey is called to transition from awaiting_signer_setup to awaiting_btc_funding_proof the signer setup fails. After a timeout of 3 hrs, anyone can force the deposit to transition from awaiting_signer_setup to failed_setup by calling notifySignerSetupFailure.",
        "The funder had to provide payment for the keep but the signing group failed to establish. Payment for the keep is not returned even though one could assume that the signing group tried to play unfairly. The signing group might intentionally try to cause this scenario to interfere with the system."
    ],
    "Examples": [
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L108-L127",
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L93-L106"
    ],
    "Recommendation": [
        "It should be ensured that a keep group always establishes or otherwise the funder is refunded the fee for the keep."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-ethereum-block-gas-limit-imposes-a-fundamental-limitation-on-spv-proofs-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "SPV fraud proofs were removed in keep-network/tbtc#521. Remember to continue exploring this limitation of the EVM with benchmarking and gas estimates in the tBTC UI."
    ],
    "Description": [
        "Several components of the tBTC system rely on SPV proofs to prove the existence of transactions on Bitcoin. Because an SPV proof must provide the entire Bitcoin transaction to the proving smart contract, the Ethereum block gas limit imposes an upper bound on the size of the transaction in question. Although an exact upper bound is subject to several variables, reasonable estimates show that even a moderately-sized Bitcoin transaction may not be able to be successfully validated on Ethereum.",
        "This limitation is significant for two reasons:"
    ],
    "Recommendation": [
        "It\u2019s important that prospective depositors are able to guarantee that their deposit transaction will be verified successfully. To that end, efforts should be made to provide a deposit UI that checks whether or not a given transaction will be verified successfully before it is submitted. Several variables can affect transaction verification:",
        "Given that not all of these can be calculated before the transaction is submitted to the Bitcoin blockchain, calculations should attempt to provide a margin of error for the process. Additionally, users should be well-educated about the process, including how to perform a deposit with relatively low risk.",
        "Understanding the relative limitations of the EVM will help this process significantly. Consider benchmarking the gas cost of verifying Bitcoin transactions of various sizes.",
        "Finally, because SPV fraud proofs can be gamed by colluding signers, they should be removed from the system entirely. Deposit owners should always be directed towards ECDSA fraud proofs, as these require relatively fewer assumptions and stronger guarantees."
    ]
}
----End JSON----

https://solodit.xyz/issues/bitcoin-spv-spv-proofs-do-not-support-transactions-with-larger-numbers-of-inputs-and-outputs-pending-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Checks that the vin passed up is properly formatted\n/// @dev Consider a vin with a valid vout in its scriptsig\n/// @param \\_vin Raw bytes length-prefixed input vector\n/// @return True if it represents a validly formatted vin\nfunction validateVin(bytes memory \\_vin) internal pure returns (bool) {\n    uint256 \\_offset = 1;\n    uint8 \\_nIns = uint8(\\_vin.slice(0, 1)[0]);\n\n    // Not valid if it says there are too many or no inputs\n    if (\\_nIns >= 0xfd || \\_nIns == 0) {\n        return false;\n    }\n\n",
        "/// @notice Determines the length of an output\n/// @dev 5 types: WPKH, WSH, PKH, SH, and OP\\_RETURN\n/// @param \\_output The output\n/// @return The length indicated by the prefix, error if invalid length\nfunction determineOutputLength(bytes memory \\_output) internal pure returns (uint256) {\n    uint8 \\_len = uint8(\\_output.slice(8, 1)[0]);\n    require(\\_len < 0xfd, \"Multi-byte VarInts not supported\");\n\n    return \\_len + 8 + 1; // 8 byte value, 1 byte for \\_len itself\n}\n\n",
        "function findAndParseFundingOutput(\n    DepositUtils.Deposit storage \\_d,\n    bytes memory \\_txOutputVector,\n    uint8 \\_fundingOutputIndex\n) public view returns (bytes8) {\n\n",
        "function validateAndParseFundingSPVProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public view returns (bytes8 \\_valueBytes, bytes memory \\_utxoOutpoint){\n\n",
        "function provideFraudBTCFundingProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public returns (bool) {\n\n",
        "function provideBTCFundingProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    uint8 \\_fundingOutputIndex,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    bytes memory \\_bitcoinHeaders\n) public returns (bool) {\n\n",
        "function provideSPVFraudProof(\n    DepositUtils.Deposit storage \\_d,\n    bytes4 \\_txVersion,\n    bytes memory \\_txInputVector,\n    bytes memory \\_txOutputVector,\n    bytes4 \\_txLocktime,\n    bytes memory \\_merkleProof,\n    uint256 \\_txIndexInBlock,\n    uint8 \\_targetInputIndex,\n    bytes memory \\_bitcoinHeaders\n) public {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The client provided the following statement:"
    ],
    "Description": [
        "There is no explicit restriction on the number of inputs and outputs a Bitcoin transaction can have - as long as the transaction fits into a block. The number of inputs and outputs in a transaction is denoted by a leading \u201cvarint\u201d - a variable length integer. In BTCUtils.validateVin and BTCUtils.validateVout, the value of this varint is restricted to under 0xFD, or 253:",
        "bitcoin-spv/solidity/contracts/BTCUtils.sol:L404-L415",
        "Transactions that include more than 252 inputs or outputs will not pass this validation, leading to some legitimate deposits being rejected by the tBTC system."
    ],
    "Examples": [
        "The 252-item limit exists in a few forms throughout the system, outside of the aforementioned BTCUtils.validateVin and BTCUtils.validateVout:",
        "bitcoin-spv/solidity/contracts/BTCUtils.sol:L294-L303",
        "tbtc/implementation/contracts/deposit/DepositUtils.sol:L150-L154",
        "tbtc/implementation/contracts/deposit/DepositUtils.sol:L181-L191",
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L213-L223",
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L263-L273",
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L150-L160"
    ],
    "Recommendation": [
        "Incorporate varint parsing in BTCUtils.validateVin and BTCUtils.validateVout. Ensure that other components of the system reflect the removal of the 252-item limit."
    ]
}
----End JSON----

https://solodit.xyz/issues/bitcoin-spv-multiple-integer-under-overflows-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @dev Target is a 256 bit number encoded as a 3-byte mantissa and 1 byte exponent\n/// @param \\_header The header\n/// @return The target threshold\nfunction extractTarget(bytes memory \\_header) internal pure returns (uint256) {\n    bytes memory \\_m = \\_header.slice(72, 3);\n    uint8 \\_e = uint8(\\_header[75]);\n    uint256 \\_mantissa = bytesToUint(reverseEndianness(\\_m));\n    uint \\_exponent = \\_e - 3;\n\n    return \\_mantissa \\* (256 \\*\\* \\_exponent);\n}\n\n\n",
        "/// @dev 5 types: WPKH, WSH, PKH, SH, and OP\\_RETURN\n/// @param \\_output The output\n/// @return The length indicated by the prefix, error if invalid length\nfunction determineOutputLength(bytes memory \\_output) internal pure returns (uint256) {\n    uint8 \\_len = uint8(\\_output.slice(8, 1)[0]);\n    require(\\_len < 0xfd, \"Multi-byte VarInts not supported\");\n\n    return \\_len + 8 + 1; // 8 byte value, 1 byte for \\_len itself\n}\n\n\n",
        "/// @dev Determines type by the length prefix and validates format\n/// @param \\_output The output\n/// @return The hash committed to by the pk\\_script, or null for errors\nfunction extractHash(bytes memory \\_output) internal pure returns (bytes memory) {\n    if (uint8(\\_output.slice(9, 1)[0]) == 0) {\n        uint256 \\_len = uint8(extractOutputScriptLen(\\_output)[0]) - 2;\n        // Check for maliciously formatted witness outputs\n        if (uint8(\\_output.slice(10, 1)[0]) != uint8(\\_len)) {\n            return hex\"\";\n        }\n        return \\_output.slice(11, \\_len);\n    } else {\n        bytes32 \\_tag = \\_output.keccak256Slice(8, 3);\n\n",
        "function slice(bytes memory \\_bytes, uint \\_start, uint \\_length) internal  pure returns (bytes memory res) {\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\n\n\n",
        "function toUint(bytes memory \\_bytes, uint \\_start) internal  pure returns (uint256) {\n    require(\\_bytes.length >= (\\_start + 32), \"Uint conversion out of bounds.\");\n\n",
        "function toAddress(bytes memory \\_bytes, uint \\_start) internal  pure returns (address) {\n    require(\\_bytes.length >= (\\_start + 20), \"Address conversion out of bounds.\");\n\n",
        "function slice(bytes memory \\_bytes, uint \\_start, uint \\_length) internal  pure returns (bytes memory res) {\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\n\n\n",
        "function keccak256Slice(bytes memory \\_bytes, uint \\_start, uint \\_length) pure internal returns (bytes32 result) {\n    require(\\_bytes.length >= (\\_start + \\_length), \"Slice out of bounds\");\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was partially addressed in https://github.com/summa-tx/bitcoin-spv/pull/118, https://github.com/summa-tx/bitcoin-spv/pull/119, and summa-tx/bitcoin-spv#122."
    ],
    "Description": [
        "The bitcoin-spv library allows for multiple integer under-/overflows while processing or converting potentially untrusted or user-provided data."
    ],
    "Examples": [
        "Note: _header[75] will throw consuming all gas if out of bounds while the majority of the library usually uses slice(start, 1) to handle this more gracefully.",
        "bitcoin-spv/solidity/contracts/BTCUtils.sol:L483-L494",
        "Note: might allow a specially crafted output to return an invalid determineOutputLength <= 9.",
        "Note: while type VarInt is implemented for inputs, it is not for the output length.",
        "bitcoin-spv/solidity/contracts/BTCUtils.sol:L295-L304",
        "bitcoin-spv/solidity/contracts/BTCUtils.sol:L366-L378",
        "Note: multiple occurrences. should check start+length > start && bytes.length >= start+length",
        "bitcoin-spv/solidity/contracts/BytesLib.sol:L246-L248",
        "bitcoin-spv/solidity/contracts/BytesLib.sol:L280-L281",
        "bitcoin-spv/solidity/contracts/BytesLib.sol:L269-L270",
        "bitcoin-spv/solidity/contracts/BytesLib.sol:L246-L248",
        "bitcoin-spv/solidity/contracts/BytesLib.sol:L410-L412"
    ],
    "Recommendation": [
        "We believe that a general-purpose parsing and verification library for bitcoin payments should be very strict when processing untrusted user input. With strict we mean, that it should rigorously validate provided input data and only proceed with the processing of the data if it is within a safe-to-use range for the method to return valid results. Relying on the caller to provide pre-validate data can be unsafe especially if the caller assumes that proper input validation is performed by the library.",
        "Given the risk profile for this library, we recommend a conservative approach that balances security instead of gas efficiency without relying on certain calls or instructions to throw on invalid input.",
        "For this issue specifically, we recommend proper input validation and explicit type expansion where necessary to prevent values from wrapping or processing data for arguments that are not within a safe-to-use range."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-unreachable-state-liquidation_in_progress-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Starts signer liquidation due to abort or undercollateralization\n/// @dev We first attempt to liquidate on chain, then by auction\n/// @param \\_d deposit storage pointer\nfunction startSignerAbortLiquidation(DepositUtils.Deposit storage \\_d) internal {\n    \\_d.logStartedLiquidation(false);\n    // Reclaim used state for gas savings\n    \\_d.redemptionTeardown();\n    \\_d.seizeSignerBonds();\n\n    \\_d.liquidationInitiated = block.timestamp;  // Store the timestamp for auction\n    \\_d.liquidationInitiator = msg.sender;\n    \\_d.setFraudLiquidationInProgress();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/tbtc/issues/497 with commits from keep-network/tbtc#517 changing all non-fraud transitions to end up in LIQUIDATION_IN_PROGRESS."
    ],
    "Description": [
        "According to the specification (overview, states, version 2020-02-06), a deposit can be in one of two liquidation_in_progress states.",
        "However, LIQUIDATION_IN_PROGRESS is unreachable and instead, FRAUD_LIQUIDATION_IN_PROGRESS is always called. This means that all non-fraud state transitions end up in the fraud liquidation path and will perform actions as if fraud was detected even though it might be caused by an undercollateralized notification or courtesy timeout."
    ],
    "Examples": [
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L96-L108"
    ],
    "Recommendation": [
        "Verify state transitions and either remove LIQUIDATION_IN_PROGRESS if it is redundant or fix the state transitions for non-fraud liquidations.",
        "Note that Deposit states can be simplified by removing redundant states by setting a flag (e.g. fraudLiquidation) in the deposit instead of adding a state to track the fraud liquidation path.",
        "According to the specification, we assume the following state transitions are desired:",
        "LIQUIDATION_IN_PROGRESS",
        "FRAUD_LIQUIDATION_IN_PROGRESS"
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-various-deposit-state-transitions-can-be-front-run-eg-fraud-proofs-timeouts-wont-fix-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @param \\_preimage The sha256 preimage of the digest\nfunction provideECDSAFraudProof(\n    DepositUtils.Deposit storage \\_d,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s,\n    bytes32 \\_signedDigest,\n    bytes memory \\_preimage\n) public {\n    require(\n        !\\_d.inFunding() && !\\_d.inFundingFailure(),\n        \"Use provideFundingECDSAFraudProof instead\"\n    );\n    require(\n        !\\_d.inSignerLiquidation(),\n        \"Signer liquidation already in progress\"\n    );\n    require(!\\_d.inEndState(), \"Contract has halted\");\n    require(submitSignatureFraud(\\_d, \\_v, \\_r, \\_s, \\_signedDigest, \\_preimage), \"Signature is not fraud\");\n    startSignerFraudLiquidation(\\_d);\n}\n\n",
        "function provideFundingECDSAFraudProof(\n    DepositUtils.Deposit storage \\_d,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s,\n    bytes32 \\_signedDigest,\n    bytes memory \\_preimage\n) public {\n    require(\n        \\_d.inAwaitingBTCFundingProof(),\n        \"Signer fraud during funding flow only available while awaiting funding\"\n    );\n\n    bool \\_isFraud = \\_d.submitSignatureFraud(\\_v, \\_r, \\_s, \\_signedDigest, \\_preimage);\n    require(\\_isFraud, \"Signature is not fraudulent\");\n    \\_d.logFraudDuringSetup();\n\n    // If the funding timeout has elapsed, punish the funder too!\n    if (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\n        address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\n        \\_d.setFailedSetup();\n    } else {\n        /\\* NB: This is reuse of the variable \\*/\n        \\_d.fundingProofTimerStart = block.timestamp;\n        \\_d.setFraudAwaitingBTCFundingProof();\n    }\n}\n\n",
        "    uint256 contractEthBalance = address(this).balance;\n    address payable initiator = \\_d.liquidationInitiator;\n\n    if (initiator == address(0)){\n        initiator = address(0xdead);\n    }\n    if (contractEthBalance > 1) {\n        if (\\_wasFraud) {\n            initiator.transfer(contractEthBalance);\n        } else {\n            // There will always be a liquidation initiator.\n            uint256 split = contractEthBalance.div(2);\n            \\_d.pushFundsToKeepGroup(split);\n            initiator.transfer(split);\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with the discussion at https://github.com/keep-network/tbtc/issues/498. It is accepted that a malicious entity may be able to front-run certain fraud proofs as long as fraud is being called out. It is also accepted that calls to certain timeouts may be front-run which could lead to a scenario where the client implementation is always front-run by a malicious actor.",
        "Additionally, the client provided the following statement:"
    ],
    "Description": [
        "An entity that can provide proof for fraudulent ECDSA signatures or SPV proofs in the liquidation flow is rewarded with part of the deposit contract ETH value.",
        "However, the methods under which proof is provided are not protected from front-running allowing anyone to observe transactions to provideECDSAFraudProof/ provideSPVFraudProof and submit the same proofs with providing a higher gas value.",
        "Please note that a similar issue exists for timeout states providing rewards for calling them out (i.e. they set the liquidationInitiator address)."
    ],
    "Examples": [
        "r,s,v,signedDigest appear to be the fraudulent signature. _preimage is the correct value.",
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L117-L137",
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L153-L179",
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L260-L276"
    ],
    "Recommendation": [
        "For fraud proofs, it should be required that the reporter uses a commit/reveal scheme to lock in a proof in one block, and reveal the details in another."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-anyone-can-emit-log-events-due-to-missing-access-control-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function approvedToLog(address \\_caller) public pure returns (bool) {\n    /\\* TODO: auth via system \\*/\n    \\_caller;\n    return true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/tbtc/issues/477, keep-network/tbtc#467 and keep-network/tbtc#537 by restricting log calls to known TBTCDepositToken. tbtcDepositToken was moved to DepositLog which is not ideal."
    ],
    "Description": [
        "Access control for DepositLog is not implemented. DepositLog is inherited by TBTCSystem and its functionality is usually consumed by Deposit contracts to emit log events on TBTCSystem. Due to the missing access control, anyone can emit log events on TBTCSystem. Users, client-software or other components that rely on these events might be tricked into performing actions that were not authorized by the system."
    ],
    "Examples": [
        "tbtc/implementation/contracts/DepositLog.sol:L95-L99"
    ],
    "Recommendation": [
        "Log events are typically initiated by the Deposit contract. Make sure only Deposit contracts deployed by an approved factory can emit logs on TBTCSystem."
    ]
}
----End JSON----

https://solodit.xyz/issues/dkgresultverificationverify-unsafe-packing-in-signed-data-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes32 resultHash = keccak256(abi.encodePacked(groupPubKey, misbehaved));\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with keep-network/keep-core#1525 by adding additional checks for groupPubKey size, the number of signatures provided and the length of the provided misbehaved group indices. No salt was added to separate the fields."
    ],
    "Description": [
        "DKGResultVerification.verify allows the sender to arbitrarily move bytes between groupPubKey and misbehaved:",
        "keep-core/contracts/solidity/contracts/libraries/operator/DKGResultVerification.sol:L80"
    ],
    "Recommendation": [
        "Validate the expected length of both and add a salt between the two."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-core-service-contract-callbacks-can-be-abused-to-call-into-other-contracts-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @dev Creates a request to generate a new relay entry, which will include\n \\* a random number (by signing the previous entry's random number).\n \\* @param callbackContract Callback contract address. Callback is called once a new relay entry has been generated.\n \\* @param callbackMethod Callback contract method signature. String representation of your method with a single\n \\* uint256 input parameter i.e. \"relayEntryCallback(uint256)\".\n \\* @param callbackGas Gas required for the callback.\n \\* The customer needs to ensure they provide a sufficient callback gas\n \\* to cover the gas fee of executing the callback. Any surplus is returned\n \\* to the customer. If the callback gas amount turns to be not enough to\n \\* execute the callback, callback execution is skipped.\n \\* @return An uint256 representing uniquely generated relay request ID. It is also returned as part of the event.\n \\*/\nfunction requestRelayEntry(\n    address callbackContract,\n    string memory callbackMethod,\n    uint256 callbackGas\n) public nonReentrant payable returns (uint256) {\n\n",
        "/\\*\\*\n \\* @dev Executes customer specified callback for the relay entry request.\n \\* @param requestId Request id tracked internally by this contract.\n \\* @param entry The generated random number.\n \\* @return Address to receive callback surplus.\n \\*/\nfunction executeCallback(uint256 requestId, uint256 entry) public returns (address payable surplusRecipient) {\n    require(\n        \\_operatorContracts.contains(msg.sender),\n        \"Only authorized operator contract can call execute callback.\"\n    );\n\n    require(\n        \\_callbacks[requestId].callbackContract != address(0),\n        \"Callback contract not found\"\n    );\n\n    \\_callbacks[requestId].callbackContract.call(abi.encodeWithSignature(\\_callbacks[requestId].callbackMethod, entry));\n\n    surplusRecipient = \\_callbacks[requestId].surplusRecipient;\n    delete \\_callbacks[requestId];\n}\n\n",
        "/\\*\\*\n \\* @dev Checks if sender is authorized.\n \\*/\nmodifier onlyServiceContract() {\n    require(\n        serviceContracts.contains(msg.sender),\n        \"Caller is not an authorized contract\"\n    );\n    \\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with keep-network/keep-core#1532 by hardcoding the callback method signature and the following statement:",
        "A subsequent change in keep-network/keep-ecdsa#339 updated keep-tecdsa to use the new, hardcoded callback function: __beaconCallback(uint256)."
    ],
    "Description": [
        "KeepRandomBeaconServiceImplV1 allows senders to specify an arbitrary method and contract that will receive a callback once the beacon generates a relay entry:",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L228-L245",
        "Once an operator contract receives the relay entry, it calls executeCallback:",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L314-L335",
        "Arbitrary callbacks can be used to force the service contract to execute many functions within the keep contract system. Currently, the KeepRandomBeaconOperator includes an onlyServiceContract modifier:",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconOperator.sol:L150-L159",
        "The functions it protects cannot be targeted by the aforementioned service contract callbacks due to Solidity\u2019s CALLDATASIZE checking. However, the presence of the modifier suggests that the service contract is expected to be a permissioned actor within some contracts."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/tbtc-disallow-signatures-with-high-s-values-in-depositredemptionprovideredemptionsignature-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function provideRedemptionSignature(\n    DepositUtils.Deposit storage \\_d,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s\n) public {\n    require(\\_d.inAwaitingWithdrawalSignature(), \"Not currently awaiting a signature\");\n\n    // If we're outside of the signature window, we COULD punish signers here\n    // Instead, we consider this a no-harm-no-foul situation.\n    // The signers have not stolen funds. Most likely they've just inconvenienced someone\n\n    // The signature must be valid on the pubkey\n    require(\n        \\_d.signerPubkey().checkSig(\n            \\_d.lastRequestedDigest,\n            \\_v, \\_r, \\_s\n        ),\n        \"Invalid signature\"\n    );\n\n",
        "// Validate `s` value for a malleability concern described in EIP-2.\n// Only signatures with `s` value in the lower half of the secp256k1\n// curve's order are considered valid.\nrequire(\n    uint256(\\_s) <=\n        0x7FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF5D576E7357A4501DDFE92F46681B20A0,\n    \"Malleable signature - s should be in the low half of secp256k1 curve's order\"\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue addressed in keep-network/tbtc#518"
    ],
    "Description": [
        "DepositRedemption.provideRedemptionSignature is used by signers to publish a signature that can be used to redeem a deposit on Bitcoin. The function accepts a signature s value in the upper half of the secp256k1 curve:",
        "tbtc/implementation/contracts/deposit/DepositRedemption.sol:L183-L202",
        "Although ecrecover accepts signatures with these s values, they are no longer used in Bitcoin. As such, the signature will appear to be valid to the Ethereum smart contract, but will likely not be accepted on Bitcoin. If no users watching malleate the signature, the redemption process will likely enter a fee increase loop, incurring a cost on the deposit owner."
    ],
    "Recommendation": [
        "Ensure the passed-in s value is restricted to the lower half of the secp256k1 curve, as done in BondedECDSAKeep:",
        "keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L333-L340"
    ]
}
----End JSON----

https://solodit.xyz/issues/consistent-use-of-safeerc20-for-external-tokens-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "token.safeTransferFrom(\\_from, address(this), \\_amount);\n\n",
        "token.transferFrom(\\_from, address(this), \\_value);\n\n",
        "token.safeTransfer(owner, amount);\n\n",
        "token.transfer(tattletale, tattletaleReward);\n\n",
        "token.transferFrom(\n    msg.sender,\n    tokenStaking.magpieOf(members[i]),\n    dividend\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/keep-core/issues/1407 and https://github.com/keep-network/keep-tecdsa/issues/272."
    ],
    "Description": [
        "Use SafeERC20 features to interact with potentially broken tokens used in the system. E.g. TokenGrant.receiveApproval() is using safeTransferFrom while other contracts aren\u2019t."
    ],
    "Examples": [
        "keep-core/contracts/solidity/contracts/TokenGrant.sol:L200-L200",
        "keep-core/contracts/solidity/contracts/TokenStaking.sol:L75-L75",
        "keep-core/contracts/solidity/contracts/TokenStaking.sol:L103-L103",
        "keep-core/contracts/solidity/contracts/TokenStaking.sol:L193-L193",
        "keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L459-L463"
    ],
    "Recommendation": [
        "Consistently use SafeERC20 to support potentially broken tokens external to the system."
    ]
}
----End JSON----

https://solodit.xyz/issues/initialize-implementations-for-proxy-contracts-and-protect-initialization-methods-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Initializes Keep Vendor contract implementation.\n/// @param registryAddress Keep registry contract linked to this contract.\nfunction initialize(\n    address registryAddress\n)\n    public\n{\n    require(!initialized(), \"Contract is already initialized.\");\n    \\_initialized[\"BondedECDSAKeepVendorImplV1\"] = true;\n    registry = Registry(registryAddress);\n}\n\n",
        "function initialize(\n    uint256 priceFeedEstimate,\n    uint256 fluctuationMargin,\n    uint256 dkgContributionMargin,\n    uint256 withdrawalDelay,\n    address registry\n)\n    public\n{\n    require(!initialized(), \"Contract is already initialized.\");\n    \\_initialized[\"KeepRandomBeaconServiceImplV1\"] = true;\n    \\_priceFeedEstimate = priceFeedEstimate;\n    \\_fluctuationMargin = fluctuationMargin;\n    \\_dkgContributionMargin = dkgContributionMargin;\n    \\_withdrawalDelay = withdrawalDelay;\n    \\_pendingWithdrawal = 0;\n    \\_previousEntry = \\_beaconSeed;\n    \\_registry = registry;\n    \\_baseCallbackGas = 18845;\n}\n\n",
        "contract DepositFactoryAuthority {\n\n    bool internal \\_initialized = false;\n    address internal \\_depositFactory;\n\n    /// @notice Set the address of the System contract on contract initialization\n    function initialize(address \\_factory) public {\n        require(! \\_initialized, \"Factory can only be initialized once.\");\n\n        \\_depositFactory = \\_factory;\n        \\_initialized = true;\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue is addressed with the following changesets that ensure that the logic contracts cannot be used by other parties by initializing them in the constructor: https://github.com/keep-network/keep-tecdsa/issues/297, https://github.com/keep-network/keep-core/issues/1424, and https://github.com/keep-network/tbtc/issues/500."
    ],
    "Description": [
        "It should be avoided that the implementation for proxy contracts can be initialized by third parties. This can be the case if the initialize function is unprotected. Since the implementation contract is not meant to be used directly without a proxy delegate-calling it is recommended to protect the initialization method of the implementation by initializing on deployment.",
        "Changing the proxies implementation (upgradeTo()) to a version that does not protect the initialization method may allow someone to front-run and initialize the contract if it is not done within the same transaction."
    ],
    "Examples": [
        "keep-tecdsa/solidity/contracts/BondedECDSAKeepVendorImplV1.sol:L22-L32",
        "keep-core/contracts/solidity/contracts/KeepRandomBeaconServiceImplV1.sol:L118-L137",
        "tbtc/implementation/contracts/system/DepositFactoryAuthority.sol:L3-L14"
    ],
    "Recommendation": [
        "Initialize unprotected implementation contracts in the implementation\u2019s constructor. Protect initialization methods from being called by unauthorized parties or ensure that deployment of the proxy and initialization is performed in the same transaction."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-tecdsa-if-caller-sends-more-than-is-contained-in-the-signer-subsidy-pool-the-value-is-burned-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// If subsidy pool is non-empty, distribute the value to signers but\n// never distribute more than the payment for opening a keep.\nuint256 signerSubsidy = subsidyPool < msg.value\n    ? subsidyPool\n    : msg.value;\nif (signerSubsidy > 0) {\n    subsidyPool -= signerSubsidy;\n    keep.distributeETHToMembers.value(signerSubsidy)();\n}\n\n",
        "(bool success, ) = address(randomBeacon).call.gas(400000).value(msg.value)(\n    abi.encodeWithSignature(\n        \"requestRelayEntry(address,string,uint256)\",\n        address(this),\n        \"setGroupSelectionSeed(uint256)\",\n        callbackGas\n    )\n);\nif (!success) {\n    subsidyPool += msg.value; // beacon is busy\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue addressed in keep-network/keep-ecdsa#306. The subsidyPool was removed in favor of a reseedPool, which is filled by the beacon by surplus sent to requestRelayEntry."
    ],
    "Description": [
        "The signer subsidy pool in BondedECDSAKeepFactory tracks funds sent to the contract. Each time a keep is opened, the subsidy pool is intended to be distributed to the members of the new keep:",
        "keep-tecdsa/solidity/contracts/BondedECDSAKeepFactory.sol:L312-L320",
        "The tracking around subsidy pool increases is inconsistent, and can lead to sent value being burned. In the case that subsidyPool contains less Ether than is sent in msg.value, msg.value is unused and remains in the contract. It may or may not be added to subsidyPool, depending on the return status of the random beacon:",
        "keep-tecdsa/solidity/contracts/BondedECDSAKeepFactory.sol:L347-L357"
    ],
    "Recommendation": [
        "Rather than tracking the subsidyPool individually, simply distribute this.balance to each new keep\u2019s members."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-core-tokengrant-and-tokenstaking-allow-staking-zero-amount-of-tokens-and-front-running-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Receives approval of token transfer and stakes the approved amount.\n \\* @dev Makes sure provided token contract is the same one linked to this contract.\n \\* @param \\_from The owner of the tokens who approved them to transfer.\n \\* @param \\_value Approved amount for the transfer and stake.\n \\* @param \\_token Token contract address.\n \\* @param \\_extraData Data for stake delegation. This byte array must have the\n \\* following values concatenated: Magpie address (20 bytes) where the rewards for participation\n \\* are sent, operator's (20 bytes) address, authorizer (20 bytes) address.\n \\*/\nfunction receiveApproval(address \\_from, uint256 \\_value, address \\_token, bytes memory \\_extraData) public {\n    require(ERC20Burnable(\\_token) == token, \"Token contract must be the same one linked to this contract.\");\n    require(\\_value <= token.balanceOf(\\_from), \"Sender must have enough tokens.\");\n    require(\\_extraData.length == 60, \"Stake delegation data must be provided.\");\n\n    address payable magpie = address(uint160(\\_extraData.toAddress(0)));\n    address operator = \\_extraData.toAddress(20);\n    require(operators[operator].owner == address(0), \"Operator address is already in use.\");\n    address authorizer = \\_extraData.toAddress(40);\n\n    // Transfer tokens to this contract.\n    token.transferFrom(\\_from, address(this), \\_value);\n\n    operators[operator] = Operator(\\_value, block.number, 0, \\_from, magpie, authorizer);\n    ownerOperators[\\_from].push(operator);\n\n    emit Staked(operator, \\_value);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/keep-core/issues/1425 and keep-network/keep-core#1461 by requiring a hardcoded minimum amount of tokens to be staked."
    ],
    "Description": [
        "Tokens are staked via the callback receiveApproval() which is normally invoked when calling approveAndCall(). The method is not restricting who can initiate the staking of tokens and relies on the fact that the token transfer to the TokenStaking contract is pre-approved by the owner, otherwise, the call would revert.",
        "However, receiveApproval() allows the staking of a zero amount of tokens. The only check performed on the number of tokens transferred is, that the token holders balance covers the amount to be transferred. This check is both relatively weak - having enough balance does not imply that tokens are approved for transfer - and does not cover the fact that someone can call the method with a zero amount of tokens.",
        "This way someone could create an arbitrary number of operators staking no tokens at all. This passes the token balance check, token.transferFrom() will succeed and an operator struct with a zero stake and arbitrary values for operator, from, magpie, authorizer can be set. Finally, an event is emitted for a zero stake.",
        "An attacker could front-run calls to receiveApproval to block staking of a legitimate operator by creating a zero stake entry for the operator before she is able to. This vector might allow someone to permanently inconvenience an operator\u2019s address. To recover from this situation one could be forced to cancelStake terminating the zero stake struct in order to call the contract with the correct stake again.",
        "The same issue exists for TokenGrant."
    ],
    "Examples": [
        "keep-core/contracts/solidity/contracts/TokenStaking.sol:L54-L81"
    ],
    "Recommendation": [
        "Require tokens to be staked and explicitly disallow the zero amount of tokens case. The balance check can be removed.",
        "Note: Consider checking the calls return value or calling the contract via SafeERC20 to support potentially broken tokens that do not revert in error cases (token.transferFrom)."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-inconsistency-between-increaseredemptionfee-and-provideredemptionproof-may-create-un-provable-redemptions-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require(block.timestamp >= \\_d.withdrawalRequestTime + TBTCConstants.getIncreaseFeeTimer(), \"Fee increase not yet permitted\");\n\n",
        "// Check that we're incrementing the fee by exactly the redeemer's initial fee\nuint256 \\_previousOutputValue = DepositUtils.bytes8LEToUint(\\_previousOutputValueBytes);\n\\_newOutputValue = DepositUtils.bytes8LEToUint(\\_newOutputValueBytes);\nrequire(\\_previousOutputValue.sub(\\_newOutputValue) == \\_d.initialRedemptionFee, \"Not an allowed fee step\");\n\n",
        "require((\\_d.utxoSize().sub(\\_fundingOutputValue)) <= \\_d.initialRedemptionFee \\* 5, \"Fee unexpectedly very high\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue addressed in keep-network/tbtc#522"
    ],
    "Description": [
        "DepositRedemption.increaseRedemptionFee is used by signers to approve a signable bitcoin transaction with a higher fee, in case the network is congested and miners are not approving the lower-fee transaction.",
        "Fee increases can be performed every 4 hours:",
        "tbtc/implementation/contracts/deposit/DepositRedemption.sol:L225",
        "In addition, each increase must increment the fee by exactly the initial proposed fee:",
        "tbtc/implementation/contracts/deposit/DepositRedemption.sol:L260-L263",
        "Outside of these two restrictions, there is no limit to the number of times increaseRedemptionFee can be called. Over a 20-hour period, for example, increaseRedemptionFee could be called 5 times, increasing the fee to initialRedemptionFee * 5. Over a 24-hour period, increaseRedemptionFee could be called 6 times, increasing the fee to initialRedemptionFee * 6.",
        "Eventually, it is expected that a transaction will be submitted and mined. At this point, anyone can call DepositRedemption.provideRedemptionProof, finalizing the redemption process and rewarding the signers. However, provideRedemptionProof will fail if the transaction fee is too high:",
        "tbtc/implementation/contracts/deposit/DepositRedemption.sol:L308",
        "In the case that increaseRedemptionFee is called 6 times and the signers provide a signature for this transaction, the transaction can be submitted and mined but provideRedemptionProof for this will always fail. Eventually, a redemption proof timeout will trigger the deposit into liquidation and the signers will be punished."
    ],
    "Recommendation": [
        "Because it is difficult to say with certainty that a 5x fee increase will always ensure a transaction\u2019s redeemability, the upper bound on fee bumps should be removed from provideRedemptionProof.",
        "This should be implemented in tandem with https://github.com/ConsenSys/thesis-tbtc-audit-2020-01/issues/38, so that signers cannot provide a proof that bypasses increaseRedemptionFee flow to spend the highest fee possible."
    ]
}
----End JSON----

https://solodit.xyz/issues/keep-tecdsa-keep-cannot-be-closed-if-a-members-bond-was-seized-or-fully-reassigned-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Closes keep when owner decides that they no longer need it.\n/// Releases bonds to the keep members. Keep can be closed only when\n/// there is no signing in progress or requested signing process has timed out.\n/// @dev The function can be called by the owner of the keep and only is the\n/// keep has not been closed already.\nfunction closeKeep() external onlyOwner onlyWhenActive {\n    require(\n        !isSigningInProgress() || hasSigningTimedOut(),\n        \"Requested signing has not timed out yet\"\n    );\n\n    isActive = false;\n\n    freeMembersBonds();\n\n    emit KeepClosed();\n}\n\n/// @notice Returns bonds to the keep members.\nfunction freeMembersBonds() internal {\n    for (uint256 i = 0; i < members.length; i++) {\n        keepBonding.freeBond(members[i], uint256(address(this)));\n    }\n}\n\n",
        "/// @notice Releases the bond and moves the bond value to the operator's\n/// unbounded value pool.\n/// @dev Function requires that caller is the holder of the bond which is\n/// being released.\n/// @param operator Address of the bonded operator.\n/// @param referenceID Reference ID of the bond.\nfunction freeBond(address operator, uint256 referenceID) public {\n    address holder = msg.sender;\n    bytes32 bondID = keccak256(\n        abi.encodePacked(operator, holder, referenceID)\n    );\n\n    require(lockedBonds[bondID] > 0, \"Bond not found\");\n\n    uint256 amount = lockedBonds[bondID];\n    lockedBonds[bondID] = 0;\n    unbondedValue[operator] = amount;\n}\n\n"
    ],
    "preamble": [],
    "Description": [
        "A keep cannot be closed if the bonds have been completely reassigned or seized before, leaving at least one member with zero lockedBonds. In this case closeKeep() will throw in freeMembersBonds() because the requirement in keepBonding.freeBond is not satisfied anymore (lockedBonds[bondID] > 0). As a result of this, none of the potentially remaining bonds (reassign) are freed, the keep stays active even though it should be closed."
    ],
    "Examples": [
        "keep-tecdsa/solidity/contracts/BondedECDSAKeep.sol:L373-L396",
        "keep-tecdsa/solidity/contracts/KeepBonding.sol:L173-L190"
    ],
    "Recommendation": [
        "Make sure the keep can be set to an end-state (closed/inactive) indicating its end-of-life even if the bond has been seized before. Avoid throwing an exception when freeing member bonds to avoid blocking the unlocking of bonds."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-providefundingecdsafraudproof-attempts-to-burn-non-existent-funds-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// If the funding timeout has elapsed, punish the funder too!\nif (block.timestamp > \\_d.fundingProofTimerStart + TBTCConstants.getFundingTimeout()) {\n    address(0).transfer(address(this).balance);  // Burn it all down (fire emoji)\n    \\_d.setFailedSetup();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed as https://github.com/keep-network/tbtc/issues/502 and fixed with keep-network/tbtc#523."
    ],
    "Description": [
        "The funding flow was recently changed from requiring the funder to provide a bond that stays in the Deposit contract to forwarding the funds to the keep, paying for the keep setup."
    ],
    "Examples": [
        "tbtc/implementation/contracts/deposit/DepositFunding.sol:L170-L173"
    ],
    "Recommendation": [
        "Remove the line that attempts to punish the funder by burning the Deposit contract balance which is zero due to recent changes in how the payment provided with createNewDepositis handled."
    ]
}
----End JSON----

https://solodit.xyz/issues/bitcoin-spv-bitcoin-output-script-length-is-not-checked-in-wpkhspendsighash-wont-fix-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function wpkhSpendSighash(\n    bytes memory \\_outpoint,  // 36 byte UTXO id\n    bytes20 \\_inputPKH,       // 20 byte hash160\n    bytes8 \\_inputValue,      // 8-byte LE\n    bytes8 \\_outputValue,     // 8-byte LE\n    bytes memory \\_outputScript    // lenght-prefixed output script\n) internal pure returns (bytes32) {\n    // Fixes elements to easily make a 1-in 1-out sighash digest\n    // Does not support timelocks\n    bytes memory \\_scriptCode = abi.encodePacked(\n        hex\"1976a914\",  // length, dup, hash160, pkh\\_length\n        \\_inputPKH,\n        hex\"88ac\");  // equal, checksig\n    bytes32 \\_hashOutputs = abi.encodePacked(\n        \\_outputValue,  // 8-byte LE\n        \\_outputScript).hash256();\n    bytes memory \\_sighashPreimage = abi.encodePacked(\n        hex\"01000000\",  // version\n        \\_outpoint.hash256(),  // hashPrevouts\n        hex\"8cb9012517c817fead650287d61bdd9c68803b6bf9c64133dcab3e65b5a50cb9\",  // hashSequence(00000000)\n        \\_outpoint,  // outpoint\n        \\_scriptCode,  // p2wpkh script code\n        \\_inputValue,  // value of the input in 8-byte LE\n        hex\"00000000\",  // input nSequence\n        \\_hashOutputs,  // hash of the single output\n        hex\"00000000\",  // nLockTime\n        hex\"01000000\"  // SIGHASH\\_ALL\n    );\n    return \\_sighashPreimage.hash256();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Summa opted not to make this change. See https://github.com/summa-tx/bitcoin-spv/issues/112 for details."
    ],
    "Description": [
        "CheckBitcoinSigs.wpkhSpendSighash calculates the sighash of a Bitcoin transaction. Among its parameters, it accepts bytes memory _outpoint, which is a 36-byte UTXO id consisting of a 32-byte transaction hash and a 4-byte output index.",
        "The function in question should not accept an _outpoint that is not 36-bytes, but no length check is made:",
        "bitcoin-spv/solidity/contracts/CheckBitcoinSigs.sol:L130-L159"
    ],
    "Recommendation": [
        "Check that _outpoint.length is 36."
    ]
}
----End JSON----

https://solodit.xyz/issues/tbtc-liquidationinitiator-can-block-purchasesignerbondsatauction-indefinitely-addressed-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @notice Closes an auction and purchases the signer bonds. Payout to buyer, funder, then signers if not fraud\n/// @dev For interface, reading auctionValue will give a past value. the current is better\n/// @param \\_d deposit storage pointer\nfunction purchaseSignerBondsAtAuction(DepositUtils.Deposit storage \\_d) public {\n    bool \\_wasFraud = \\_d.inFraudLiquidationInProgress();\n    require(\\_d.inSignerLiquidation(), \"No active auction\");\n\n    \\_d.setLiquidated();\n    \\_d.logLiquidated();\n\n    // send the TBTC to the TDT holder. If the TDT holder is the Vending Machine, burn it to maintain the peg.\n    address tdtHolder = \\_d.depositOwner();\n\n    TBTCToken \\_tbtcToken = TBTCToken(\\_d.TBTCToken);\n\n    uint256 lotSizeTbtc = \\_d.lotSizeTbtc();\n    require(\\_tbtcToken.balanceOf(msg.sender) >= lotSizeTbtc, \"Not enough TBTC to cover outstanding debt\");\n\n    if(tdtHolder == \\_d.VendingMachine){\n        \\_tbtcToken.burnFrom(msg.sender, lotSizeTbtc);  // burn minimal amount to cover size\n    }\n    else{\n        \\_tbtcToken.transferFrom(msg.sender, tdtHolder, lotSizeTbtc);\n    }\n\n    // Distribute funds to auction buyer\n    uint256 \\_valueToDistribute = \\_d.auctionValue();\n    msg.sender.transfer(\\_valueToDistribute);\n\n    // Send any TBTC left to the Fee Rebate Token holder\n    \\_d.distributeFeeRebate();\n\n    // For fraud, pay remainder to the liquidation initiator.\n    // For non-fraud, split 50-50 between initiator and signers. if the transfer amount is 1,\n    // division will yield a 0 value which causes a revert; instead, \n    // we simply ignore such a tiny amount and leave some wei dust in escrow\n    uint256 contractEthBalance = address(this).balance;\n    address payable initiator = \\_d.liquidationInitiator;\n\n    if (initiator == address(0)){\n        initiator = address(0xdead);\n    }\n    if (contractEthBalance > 1) {\n        if (\\_wasFraud) {\n            initiator.transfer(contractEthBalance);\n        } else {\n            // There will always be a liquidation initiator.\n            uint256 split = contractEthBalance.div(2);\n            \\_d.pushFundsToKeepGroup(split);\n            initiator.transfer(split);\n        }\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://github.com/keep-network/tbtc/issues/503 and commits from keep-network/tbtc#524 switching from transfer to send."
    ],
    "Description": [
        "When reporting a fraudulent proof the deposits liquidationInitiator is set to the entity reporting and proofing the fraud. The deposit that is in a *_liquidation_in_progress state can be bought by anyone at an auction calling purchaseSignerBondsAtAuction.",
        "Instead of receiving a share of the funds the liquidationInitiator can decide to intentionally reject the funds by raising an exception causing initiator.transfer(contractEthBalance) to throw, blocking the auction and forcing the liquidation to fail. The deposit will stay in one of the *_liquidation_in_progress states."
    ],
    "Examples": [
        "tbtc/implementation/contracts/deposit/DepositLiquidation.sol:L224-L276"
    ],
    "Recommendation": [
        "Use a pull vs push funds pattern or use address.send instead of address.transfer which might leave some funds locked in the contract if it fails."
    ]
}
----End JSON----

https://solodit.xyz/issues/bitcoin-spv-verifyhash256merkle-allows-existence-proofs-for-the-same-leaf-in-multiple-locations-in-the-tree-wont-fix-consensys-thesis-tbtc-and-keep-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint \\_idx = \\_index;\nbytes32 \\_root = \\_proof.slice(\\_proof.length - 32, 32).toBytes32();\nbytes32 \\_current = \\_proof.slice(0, 32).toBytes32();\n\nfor (uint i = 1; i < (\\_proof.length.div(32)) - 1; i++) {\n    if (\\_idx % 2 == 1) {\n        \\_current = \\_hash256MerkleStep(\\_proof.slice(i \\* 32, 32), abi.encodePacked(\\_current));\n    } else {\n        \\_current = \\_hash256MerkleStep(abi.encodePacked(\\_current), \\_proof.slice(i \\* 32, 32));\n    }\n    \\_idx = \\_idx >> 1;\n}\nreturn \\_current == \\_root;\n\n",
        "it('verifies a bitcoin merkle root', async () => {\r\n  for (let i = 0; i < verifyHash256Merkle.length; i += 1) {\r\n    const res = await instance.verifyHash256Merkle(\r\n      verifyHash256Merkle[i].input.proof,\r\n      verifyHash256Merkle[i].input.index\r\n    ); // 0-indexed\r\n    assert.strictEqual(res, verifyHash256Merkle[i].output);\r\n\r\n    // Now, attempt to use the same proof to verify the same leaf at\r\n    // a different index in the tree:\r\n    let pLen = verifyHash256Merkle[i].input.proof.length;\r\n    let height = ((pLen - 2) / 64) - 2;\r\n\r\n    // Only attempt to verify roots that are meant to be verified\r\n    if (verifyHash256Merkle[i].output && height >= 1) {\r\n      let altIdx = (2 ** height) + verifyHash256Merkle[i].input.index;\r\n\r\n      const resNext = await instance.verifyHash256Merkle(\r\n        verifyHash256Merkle[i].input.proof,\r\n        altIdx\r\n      );\r\n\r\n      assert.strictEqual(resNext, verifyHash256Merkle[i].output);\r\n\r\n      console.log('Verified transaction twice!');\r\n    }\r\n  }\r\n});\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Summa opted not to make this change, citing inconsistencies in Bitcoin\u2019s merkle implementation. See https://github.com/summa-tx/bitcoin-spv/issues/108 for details."
    ],
    "Description": [
        "BTCUtils.verifyHash256Merkle is used by ValidateSPV.prove to validate a transaction\u2019s existence in a Bitcoin block. The function accepts as input a _proof and an _index. The _proof consists of, in order: the transaction hash, a list of intermediate nodes, and the merkle root.",
        "The proof is performed iteratively, and uses the _index to determine whether the next proof element represents a \u201cleft branch\u201d or a \u201cright branch:\u201d",
        "bitcoin-spv/solidity/contracts/BTCUtils.sol:L574-L586",
        "If _idx is even, the computed hash is placed before the next proof element. If _idx is odd, the computed hash is placed after the next proof element. After each iteration, _idx is decremented by _idx /= 2.",
        "Because verifyHash256Merkle makes no requirements on the size of _proof relative to _index, it is possible to pass in invalid values for _index that prove a transaction\u2019s existence in multiple locations in the tree."
    ],
    "Examples": [
        "By modifying existing tests, we showed that any transaction can be proven to exist at least one alternate index. This alternate index is calculated as (2 ** treeHeight) + prevIndex - though other alternate indices are possible. The modified test is below:"
    ],
    "Recommendation": [
        "Use the length of _proof to determine the maximum allowed _index. _index should satisfy the following criterion: _index < 2 ** (_proof.length.div(32) - 2).",
        "Note that subtraction by 2 accounts for the transaction hash and merkle root, which are assumed to be encoded in the proof along with the intermediate nodes."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokens-with-no-decimals-can-be-locked-in-niftyswap-acknowledged-consensys-horizon-games-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This will be addressed by only listing tokens with at least 2 decimals. This should be well documented in the Niftyswap repository and code comments."
    ],
    "Description": [
        "Assume the Niftyswap exchange has:",
        "Consider the following scenario on the Niftyswap exchange:"
    ],
    "Recommendation": [
        "Through conversation with the developers, we agreed the right approach is for tokens to have at least 2 decimals to minimize the negative effects of rounding down."
    ]
}
----End JSON----

https://solodit.xyz/issues/incorrect-response-from-price-feed-if-called-during-an-onerc1155received-callback-acknowledged-consensys-horizon-games-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// // Refund Base Token if any\nif (totalRefundBaseTokens > 0) {\n  baseToken.safeTransferFrom(address(this), \\_recipient, baseTokenID, totalRefundBaseTokens, \"\");\n}\n\n// Send Tokens all tokens purchased\ntoken.safeBatchTransferFrom(address(this), \\_recipient, \\_tokenIds, \\_tokensBoughtAmounts, \"\");\n\n",
        "// Transfer total Base Tokens and all Tokens ids\nbaseToken.safeTransferFrom(address(this), \\_provider, baseTokenID, totalBaseTokens, \"\");\ntoken.safeBatchTransferFrom(address(this), \\_provider, \\_tokenIds, tokenAmounts, \"\");\n\n",
        "// Mint liquidity pool tokens\n\\_batchMint(\\_provider, \\_tokenIds, liquiditiesToMint, \"\");\n\n// Transfer all Base Tokens to this contract\nbaseToken.safeTransferFrom(\\_provider, address(this), baseTokenID, totalBaseTokens, abi.encode(DEPOSIT\\_SIG));\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The design will not be modified. Horizon Games should clearly document this risk for 3rd parties seeking to use Niftyswap as a price feed."
    ],
    "Description": [
        "The ERC 1155 standard requires that smart contracts must implement onERC1155Received and onERC1155BatchReceived to accept transfers.",
        "This means that on any token received, code run on the receiving smart contract.",
        "In NiftyswapExchange when adding / removing liquidity or buying tokens, the methods mentioned above are called when the tokens are sent. When this happens, the state of the contract is changed but not completed, the tokens are sent to the receiving smart contract but the state is not completely updated.",
        "This happens in these cases",
        "_baseToToken (when buying tokens)",
        "code/niftyswap/contracts/exchange/NiftyswapExchange.sol:L163-L169",
        "_removeLiquidity",
        "code/niftyswap/contracts/exchange/NiftyswapExchange.sol:L485-L487",
        "_addLiquidity",
        "code/niftyswap/contracts/exchange/NiftyswapExchange.sol:L403-L407",
        "Each of these examples send some tokens to the smart contract, which triggers calling some code on the receiving smart contract.",
        "While these methods have the nonReentrant modifier which protects them from re-netrancy, the result of the methods getPrice_baseToToken and getPrice_tokenToBase is affected. These 2 methods do not have the nonReentrant modifier.",
        "The price reported by the getPrice_baseToToken and getPrice_tokenToBase methods is incorrect (until after the end of the transaction) because they rely on the number of tokens owned by the NiftyswapExchange; which between the calls is not finalized. Hence the price reported will be incorrect.",
        "This gives the smart contract which receives the tokens, the opportunity to use other systems (if they exist) that rely on the result of getPrice_baseToToken and getPrice_tokenToBase to use the returned price to its advantage.",
        "It\u2019s important to note that this is a bug only if other systems rely on the price reported by this NiftyswapExchange. Also the current contract is not affected, nor its balances or internal ledger, only other systems relying on its reported price will be fooled."
    ],
    "Recommendation": [
        "Because there is no way to enforce how other systems work, a restriction can be added on NiftyswapExchange to protect other systems (if any) that rely on NiftyswapExchange for price discovery.",
        "Adding a nonReentrant modifier on the view methods getPrice_baseToToken and getPrice_tokenToBase will add a bit of protection for the ecosystem."
    ]
}
----End JSON----

https://solodit.xyz/issues/uint-overflow-may-lead-to-stealing-funds-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint holderBalance = SkaleToken(contractManager.getContract(\"SkaleToken\")).balanceOf(holder);\nuint lockedToDelegate = tokenState.getLockedCount(holder) - tokenState.getPurchasedAmount(holder);\nrequire(holderBalance >= amount + lockedToDelegate, \"Delegator hasn't enough tokens to delegate\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "safeMath was added in SKALE-215. At the time of the writing this comment, the review has not been comprehensive to all arithmetic calculations in the scope.",
        "Note that in some cases usage of safeMath due to reverts can result in unexpected halting of the system, that too should be reviewed again."
    ],
    "Description": [
        "It\u2019s possible to create a delegation with a very huge amount which may result in a lot of critically bad malicious usages:",
        "code/contracts/delegation/DelegationRequestManager.sol:L74-L76",
        "amount is passed by a user as a parameter, so if it\u2019s close to uint max value, amount + lockedToDelegate would overflow and this requirement would pass.",
        "Having delegation with an almost infinite amount of tokens can lead to many various attacks on the system up to stealing funds and breaking everything."
    ],
    "Recommendation": [
        "Using SafeMath everywhere should prevent this and other similar issues.\nThere should be more critical attacks caused by overflows/underflows, so SafeMath should be used everywhere in the codebase."
    ]
}
----End JSON----

https://solodit.xyz/issues/holders-can-burn-locked-funds-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Property of the company SKALE Labs inc.---------------------------------\n        uint locked = \\_getLockedOf(from);\n        if (locked > 0) {\n            require(\\_balances[from] >= locked + amount, \"Token should be unlocked for transferring\");\n        }\n//-------------------------------------------------------------------------\n        \\_balances[from] = \\_balances[from].sub(amount);\n        \\_balances[to] = \\_balances[to].add(amount);\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in SKALE-2144 by adding proper checks in _burn()."
    ],
    "Description": [
        "Skale token is a modified ERC-777 that allows locking some part of the balance. Locking is checked during every transfer:",
        "code/contracts/ERC777/LockableERC777.sol:L433-L441",
        "But it\u2019s not checked during burn function and it\u2019s possible to \u201cburn\u201d locked tokens. Tokens will be burned, but locked amount will remain the same. That will result in having more locked tokens than the balance which may have very unpredictable behaviour."
    ],
    "Recommendation": [
        "Allow burning only unlocked tokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/node-can-unlink-validator-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function linkNodeAddress(address validatorAddress, address nodeAddress) external allow(\"DelegationService\") {\n    uint validatorId = getValidatorId(validatorAddress);\n    require(\\_validatorAddressToId[nodeAddress] == 0, \"Validator cannot override node address\");\n    \\_validatorAddressToId[nodeAddress] = validatorId;\n}\n\nfunction unlinkNodeAddress(address validatorAddress, address nodeAddress) external allow(\"DelegationService\") {\n    uint validatorId = getValidatorId(validatorAddress);\n    require(\\_validatorAddressToId[nodeAddress] == validatorId, \"Validator hasn't permissions to unlink node\");\n    \\_validatorAddressToId[nodeAddress] = 0;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in SKALE-2145-unlink-node by adding a check in unlinkNodeAddress() that only validatorAddress has the permission to remove nodes from validators[validatorId] where msg.sender == validators[validatorId].validatorAddress"
    ],
    "Description": [
        "Validators can link a node address to them by calling linkNodeAddress function:",
        "code/contracts/delegation/ValidatorService.sol:L109-L119",
        "After that, the node has the same rights and is almost indistinguishable from the validator. So the node can even remove validator\u2019s address from _validatorAddressToId list and take over full control over validator. Additionally, the node can even remove itself by calling unlinkNodeAddress, leaving validator with no control at all forever.",
        "Also, even without nodes, a validator can initially call unlinkNodeAddress to remove itself."
    ],
    "Recommendation": [
        "Linked nodes (and validator) should not be able to unlink validator\u2019s address from the _validatorAddressToId mapping."
    ]
}
----End JSON----

https://solodit.xyz/issues/unlocking-funds-after-slashing-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\\_isPurchased[delegationId]) {\n    address holder = delegation.holder;\n    \\_totalDelegated[holder] += delegation.amount;\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\n        purchasedToUnlocked(holder);\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "The initial funds can be unlocked if 51+% of them are delegated. However if any portion of the funds are slashed, the rest of the funds will not be unlocked at the end of the delegation period.",
        "code/contracts/delegation/TokenState.sol:L258-L263"
    ],
    "Recommendation": [
        "Consider slashed tokens as delegated, or include them in the calculation for process to unlock in endingDelegatedToUnlocked"
    ]
}
----End JSON----

https://solodit.xyz/issues/bounties-and-fees-should-only-be-locked-for-the-first-3-months-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "skaleBalances.lockBounty(shares[i].holder, timeHelpers.addMonths(delegationStarted, 3));\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "Bounties are currently locked for the first 3 months after delegation:",
        "code/contracts/delegation/DelegationService.sol:L315",
        "Instead, they should be locked for the first 3 months after the token launch."
    ],
    "Recommendation": [
        "It\u2019s better just to forbid any withdrawals for the first 3 months, no need to track it separately for every delegation. This recommendation is mainly to simplify the process."
    ]
}
----End JSON----

https://solodit.xyz/issues/getlockedcount-is-iterating-over-all-history-of-delegations-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getLockedCount(address holder) external returns (uint amount) {\n    amount = 0;\n    DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\n    uint[] memory delegationIds = delegationController.getDelegationsByHolder(holder);\n    for (uint i = 0; i < delegationIds.length; ++i) {\n        uint id = delegationIds[i];\n        if (isLocked(getState(id))) {\n            amount += delegationController.getDelegation(id).amount;\n        }\n    }\n    return amount + getPurchasedAmount(holder) + this.getSlashedAmount(holder);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "getLockedCount is iterating over all delegations of a specific holder and may even change the state of these delegations by calling getState.",
        "code/contracts/delegation/TokenState.sol:L60-L71",
        "This problem is major because delegations number is growing over time and may even potentially grow more than the gas limit and lock all tokens forever. getLockedCount is called during every transfer which makes any token transfer much more expensive than it should be."
    ],
    "Recommendation": [
        "Remove iterations over a potentially unlimited amount of tokens. All the necessary data can be precalculated before and getLockedCount function can have O(1) complexity."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokens-are-unlocked-only-when-delegation-ends-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\\_isPurchased[delegationId]) {\n    address holder = delegation.holder;\n    \\_totalDelegated[holder] += delegation.amount;\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\n        purchasedToUnlocked(holder);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "After the first 3 months since at least 50% of tokens are delegated, all tokens should be unlocked. In practice, they are only unlocked if at least 50% of tokens, that were bought on the initial launch, are undelegated.",
        "code/contracts/delegation/TokenState.sol:L258-L264"
    ],
    "Recommendation": [
        "Implement lock mechanism according to the legal requirement."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokens-after-delegation-should-not-be-unlocked-automatically-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\\_isPurchased[delegationId]) {\n    address holder = delegation.holder;\n    \\_totalDelegated[holder] += delegation.amount;\n    if (\\_totalDelegated[holder] >= \\_purchased[holder]) {\n        purchasedToUnlocked(holder);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "When some amount of tokens are delegated to a validator when the delegation period ends, these tokens are unlocked. However these tokens should be added to _purchased as they were in that state before their delegation.",
        "code/contracts/delegation/TokenState.sol:L258-L264"
    ],
    "Recommendation": [
        "Tokens should only be unlocked if the main legal requirement (_totalDelegated[holder] >= _purchased[holder]) is satisfied, which in the above case this has not happened."
    ]
}
----End JSON----

https://solodit.xyz/issues/some-unlocked-tokens-can-become-locked-after-delegation-is-rejected-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\\_purchased[delegation.holder] > 0) {\n    \\_isPurchased[delegationId] = true;\n    if (\\_purchased[delegation.holder] > delegation.amount) {\n        \\_purchased[delegation.holder] -= delegation.amount;\n    } else {\n        \\_purchased[delegation.holder] = 0;\n    }\n} else {\n    \\_isPurchased[delegationId] = false;\n}\n\n",
        "function \\_cancel(uint delegationId, DelegationController.Delegation memory delegation) internal returns (State state) {\n    if (\\_isPurchased[delegationId]) {\n        state = purchasedProposedToPurchased(delegationId, delegation);\n    } else {\n        state = proposedToUnlocked(delegationId);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "When some amount of tokens are requested to be delegated to a validator, the validator can reject the request. The previous status of these tokens should be intact and not changed (locked or unlocked).",
        "Here the initial status of tokens gets stored and it\u2019s either completely locked or unlocked:",
        "code/contracts/delegation/TokenState.sol:L205-L214",
        "The problem is that if some amount of these tokens are locked at the time of the request and the rest tokens are unlocked, they will all be considered as locked after the delegation was rejected.",
        "code/contracts/delegation/TokenState.sol:L272-L278"
    ],
    "Recommendation": [
        "Don\u2019t change the status of the rejected tokens."
    ]
}
----End JSON----

https://solodit.xyz/issues/gas-limit-for-bounty-and-slashing-distribution-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint i = 0; i < shares.length; ++i) {\n    skaleToken.send(address(skaleBalances), shares[i].amount, abi.encode(shares[i].holder));\n\n    uint created = delegationController.getDelegation(shares[i].delegationId).created;\n    uint delegationStarted = timeHelpers.getNextMonthStartFromDate(created);\n    skaleBalances.lockBounty(shares[i].holder, timeHelpers.addMonths(delegationStarted, 3));\n}\n\n",
        "function slash(uint validatorId, uint amount) external allow(\"SkaleDKG\") {\n    ValidatorService validatorService = ValidatorService(contractManager.getContract(\"ValidatorService\"));\n    require(validatorService.validatorExists(validatorId), \"Validator does not exist\");\n\n    Distributor distributor = Distributor(contractManager.getContract(\"Distributor\"));\n    TokenState tokenState = TokenState(contractManager.getContract(\"TokenState\"));\n\n    Distributor.Share[] memory shares = distributor.distributePenalties(validatorId, amount);\n    for (uint i = 0; i < shares.length; ++i) {\n        tokenState.slash(shares[i].delegationId, shares[i].amount);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "After every bounty payment (should be once per month) to a validator, the bounty is distributed to all delegators. In order to do that, there is a for loop that iterates over all active delegators and sends their bounty to SkaleBalances contract:",
        "code/contracts/delegation/DelegationService.sol:L310-L316",
        "There are also few more loops over all the active delegators. This leads to a huge gas cost of distribution mechanism. A number of active delegators that can be processed before hitting the gas limit is limited and not big enough.",
        "The same issue is with slashing:",
        "code/contracts/delegation/DelegationService.sol:L95-L106"
    ],
    "Recommendation": [
        "The best solution would require major changes to the codebase, but would eventually make it simpler and safer. Instead of distributing and centrally calculating bounty for each delegator during one call it\u2019s better to just store all the necessary values, so delegator would be able to calculate the bounty on withdrawal. Amongst the necessary values, there should be history of total delegated amounts per validator during each bounty payment and history of all delegations with durations of their active state."
    ]
}
----End JSON----

https://solodit.xyz/issues/erc-777-callback-issue-partially-fixed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function tokensReceived(\n    address operator,\n    address from,\n    address to,\n    uint256 amount,\n    bytes calldata userData,\n    bytes calldata operatorData\n)\n    external\n    allow(\"SkaleToken\")\n{\n    address recipient = abi.decode(userData, (address));\n    stashBalance(recipient, amount);\n}\n\n",
        "function tokensReceived(\n    address operator,\n    address from,\n    address to,\n    uint256 amount,\n    bytes calldata userData,\n    bytes calldata operatorData\n)\n    external\n    allow(\"SkaleToken\")\n{\n    require(userData.length == 32, \"Data length is incorrect\");\n    uint validatorId = abi.decode(userData, (uint));\n    distributeBounty(amount, validatorId);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "reentrancyGaurd was added in SKALE-2153 to transfer() and transferFrom(). However other functions are still may contain reentrancy bug, such as burn(), send, etc.\nEven if all the functions in the token contract (even view functions like balanceOf) have re-entrancy protection, some projects might be still potentially vulnerable to re-entrancy attacks that use callbacks of ERC-777.",
        "UPDATE: in skalenetwork/skale-manager#128 nonReentrant modifier is now only added to callbacks: _callTokensToSend  and _callTokensReceived. So far it\u2019s impossible to make balance changes inside of the callbacks because any new balance change also triggers a callback. Therefore, it addresses the issue of re-entrancy by a malicious outside party (non-SKALE). Note since SKALE network retains upgrade capacity of smart contracts. Therefore, it\u2019s potentially possible to do re-entrancy from the _getAndUpdateLockedAmount function call, if the corresponding contract is upgraded in a specific way.",
        "This report raises this as an unfixed minor issue. This issue will be fixed if the upgrade capability for _getAndUpdateLockedAmount() is revoked by SKALE network governance in the future."
    ],
    "Description": [
        "ERC-777 token comes with callback functions to the receiver and the sender on every token transfer. This gives re-entrancy opportunities for everyone who\u2019s using this token. There is a chance that other systems might not handle ERC-777 correctly."
    ],
    "Examples": [
        "Uniswap reentrancy critical bug: https://medium.com/consensys-diligence/uniswap-audit-b90335ac007"
    ],
    "Recommendation": [
        "Use ERC-20 standard or remove callback function calls.",
        "Remove callback function usage from the system and replace them with a standard ERC-20 flow:",
        "code/contracts/delegation/SkaleBalances.sol:L55-L68",
        "code/contracts/delegation/DelegationService.sol:L275-L289"
    ]
}
----End JSON----

https://solodit.xyz/issues/rename-functions-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Fixed in SKALE-2154-naming by renaming the functions. The functions that are not solely getters and update the state of the smart contract are renamed to have getAndUpdate in their names. At the time of the writing this comment, the review has not been comprehensive to all functions in the scope."
    ],
    "Description": [
        "The naming of the functions should reflect their nature, such as functions starting with \u201cget\u201d should be only getters and do not change state. This will result in confusion developments and the implicit state changes might not be noticed.",
        "Other than getters, some other function or variable names are misleading."
    ],
    "Examples": [
        "The following functions are a few examples that are named as getters but they change the state.",
        "Some other naming that does not reflect the nature of the functionality:"
    ],
    "Recommendation": [
        "For functions that get and update variables use getAndUpdate naming. Similarly use variable names that reflect the nature of the values they store."
    ]
}
----End JSON----

https://solodit.xyz/issues/delegations-might-stuck-in-non-active-validator-pending-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "require((validatorNodes.length + 1) \\* msr <= delegationsTotal, \"Validator has to meet Minimum Staking Requirement\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Skale team acknowledged this issue and will address this in future versions."
    ],
    "Description": [
        "If a validator does not get enough funds to run a node (MSR - Minimum staking requirement), all token holders that delegated tokens to the validator cannot switch to a different validator, and might result in funds getting stuck with the nonfunctioning validator for up to 12 months."
    ],
    "Example": [
        "code/contracts/delegation/ValidatorService.sol:L166"
    ],
    "Recommendation": [
        "Allow token holders to withdraw delegation earlier if the validator didn\u2019t get enough funds for running nodes."
    ]
}
----End JSON----

https://solodit.xyz/issues/disabled-validators-still-have-delegated-funds-pending-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function enableValidator(uint validatorId) external checkValidatorExists(validatorId) onlyOwner {\n    trustedValidators[validatorId] = true;\n}\n\nfunction disableValidator(uint validatorId) external checkValidatorExists(validatorId) onlyOwner {\n    trustedValidators[validatorId] = false;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Skale team acknowledged this issue and will address this in future versions."
    ],
    "Description": [
        "The owner of ValidatorService contract can enable and disable validators. The issue is that when a validator is disabled, it still has its delegations, and delegated funds will be locked until the end of their delegation period (up to 12 months).",
        "code/contracts/delegation/ValidatorService.sol:L84-L90"
    ],
    "Recommendation": [
        "It might make sense to release all delegations and stop validator\u2019s nodes if it\u2019s not trusted anymore.\nHowever, the rationale behind disabling the validators might be different that what we think, in any case there should be a way to handle this scenario, where the validator is disabled but there are funds delegated to it."
    ]
}
----End JSON----

https://solodit.xyz/issues/fees-can-be-100-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Added a check to prevent fee rates equal or higher than 100% in SKALE-2157-fee-check."
    ],
    "Description": [
        "A validator can be created with feeRate > 1000 which would mean that the fee rate would be higher than 100%. Severity is not high because that validator will most likely be not whitelisted.",
        "Also, 100%+ fees would still somehow work and not revert because of the absence of SafeMath."
    ],
    "Recommendation": [
        "Add sanity check for the input values in registerValidator, and do not allow adding a validator with a fee rate higher than 100%."
    ]
}
----End JSON----

https://solodit.xyz/issues/getstate-changes-state-implicitly-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "getState function is checking and changing the state of a delegation struct. This function is called in many places in the codebase. Every delegation has a lot of different possible states and all of them are changed implicitly during other transactions, which makes it hard to track the logic in the code and make future changes in the code close to impossible without breaking some functionalities."
    ],
    "Recommendation": [
        "The general suggestion would be to minimize the number of implicit storage changes. Many states can be either changed explicitly or be calculated without additional storage changes.",
        "As an option, it\u2019s possible to get rid of state storage slot at all. startDate and endDate fields may set the current state:",
        "Also see issue 5.19 for other suggestions regarding getState usage in the code"
    ]
}
----End JSON----

https://solodit.xyz/issues/endingdelegations-list-is-redundant-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getPurchasedAmount(address holder) public returns (uint amount) {\n    // check if any delegation was ended\n    for (uint i = 0; i < \\_endingDelegations[holder].length; ++i) {\n        getState(\\_endingDelegations[holder][i]);\n    }\n    return \\_purchased[holder];\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "_endingDelegations is a list of delegations that is created for optimisation purposes.\nBut the only place it\u2019s used is in getPurchasedAmount function, so only a subset of all delegations is going to be updated.",
        "code/contracts/delegation/TokenState.sol:L159-L164",
        "But getPurchasedAmount function is mostly used after iterating over all delegations of the holder."
    ],
    "Recommendation": [
        "Remove _endingDelegations and switch to a mechanism that does not require looping through delegations list of potentially unlimited size."
    ]
}
----End JSON----

https://solodit.xyz/issues/some-functions-are-defined-but-not-implemented-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getAllDelegationRequests() external returns(uint[] memory) {\n    revert(\"Not implemented\");\n}\n\nfunction getDelegationRequestsForValidator(uint validatorId) external returns (uint[] memory) {\n    revert(\"Not implemented\");\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by removing the empty functions and implementing some others in SKALE-2160. At the time of the writing this comment, the review has not been comprehensive to all functions in the scope."
    ],
    "Description": [
        "There are many functions that are defined but not implemented. They have a revert with a message as not implemented.",
        "This results in complex code and reduces readability. Here is a some of these functions within the scope of this audit:"
    ],
    "Examples": [
        "code/contracts/delegation/DelegationService.sol:L152-L158"
    ],
    "Recommendation": [
        "If these functions are needed for this release, they must be implemented. If they are for future plan, it\u2019s better to remove the extra code in the smart contracts."
    ]
}
----End JSON----

https://solodit.xyz/issues/tokenstatesetstate-redundant-checks-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setState(uint delegationId, State newState) internal {\n    TimeHelpers timeHelpers = TimeHelpers(contractManager.getContract(\"TimeHelpers\"));\n    DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\n\n    require(newState != State.PROPOSED, \"Can't set state to proposed\");\n\n    if (newState == State.ACCEPTED) {\n        State currentState = getState(delegationId);\n        require(currentState == State.PROPOSED, \"Can't set state to accepted\");\n\n        \\_state[delegationId] = State.ACCEPTED;\n        \\_timelimit[delegationId] = timeHelpers.getNextMonthStart();\n    } else if (newState == State.DELEGATED) {\n        revert(\"Can't set state to delegated\");\n    } else if (newState == State.ENDING\\_DELEGATED) {\n        require(getState(delegationId) == State.DELEGATED, \"Can't set state to ending delegated\");\n        DelegationController.Delegation memory delegation = delegationController.getDelegation(delegationId);\n\n        \\_state[delegationId] = State.ENDING\\_DELEGATED;\n        \\_timelimit[delegationId] = timeHelpers.calculateDelegationEndTime(delegation.created, delegation.delegationPeriod, 3);\n        \\_endingDelegations[delegation.holder].push(delegationId);\n    } else {\n        revert(\"Unknown state\");\n    }\n}\n\n",
        "function setState(uint delegationId, State newState) internal {\n        TimeHelpers timeHelpers = TimeHelpers(contractManager.getContract(\"TimeHelpers\"));\n        DelegationController delegationController = DelegationController(contractManager.getContract(\"DelegationController\"));\n\n        require(newState != State.PROPOSED || newState != State.DELEGATED, \"Invalid state change\");\n        State currentState = getState(delegationId);\n\n        if (newState == State.ACCEPTED) {\n            require(currentState == State.PROPOSED, \"Can't set state to accepted\");\n\n            \\_state[delegationId] = State.ACCEPTED;\n            \\_timelimit[delegationId] = timeHelpers.getNextMonthStart();\n        } else if (newState == State.ENDING\\_DELEGATED) {\n            require(currentState == State.DELEGATED, \"Can't set state to ending delegated\");\n            DelegationController.Delegation memory delegation = delegationController.getDelegation(delegationId);\n\n            \\_state[delegationId] = State.ENDING\\_DELEGATED;\n            \\_timelimit[delegationId] = timeHelpers.calculateDelegationEndTime(delegation.created, delegation.delegationPeriod, 3);\n            \\_endingDelegations[delegation.holder].push(delegationId);\n        }\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue is fixed as a part of the major code changes in skalenetwork/skale-manager#92"
    ],
    "Description": [
        "tokenState.setState is used to change the state of the token from:",
        "The if/else statement in setState is too complicated and can be simplified, both to optimize gas usage and to increase readability."
    ],
    "Examples": [
        "code/contracts/delegation/TokenState.sol:L173-L197"
    ],
    "Recommendation": [
        "Some of the changes that do not change the functionality of the setState function:"
    ]
}
----End JSON----

https://solodit.xyz/issues/validator-should-be-able-to-remove-delegator-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Code added in SKALE-2162, If the delegation is not in DELEGATED state, both validator and the delegator can request undelegation."
    ],
    "Description": [
        "In order to delegate tokens to a validator, the validator should accept the delegation request, however it\u2019s not possible to remove the delegator for the next period."
    ],
    "Recommendation": [
        "For consistency, either allow a validator to undelegate delegators for the next period or remove acceptance mechanism if it\u2019s not needed."
    ]
}
----End JSON----

https://solodit.xyz/issues/users-can-burn-delegated-tokens-using-re-entrancy-attack-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "        uint locked = \\_getAndUpdateLockedAmount(from);\n        if (locked > 0) {\n            require(\\_balances[from] >= locked.add(amount), \"Token should be unlocked for burning\");\n        }\n//-------------------------------------------------------------------------\n\n        \\_callTokensToSend(\n            operator, from, address(0), amount, data, operatorData\n        );\n\n        // Update state variables\n        \\_totalSupply = \\_totalSupply.sub(amount);\n        \\_balances[from] = \\_balances[from].sub(amount);\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated in skalenetwork/skale-manager#128"
    ],
    "Description": [
        "When a user burns tokens, the following code is called:",
        "new_code/contracts/ERC777/LockableERC777.sol:L413-L426",
        "There is a callback function right after the check that there are enough unlocked tokens to burn. In this callback, the user can delegate all the tokens right before burning them without breaking the code flow."
    ],
    "Recommendation": [
        "_callTokensToSend  should be called before checking for the unlocked amount of tokens, which is better defined as Checks-Effects-Interactions Pattern."
    ]
}
----End JSON----

https://solodit.xyz/issues/rounding-errors-after-slashing-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function confiscate(uint validatorId, uint amount) external {\n    uint currentMonth = getCurrentMonth();\n    Fraction memory coefficient = reduce(\\_delegatedToValidator[validatorId], amount, currentMonth);\n    reduce(\\_effectiveDelegatedToValidator[validatorId], coefficient, currentMonth);\n    putToSlashingLog(\\_slashesOfValidator[validatorId], coefficient, currentMonth);\n    \\_slashes.push(SlashingEvent({reducingCoefficient: coefficient, validatorId: validatorId, month: currentMonth}));\n}\n\n",
        "if (oldValue > 0) {\n    reduce(\n        \\_delegatedByHolderToValidator[holder][validatorId],\n        \\_delegatedByHolder[holder],\n        \\_slashes[index].reducingCoefficient,\n        month);\n    reduce(\n        \\_effectiveDelegatedByHolderToValidator[holder][validatorId],\n        \\_slashes[index].reducingCoefficient,\n        month);\n    slashingSignals[index.sub(begin)].holder = holder;\n    slashingSignals[index.sub(begin)].penalty = oldValue.sub(getAndUpdateDelegatedByHolderToValidator(holder, validatorId, month));\n}\n\n",
        "uint amountAfterSlashing = calculateDelegationAmountAfterSlashing(delegationId);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated in skalenetwork/skale-manager#130. epsilon of 10^6 is added. Most subtractions are not throwing errors anymore and just assign value to zero."
    ],
    "Description": [
        "When slashing happens _delegatedToValidator and _effectiveDelegatedToValidator values are reduced.",
        "new_code/contracts/delegation/DelegationController.sol:L349-L355",
        "When holders process slashings, they reduce _delegatedByHolderToValidator, _delegatedByHolder, _effectiveDelegatedByHolderToValidator values.",
        "new_code/contracts/delegation/DelegationController.sol:L892-L904",
        "Also when holders are undelegating, they are calculating how many tokens from delegations[delegationId].amount were slashed.",
        "new_code/contracts/delegation/DelegationController.sol:L316",
        "All these values should be calculated one from another, but they all will have different rounding errors after slashing. For example, the assumptions that the total sum of all delegations from holder X to validator Y should still be equal to _delegatedByHolderToValidator[X][Y] is not true anymore. The problem is that these assumptions are still used. For example, when undelegating some delegation with delegated amount equals amount(after slashing), the holder will reduce _delegatedByHolderToValidator[X][Y], _delegatedByHolder[X] and _delegatedToValidator[Y] by amount. Since rounding errors of all these values are different that will lead to 2 possible scenarios:",
        "Developers already made sure that rounding errors are aligned in a correct way, and that the reduced value should always be larger than the subtracted, so there should not be underflow. This solution is very unstable because it\u2019s hard to verify it and keep in mind even during a small code change.\n2. If rounding errors make amount smaller then it should be, when other values should be zero (for example, when all the delegations are undelegated), these values will become some very small values. The problem here is that it would be impossible to compare values to zero."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/slashes-do-not-affect-bounty-distribution-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint oldValue = getAndUpdateDelegatedByHolderToValidator(holder, validatorId);\nif (oldValue > 0) {\n    uint month = \\_slashes[index].month;\n    reduce(\n        \\_delegatedByHolderToValidator[holder][validatorId],\n        \\_delegatedByHolder[holder],\n        \\_slashes[index].reducingCoefficient,\n        month);\n    slashingSignals[index.sub(begin)].holder = holder;\n    slashingSignals[index.sub(begin)].penalty = oldValue.sub(getAndUpdateDelegatedByHolderToValidator(holder, validatorId));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated in skalenetwork/skale-manager#118"
    ],
    "Description": [
        "When slashes are processed by a holder, only _delegatedByHolderToValidator and _delegatedByHolder values are reduced. But _effectiveDelegatedByHolderToValidator value remains the same. This value is used to distribute bounties amongst delegators. So slashing will not affect that distribution.",
        "contracts/delegation/DelegationController.sol:L863-L873"
    ],
    "Recommendation": [
        "Reduce _effectiveDelegatedByHolderToValidator and _effectiveDelegatedToValidator when slashes are processed."
    ]
}
----End JSON----

https://solodit.xyz/issues/iterations-over-slashes-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Partially mitigated in skalenetwork/skale-manager#163 . sendSlashingSignals function is now aggregating slashes per holder (if it\u2019s sorted by holder), which optimises gas cost."
    ],
    "Description": [
        "Every user should iterate over each slash (but only once) and process them in order to determine whether this slash impacted his delegations or not.",
        "However, the check is done during almost every action that the user does because it updates the current state of the user\u2019s balance. The downside of this method is that if there are a lot of slashes in the system, every user would be forced to iterate over all of them even if the user is only trading tokens and only calls transfer function.",
        "If the number of slashes is huge, checking them all in one function would impossible due to the block gas limit. It\u2019s possible to call the checking function separately and process slashes in batches. So this attack should not result in system halt and can be mitigated with manual intervention.",
        "Also, there are two separate pipelines for iterating over slashes. One pipeline is for iterating over months to determine amount of slashed tokens in separate delegations. This one can potentially hit gas limit in many-many years. The other one is for modifying aggregated delegation values."
    ],
    "Recommendation": [
        "Try to avoid all the unnecessary iterations over a potentially unlimited number of items. Additionally, it\u2019s possible to optimize some calculations:"
    ]
}
----End JSON----

https://solodit.xyz/issues/storage-operations-optimization-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint i = sequence.firstUnprocessedMonth; i <= month; ++i) {\n    sequence.value = sequence.value.add(sequence.addDiff[i]).sub(sequence.subtractDiff[i]);\n    delete sequence.addDiff[i];\n    delete sequence.subtractDiff[i];\n}\n\n",
        "function handleSlash(address holder, uint amount) external allow(\"DelegationController\") {\n    \\_locked[holder] = \\_locked[holder].add(amount);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated in skalenetwork/skale-manager#179"
    ],
    "Description": [
        "There are a lot of operations that write some value to the storage (uses SSTORE opcode) without actually changing it."
    ],
    "Examples": [
        "In getAndUpdateValue  function of DelegationController and TokenLaunchLocker:",
        "new_code/contracts/delegation/DelegationController.sol:L711-L715",
        "In handleSlash function of Punisher contract amount will be zero in most cases:",
        "new_code/contracts/delegation/Punisher.sol:L66-L68"
    ],
    "Recommendation": [
        "Check if the value is the same and don\u2019t write it to the storage in that case."
    ]
}
----End JSON----

https://solodit.xyz/issues/duplicate-function-implementation-addmonths-addressed-consensys-skale-token-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Fixed in skalenetwork/skale-manager#127"
    ],
    "Description": [
        "TimeHelpers.addMonths() implementation is redundant as it can directly use BokkyPooBahsDateTimeLibrary.addMonths() function."
    ],
    "Recommendation": [
        "Simply use return BokkyPooBahsDateTimeLibrary.addMonths() on the same function to prevent further code changes, it\u2019s still a good idea to call addMonth through TimeHelpers contract."
    ]
}
----End JSON----

https://solodit.xyz/issues/merklecheckmembership-allows-existence-proofs-for-the-same-leaf-in-multiple-locations-in-the-tree-addressed-consensys-omisego-morevp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 j = index;\n// Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`\nfor (uint256 i = 32; i <= proof.length; i += 32) {\n    // solhint-disable-next-line no-inline-assembly\n    assembly {\n        proofElement := mload(add(proof, i))\n    }\n    if (j % 2 == 0) {\n        computedHash = keccak256(abi.encodePacked(NODE\\_SALT, computedHash, proofElement));\n    } else {\n        computedHash = keccak256(abi.encodePacked(NODE\\_SALT, proofElement, computedHash));\n    }\n    j = j / 2;\n}\n\n",
        "it('should accidentally allow different indices to use the same proof', async () => {\r\n  const rootHash = this.merkleTree.root;\r\n  const proof = this.merkleTree.getInclusionProof(leaves[2]);\r\n\r\n  const result = await this.merkleContract.checkMembership(\r\n    leaves[2],\r\n    2,\r\n    rootHash,\r\n    proof,\r\n  );\r\n  expect(result).to.be.true;\r\n\r\n  const nextResult = await this.merkleContract.checkMembership(\r\n    leaves[2],\r\n    6,\r\n    rootHash,\r\n    proof,\r\n  );\r\n  expect(nextResult).to.be.true;\r\n\r\n  const nextNextResult = await this.merkleContract.checkMembership(\r\n    leaves[2],\r\n    10,\r\n    rootHash,\r\n    proof,\r\n  );\r\n  expect(nextNextResult).to.be.true;\r\n});\r\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in omisego/plasma-contracts#533 by including a check in PosLib that restricts transaction indices to between 0 and 2**16 - 1 inclusive. A subsequent change in omisego/plasma-contracts#547 ensured the passed-in index satisfied the recommended criterion."
    ],
    "Description": [
        "checkMembership is used by several contracts to prove that transactions exist in the child chain. The function uses a leaf, an index, and a proof to construct a hypothetical root hash. This constructed hash is compared to the passed in rootHash parameter. If the two are equivalent, the proof is considered valid.",
        "The proof is performed iteratively, and uses a pseudo-index (j) to determine whether the next proof element represents a \u201cleft branch\u201d or \u201cright branch\u201d:",
        "code/plasma_framework/contracts/src/utils/Merkle.sol:L28-L41",
        "If j is even, the computed hash is placed before the next proof element. If j is odd, the computed hash is placed after the next proof element. After each iteration, j is decremented by j = j / 2.",
        "Because checkMembership makes no requirements on the height of the tree or the size of the proof relative to the provided index, it is possible to pass in invalid values for index that prove a leaf\u2019s existence in multiple locations in the tree."
    ],
    "Examples": [
        "By modifying existing tests, we showed that for a tree with 3 leaves, leaf 2 can be proven to exist at indices 2, 6, and 10 using the same proof each time. The modified test can be found here: https://gist.github.com/wadeAlexC/01b60099282a026f8dc1ac85d83489fd#file-merkle-test-js-L40-L67"
    ],
    "Conclusion": [
        "Exit processing is meant to bypass exits processed more than once. This is implemented using an \u201coutput id\u201d system, where each exited output should correspond to a unique id that gets flagged in the ExitGameController contract as it\u2019s exited. Before an exit is processed, its output id is calculated and checked against ExitGameController. If the output has already been exited, the exit being processed is deleted and skipped. Crucially, output id is calculated differently for standard transactions and deposit transactions: deposit output ids factor in the transaction index.",
        "By using the behavior described in this issue in conjunction with methods discussed in issue 5.8 and https://github.com/ConsenSys/omisego-morevp-audit-2019-10/issues/20, we showed that deposit transactions can be exited twice using indices 0 and 2**16. Because of the distinct output id calculation, these exits have different output ids and can be processed twice, allowing users to exit double their deposited amount.",
        "A modified StandardExit.load.test.js shows that exits are successfully enqueued with a transaction index of 65536: https://gist.github.com/wadeAlexC/4ad459b7510e512bc9556e7c919e0965#file-standardexit-load-test-js-L55"
    ],
    "Recommendation": [
        "Use the length of the proof to determine the maximum allowed index. The passed-in index should satisfy the following criterion: index < 2**(proof.length/32). Additionally, ensure range checks on transaction position decoding are sufficiently restrictive (see https://github.com/ConsenSys/omisego-morevp-audit-2019-10/issues/20).",
        "Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/546"
    ]
}
----End JSON----

https://solodit.xyz/issues/improper-initialization-of-spending-condition-abstraction-allows-v2-transactions-to-exit-using-paymentexitgame-addressed-consensys-omisego-morevp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function verify(\n    bytes calldata inputTxBytes,\n    uint16 outputIndex,\n    uint256 inputTxPos,\n    bytes calldata spendingTxBytes,\n    uint16 inputIndex,\n    bytes calldata signature,\n    bytes calldata /\\*optionalArgs\\*/\n)\n    external\n    view\n    returns (bool)\n{\n    PaymentTransactionModel.Transaction memory inputTx = PaymentTransactionModel.decode(inputTxBytes);\n    require(inputTx.txType == supportInputTxType, \"Input tx is an unsupported payment tx type\");\n\n    PaymentTransactionModel.Transaction memory spendingTx = PaymentTransactionModel.decode(spendingTxBytes);\n    require(spendingTx.txType == supportSpendingTxType, \"The spending tx is an unsupported payment tx type\");\n\n    UtxoPosLib.UtxoPos memory utxoPos = UtxoPosLib.build(TxPosLib.TxPos(inputTxPos), outputIndex);\n    require(\n        spendingTx.inputs[inputIndex] == bytes32(utxoPos.value),\n        \"Spending tx points to the incorrect output UTXO position\"\n    );\n\n    address payable owner = inputTx.outputs[outputIndex].owner();\n    require(owner == ECDSA.recover(eip712.hashTx(spendingTx), signature), \"Tx in not signed correctly\");\n\n    return true;\n}\n\n",
        "/\\*\\*\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\n \\* @dev Emits ExitGameRegistered event to notify clients\n \\* @param \\_txType The tx type where the exit game wants to register\n \\* @param \\_contract Address of the exit game contract\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\n \\*/\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\n    require(\\_txType != 0, \"Should not register with tx type 0\");\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\n\n    \\_exitGames[\\_txType] = \\_contract;\n    \\_exitGameToTxType[\\_contract] = \\_txType;\n    \\_protocols[\\_txType] = \\_protocol;\n    \\_exitGameQuarantine.quarantine(\\_contract);\n\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\n}\n\n",
        "// handle spending condition\nawait deployer.deploy(\n    PaymentOutputToPaymentTxCondition,\n    plasmaFramework.address,\n    PAYMENT\\_OUTPUT\\_TYPE,\n    PAYMENT\\_TX\\_TYPE,\n);\nconst paymentToPaymentCondition = await PaymentOutputToPaymentTxCondition.deployed();\n\nawait deployer.deploy(\n    PaymentOutputToPaymentTxCondition,\n    plasmaFramework.address,\n    PAYMENT\\_OUTPUT\\_TYPE,\n    PAYMENT\\_V2\\_TX\\_TYPE,\n);\nconst paymentToPaymentV2Condition = await PaymentOutputToPaymentTxCondition.deployed();\n\n",
        "console.log(`Registering paymentToPaymentCondition (${paymentToPaymentCondition.address}) to spendingConditionRegistry`);\nawait spendingConditionRegistry.registerSpendingCondition(\n    PAYMENT\\_OUTPUT\\_TYPE, PAYMENT\\_TX\\_TYPE, paymentToPaymentCondition.address,\n);\n\nconsole.log(`Registering paymentToPaymentV2Condition (${paymentToPaymentV2Condition.address}) to spendingConditionRegistry`);\nawait spendingConditionRegistry.registerSpendingCondition(\n    PAYMENT\\_OUTPUT\\_TYPE, PAYMENT\\_V2\\_TX\\_TYPE, paymentToPaymentV2Condition.address,\n);\nawait spendingConditionRegistry.renounceOwnership();\n\n",
        "// register the exit game to framework\nawait plasmaFramework.registerExitGame(\n    PAYMENT\\_TX\\_TYPE,\n    paymentExitGame.address,\n    config.frameworks.protocols.moreVp,\n    { from: maintainerAddress },\n);\n\n",
        "/\\*\\*\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\n \\* @dev Emits ExitGameRegistered event to notify clients\n \\* @param \\_txType The tx type where the exit game wants to register\n \\* @param \\_contract Address of the exit game contract\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\n \\*/\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\n    require(\\_txType != 0, \"Should not register with tx type 0\");\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\n\n    \\_exitGames[\\_txType] = \\_contract;\n    \\_exitGameToTxType[\\_contract] = \\_txType;\n    \\_protocols[\\_txType] = \\_protocol;\n    \\_exitGameQuarantine.quarantine(\\_contract);\n\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in omisego/plasma-contracts#478 by requiring that PaymentStartStandardExit and PaymentStartInFlightExit check the exiting transaction\u2019s transaction type."
    ],
    "Description": [
        "PaymentOutputToPaymentTxCondition is an abstraction around the transaction signature check needed for many components of the exit games. Its only function, verify, returns true if one transaction (inputTxBytes) is spent by another transaction (spendingTxBytes):",
        "code/plasma_framework/contracts/src/exits/payment/spendingConditions/PaymentOutputToPaymentTxCondition.sol:L40-L69",
        "The verification process is relatively straightforward. The contract performs some basic input validation, checking that the input transaction\u2019s txType matches supportInputTxType, and that the spending transaction\u2019s txType matches supportSpendingTxType. These values are set during construction.",
        "Next, verify checks that the spending transaction contains an input that matches the position of one of the input transaction\u2019s outputs.",
        "Finally, verify performs an EIP-712 hash on the spending transaction, and ensures it is signed by the owner of the output in question.",
        "The abstraction used requires several files to be visited to fully understand the function of each line of code: ISpendingCondition, PaymentEIP712Lib, UtxoPosLib, TxPosLib, PaymentTransactionModel, PaymentOutputModel, RLPReader, ECDSA, and SpendingConditionRegistry. Additionally, the abstraction obfuscates the underlying spending condition verification primitive where used.",
        "Finally, understanding the abstraction requires an understanding of how SpendingConditionRegistry is initialized, as well as the nature of its relationship with PlasmaFramework and ExitGameRegistry. The aforementioned txType values, supportInputTxType and supportSpendingTxType, are set during construction. Their use in ExitGameRegistry seems to suggest they are intended to represent different versions of transaction types, and that separate exit game contracts are meant to handle different transaction types:",
        "code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L58-L78",
        "The migration script seems to corroborate this interpretation:",
        "code/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L109-L124",
        "The migration script shown above deploys two different versions of PaymentOutputToPaymentTxCondition. The first sets supportInputTxType and supportSpendingTxType to PAYMENT_OUTPUT_TYPE and PAYMENT_TX_TYPE, respectively. The second sets those same variables to PAYMENT_OUTPUT_TYPE and PAYMENT_V2_TX_TYPE, respectively.",
        "The migration script then registers both of these contracts in SpendingConditionRegistry, and then calls renounceOwnership, freezing the spending conditions registered permanently:",
        "code/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L126-L135",
        "Finally, the migration script registers a single exit game contract in PlasmaFramework:",
        "code/plasma_framework/migrations/5_deploy_and_register_payment_exit_game.js:L137-L143",
        "Note that the associated _txType is permanently associated with the deployed exit game contract:",
        "code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L58-L78",
        "Crucially, this association is never used. It is implied heavily that transactions with some txType must use a certain registered exit game contract. In fact, this is not true. When using PaymentExitGame, its routers, and their associated controllers, the txType is invariably inferred from the encoded transaction, not from the mappings in ExitGameRegistry. If initialized as-is, both PAYMENT_TX_TYPE and PAYMENT_V2_TX_TYPE transactions may be exited using PaymentExitGame, provided they exist in the plasma chain."
    ],
    "Recommendation": [
        "Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/472"
    ]
}
----End JSON----

https://solodit.xyz/issues/rlpreader-leading-zeroes-allow-multiple-valid-encodings-and-exit-output-ids-for-the-same-transaction-addressed-consensys-omisego-morevp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "result := mload(memPtr)\n\n",
        "return keccak256(abi.encodePacked(\\_txBytes, \\_outputIndex, \\_utxoPosValue));\n\n",
        "return keccak256(abi.encodePacked(\\_txBytes, \\_outputIndex));\n\n",
        "bytes32 hashData = keccak256(abi.encodePacked(\\_txBytes, \\_utxoPos.value));\n\n",
        "return uint160((uint256(keccak256(\\_txBytes)) >> 105).setBit(151));\n\n",
        "bytes32 leafData = keccak256(data.txBytes);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in omisego/plasma-contracts#507 with the addition of checks to ensure primitive decoding functions in RLPReader (toAddress, toUint, toBytes32) do not decode lists. A subsequent change in omisego/plasma-contracts#476 rejects leading zeroes in toUint, and improves on size requirements for decoded payloads. Note that the scalar \u201c0\u201d should be encoded as 0x80."
    ],
    "Description": [
        "The current implementation of RLP decoding can take 2 different txBytes and decode them to the same structure. Specifically, the RLPReader.toUint method can decode 2 different types of bytes to the same number. For example:",
        "As explanation for this encoding:",
        "0x821234 is broken down into 2 parts:",
        "The same for 0x83001234:",
        "The current implementation casts the encoded bytes into a uint256, so these different encodings are interpreted by the contracts as the same number:",
        "uint(0x1234) = uint(0x001234)",
        "code/plasma_framework/contracts/src/utils/RLPReader.sol:L112",
        "Having different valid encodings for the same data is a problem because the encodings are used to create hashes that are used as unique ids. This means that multiple ids can be created for the same data. The data should only have one possible id.",
        "The encoding is used to create ids in these parts of the code:",
        "code/plasma_framework/contracts/src/exits/utils/OutputId.sol:L18",
        "code/plasma_framework/contracts/src/exits/utils/OutputId.sol:L32",
        "code/plasma_framework/contracts/src/exits/utils/ExitId.sol:L41",
        "code/plasma_framework/contracts/src/exits/utils/ExitId.sol:L54",
        "code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L55",
        "Other methods that are affected because they rely on the return values of these methods:"
    ],
    "Recommendation": [
        "Enforce strict-length decoding for txBytes, and specify that uint is decoded from a 32-byte short string.",
        "Enforcing a 32-byte length for uint means that 0x1234 should always be encoded as:",
        "0xa00000000000000000000000000000000000000000000000000000000000001234",
        "Unfortunately, using leading zeroes is against the RLP spec:",
        "https://github.com/ethereum/wiki/wiki/RLP",
        "This means that libraries interacting with OMG contracts which are going to correctly and fully implement the spec will generate \u201cincorrect\u201d encodings for uints; encodings that are not going to be recognized by the OMG contracts.",
        "Fully correct spec encoding: 0x821234. Proposed encoding in this solution: 0xa00000000000000000000000000000000000000000000000000000000000001234.",
        "Similarly enforce restrictions where they can be added; this is possible because of the strict structure format that needs to be encoded.",
        "Some other potential solutions are included below. Note that these solutions are not recommended for reasons included below:",
        "This can be implemented in the methods that call keccak256 on txBytes and should decode and re-encode the passed txBytes in order to normalize the passed encoding.",
        "This method is not recommended because it needs a Solidity encoder to be implemented and a lot of gas will be used to decode and re-encode the initial txBytes.",
        "This is another solution that adds a lot of code and is prone to errors.",
        "The solution would be to enforce all of the restrictions when decoding and not accept any encoding that doesn\u2019t fully follow the spec. This for example means that is should not accept uints with leading zeroes.",
        "This is a problem because it needs a lot of code that is not easy to write in Solidity (or EVM)."
    ]
}
----End JSON----

https://solodit.xyz/issues/recommendation-remove-txfinalizationmodel-and-txfinalizationverifier-implement-stronger-checks-in-merkle-consensys-omisego-morevp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n\\* @notice Checks whether a transaction is \"standard finalized\"\n\\* @dev MVP: requires that both inclusion proof and confirm signature is checked\n\\* @dev MoreVp: checks inclusion proof only\n\\*/\nfunction isStandardFinalized(Model.Data memory data) public view returns (bool) {\n    if (data.protocol == Protocol.MORE\\_VP()) {\n        return checkInclusionProof(data);\n    } else if (data.protocol == Protocol.MVP()) {\n        revert(\"MVP is not yet supported\");\n    } else {\n        revert(\"Invalid protocol value\");\n    }\n}\n\n",
        "/\\*\\*\n\\* @notice Checks whether a transaction is \"protocol finalized\"\n\\* @dev MVP: must be standard finalized\n\\* @dev MoreVp: allows in-flight tx, so only checks for the existence of the transaction\n\\*/\nfunction isProtocolFinalized(Model.Data memory data) public view returns (bool) {\n    if (data.protocol == Protocol.MORE\\_VP()) {\n        return data.txBytes.length > 0;\n    } else if (data.protocol == Protocol.MVP()) {\n        revert(\"MVP is not yet supported\");\n    } else {\n        revert(\"Invalid protocol value\");\n    }\n}\n\n",
        "function checkInclusionProof(Model.Data memory data) private view returns (bool) {\n    if (data.inclusionProof.length == 0) {\n        return false;\n    }\n\n    (bytes32 root,) = data.framework.blocks(data.txPos.blockNum());\n    bytes32 leafData = keccak256(data.txBytes);\n    return Merkle.checkMembership(\n        leafData, data.txPos.txIndex(), root, data.inclusionProof\n    );\n}\n\n",
        "function verifyAndDeterminePositionOfTransactionIncludedInBlock(\n    bytes memory txbytes,\n    UtxoPosLib.UtxoPos memory utxoPos,\n    bytes32 root,\n    bytes memory inclusionProof\n)\n    private\n    pure\n    returns(uint256)\n{\n    bytes32 leaf = keccak256(txbytes);\n    require(\n        Merkle.checkMembership(leaf, utxoPos.txIndex(), root, inclusionProof),\n        \"Transaction is not included in block of Plasma chain\"\n    );\n\n    return utxoPos.value;\n}\n\n",
        "require(controller.txFinalizationVerifier.isStandardFinalized(finalizationData), \"In-flight transaction not finalized\");\n\n",
        "require(self.txFinalizationVerifier.isStandardFinalized(finalizationData), \"Failed to verify the position of competing tx\");\n\n",
        "require(exitData.controller.txFinalizationVerifier.isStandardFinalized(finalizationData),\n        \"Input transaction is not standard finalized\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was partially addressed in https://github.com/omisego/plasma-contracts/pull/503, with the removal of several unneeded branches of logic in TxFinalizationModel (now renamed to MoreVpFinalization). A subsequent change in omisego/plasma-contracts#533 added a non-zero proof length check in Merkle. Note that PaymentChallengeIFENotCanonical.respond still calls Merkle.checkMembership directly, and lacks the typical transaction type protocol check made in MoreVpFinalization.isStandardFinalized."
    ],
    "Description": [
        "TxFinalizationVerifier is an abstraction around the block inclusion check needed for many of the features of plasma exit games. It uses a struct defined in TxFinalizationModel as inputs to its two functions: isStandardFinalized and isProtocolFinalized.",
        "isStandardFinalized returns the result of an inclusion proof. Although there are several branches, only the first is used:",
        "code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L19-L32",
        "isProtocolFinalized is unused:",
        "code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L34-L47",
        "The abstraction used introduces branching logic and requires several files to be visited to fully understand the function of each line of code: ITxFinalizationVerifier, TxFinalizationModel, TxPosLib, Protocol, BlockController, and Merkle. Additionally, the abstraction obfuscates the underlying inclusion proof primitive when used in the exit game contracts. isStandardFinalized is not clearly an inclusion proof, and isProtocolFinalized simply adds confusion.",
        "Finally, the abstraction may have ramifications on the safety of Merkle.sol. As it stands now, Merkle.checkMembership should never be called directly by the exit game controllers, as it lacks an important check made in TxFinalizationVerifier.checkInclusionProof:",
        "code/plasma_framework/contracts/src/exits/utils/TxFinalizationVerifier.sol:L49-L59",
        "By introducing the abstraction of TxFinalizationVerifier, the input validation performed by Merkle is split across multiple files, and the reasonable-seeming decision of calling Merkle.checkMembership directly becomes unsafe. In fact, this occurs in one location in the contracts:",
        "code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L187-L204"
    ],
    "Recommendation": [
        "code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFEOutputSpent.sol:L91",
        "code/plasma_framework/contracts/src/exits/payment/controllers/PaymentChallengeIFENotCanonical.sol:L244",
        "code/plasma_framework/contracts/src/exits/payment/controllers/PaymentStartInFlightExit.sol:L307-L308",
        "Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/471"
    ]
}
----End JSON----

https://solodit.xyz/issues/merkle-the-implementation-does-not-enforce-inclusion-of-leaf-nodes-addressed-consensys-omisego-morevp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Checks that a leaf hash is contained in a root hash\n \\* @param leaf Leaf hash to verify\n \\* @param index Position of the leaf hash in the Merkle tree\n \\* @param rootHash Root of the Merkle tree\n \\* @param proof A Merkle proof demonstrating membership of the leaf hash\n \\* @return True, if the leaf hash is in the Merkle tree; otherwise, False\n\\*/\nfunction checkMembership(bytes32 leaf, uint256 index, bytes32 rootHash, bytes memory proof)\n    internal\n    pure\n    returns (bool)\n{\n    require(proof.length % 32 == 0, \"Length of Merkle proof must be a multiple of 32\");\n\n    bytes32 proofElement;\n    bytes32 computedHash = leaf;\n    uint256 j = index;\n    // Note: We're skipping the first 32 bytes of `proof`, which holds the size of the dynamically sized `bytes`\n    for (uint256 i = 32; i <= proof.length; i += 32) {\n        // solhint-disable-next-line no-inline-assembly\n        assembly {\n            proofElement := mload(add(proof, i))\n        }\n        if (j % 2 == 0) {\n            computedHash = keccak256(abi.encodePacked(computedHash, proofElement));\n        } else {\n            computedHash = keccak256(abi.encodePacked(proofElement, computedHash));\n        }\n        j = j / 2;\n    }\n\n    return computedHash == rootHash;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in omisego/plasma-contracts#452 with the addition of leaf and node salts to the checkMembership function."
    ],
    "Description": [
        "A observation with the current Merkle tree implementation is that it may be possible to validate nodes other than leaves. This is done by providing checkMembership with a reference to a hash within the tree, rather than a leaf.",
        "code/plasma_framework/contracts/src/utils/Merkle.sol:L9-L42",
        "The current implementation will validate the provided \u201cleaf\u201d and return true. This is a known problem of Merkle trees https://en.wikipedia.org/wiki/Merkle_tree#Second_preimage_attack."
    ],
    "Examples": [
        "Provide a hash from within the Merkle tree as the leaf argument. The index has to match the index of that node in regards to its current level in the tree.\nThe rootHash has to be the correct Merkle tree rootHash.\nThe proof has to skip the necessary number of levels because the nodes \u201cunderneath\u201d the provided \u201cleaf\u201d will not be processed."
    ],
    "Recommendation": [
        "A remediation needs a fixed Merkle tree size as well as the addition of a byte prepended to each node in the tree. Another way would be to create a structure for the Merkle node and mark it as leaf or no leaf.",
        "Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/425"
    ]
}
----End JSON----

https://solodit.xyz/issues/maintainer-can-bypass-exit-game-quarantine-by-registering-not-yet-deployed-contracts-addressed-consensys-omisego-morevp-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Registers an exit game within the PlasmaFramework. Only the maintainer can call the function.\n \\* @dev Emits ExitGameRegistered event to notify clients\n \\* @param \\_txType The tx type where the exit game wants to register\n \\* @param \\_contract Address of the exit game contract\n \\* @param \\_protocol The transaction protocol, either 1 for MVP or 2 for MoreVP\n \\*/\nfunction registerExitGame(uint256 \\_txType, address \\_contract, uint8 \\_protocol) public onlyFrom(getMaintainer()) {\n    require(\\_txType != 0, \"Should not register with tx type 0\");\n    require(\\_contract != address(0), \"Should not register with an empty exit game address\");\n    require(\\_exitGames[\\_txType] == address(0), \"The tx type is already registered\");\n    require(\\_exitGameToTxType[\\_contract] == 0, \"The exit game contract is already registered\");\n    require(Protocol.isValidProtocol(\\_protocol), \"Invalid protocol value\");\n\n    \\_exitGames[\\_txType] = \\_contract;\n    \\_exitGameToTxType[\\_contract] = \\_txType;\n    \\_protocols[\\_txType] = \\_protocol;\n    \\_exitGameQuarantine.quarantine(\\_contract);\n\n    emit ExitGameRegistered(\\_txType, \\_contract, \\_protocol);\n}\n\n",
        "/\\*\\*\n \\* @notice A modifier to verify that the call is from a non-quarantined exit game\n \\*/\nmodifier onlyFromNonQuarantinedExitGame() {\n    require(\\_exitGameToTxType[msg.sender] != 0, \"The call is not from a registered exit game contract\");\n    require(!\\_exitGameQuarantine.isQuarantined(msg.sender), \"ExitGame is quarantined\");\n    \\_;\n}\n\n",
        "/\\*\\*\n \\* @notice Checks whether the contract is safe to use and is not under quarantine\n \\* @dev Exposes information about exit games quarantine\n \\* @param \\_contract Address of the exit game contract\n \\* @return boolean Whether the contract is safe to use and is not under quarantine\n \\*/\nfunction isExitGameSafeToUse(address \\_contract) public view returns (bool) {\n    return \\_exitGameToTxType[\\_contract] != 0 && !\\_exitGameQuarantine.isQuarantined(\\_contract);\n}\n\n",
        "function withdraw(address payable receiver, address token, uint256 amount) external onlyFromNonQuarantinedExitGame {\n    IERC20(token).safeTransfer(receiver, amount);\n    emit Erc20Withdrawn(receiver, token, amount);\n}\n\n",
        "function withdraw(address payable receiver, uint256 amount) external onlyFromNonQuarantinedExitGame {\n    // we do not want to block exit queue if transfer is unucessful\n    // solhint-disable-next-line avoid-call-value\n    (bool success, ) = receiver.call.value(amount)(\"\");\n    if (success) {\n        emit EthWithdrawn(receiver, amount);\n    } else {\n        emit WithdrawFailed(receiver, amount);\n    }\n\n",
        "function activateNonReentrant() external onlyFromNonQuarantinedExitGame() {\n    require(!mutex, \"Reentrant call\");\n    mutex = true;\n}\n\n",
        "function deactivateNonReentrant() external onlyFromNonQuarantinedExitGame() {\n    require(mutex, \"Not locked\");\n    mutex = false;\n}\n\n",
        "function enqueue(\n    uint256 vaultId,\n    address token,\n    uint64 exitableAt,\n    TxPosLib.TxPos calldata txPos,\n    uint160 exitId,\n    IExitProcessor exitProcessor\n)\n    external\n    onlyFromNonQuarantinedExitGame\n    returns (uint256)\n{\n    bytes32 key = exitQueueKey(vaultId, token);\n    require(hasExitQueue(key), \"The queue for the (vaultId, token) pair is not yet added to the Plasma framework\");\n    PriorityQueue queue = exitsQueues[key];\n\n    uint256 priority = ExitPriority.computePriority(exitableAt, txPos, exitId);\n\n    queue.insert(priority);\n    delegations[priority] = exitProcessor;\n\n    emit ExitQueued(exitId, priority);\n    return priority;\n}\n\n",
        "function flagOutputSpent(bytes32 \\_outputId) external onlyFromNonQuarantinedExitGame {\n    require(\\_outputId != bytes32(\"\"), \"Should not flag with empty outputId\");\n    isOutputSpent[\\_outputId] = true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in commit 7669076be1dff47473ee877dcebef5989d7617ac by adding a check that registered contracts had nonzero extcodesize."
    ],
    "Description": [
        "The plasma framework uses an ExitGameRegistry to allow the maintainer to add new exit games after deployment. An exit game is any arbitrary contract. In order to prevent the maintainer from adding malicious exit games that steal user funds, the framework uses a \u201cquarantine\u201d system whereby newly-registered exit games have restricted permissions until their quarantine period has expired. The quarantine period is by default 3 * minExitPeriod, and is intended to facilitate auditing of the new exit game\u2019s functionality by the plasma users.",
        "However, by registering an exit game at a contract which has not yet been deployed, the maintainer can prevent plasma users from auditing the game until the quarantine period has expired. After the quarantine period has expired, the maintainer can deploy the malicious exit game and immediately steal funds."
    ],
    "Explanation": [
        "Exit games are registered in the following function, callable only by the plasma contract maintainer:",
        "code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L58-L78",
        "Notably, the function does not check the extcodesize of the submitted contract. As such, the maintainer can submit the address of a contract which does not yet exist and is not auditable.",
        "After at least 3 * minExitPeriod seconds pass, the submitted contract now has full permissions as a registered exit game and can pass all checks using the onlyFromNonQuarantinedExitGame modifier:",
        "code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L33-L40",
        "Additionally, the submitted contract passes checks made by external contracts using the isExitGameSafeToUse function:",
        "code/plasma_framework/contracts/src/framework/registries/ExitGameRegistry.sol:L48-L56",
        "These permissions allow a registered quarantine to:",
        "code/plasma_framework/contracts/src/vaults/Erc20Vault.sol:L52-L55",
        "code/plasma_framework/contracts/src/vaults/EthVault.sol:L46-L54",
        "code/plasma_framework/contracts/src/framework/ExitGameController.sol:L63-L66",
        "code/plasma_framework/contracts/src/framework/ExitGameController.sol:L72-L75",
        "code/plasma_framework/contracts/src/framework/ExitGameController.sol:L115-L138",
        "code/plasma_framework/contracts/src/framework/ExitGameController.sol:L210-L213"
    ],
    "Recommendation": [
        "registerExitGame should check that extcodesize of the submitted contract is non-zero.",
        "Corresponding issue in plasma-contracts repo: https://github.com/omisego/plasma-contracts/issues/410"
    ]
}
----End JSON----

https://solodit.xyz/issues/saferagequit-makes-you-lose-funds-fixed-in-pull-pattern-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "safeRagequit no longer exists in the Pull Pattern update. ragequit is considered safe as there are no longer any ERC20 transfers in its code flow."
    ],
    "Description": [
        "safeRagequit and ragequit functions are used for withdrawing funds from the LAO. The difference between them is that ragequit function tries to withdraw all the allowed tokens and safeRagequit function withdraws only some subset of these tokens, defined by the user. It\u2019s needed in case the user or GuildBank is blacklisted in some of the tokens and the transfer reverts. The problem is that even though you can quit in that case, you\u2019ll lose the tokens that you exclude from the list.",
        "To be precise, the tokens are not completely lost, they will belong to the LAO and can still potentially be transferred to the user who quit. But that requires a lot of trust, coordination, time and anyone can steal some part of these tokens."
    ],
    "Recommendation": [
        "Implementing pull pattern for token withdrawals should solve the issue. Users will be able to quit the LAO and burn their shares but still keep their tokens in the LAO\u2019s contract for some time if they can\u2019t withdraw them right now."
    ]
}
----End JSON----

https://solodit.xyz/issues/creating-proposal-is-not-trustless-fixed-in-pull-pattern-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (!emergencyProcessing) {\n    require(\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\n        \"failing vote token transfer failed\"\n    );\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "this issue no longer exists in the Pull Pattern update, due to the fact that emergency processing and in function ERC20 transfers are removed."
    ],
    "Description": [
        "Usually, if someone submits a proposal and transfers some amount of tribute tokens, these tokens are transferred back if the proposal is rejected. But if the proposal is not processed before the emergency processing, these tokens will not be transferred back to the proposer. This might happen if a tribute token or a deposit token transfers are blocked.",
        "code/contracts/Moloch.sol:L407-L411",
        "Tokens are not completely lost in that case, they now belong to the LAO shareholders and they might try to return that money back. But that requires a lot of coordination and time and everyone who ragequits during that time will take a part of that tokens with them."
    ],
    "Recommendation": [
        "Pull pattern for token transfers would solve the issue."
    ]
}
----End JSON----

https://solodit.xyz/issues/emergency-processing-can-be-blocked-fixed-in-pull-pattern-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (!emergencyProcessing) {\n    require(\n        proposal.tributeToken.transfer(proposal.proposer, proposal.tributeOffered),\n        \"failing vote token transfer failed\"\n    );\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Emergency Processing no longer exists in the Pull Pattern update."
    ],
    "Description": [
        "The main reason for the emergency processing mechanism is that there is a chance that some token transfers might be blocked. For example, a sender or a receiver is in the USDC blacklist. Emergency processing saves from this problem by not transferring tribute token back to the user (if there is some) and rejecting the proposal.",
        "code/contracts/Moloch.sol:L407-L411",
        "The problem is that there is still a deposit transfer back to the sponsor and it could be potentially blocked too. If that happens, proposal can\u2019t be processed and the LAO is blocked."
    ],
    "Recommendation": [
        "Implementing pull pattern for all token withdrawals would solve the problem. The alternative solution would be to also keep the deposit tokens in the LAO, but that makes sponsoring the proposal more risky for the sponsor."
    ]
}
----End JSON----

https://solodit.xyz/issues/token-overflow-might-result-in-system-halt-or-loss-of-funds-fixed-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function max(uint256 x, uint256 y) internal pure returns (uint256) {\n    return x >= y ? x : y;\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in fd2da6, and 32ad9b by allowing overflows in most balance calculations (e.g. unsafeSubtractFromBalance and unsafeAddToBalance).\nThis is to prevent system halt, however as mentioned above, in case of overflow the token balance will be incorrect for token holders and members should take that into account when approving future proposals."
    ],
    "Description": [
        "If a token overflows, some functionality such as processProposal, cancelProposal will break due to safeMath reverts. The overflow could happen because the supply of the token was artificially inflated to oblivion.",
        "This issue was pointed out by Heiko Fisch in Telegram chat."
    ],
    "Examples": [
        "Any function using internalTransfer() can result in an overflow:",
        "contracts/Moloch.sol:L631-L634"
    ],
    "Recommendation": [
        "We recommend to allow overflow for broken or malicious tokens. This is to prevent system halt or loss of funds. It should be noted that in case an overflow occurs, the balance of the token will be incorrect for all token holders in the system.",
        "rageKick, rageQuit were fixed by not using safeMath within the function code, however this fix is risky and not recommended, as there are other overflows in other functions that might still result in system halt or loss of funds.",
        "One suggestion is having a function named unsafeInternalTransfer() which does not use safeMath for the cases that overflow should be allowed. This mainly adds better readability to the code.",
        "It is still a risky fix and a better solution should be planned."
    ]
}
----End JSON----

https://solodit.xyz/issues/whitelisted-tokens-limit-fixed-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 constant MAX\\_TOKEN\\_WHITELIST\\_COUNT = 400; // maximum number of whitelisted tokens\nuint256 constant MAX\\_TOKEN\\_GUILDBANK\\_COUNT = 200; // maximum number of tokens with non-zero balance in guildbank\nuint256 public totalGuildBankTokens = 0; // total tokens with non-zero balance in guild bank\n\n",
        "for (uint256 i = 0; i < tokens.length; i++) {\n    uint256 amountToRagequit = fairShare(userTokenBalances[GUILD][tokens[i]], sharesAndLootToBurn, initialTotalSharesAndLoot);\n    // deliberately not using safemath here to keep overflows from preventing the function execution (which would break ragekicks)\n    // if a token overflows, it is because the supply was artificially inflated to oblivion, so we probably don't care about it anyways\n    userTokenBalances[GUILD][tokens[i]] -= amountToRagequit;\n    userTokenBalances[memberAddress][tokens[i]] += amountToRagequit;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "mitigated by having separate limits for number of whitelisted tokens (for non-zero balance and for zero balance) in 486f1b3 and follow up commits. That\u2019s helpful because it\u2019s much cheaper to process tokens with zero balance in the guild bank and you can have much more whitelisted tokens overall.",
        "It should be noted that this is an estimated limit based on the manual calculations and current OP code gas costs. DAO members should consider splitting the DAO into two if more than 100 tokens with non-zero balance are used in the DAO to be safe."
    ],
    "Description": [
        "_ragequit function is iterating over all whitelisted tokens:",
        "contracts/Moloch.sol:L507-L513",
        "If the number of tokens is too big, a transaction can run out of gas and all funds will be blocked forever. Ballpark estimation of this number is around 300 tokens based on the current OpCode gas costs and the block gas limit."
    ],
    "Recommendation": [
        "A simple solution would be just limiting the number of whitelisted tokens.",
        "If the intention is to invest in many new tokens over time, and it\u2019s not an option to limit the number of whitelisted tokens, it\u2019s possible to add a function that removes tokens from the whitelist. For example, it\u2019s possible to add a new type of proposals, that is used to vote on token removal if the balance of this token is zero. Before voting for that, shareholders should sell all the balance of that token."
    ]
}
----End JSON----

https://solodit.xyz/issues/summoner-can-steal-funds-using-bailout-fixed-in-pull-pattern-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "bailout no longer exists in the Pull Pattern update. Note that in case the member loses their private key the funds will be lost."
    ],
    "Description": [
        "Currently, there are 2 major reasons for using the bailout function:"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/sponsorship-front-running-fixed-in-pull-pattern-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "this issue no longer exists in the Pull Pattern update with Major severity, as mentioned in the recommendation, the front-running vector is still open but no rationale exist for such a behaviour."
    ],
    "Description": [
        "If proposal submission and sponsorship are done in 2 different transactions, it\u2019s possible to front-run the sponsorProposal function by any member. The incentive to do that is to be able to block the proposal afterwards. It\u2019s sometimes possible to block the proposal by getting blacklisted at depositToken. In that case, the proposal won\u2019t be accepted and the emergency processing is going to happen next. Currently, if the attacker can become whitelisted again, he might even not lose the deposit tokens. If not, it will block the whole system forever and everyone would have to ragequit (but that\u2019s the part of another issue)."
    ],
    "Recommendation": [
        "Pull pattern for token transfers will solve the issue. Front-running will still be possible but it doesn\u2019t affect anything."
    ]
}
----End JSON----

https://solodit.xyz/issues/delegate-assignment-front-running-wont-fix-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "Any member can front-run another member\u2019s delegateKey assignment.",
        "if you try to submit an address as your delegateKey, someone else can try to assign your delegate address tp themselves. While incentive of this action is unclear, it\u2019s possible to block some address from being a delegate forever. ragekick and ragequit do not free the delegate address and the delegate itself also cannot change the address.",
        "The possible attack could be that a well-known hard-to-replace multisig address is assigned as a delegateKey and someone else take this address to block it. Also, if the malicious member is about to ragequit or be kicked, it\u2019s possible to do this attack without losing anything.",
        "The only way to free the delegate is to make it a member, but then it can never be a delegate after."
    ],
    "Recommendation": [
        "Make it possible for a delegateKey to approve delegateKey assignment or cancel the current delegation. And additionally, it may be valuable to clear the delegate address in the _ragequit function.",
        "Commit-reveal methods can also be used to mitigate this attack."
    ]
}
----End JSON----

https://solodit.xyz/issues/no-votes-are-still-valid-after-the-ragequitragekick-wont-fix-consensys-the-lao-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Description": [
        "Shareholders can vote for the upcoming proposals 2 weeks before they can be executed. If they ragequit or get ragekicked, their votes are still considered valid. And while the LAO does not allow anyone to ragequit before the last proposal with Yes vote is processed, it\u2019s still possible to quit the LAO and having active No votes on some proposals.",
        "It\u2019s not naturally expected behaviour because by that time a user ragequits, they are not part of the LAO and do not have any voting power. Moreover, there is no incentive not to vote No just to fail all the possible proposals, because the user won\u2019t be sharing any consequences of the result of these proposals. And even incentivized to vote No for every proposal just as the act of revenge for the ragekick."
    ],
    "Recommendation": [
        "The problem is mitigated by the fact that all rejected proposals can be submitted again and be processed a few weeks after.",
        "It\u2019s possible to remove all the No votes from the proposals after user\u2019s ragekick/ragequit."
    ]
}
----End JSON----

https://solodit.xyz/issues/timelock-spam-prevention-can-be-bypassed-addressed-consensys-dandelion-organizations-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This was addressed in commit aa6fc49fbf3230d7f02956b33a3150c6885ee93f by parsing the input evm script and ensuring only a single external call is made. Additionally, commit 453179e98159413d38196b6a5373cdd729483567 added TimeLock and token to the script runner blacklist."
    ],
    "Description": [
        "The TimeLock app is a forwarder that requires users to lock some token before forwarding an EVM callscript. Its purpose is to introduce a \u201cspam penalty\u201d to hamper repeat actions within an Aragon org. In the context of a Dandelion org, this spam penalty is meant to stop users from repeatedly creating votes in DandelionVoting, as subsequent votes are buffered by a configurable number of blocks (DandelionVoting.bufferBlocks). Spam prevention is important, as the more votes are buffered, the longer it takes before \u201cnon-spam\u201d votes are able to be executed.",
        "By allowing arbitrary calls to be executed, the TimeLock app opens several potential vectors for bypassing spam prevention."
    ],
    "Examples": [
        "By constructing a callscript that executes a call to the lock token address, the sender execute calls to the lock token on behalf of TimeLock. Any function can be executed, making it possible to not only transfer \u201clocked\u201d tokens back to the sender, but also steal other users' locked tokens by way of transfer.",
        "Callscripts can be batched, meaning they can execute multiple calls before finishing. Within a Dandelion org, the spam prevention mechanism is used for the DandelionVoting.newVote function. A callscript that batches multiple calls to this function can execute newVote several times per call to TimeLock.forward. Although multiple new votes are created, only one spam penalty is incurred, making it trivial to extend the buffer imposed on \u201cnon-spam\u201d votes.",
        "A callscript can be used to re-enter TimeLock.forward, as well as any other TimeLock functions. Although this may not be directly exploitable, it does seem unintentional that many of the TimeLock contract functions are accessible to itself in this manner."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/passing-duplicate-tokens-to-redemptions-and-tokenrequest-may-have-unintended-consequences-addressed-consensys-dandelion-organizations-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < redeemableTokens.length; i++) {\n    vaultTokenBalance = vault.balance(redeemableTokens[i]);\n\n    redemptionAmount = \\_burnableAmount.mul(vaultTokenBalance).div(burnableTokenTotalSupply);\n    totalRedemptionAmount = totalRedemptionAmount.add(redemptionAmount);\n\n    if (redemptionAmount > 0) {\n        vault.transfer(redeemableTokens[i], msg.sender, redemptionAmount);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in Redemptions commit 2b0034206a5b9cdf239da7a51900e89d9931554f by checking redeemableTokenAdded[token] == false for each subsequent token added during initialization. Note that ordering is not enforced.",
        "Additionally, the issue in TokenRequest was addressed in commit eb4181961093439f142f2e74eb706b7f501eb5c0 by requiring that each subsequent token added during initialization has a value strictly greater than the previous token added."
    ],
    "Description": [
        "Both Redemptions and TokenRequest are initialized with a list of acceptable tokens to use with each app. For Redemptions, the list of tokens corresponds to an organization\u2019s treasury assets. For TokenRequest, the list of tokens corresponds to tokens accepted for payment to join an organization. Neither contract makes a uniqueness check on input tokens during initialization, which can lead to unintended behavior."
    ],
    "Examples": [
        "code/redemptions-app/contracts/Redemptions.sol:L112-L121",
        "If a token address is included more than once, the sender will be paid out more than once, potentially earning many times more than their proportional share of the token."
    ],
    "Recommendation": [
        "During initialization in both apps, check that input token addresses are unique. One simple method is to require that token addresses are submitted in ascending order, and that each subsequent address added is greater than the one before."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-delay-app-allows-scripts-to-be-paused-even-after-execution-time-has-elapsed-addressed-consensys-dandelion-organizations-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_delayExecution(bytes \\_evmCallScript) internal returns (uint256) {\n    uint256 delayedScriptIndex = delayedScriptsNewIndex;\n    delayedScriptsNewIndex++;\n\n    delayedScripts[delayedScriptIndex] = DelayedScript(getTimestamp64().add(executionDelay), 0, \\_evmCallScript);\n\n    emit DelayedScriptStored(delayedScriptIndex);\n\n    return delayedScriptIndex;\n}\n\n",
        "function pauseExecution(uint256 \\_delayedScriptId) external auth(PAUSE\\_EXECUTION\\_ROLE) {\n    require(!\\_isExecutionPaused(\\_delayedScriptId), ERROR\\_CAN\\_NOT\\_PAUSE);\n    delayedScripts[\\_delayedScriptId].pausedAt = getTimestamp64();\n\n    emit ExecutionPaused(\\_delayedScriptId);\n}\n\n",
        "function resumeExecution(uint256 \\_delayedScriptId) external auth(RESUME\\_EXECUTION\\_ROLE) {\n    require(\\_isExecutionPaused(\\_delayedScriptId), ERROR\\_CAN\\_NOT\\_RESUME);\n    DelayedScript storage delayedScript = delayedScripts[\\_delayedScriptId];\n\n    uint64 timePaused = getTimestamp64().sub(delayedScript.pausedAt);\n    delayedScript.executionTime = delayedScript.executionTime.add(timePaused);\n    delayedScript.pausedAt = 0;\n\n    emit ExecutionResumed(\\_delayedScriptId);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in commit 46d8fa414cc3e68c68a5d9bc1174be5f32970611 by requiring that the current timestamp is before the delayed script\u2019s execution time."
    ],
    "Description": [
        "The Delay app is used to configure a delay between when an evm script is created and when it is executed. The entry point for this process is Delay.delayExecution, which stores the input script with a future execution date:",
        "code/delay-app/contracts/Delay.sol:L153-L162",
        "An auxiliary capability of the Delay app is the ability to \u201cpause\u201d the delayed script, which sets the script\u2019s pausedAt value to the current block timestamp:",
        "code/delay-app/contracts/Delay.sol:L80-L85",
        "A paused script cannot be executed until resumeExecution is called, which extends the script\u2019s executionTime by the amount of time paused. Essentially, the delay itself is paused:",
        "code/delay-app/contracts/Delay.sol:L91-L100",
        "A delayed script whose execution time has passed and is not currently paused should be able to be executed via the execute function. However, the pauseExecution function still allows the aforementioned script to be paused, halting execution."
    ],
    "Recommendation": [
        "Add a check to pauseExecution to ensure that execution is not paused if the script\u2019s execution delay has already transpired."
    ]
}
----End JSON----

https://solodit.xyz/issues/misleading-intentional-misconfiguration-possible-through-misuse-of-newtoken-and-newbaseinstance-addressed-consensys-dandelion-organizations-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n\\* @dev Create a new MiniMe token and save it for the user\n\\* @param \\_name String with the name for the token used by share holders in the organization\n\\* @param \\_symbol String with the symbol for the token used by share holders in the organization\n\\*/\nfunction newToken(string memory \\_name, string memory \\_symbol) public returns (MiniMeToken) {\n    MiniMeToken token = \\_createToken(\\_name, \\_symbol, TOKEN\\_DECIMALS);\n    \\_saveToken(token);\n    return token;\n}\n\n",
        "/\\*\\*\n\\* @dev Deploy a Dandelion Org DAO using a previously saved MiniMe token\n\\* @param \\_id String with the name for org, will assign `[id].aragonid.eth`\n\\* @param \\_holders Array of token holder addresses\n\\* @param \\_stakes Array of token stakes for holders (token has 18 decimals, multiply token amount `\\* 10^18`)\n\\* @param \\_useAgentAsVault Boolean to tell whether to use an Agent app as a more advanced form of Vault app\n\\*/\nfunction newBaseInstance(\n    string memory \\_id,\n    address[] memory \\_holders,\n    uint256[] memory \\_stakes,\n    uint64 \\_financePeriod,\n    bool \\_useAgentAsVault\n)\n    public\n{\n    \\_validateId(\\_id);\n    \\_ensureBaseSettings(\\_holders, \\_stakes);\n\n    (Kernel dao, ACL acl) = \\_createDAO();\n    \\_setupBaseApps(dao, acl, \\_holders, \\_stakes, \\_financePeriod, \\_useAgentAsVault);\n}\n\n",
        "function \\_setupBaseApps(\n    Kernel \\_dao,\n    ACL \\_acl,\n    address[] memory \\_holders,\n    uint256[] memory \\_stakes,\n    uint64 \\_financePeriod,\n    bool \\_useAgentAsVault\n)\n    internal\n{\n    MiniMeToken token = \\_getToken();\n    Vault agentOrVault = \\_useAgentAsVault ? \\_installDefaultAgentApp(\\_dao) : \\_installVaultApp(\\_dao);\n    TokenManager tokenManager = \\_installTokenManagerApp(\\_dao, token, TOKEN\\_TRANSFERABLE, TOKEN\\_MAX\\_PER\\_ACCOUNT);\n    Finance finance = \\_installFinanceApp(\\_dao, agentOrVault, \\_financePeriod == 0 ? DEFAULT\\_FINANCE\\_PERIOD : \\_financePeriod);\n\n    \\_mintTokens(\\_acl, tokenManager, \\_holders, \\_stakes);\n    \\_saveBaseApps(\\_dao, finance, tokenManager, agentOrVault);\n    \\_saveAgentAsVault(\\_dao, \\_useAgentAsVault);\n\n}\n\n\n",
        "function \\_saveToken(MiniMeToken \\_token) internal {\n    DeployedContracts storage senderDeployedContracts = deployedContracts[msg.sender];\n\n    senderDeployedContracts.token = address(\\_token);\n}\n\n",
        "function \\_getToken() internal returns (MiniMeToken) {\n    DeployedContracts storage senderDeployedContracts = deployedContracts[msg.sender];\n    require(senderDeployedContracts.token != address(0), ERROR\\_MISSING\\_TOKEN\\_CONTRACT);\n\n    MiniMeToken token = MiniMeToken(senderDeployedContracts.token);\n    return token;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in commit b68d89ab0deb22161987e19d1ff0bb9d7303f0a9 by making newToken and newBaseInstance internal. A later commit addressed an invalid DandelionVoting import statement."
    ],
    "Description": [
        "The instantiation process for a Dandelion organization requires two separate external calls to DandelionOrg. There are two primary functions: installDandelionApps, and newTokenAndBaseInstance.",
        "installDandelionApps relies on cached results from prior calls to newTokenAndBaseInstance and completes the initialization step for a Dandelion org.",
        "newTokenAndBaseInstance is a wrapper around two publicly accessible functions: newToken and newBaseInstance. Called together, the functions:",
        "code/dandelion-org/contracts/DandelionOrg.sol:L128-L137",
        "code/dandelion-org/contracts/DandelionOrg.sol:L139-L160",
        "code/dandelion-org/contracts/DandelionOrg.sol:L162-L182",
        "Note that newToken and newBaseInstance can be called separately. The token created in newToken is cached in _saveToken, which overwrites any previously-cached value:",
        "code/dandelion-org/contracts/DandelionOrg.sol:L413-L417",
        "Cached tokens are retrieved in _getToken:",
        "code/dandelion-org/contracts/DandelionOrg.sol:L441-L447",
        "By exploiting the overwriteable caching mechanism, it is possible to intentionally misconfigure Dandelion orgs."
    ],
    "Examples": [
        "installDandelionApps uses _getToken to associate a token with the DandelionVoting app. The value returned from _getToken depends on the sender\u2019s previous call to newToken, which overwrites any previously-cached value. The steps for intentional misconfiguration are as follows:",
        "Further calls to newBaseInstance and installDandelionApps create DAO B, populate it with Dandelion apps, and assign B.TokenManager as the controller of the earlier DandelionVoting app token, m0.",
        "Many different misconfigurations are possible, and some may be underhandedly abusable."
    ],
    "Recommendation": [
        "Make newToken and newBaseInstance internal so they are only callable via newTokenAndBaseInstance."
    ]
}
----End JSON----

https://solodit.xyz/issues/fair-can-be-stolen-using-erc-777-hooks-fixed-consensys-fairmint-continuous-securities-offering-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "tokenValue: uint256 = self.estimateBuyValue(\\_currencyValue)\n\n",
        "if(self.isCurrencyERC777):\n  self.currency.operatorSend(\\_from, self, \\_quantityToInvest, \"\", \"\")\n\n",
        "self.fair.mint(msg.sender, \\_to, tokenValue, \"\", \"\")\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "fixed by completely removing ERC-777 support."
    ],
    "Description": [
        "The sell() function calls out to user-configured hooks when burning incoming FAIR tokens. The buy() function does the same if the DAT\u2019s currency is ERC-777 compliant.",
        "Either of these hooks might invoke malicious code to re-enter the DAT, allowing them to sell and/or buy FAIR tokens at an unintentionally favourable price.",
        "Such attacks may leave the DAT undercollateralized, resulting in other investors being unable to redeem their FAIR for currency."
    ],
    "Example": [
        "Here are some ordered extracts from the code invoked when DAT.buy() is called, when the DAT\u2019s currency is an ERC-777 compliant token.",
        "code/contracts/DecentralizedAutonomousTrust.vy:L629",
        "The code above does a calculation using FAIR.totalSupply as input. The higher FAIR.totalSupply is, the more expensive FAIR tokens become.",
        "code/contracts/DecentralizedAutonomousTrust.vy:L502-L503",
        "Per the ERC-777 standard, the code above invokes an arbitrary tokensToSend() hook configured by the buyer.",
        "code/contracts/DecentralizedAutonomousTrust.vy:L654",
        "The code above increments FAIR.totalSupply, effectively increasing the price of FAIR tokens. This happens after the other two code extracts have completed.",
        "An attacker can exploit re-entrancy during the tokensToSend() hook, to purchase further tokens at a (perhaps extremely) favourable price before FAIR.totalSupply is incremented.",
        "If the price at the time of the initial buy() is very low (as it will be when totalSupply is small or zero), then they may be able to buy huge amounts of FAIR at that very low price."
    ],
    "Recommendation": [
        "Prevent reentrancy by adding a mutex (using Vyper\u2019s @nonreentrant() decorator) across all functions that result in ERC-777 token transfers (of FAIR or an ERC-777 currency)."
    ]
}
----End JSON----

https://solodit.xyz/issues/bigdiv-does-not-prevent-overflow-in-some-cases-where-it-should-fixed-consensys-fairmint-continuous-securities-offering-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "a='340282366920938463463374607431768211455'\r\nb='340282366920938463463374607431768211457'\r\nBigDiv.bigDiv2x1(a, b, '1', false) -- ???\r\n\n",
        "a='340282366920938463463374607431768211456'\r\nBigDiv.bigDiv2x1(a, a, a, false) -- overflows, despite result being ~sqrt(MAX_INT)\r\n\n",
        "if(factor == 0):\n  factor = 1\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed in the Solidity implementation."
    ],
    "Description": [
        "BigDiv.vy has been created with the aim of allowing calculations like (a * b) / d to succeed where an intermediate step (e.g. a * b) might overflow but the end result is <= MAX_UINT256.",
        "All of the functions sometimes fail in this aim if the numerators are large and of the same order of magnitude. (E.g. for bigDiv2x1, it fails if _numA / MAX_BEFORE_SQUARE = numB / MAX_BEFORE_SQUARE > 0)",
        "The chances of this issue being hit accidentally or exploited deliberately in the current code will both greatly depend on the DAT\u2019s configuration and its state. (If the numbers are amenable, an attacker could conceivably front run transactions and adjust FAIR balances in a way that causes targeted transactions to fail.)",
        "Having functions that unexpectedly fail is dangerous for future consumers of this code, and the (simplest possible) fix is small."
    ],
    "Examples": [
        "The following code overflows in the code as audited, but succeeds (returning MAX_INT) if MAX_BEFORE_SQUARE is altered as suggested in issue 6.4.",
        "bigDiv2x1 also overflows for some simple cases where the result is far below MAX_UINT256. E.g.:"
    ],
    "Recommendations": [
        "The following code appears in each BigDiv function:",
        "code/contracts/BigDiv.vy:L30-L31",
        "Replacing every instance of these two lines with simply factor += 1 will avoid overflows. It will also reduce the (currently undocumented) accuracy of the result in some cases, so see recommendations in issue 6.4.",
        "We have already written some basic test code and can supply it on request."
    ]
}
----End JSON----

https://solodit.xyz/issues/eopbctemplate-permission-documentation-inconsistencies-fixed-consensys-aragonone-aragon-network-presale-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_createPermissions(\\_acl, grantees, \\_fundraisingApps.bondedTokenManager, \\_fundraisingApps.bondedTokenManager.MINT\\_ROLE(), \\_owner);\n\\_acl.createPermission(\\_fundraisingApps.marketMaker, \\_fundraisingApps.bondedTokenManager, \\_fundraisingApps.bondedTokenManager.BURN\\_ROLE(), \\_owner);\n\n",
        "- app: anj-token-manager\n  role: MINT\\_ROLE\n  grantee: market-maker\n  manager: owner\n- app: anj-token-manager\n  role: MINT\\_ROLE\n  grantee: presale\n  manager: owner\n- app: anj-token-manager\n  role: BURN\\_ROLE\n  grantee: market-maker\n  manager: owner\n\n",
        "| App        | Permission                            | Grantee | Manager |\r\n| ---------- | ------------------------------------- | ------- | ------- |\r\n| Controller | UPDATE_BENEFICIARY                    | NULL    | NULL    |\r\n| Controller | UPDATE_FEES                           | NULL    | NULL    |\r\n| Controller | ADD_COLLATERAL_TOKEN                  | Owner   | Owner   |\r\n| Controller | REMOVE_COLLATERAL_TOKEN               | Owner   | Owner   |\r\n| Controller | UPDATE_COLLATERAL_TOKEN               | Owner   | Owner   |\r\n| Controller | UPDATE_MAXIMUM_TAP_RATE_INCREASE_PCT  | NULL    | NULL    |\r\n| Controller | UPDATE_MAXIMUM_TAP_FLOOR_DECREASE_PCT | NULL    | NULL    |\r\n| Controller | ADD_TOKEN_TAP                         | NULL    | NULL    |\r\n| Controller | UPDATE_TOKEN_TAP                      | NULL    | NULL    |\r\n| Controller | OPEN_PRESALE                          | Owner   | Owner   |\r\n| Controller | OPEN_TRADING                          | Presale | Owner   |\r\n| Controller | CONTRIBUTE                            | Any     | Owner   |\r\n| Controller | OPEN_BUY_ORDER                        | Any     | Owner   |\r\n| Controller | OPEN_SELL_ORDER                       | Any     | Owner   |\r\n| Controller | WITHDRAW                              | NULL    | NULL    |\r\n\n",
        "\\_acl.createPermission(\\_owner, \\_fundraisingApps.controller, \\_fundraisingApps.controller.UPDATE\\_BENEFICIARY\\_ROLE(), \\_owner);\n\\_acl.createPermission(\\_owner, \\_fundraisingApps.controller, \\_fundraisingApps.controller.UPDATE\\_FEES\\_ROLE(), \\_owner);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with aragonone/[email\u00a0protected]bafe100 by adding the undocumented and deviating permissions to the documentation."
    ],
    "Description": [
        "The template documentation provides an overview of the permissions set with the template. The following permissions are set by the template contract but are not documented in the accompanied fundraising/templates/externally_owned_presale_bonding_curve/README.md.",
        "TokenManager",
        "code/fundraising/templates/externally_owned_presale_bonding_curve/contracts/EOPBCTemplate.sol:L220-L221",
        "code/fundraising/templates/externally_owned_presale_bonding_curve/eopbc.yaml:L33-L44",
        "The following permissions are set by the template but are inconsistent to the outline in the documentation:",
        "Controller",
        "owner has the following permissions even though they are documented as not being set https://github.com/ConsenSys/aragonone-presale-audit-2019-11/blob/9ddae8c7fde9dea3af3982b965a441239d81f370/code/fundraising/templates/externally_owned_presale_bonding_curve/README.md#controller.",
        "code/fundraising/templates/externally_owned_presale_bonding_curve/contracts/EOPBCTemplate.sol:L239-L240"
    ],
    "Recommendation": [
        "For transparency, all permissions set-up by the template must be documented."
    ]
}
----End JSON----

https://solodit.xyz/issues/eopbctemplate-appid-of-balanceredirectpresale-should-be-different-from-aragonblackpresale-namehash-to-avoid-collisions-fixed-consensys-aragonone-aragon-network-presale-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes32   private constant PRESALE\\_ID                    = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;\n\n",
        "bytes32   private constant PRESALE\\_ID             = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with aragonone/[email\u00a0protected]bafe100 by generating a unique APMNameHash for BalanceRedirectPresale that does not collide with the one from Presale."
    ],
    "Description": [
        "The template references the new presale contract with apmNamehash 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5. However, this namehash is already used by the aragonBlack/Presale contract. To avoid confusion and collision a unique apmNamehash should be used for this variant of the contract.",
        "Note that the contract that is referenced from an apmNamehash is controlled by the ENS resolver that is configured when deploying the template contract. Using the same namehash for both variants of the contract does not allow a single registry to simultaneously provide both variants of the contract and might lead to confusion as to which application is actually deployed. This also raises the issue that the ENS registry must be verified before actually using the contract as a malicious registry could force the template to deploy potentially malicious applications.",
        "code/fundraising/templates/externally_owned_presale_bonding_curve/contracts/EOPBCTemplate.sol:L32",
        "templates/multisig/contracts/FundraisingMultisigTemplate.sol:L35",
        "bytes32 private constant PRESALE_ID = 0x5de9bbdeaf6584c220c7b7f1922383bcd8bbcd4b48832080afd9d5ebf9a04df5;"
    ],
    "Recommendation": [
        "Create a new apmNamehash for BalanceRedirectPresale."
    ]
}
----End JSON----

https://solodit.xyz/issues/balanceredirectpresale-presale-can-be-extended-indefinitely-wont-fix-consensys-aragonone-aragon-network-presale-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setPeriod(uint64 \\_period) external auth(OPEN\\_ROLE) {\n    \\_setPeriod(\\_period);\n}\n\n",
        "function \\_setPeriod(uint64 \\_period) internal {\n    require(\\_period > 0, ERROR\\_TIME\\_PERIOD\\_ZERO);\n    require(openDate == 0 || openDate + \\_period > getTimestamp64(), ERROR\\_INVALID\\_TIME\\_PERIOD);\n    period = \\_period;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed with the following statement:"
    ],
    "Description": [
        "The OPEN_ROLE can indefinitely extend the Presale even after users contributed funds to it by adjusting the presale period. The period might be further manipulated to avoid that token trading in the MarketMaker is opened.",
        "code/fundraising/apps/presale/contracts/BalanceRedirectPresale.sol:L136-L138",
        "code/fundraising/apps/presale/contracts/BalanceRedirectPresale.sol:L253-L257"
    ],
    "Recommendation": [
        "Do not allow to extend the presale after funds have been contributed to it or only allow period adjustments in State.PENDING."
    ]
}
----End JSON----

https://solodit.xyz/issues/repository-structure-create-a-clean-repository-containing-one-aragon-application-unless-changes-are-contributed-upstream-deferred-consensys-aragonone-aragon-network-presale-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The issue has been deferred pending internal discussion."
    ],
    "Description": [
        "The repository is a fork of AragonBlack/fundraising. The main development repository for Aragon Fundraising is the origin repository at AragonBlock. This repository duplicates a state of the upstream repository that can quickly get out of sync and therefore hard to maintain.",
        "It is unclear if both repositories will live side-by-side or if the BalanceRedirectPresale variant is contributed upstream."
    ],
    "Recommendation": [
        "In case changes are not planned to be contributed upstream it is recommended to create a clean Aragon Application from scratch removing any unused or duplicated files."
    ]
}
----End JSON----

https://solodit.xyz/issues/balanceredirectpresale-tokens-vest-during-the-presale-phase-wont-fix-consensys-aragonone-aragon-network-presale-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "The issue was addressed with the following statement:"
    ],
    "Description": [
        "Tokens are directly minted and assigned to contributors during the Presale. While this might not be an issue if the minted token does not give any voting power of some sort in a DAO it can be a problem for scenarios where contributors get stake in return for contributions."
    ],
    "Recommendation": [
        "Vest tokens for contributors after the presale finishes. In case this is the expected we suggest to add a note to the documentation to make potential users aware of this behaviour that might have security implications if contributors get stake in return for their investments."
    ]
}
----End JSON----

https://solodit.xyz/issues/balanceredirectpresale-setperiod-uint64-overflow-in-validation-check-fixed-consensys-aragonone-aragon-network-presale-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_setPeriod(uint64 \\_period) internal {\n    require(\\_period > 0, ERROR\\_TIME\\_PERIOD\\_ZERO);\n    require(openDate == 0 || openDate + \\_period > getTimestamp64(), ERROR\\_INVALID\\_TIME\\_PERIOD);\n    period = \\_period;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with aragonone/[email\u00a0protected]bafe100 by performing the addition using SafeMath."
    ],
    "Description": [
        "setPeriod() allows setting an arbitrary Presale starting date. The method can be called by an entity with the OPEN_ROLE permission. Providing a large enough value for uint64 _period can overflow the second input validation check. The result is unwanted behaviour where for relatively large values of period the require might fail because the overflow openDate + _period is less than or equal the current timestamp (getTimestamp64()) but if high enough it still might succeed because openDate + _period is higher than the current timestamp. The overflow has no effect on the presale end as it is calculated against _timeSinceOpen.",
        "code/fundraising/apps/presale/contracts/BalanceRedirectPresale.sol:L253-L257",
        ""
    ],
    "Recommendation": [
        "Use SafeMath which is already imported to protect from overflow scenarios."
    ]
}
----End JSON----

https://solodit.xyz/issues/staking-node-can-be-inappropriately-removed-from-the-tree-fixed-consensys-orchid-network-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (name(stake.left\\_) == key) {\n    current.right\\_ = stake.right\\_;\n    current.after\\_ = stake.after\\_;\n} else {\n    current.left\\_ = stake.left\\_;\n    current.before\\_ = stake.before\\_;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in OrchidProtocol/[email\u00a0protected]8c586f2."
    ],
    "Description": [
        "The following code in OrchidDirectory.pull() is responsible for reattaching a child from a removed tree node:",
        "code/dir-ethereum/directory.sol:L275-L281",
        "The condition name(stake.left_) == key can never hold because key is the key for stake itself.",
        "The result of this bug is somewhat catastrophic. The child is not reattached, but it still has a link to the rest of the tree via its \u2018parent_\u2019 pointer. This means reducing the stake of that node can underflow the ancestors' before/after amounts, leading to improper random selection or failing altogether.",
        "The node replacing the removed node also ends up with itself as a child, which violates the basic tree structure and is again likely to produce integer underflows and other failures."
    ],
    "Recommendation": [
        "As a simple fix, use if(name(stake.left_) == name(last)) as already suggested by the development team when this bug was first shared.",
        "Two suggestions for better long-term fixes:"
    ]
}
----End JSON----

https://solodit.xyz/issues/verifiers-need-to-be-pure-but-its-very-difficult-to-validate-pureness-fixed-consensys-orchid-network-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function good(bytes calldata shared, address target, bytes calldata receipt) external pure returns (bool);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is addressed in OrchidProtocol/[email\u00a0protected]1b405fb. With this change, the contract checks that the verifier\u2019s code doesn\u2019t change (via extcodehash). If the code does change, the contract \u201cfails open\u201d by skipping the verifier and allowing all payments.",
        "Because the code can no longer change, the server can use the (relatively) simple method of executing the contract locally and only allowing a whitelist of opcodes that don\u2019t depend on or modify state.",
        "The server already has mitigations for denial of service attacks, including limiting the amount of computing resources that can be used for validating code."
    ],
    "Description": [
        "After the initial audit, a \u201cverifier\u201d was introduced to the OrchidLottery code. Each Pot can have an associated OrchidVerifier. This is a contract with a good() function that accepts three parameters:",
        "code/lot-ethereum/lottery.sol:L28",
        "The verifier returns a boolean indicating whether a given micropayment should be allowed or not. An example use case is a verifier that only allows certain target addresses to be paid. In this case, shared (a single value for a given Pot) is a merkle root, target is (as always) the address being paid, and receipt (specified by the payment recipient) is a merkle proof that the target address is within the merkle tree with the given root.",
        "A server providing bandwidth needs to know whether to accept a certain receipt. To do that, it needs to know that at some time in the future, a call to the verifier\u2019s good() function with a particular set of parameters will return true. The proposed scheme for determining that is for the server to run the contract\u2019s code locally and ensure that it returns true and that it doesn\u2019t execute any EVM opcodes that would read state. This prevents, for example, a contract from returning true until a certain timestamp and then start returning false. If a contract could do that, the server would be tricked into providing bandwidth without then receiving payment.",
        "Unfortunately, this simple scheme is insufficient. As a simple example, a verifier contract could be created with the CREATE2 opcode. It could be demonstrated that it reads no state when good() is called. Then the contract could be destroyed by calling a function that performs a SELFDESTRUCT, and it could be replaced via another CREATE2 call with different code.",
        "This could be mitigated by rejecting any verifier contract that contains the SELFDESTRUCT opcode, but this would also catch harmless occurrences of that particular byte. https://gist.github.com/Arachnid/e8f0638dc9f5687ff8170a95c47eac1e attempts to find SELFDESTRUCT opcodes but fails to account for tricks where the SELFDESTRUCT appears to be data but can actually be executed. (See Recmo\u2019s comment.) In general, this approach is difficult to get right and probably requires full data flow analysis to be correct.",
        "Another possible mitigation is to use a factory contract to deploy the verifiers, guaranteeing that they\u2019re not created with CREATE2. This should render SELFDESTRUCT harmless, but there\u2019s no guarantee that future forks won\u2019t introduce new vectors here.",
        "Finally, requiring servers to implement potentially complex contract validation opens up potential for denial-of-service attacks. A server will have to implement mitigations to prevent repeatedly checking the same verifier or spending inordinate resources checking a maliciously crafted contract (e.g. one with high branching factors)."
    ],
    "Recommendation": [
        "The verifiers add quite a bit of complexity and risk. We recommend looking for an alternative approach, such as including a small number of vetted verifiers (e.g. a merkle proof verifier) or having servers use their own \u201callow list\u201d for verifiers that they trust."
    ]
}
----End JSON----

https://solodit.xyz/issues/simplify-the-logic-in-orchiddirectorypull-fixed-consensys-orchid-network-protocol-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes32 direct = current.parent\\_;\ncopy(pivot, last);\ncurrent.parent\\_ = stake.parent\\_;\n\nif (direct == key) {\n    Primary storage other = stake.before\\_ > stake.after\\_ ? stake.right\\_ : stake.left\\_;\n    if (!nope(other))\n        stakes\\_[name(other)].parent\\_ = name(last);\n\n    if (name(stake.left\\_) == key) {\n        current.right\\_ = stake.right\\_;\n        current.after\\_ = stake.after\\_;\n    } else {\n        current.left\\_ = stake.left\\_;\n        current.before\\_ = stake.before\\_;\n    }\n} else {\n    if (!nope(stake.left\\_))\n        stakes\\_[name(stake.left\\_)].parent\\_ = name(last);\n    if (!nope(stake.right\\_))\n        stakes\\_[name(stake.right\\_)].parent\\_ = name(last);\n\n    current.right\\_ = stake.right\\_;\n    current.after\\_ = stake.after\\_;\n\n    current.left\\_ = stake.left\\_;\n    current.before\\_ = stake.before\\_;\n\n    stake.parent\\_ = direct;\n    copy(last, staker, stakee);\n    step(key, stake, -current.amount\\_, current.parent\\_);\n    kill(last);\n\n",
        "// Remember this key so we can update `pivot` later\nbytes32 currentKey = name(last);\n\n// Remove `current` from the subtree rooted at `stake`\nstep(currentKey, current, -current.amount\\_, stake.parent\\_);\nkill(last);\n\n// Replace `stake` with `current`\ncurrent.left\\_ = stake.left\\_;\nif (!nope(current.left\\_))\n    stakes\\_[name(current.left\\_)].parent\\_ = currentKey;\ncurrent.right\\_ = stake.right\\_;\nif (!nope(current.right\\_))\n    stakes\\_[name(current.right\\_)].parent\\_ = currentKey;\ncurrent.before\\_ = stake.before\\_;\ncurrent.after\\_ = stake.after\\_;\ncurrent.parent\\_ = stake.parent\\_;\npivot.value\\_ = currentKey; // `pivot` was parent's pointer to `stake`\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This was addressed in the following commits:"
    ],
    "Description": [
        "pull() is the most complex function in OrchidDirectory, due to its need to handle removing a node altogether when its stake amount reaches 0.",
        "The current logic for removing an interior node is roughly this:",
        "The code for this is fairly complex, and one serious bug (issue 6.1) was identified in this code.",
        "This logic can be simplified by combining the two cases (direct child and not) and thinking of it as roughly a two-step operation of \u201cdetach leaf node\u201d and \u201creplace interior node with leaf node\u201d.",
        "(Note that in the code, \u201cold\u201d above is called stake and \u201ctarget\u201d is calledcurrent.)"
    ],
    "Recommendation": [
        "Replace this code:",
        "code/dir-ethereum/directory.sol:L266-L297",
        "with something like this code:"
    ]
}
----End JSON----

https://solodit.xyz/issues/collaterals-are-not-guaranteed-to-be-returned-after-a-batch-is-cancelled-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/fundraising#162"
    ],
    "Description": [
        "When traders open buy orders, they also transfer collateral tokens to the market maker contract. If the current batch is going to be cancelled, there is a chance that these collateral tokens will not be returned to the traders."
    ],
    "Examples": [
        "If a current collateralsToBeClaimed value is zero on a batch initialization and in this new batch only buy orders are submitted, collateralsToBeClaimed value will still stay zero.",
        "At the same time if in Tap contract tapped amount was bigger than _maximumWithdrawal() on batch initialisation, _maximumWithdrawal() will most likely increase when the traders transfer new collateral tokens with the buy orders. And a beneficiary will be able to withdraw part of these tokens. Because of that, there might be not enough tokens to withdraw by the traders if the batch is cancelled.",
        "It\u2019s partially mitigated by having floor value in Tap contract, but if there are more collateral tokens in the batch than floor, the issue is still valid."
    ],
    "Recommendation": [
        "Ensure that tapped is not bigger than _maximumWithdrawal()"
    ]
}
----End JSON----

https://solodit.xyz/issues/fees-can-be-changed-during-the-batch-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (fee > 0) {\n    reserve.transfer(\\_collateral, beneficiary, fee);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]0941f53 by storing current fee in meta batch."
    ],
    "Description": [
        "Shareholders can vote to change the fees. For buy orders, fees are withdrawn immediately when order is submitted and the only risk is frontrunning by the shareholder\u2019s voting contract.",
        "For sell orders, fees are withdrawn when a trader claims an order and withdraws funds in _claimSellOrder  function:",
        "code/apps/batched-bancor-market-maker/contracts/BatchedBancorMarketMaker.sol:L790-L792",
        "Fees can be changed between opening order and claiming this order which makes the fees unpredictable."
    ],
    "Recommendation": [
        "Fees for an order should not be updated during its lifetime."
    ]
}
----End JSON----

https://solodit.xyz/issues/bancor-formula-should-not-be-updated-during-the-batch-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function updateFormula(IBancorFormula \\_formula) external auth(UPDATE\\_FORMULA\\_ROLE) {\n    require(isContract(\\_formula), ERROR\\_CONTRACT\\_IS\\_EOA);\n\n    \\_updateFormula(\\_formula);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]a8c2e21 by storing a ref to the Formula with the meta batch."
    ],
    "Description": [
        "Shareholders can vote to change the bancor formula contract. That can make a price in the current batch unpredictable.",
        "code/apps/batched-bancor-market-maker/contracts/BatchedBancorMarketMaker.sol:L212-L216"
    ],
    "Recommendation": [
        "Bancor formula update should be executed in the next batch or with a timelock that is greater than batch duration."
    ]
}
----End JSON----

https://solodit.xyz/issues/maximum-slippage-shouldnt-be-updated-for-the-current-batch-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_slippageIsValid(Batch storage \\_batch, address \\_collateral) internal view returns (bool) {\n    uint256 staticPricePPM = \\_staticPricePPM(\\_batch.supply, \\_batch.balance, \\_batch.reserveRatio);\n    uint256 maximumSlippage = collaterals[\\_collateral].slippage;\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]aa4f03e by storing slippage with the batch."
    ],
    "Description": [
        "When anyone submits a new order, the batch price is updated and it\u2019s checked whether the price slippage is acceptable. The problem is that the maximum slippage can be updated during the batch and traders cannot be sure that price is limited as they initially expected.",
        "code/apps/batched-bancor-market-maker/contracts/BatchedBancorMarketMaker.sol:L487-L489",
        "Additionally, if a maximum slippage is updated to a lower value, some of the orders that should lower the current slippage will also revert."
    ],
    "Recommendation": [
        "Save a slippage value on batch initialization and use it during the current batch."
    ]
}
----End JSON----

https://solodit.xyz/issues/aragonfundraisingcontroller-an-untapped-address-in-toreset-can-block-attempts-of-opening-trading-after-presale-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint256 i = 0; i < \\_toReset.length; i++) {\n    require(\\_tokenIsContractOrETH(\\_toReset[i]), ERROR\\_INVALID\\_TOKENS);\n    toReset.push(\\_toReset[i]);\n}\n\n",
        "function openTrading() external auth(OPEN\\_TRADING\\_ROLE) {\n    for (uint256 i = 0; i < toReset.length; i++) {\n        tap.resetTappedToken(toReset[i]);\n    }\n\n    marketMaker.open();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]9451147 by checking if token is tapped. Gas consumption is increased due to external call to Tap to check if token is actually tapped. The number of tokens to be reset is capped."
    ],
    "Description": [
        "AragonFundraisingController can be initialized with a list of token addresses _toReset that are to be reset when trading opens after the presale. These addresses are supposed to be addresses of tapped tokens. However, the list needs to be known when initializing the contract but the tapped tokens are added after initialization when calling addCollateralToken (and tapped with _rate>0). This can lead to an inconsistency that blocks openTrading.",
        "code/apps/aragon-fundraising/contracts/AragonFundraisingController.sol:L99-L102",
        "In case a token address makes it into the list of toReset tokens that is not tapped it will be impossible to openTrading as tap.resetTappedToken(toReset[i]); throws for untapped tokens. According to the permission setup in FundraisingMultisigTemplate only Controller can call Marketmaker.open",
        "code/apps/aragon-fundraising/contracts/AragonFundraisingController.sol:L163-L169"
    ],
    "Recommendation": [
        "Instead of initializing the Controller with a list of tapped tokens to be reset when trading opens, add a flag to addCollateralToken to indicate that the token should be reset when calling openTrading, making sure only tapped tokens are added to this list. This also allows adding tapped tokens that are to be reset at a later point in time."
    ]
}
----End JSON----

https://solodit.xyz/issues/tap-payments-inconsistency-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_maximumWithdrawal(address \\_token) internal view returns (uint256) {\n    uint256 toBeClaimed = controller.collateralsToBeClaimed(\\_token);\n    uint256 floor = floors[\\_token];\n    uint256 minimum = toBeClaimed.add(floor);\n    uint256 balance = \\_token == ETH ? address(reserve).balance : ERC20(\\_token).staticBalanceOf(reserve);\n    uint256 tapped = (\\_currentBatchId().sub(lastWithdrawals[\\_token])).mul(rates[\\_token]);\n\n    if (minimum >= balance) {\n        return 0;\n    }\n\n    if (balance >= tapped.add(minimum)) {\n        return tapped;\n    }\n\n    return balance.sub(minimum);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/fundraising#162"
    ],
    "Description": [
        "Every time project managers want to withdraw tapped funds, the maximum amount of withdrawable funds is calculated in tap._maximumWithdrawal function. The method ensures that project managers can only withdraw unlocked funds (balance exceeding the collaterals minimum comprised of the collaterals configured floor including the minimum tokens to hold) even though their allowance might be higher.",
        "This means that in the case of (3) if there are not enough funds to withdraw tapped(time*tap_rate) amount of tokens, it gets truncated and only a part of tapped tokens gets withdrawn.",
        "code/apps/tap/contracts/Tap.sol:L239-L255",
        "The problem is that the remaining tokens (tapped - capped_tapped) cannot be claimed afterward and tapped value is reset to zero."
    ],
    "Remediation": [
        "In case the maximum withdrawal amount gets capped, the information about the remaining tokens that the project team should have been able to withdraw should be kept to allow them to withdraw the tokens at a later point in time when there are enough funds for it."
    ]
}
----End JSON----

https://solodit.xyz/issues/new-tapped-collaterals-can-be-bought-by-traders-wont-fix-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function \\_poolBalanceIsSufficient(address \\_collateral) internal view returns (bool) {\n    return controller.balanceOf(address(reserve), \\_collateral) >= collateralsToBeClaimed[\\_collateral];\n}\n\n",
        "function balanceOf(address \\_who, address \\_token) public view isInitialized returns (uint256) {\n    uint256 balance = \\_token == ETH ? \\_who.balance : ERC20(\\_token).staticBalanceOf(\\_who);\n\n    if (\\_who == address(reserve)) {\n        return balance.sub(tap.getMaximumWithdrawal(\\_token));\n    } else {\n        return balance;\n    }\n}\n\n",
        "function \\_tappedAmount(address \\_token) internal view returns (uint256) {\n    uint256 toBeKept = controller.collateralsToBeClaimed(\\_token).add(floors[\\_token]);\n    uint256 balance = \\_token == ETH ? address(reserve).balance : ERC20(\\_token).staticBalanceOf(reserve);\n    uint256 flow = (\\_currentBatchId().sub(lastTappedAmountUpdates[\\_token])).mul(rates[\\_token]);\n    uint256 tappedAmount = tappedAmounts[\\_token].add(flow);\n    /\\*\\*\n \\* whatever happens enough collateral should be\n \\* kept in the reserve pool to guarantee that\n \\* its balance is kept above the floor once\n \\* all pending sell orders are claimed\n \\*/\n\n    /\\*\\*\n \\* the reserve's balance is already below the balance to be kept\n \\* the tapped amount should be reset to zero\n \\*/\n    if (balance <= toBeKept) {\n        return 0;\n    }\n\n    /\\*\\*\n \\* the reserve's balance minus the upcoming tap flow would be below the balance to be kept\n \\* the flow should be reduced to balance - toBeKept\n \\*/\n    if (balance <= toBeKept.add(tappedAmount)) {\n        return balance.sub(toBeKept);\n    }\n\n    /\\*\\*\n \\* the reserve's balance minus the upcoming flow is above the balance to be kept\n \\* the flow can be added to the tapped amount\n \\*/\n    return tappedAmount;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This behaviour is intentional and if there is not a lot of funds in the pool, shareholders have a priority to buy tokens even if these tokens can already be withdrawn by the beneficiary. It is done in order to protect shareholders in case if the project is dying and running out of funds. The downside of this behaviour is that it creates an additional incentive for the beneficiary to withdraw tapped tokens as soon and as often as possible which creates a race condition."
    ],
    "Description": [
        "When a trader submits a sell order, _openSellOrder() function checks that there are enough tokens in reserve by calling _poolBalanceIsSufficient function",
        "code/apps/batched-bancor-market-maker/contracts/BatchedBancorMarketMaker.sol:L483-L485",
        "the problem is that because collateralsToBeClaimed[_collateral] has increased, controller.balanceOf(address(reserve), _collateral) could also increase. It happens so because controller.balanceOf() function subtracts tapped amount from the reserve\u2019s balance.",
        "code/apps/aragon-fundraising/contracts/AragonFundraisingController.sol:L358-L366",
        "And tap.getMaximumWithdrawal(_token) could decrease because it depends on collateralsToBeClaimed[_collateral]",
        "apps/tap/contracts/Tap.sol:L231-L264",
        "That means that the amount that beneficiary can withdraw has just decreased, which should not be possible."
    ],
    "Recommendation": [
        "Ensure that tappedAmount cannot be decreased once updated."
    ]
}
----End JSON----

https://solodit.xyz/issues/presale-contributiontoken-double-cast-and-invalid-comparison-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function contribute(address \\_contributor, uint256 \\_value) external payable nonReentrant auth(CONTRIBUTE\\_ROLE) {\n    require(state() == State.Funding, ERROR\\_INVALID\\_STATE);\n\n    if (contributionToken == ETH) {\n        require(msg.value == \\_value, ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\n    } else {\n        require(msg.value == 0,      ERROR\\_INVALID\\_CONTRIBUTE\\_VALUE);\n    }\n\n",
        "require(ERC20(\\_token).safeTransfer(\\_to, \\_amount), ERROR\\_TOKEN\\_TRANSFER\\_REVERTED);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]61f5803."
    ],
    "Description": [
        "The Presale can be configured to accept ETH or a valid ERC20 token. This token is stored as an ERC20 contract type in the state variable contributionToken. It is then directly compared to constant ETH which is address(0x0) in various locations. Additionally, the _transfer function double casts the token to ERC20 if the contributionToken is passed as an argument."
    ],
    "Examples": [
        "code/apps/presale/contracts/Presale.sol:L163-L170",
        "code/apps/presale/contracts/Presale.sol:L344-L344"
    ],
    "Recommendation": [
        "contributionToken can either be ETH or a valid ERC20 contract address. It is therefore recommended to store the token as an address type instead of the more precise contract type to resolve the double cast and the invalid contract type to address comparison or cast the ERC20 type to address() before comparison."
    ]
}
----End JSON----

https://solodit.xyz/issues/fees-are-not-returned-for-buy-orders-if-a-batch-is-canceled-wont-fix-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "uint256 fee = \\_value.mul(buyFeePct).div(PCT\\_BASE);\nuint256 value = \\_value.sub(fee);\n\n// collect fee and collateral\nif (fee > 0) {\n    \\_transfer(\\_buyer, beneficiary, \\_collateral, fee);\n}\n\\_transfer(\\_buyer, address(reserve), \\_collateral, value);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been addressed with the following statement:"
    ],
    "Description": [
        "Every trader pays fees on each buy order and transfers it directly to the beneficiary.",
        "code/apps/batched-bancor-market-maker/contracts/BatchedBancorMarketMaker.sol:L706-L713",
        "If the batch is canceled, fees are not returned to the traders because there is no access to the beneficiary account.",
        "Additionally, fees are returned to traders for all the sell orders if the batch is canceled."
    ],
    "Recommendation": [
        "Consider transferring fees to a beneficiary only after the batch is over."
    ]
}
----End JSON----

https://solodit.xyz/issues/tap-controller-should-not-be-updateable-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Update controller to `\\_controller`\n \\* @param \\_controller The address of the new controller contract\n\\*/\nfunction updateController(IAragonFundraisingController \\_controller) external auth(UPDATE\\_CONTROLLER\\_ROLE) {\n    require(isContract(\\_controller), ERROR\\_CONTRACT\\_IS\\_EOA);\n\n    \\_updateController(\\_controller);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]f6054443 by removing update functionality."
    ],
    "Description": [
        "Similar to the issue 6.11, Tap allows updating the Controller contract it is using. The permission is currently not assigned in the FundraisingMultisigTemplate but might be used in custom deployments.",
        "code/apps/tap/contracts/Tap.sol:L117-L125"
    ],
    "Recommendation": [
        "To avoid inconsistencies, we suggest to remove this functionality and provide a guideline on how to safely upgrade components of the system."
    ]
}
----End JSON----

https://solodit.xyz/issues/tap-reserve-can-be-updated-in-tap-but-not-in-marketmaker-or-controller-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n \\* @notice Update reserve to `\\_reserve`\n \\* @param \\_reserve The address of the new reserve [pool] contract\n\\*/\nfunction updateReserve(Vault \\_reserve) external auth(UPDATE\\_RESERVE\\_ROLE) {\n    require(isContract(\\_reserve), ERROR\\_CONTRACT\\_IS\\_EOA);\n\n    \\_updateReserve(\\_reserve);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]987720b1 by removing update functionality."
    ],
    "Description": [
        "The address of the pool/reserve contract can be updated in Tap if someone owns the UPDATE_RESERVE_ROLE permission. The permission is currently not assigned in the template.",
        "The reserve is being referenced by multiple Contracts. Tap interacts with it to transfer funds to the beneficiary, Controller adds new protected tokens, and MarketMaker transfers funds when someone sells their Shareholder token.",
        "Updating reserve only in Tap is inconsistent with the system as the other contracts are still referencing the old reserve unless they are updated via the Aragon Application update mechanisms.",
        "code/apps/tap/contracts/Tap.sol:L127-L135"
    ],
    "Recommendation": [
        "Remove the possibility to update reserve in Tap to keep the system consistent. Provide information about update mechanisms in case the reserve needs to be updated for all components."
    ]
}
----End JSON----

https://solodit.xyz/issues/presale-can-be-opened-earlier-than-initially-assigned-date-fixed-consensys-aragonblack-fundraising-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (\\_openDate != 0) {\n    \\_setOpenDate(\\_openDate);\n}\n\n",
        "function open() external auth(OPEN\\_ROLE) {\n    require(state() == State.Pending, ERROR\\_INVALID\\_STATE);\n\n    \\_open();\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed with AragonBlack/[email\u00a0protected]0726e29."
    ],
    "Description": [
        "There are 2 ways how presale opening date can be assigned. Either it\u2019s defined on initialization or the presale will start when open() function is executed.",
        "code/apps/presale/contracts/Presale.sol:L144-L146",
        "The problem is that even if openDate is assigned to some non-zero date, it can still be opened earlier by calling open() function.",
        "code/apps/presale/contracts/Presale.sol:L152-L156"
    ],
    "Recommendation": [
        "Require that openDate is not set (0) when someone manually calls the open() function."
    ]
}
----End JSON----

https://solodit.xyz/issues/anyone-can-remove-a-makers-pending-pool-join-status-fixed-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_poolById[poolId].numberOfMakers = uint256(pool.numberOfMakers).safeAdd(1).downcastToUint32();\n\n",
        "bytes32 makerPoolId = getStakingPoolIdOfMaker(makerAddress);\nif (makerPoolId != poolId) {\n    LibRichErrors.rrevert(LibStakingRichErrors.MakerPoolAssignmentError(\n        LibStakingRichErrors.MakerPoolAssignmentErrorCodes.MakerAddressNotRegistered,\n        makerAddress,\n        makerPoolId\n    ));\n}\n\n",
        "delete \\_poolJoinedByMakerAddress[makerAddress];\n\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2250 by removing the two-step handshake for a maker to join a pool."
    ],
    "Description": [
        "Using behavior described in https://github.com/ConsenSys/0x-v3-staking-audit-2019-10/issues/11, it is possible to delete the pending join status of any maker in any pool by passing in NIL_POOL_ID to removeMakerFromStakingPool. Note that the attacker in the following example must not be a confirmed member of any pool:",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L262",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L166-L173",
        "The check passes, and the target\u2019s _poolJoinedByMakerAddress struct is deleted. Additionally, the number of makers in pool 0 is decreased:",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L176-L177",
        "This can be used to prevent any makers from being confirmed into a pool."
    ],
    "Recommendation": [
        "See issue 5.6."
    ]
}
----End JSON----

https://solodit.xyz/issues/delegated-stake-weight-reduction-can-be-bypassed-by-using-an-external-contract-wont-fix-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "From the development team:"
    ],
    "Description": [
        "Staking pools allow ZRX holders to delegate their staked ZRX to a market maker in exchange for a configurable percentage of the stake reward (accrued over time through exchange fees). When staking as expected through the 0x contracts, the protocol favors ZRX staked directly by the operator of the pool, assigning a lower weight (90%) to ZRX staked by delegation. In return, delegated members receive a configurable portion of the operator\u2019s stake reward.",
        "Using a smart contract, it is possible to represent ZRX owned by any number of parties as ZRX staked by a single party. This contract can serve as the operator of a pool with a single member\u2014itself. The advantages are clear for ZRX holders:"
    ],
    "Recommendation": [
        "Remove stake weight reduction for delegated stake."
    ]
}
----End JSON----

https://solodit.xyz/issues/mixinparamssetparams-bypasses-safety-checks-made-by-standard-stakingproxy-upgrade-path-fixed-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Call `init()` on the staking contract to initialize storage.\n(bool didInitSucceed, bytes memory initReturnData) = stakingContract.delegatecall(\n    abi.encodeWithSelector(IStorageInit(0).init.selector)\n);\nif (!didInitSucceed) {\n    assembly {\n        revert(add(initReturnData, 0x20), mload(initReturnData))\n    }\n}\n  \n// Assert initialized storage values are valid\n\\_assertValidStorageParams();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2279. Now the parameter validity is asserted in setParams()."
    ],
    "Description": [
        "The staking contracts use a set of configurable parameters to determine the behavior of various parts of the system. The parameters dictate the duration of epochs, the ratio of delegated stake weight vs operator stake, the minimum pool stake, and the Cobb-Douglas numerator and denominator. These parameters can be configured in two ways:",
        "code/contracts/staking/contracts/src/StakingProxy.sol:L208-L219",
        "The latter method introduces the possibility of setting unsafe or nonsensical values for the contract parameters: epochDurationInSeconds can be set to 0, cobbDouglassAlphaNumerator can be larger than cobbDouglassAlphaDenominator, rewardDelegatedStakeWeight can be set to a value over 100% of the staking reward, and more.",
        "Note, too, that by using MixinParams.setParams to set all parameters to 0, the Staking contract can be re-initialized by way of Staking.init. Additionally, it can be re-attached by way of StakingProxy.attachStakingContract, as the delegatecall to Staking.init will succeed."
    ],
    "Recommendation": [
        "Ensure that calls to setParams check that the provided values are within the same range currently enforced by the proxy."
    ]
}
----End JSON----

https://solodit.xyz/issues/authorized-addresses-can-indefinitely-stall-zrxvaultbackstop-catastrophic-failure-mode-fixed-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @dev Set read-only mode (state cannot be changed).\nfunction setReadOnlyMode(bool shouldSetReadOnlyMode)\n    external\n    onlyAuthorized\n{\n    // solhint-disable-next-line not-rely-on-time\n    uint96 timestamp = block.timestamp.downcastToUint96();\n    if (shouldSetReadOnlyMode) {\n        stakingContract = readOnlyProxy;\n        readOnlyState = IStructs.ReadOnlyState({\n            isReadOnlyModeSet: true,\n            lastSetTimestamp: timestamp\n        });\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2295 by removing the ZrxVaultBackstop and read-only mode altogether."
    ],
    "Description": [
        "The ZrxVaultBackstop contract was added to allow anyone to activate the staking system\u2019s \u201ccatastrophic failure\u201d mode if the StakingProxy is in \u201cread-only\u201d mode for at least 40 days. To enable this behavior, the StakingProxy contract was modified to track the last timestamp at which \u201cread-only\u201d mode was activated. This is done by way of StakingProxy.setReadOnlyMode:",
        "code/contracts/staking/contracts/src/StakingProxy.sol:L92-L104",
        "Because the timestamp is updated even if \u201cread-only\u201d mode is already active, any authorized address can prevent ZrxVaultBackstop from activating catastrophic failure mode by repeatedly calling setReadOnlyMode."
    ],
    "Recommendation": [
        "If \u201cread-only\u201d mode is already active, setReadOnlyMode(true) should result in a no-op."
    ]
}
----End JSON----

https://solodit.xyz/issues/pool-0-can-be-used-to-temporarily-prevent-makers-from-joining-another-pool-fixed-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\n\n",
        "poolJoinStatus = IStructs.MakerPoolJoinStatus({\n    poolId: poolId,\n    confirmed: true\n});\n\\_poolJoinedByMakerAddress[makerAddress] = poolJoinStatus;\n\\_poolById[poolId].numberOfMakers = uint256(pool.numberOfMakers).safeAdd(1).downcastToUint32();\n\n",
        "delete \\_poolJoinedByMakerAddress[makerAddress];\n\\_poolById[poolId].numberOfMakers = uint256(\\_poolById[poolId].numberOfMakers).safeSub(1).downcastToUint32();\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2250. Pool IDs now start at 1."
    ],
    "Description": [
        "removeMakerFromStakingPool reverts if the number of makers currently in the pool is 0, due to safeSub catching an underflow:",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L177",
        "Because of this, edge behavior described in issue 5.6 can allow an attacker to temporarily prevent makers from joining a pool:",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L257-L262",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L176-L177",
        "Typically, the victim should be able to remove themselves from pool 0 by calling removeMakerFromStakingPool(NIL_POOL_ID, victimAddress), but because the attacker can set the pool\u2019s number of makers to 0, the aforementioned underflow causes this call to fail. The victim must first understand what is happening in MixinStakingPool before they are able to remedy the situation:",
        "Additionally, if the victim in question currently has a pending join, the attacker can use issue 5.1 to first remove their pending status before locking them in pool 0."
    ],
    "Recommendation": [
        "See issue 5.1."
    ]
}
----End JSON----

https://solodit.xyz/issues/recommendation-fix-weak-assertions-in-mixinstakingpool-stemming-from-use-of-nil_pool_id-fixed-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getStakingPoolIdOfMaker(address makerAddress)\n    public\n    view\n    returns (bytes32)\n{\n    IStructs.MakerPoolJoinStatus memory poolJoinStatus = \\_poolJoinedByMakerAddress[makerAddress];\n    if (poolJoinStatus.confirmed) {\n        return poolJoinStatus.poolId;\n    } else {\n        return NIL\\_POOL\\_ID;\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2250. Pool IDs now start at 1."
    ],
    "Description": [
        "The modifier onlyStakingPoolOperatorOrMaker(poolId) is used to authorize actions taken on a given pool. The sender must be either the operator or a confirmed maker of the pool in question. However, the modifier queries getStakingPoolIdOfMaker(maker), which returns NIL_POOL_ID if the maker\u2019s MakerPoolJoinStatus struct is not confirmed. This implicitly makes anyone a maker of the nonexistent \u201cpool 0\u201d:",
        "code/contracts/staking/contracts/src/staking_pools/MixinStakingPool.sol:L189-L200",
        "joinStakingPoolAsMaker(poolId) makes no existence checks on the provided pool id, and allows makers to become pending makers in nonexistent pools.",
        "addMakerToStakingPool(poolId, maker) makes no existence checks on the provided pool id, allowing makers to be added to nonexistent pools (as long as the sender is an operator or maker in the pool)."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/libfixedmath-functions-fail-to-catch-a-number-of-overflows-fixed-consensys-0x-v3-staking-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @dev Adds two numbers, reverting on overflow.\nfunction \\_add(int256 a, int256 b) private pure returns (int256 c) {\n    c = a + b;\n    if (c > 0 && a < 0 && b < 0) {\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\n            LibFixedMathRichErrors.BinOpErrorCodes.SUBTRACTION\\_OVERFLOW,\n            a,\n            b\n        ));\n    }\n    if (c < 0 && a > 0 && b > 0) {\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\n            LibFixedMathRichErrors.BinOpErrorCodes.ADDITION\\_OVERFLOW,\n            a,\n            b\n        ));\n    }\n}\n\n",
        "/// @dev Returns the multiplication two numbers, reverting on overflow.\nfunction \\_mul(int256 a, int256 b) private pure returns (int256 c) {\n    if (a == 0) {\n        return 0;\n    }\n    c = a \\* b;\n    if (c / a != b) {\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\n            LibFixedMathRichErrors.BinOpErrorCodes.MULTIPLICATION\\_OVERFLOW,\n            a,\n            b\n        ));\n    }\n}\n\n",
        "/// @dev Returns the division of two numbers, reverting on division by zero.\nfunction \\_div(int256 a, int256 b) private pure returns (int256 c) {\n    if (b == 0) {\n        LibRichErrors.rrevert(LibFixedMathRichErrors.BinOpError(\n            LibFixedMathRichErrors.BinOpErrorCodes.DIVISION\\_BY\\_ZERO,\n            a,\n            b\n        ));\n    }\n    c = a / b;\n}\n\n",
        "// if b is negative, then the result should be less than a\nif (b < 0 && c >= a) { /\\* subtraction overflow \\*/ }\n\n// if b is positive, then the result should be greater than a\nif (b > 0 && c <= a) { /\\* addition overflow \\*/ }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2255 and 0xProject/0x-monorepo#2311."
    ],
    "Description": [
        "The __add(), __mul(), and __div() functions perform arithmetic on 256-bit signed integers, and they all miss some specific overflows."
    ],
    "Addition Overflows": [
        "code/contracts/staking/contracts/src/libs/LibFixedMath.sol:L359-L376",
        "The two overflow conditions it tests for are:",
        "__add(-2**255, -2**255) returns 0 without reverting because the overflow didn\u2019t match either of the above conditions."
    ],
    "Multiplication Overflows": [
        "code/contracts/staking/contracts/src/libs/LibFixedMath.sol:L332-L345",
        "The function checks via division for most types of overflows, but it fails to catch one particular case. __mul(-2**255, -1) returns -2**255 without error."
    ],
    "Division Overflows": [
        "code/contracts/staking/contracts/src/libs/LibFixedMath.sol:L347-L357",
        "It does not check for overflow. Due to this, __div(-2**255, -1) erroneously returns -2**255."
    ],
    "Recommendation": [
        "For addition, the specific case of __add(-2**255, -2**255) can be detected by using a >= 0 check instead of > 0, but the below seems like a clearer check for all cases:",
        "For multiplication and division, the specific values of -2**255 and -1 are the only missing cases, so that can be explicitly checked in the __mul() and __div() functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-amplified-ddos-on-incubed-requests-on-proof-with-signature-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "{\n    \"jsonrpc\": \"2.0\",\n    \"id\": 2,\n    \"method\": \"eth\\_getTransactionByHash\",\n    \"params\": [\"0xf84cfb78971ebd940d7e4375b077244e93db2c3f88443bb93c561812cfed055c\"],\n    \"in3\": {\n        \"chainId\": \"0x1\",\n        \"verification\": \"proofWithSignature\",\n        \"signatures\":[\"0x784bfa9eb182C3a02DbeB5285e3dBa92d717E07a\", ALL OTHER SIGNERS HERE]\n  }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by adding maxBlocksSigned and maxSignatures for requests of any client. \u201cThe Numbers of signatures a client can ask to fetch is now limited to maxSignatures which defaults to 5\u201d in merge_requests/101. The full extent of this fix is outside the scope of this audit."
    ],
    "Description": [
        "It is possible for a client to send a request to each node of the network to request a signature with proof for every other node in the network. This can result in DDoSing the network as there are no costs for the client to request this and client can send the same request to all the nodes in the network, resulting in n^2 requests."
    ],
    "Examples": [
        "All the nodes are now sending requests to each other with signature required which is an expensive computation. This can go on for more transactions (or blocks, or other Eth_ requests) and can result in DDoS of the network."
    ],
    "Recommendation": [
        "Limit the number of signers in proof with signature requests. Also exclude self.signer from the list. This combined with the remediation of issue 6.6 can partially mitigate the attack vector."
    ]
}
----End JSON----

https://solodit.xyz/issues/blockproof-node-conviction-race-condition-may-trick-all-but-one-node-into-losing-funds-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// handle special jspn-rpc\nif (request.in3.verification.startsWith('proof'))\n  switch (request.method) {\n    case 'eth\\_getBlockByNumber':\n    case 'eth\\_getBlockByHash':\n    case 'eth\\_getBlockTransactionCountByHash':\n    case 'eth\\_getBlockTransactionCountByNumber':\n      return handleBlock(this, request)\n\n",
        "// create the proof\nresponse.in3 = {\n  proof: {\n    type: 'blockProof',\n    signatures: await collectSignatures(handler, request.in3.signatures, [{ blockNumber: toNumber(blockData.number), hash: blockData.hash }], request.in3.verifiedHashes)\n  }\n}\n\n",
        "const config = nodes.nodes.find(\\_ => \\_.address.toLowerCase() === adr.toLowerCase())\nif (!config) // TODO do we need to throw here or is it ok to simply not deliver the signature?\n  throw new Error('The ' + adr + ' does not exist within the current registered active nodeList!')\n\n",
        "// send the sign-request\nlet response: RPCResponse\ntry {\n  response = (blocksToRequest.length\n    ? await handler.transport.handle(config.url, { id: handler.counter++ || 1, jsonrpc: '2.0', method: 'in3\\_sign', params: blocksToRequest })\n    : { result: [] }) as RPCResponse\n  if (response.error) {\n    //throw new Error('Could not get the signature from ' + adr + ' for blocks ' + blocks.map(\\_ => \\_.blockNumber).join() + ':' + response.error)\n    logger.error('Could not get the signature from ' + adr + ' for blocks ' + blocks.map(\\_ => \\_.blockNumber).join() + ':' + response.error)\n    return null\n  }\n} catch (error) {\n  logger.error(error.toString())\n  return null\n}\n\n\n",
        "const convictSignature: Buffer = keccak(Buffer.concat([bytes32(s.blockHash), address(singingNode.address), toBuffer(s.v, 1), bytes32(s.r), bytes32(s.s)]))\n\nif (diffBlocks < 255) {\n\n  await callContract(handler.config.rpcUrl, nodes.contract, 'convict(uint,bytes32)', [s.block, convictSignature], {\n    privateKey: handler.config.privateKey,\n    gas: 500000,\n    value: 0,\n    confirm: true                       // we are not waiting for confirmation, since we want to deliver the answer to the client.\n  })\n\n  handler.watcher.futureConvicts.push({\n    convictBlockNumber: latestBlockNumber,\n    signer: singingNode.address,\n    wrongBlockHash: s.blockHash,\n    wrongBlockNumber: s.block,\n    v: s.v,\n    r: s.r,\n    s: s.s,\n    recreationDone: true\n  })\n}\nelse {\n  await handleRecreation(handler, nodes, singingNode, s, diffBlocks)\n}\n\n",
        "const costPerBlock = 86412400000000\nconst blocksMissing = latestSS - s.block\nconst costs = blocksMissing \\* costPerBlock \\* 1.25\n\nif (costs > (deposit / 2)) {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by:",
        "It should be noted that the changes are scattered and modified in the final source code, and this behaviour of IN3-server code is outside the scope of this audit."
    ],
    "Description": [
        "TLDR; One node can force all other nodes to convict a specific malicious signer controlled by the attacker and spend gas on something they are not going to be rewarded for. The attacker loses deposit but all other nodes that try to convict and recreate in the same block will lose the fees less or equal to deposit/2. Another variant forces the same node to recreate the blockheaders multiple times within the same block as the node does not check if it is already convicting/recreating blockheaders.",
        "Nodes can request various types of proofs from other nodes. For example, if a node requests a proof when calling one of the eth_getBlock* methods, the in3-server\u2019s method handleBlock will be called. The request should contain a list of addresses registered to the NodeRegistry that are requested to sign the blockhash.",
        "code/in3-server/src/modules/eth/EthHandler.ts:L105-L112",
        "in3-server will subsequently reach out to it\u2019s connected blockchain node execute the eth_getBlock* call to get the block data. If the block data is available the in3-server, it will try to collect signatures from the nodes that signature was requested from (request.in3.signatures, collectSignatures())",
        "code/in3-server/src/modules/eth/proof.ts:L237-L243",
        "If the node does not find the address it will throw an exception. Note that if this exception is not caught it will actually allow someone to boot nodes off the network - which is critical.",
        "code/in3-server/src/chains/signatures.ts:L58-L60",
        "If the address is valid and existent in the NodeRegistry the in3-node will ask the node to sign the blockhash of the requested blocknumber:",
        "code/in3-server/src/chains/signatures.ts:L69-L84",
        "For all the signed blockhashes that have been returned the in3-server will subsequently check if one of the nodes provided a wrong blockhash.",
        "We note that nodes might:",
        "In all these cases, the node will not be convicted, even though it was able to request other nodes to perform work.",
        "If another node signed a wrong blockhash the in3-server will automatically try to convict it. If the block is within the most recent 255 it will directly call convict() on the NodeRegistry (takes less gas). if it is an older block, it will try to recreate the blockchain in the RlockhashRegistry (takes more gas).",
        "code/in3-server/src/chains/signatures.ts:L128-L152",
        "The recreation and convict is only done if it is profitable for the node. (Note the issue mentioned in issue 6.13)",
        "code/in3-server/src/chains/signatures.ts:L209-L213",
        "A malicious node can exploit the hardcoded profit economics and the fact that in3-server implementation will try to auto-convict nodes in the following scenario:",
        "In this scenario one malicious node tries to trick another node into convicting a malicious signer while having to spend the maximum amount of gas to make it profitable for the node.",
        "The problem is, that the malicious node can ask multiple (or even all other nodes in the registry) to provide a blockproof and ask the malicious signer for a signed blockhash. All nodes will come to the conclusion that the signer returned an invalid hash and will try to convict the node. They will try to recreate the blockchain in the BlockhashRegistry for a barely profitable scenario. Since in3-nodes do not monitor the tx-pool they will not know that other nodes are already trying to convict the node. All nodes are going to spend gas on recreating the same blockchain in the BlockhashRegistry leading to all but the first transaction in the block to lose funds (up to deposit/2 based on the hardcoded costPerBlock)",
        "Another variant of the same issue is that nodes do not check if they already convicted another node (or recreated blockheaders). An attacker can therefore force a specific node to convict a malicious node multiple times before the nodes transactions are actually in a block as the nodes does not check if it is already convicting that node. The node might lose gas on the recreation/conviction process multiple times."
    ],
    "Recommendation": [
        "To reduce the impact of multiple nodes trying to update the blockhashRegistry at the same time and avoid nodes losing gas by recreating the same blocks over and over again, the BlockhashRegistry should require that the target blockhash for the blocknumber does not yet exist in the registry (similar to the issue mentioned in https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/24)."
    ]
}
----End JSON----

https://solodit.xyz/issues/noderegistry-front-running-attack-on-convict-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Blocknumber is removed from convict function, which removes any signal for an attacker in the scenario provided. However, the order of the transactions to convict a wrong signed hash is necessary to prevent any front-running attacks:",
        "The fixes were introduced in ecf2c6a6 and f4250c9a, although later on NodeRegistry contract was split in two other contracts NodeRegistryLogic and NodeRegistryData and further changes were done in the conviction flow in different commits."
    ],
    "Description": [
        "convict(uint _blockNumber, bytes32 _hash) and revealConvict() are designed to prevent front-running and they do so for the purpose they are designed for. However, if the malicious node, is still sending out the wrong blockhash for the convicted block, anyone seeing the initial convict transaction, can check the convicted blocknumber with the nodes and send his own revealConvict before the original sender.",
        "The original sender will be the one updating the block headers recreateBlockheaders(_blockNumber, _blockheaders), and the attacker can just watch for the update headers to perform this attack."
    ],
    "Recommendation": [
        "For the first attack vector, remove the blocknumber from the convict(uint _blockNumber, bytes32 _hash) inputs and just use the hash."
    ]
}
----End JSON----

https://solodit.xyz/issues/noderegistry-url-can-be-arbitrary-dns-resolvable-names-ips-and-even-localhost-or-private-subnets-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const config = nodes.nodes.find(\\_ => \\_.address.toLowerCase() === adr.toLowerCase())\nif (!config) // TODO do we need to throw here or is it ok to simply not deliver the signature?\n  throw new Error('The ' + adr + ' does not exist within the current registered active nodeList!')\n\n// get cache signatures and remaining blocks that have no signatures\nconst cachedSignatures: Signature[] = []\nconst blocksToRequest = blocks.filter(b => {\n  const s = signatureCaches.get(b.hash) && false\n  return s ? cachedSignatures.push(s) \\* 0 : true\n})\n\n// send the sign-request\nlet response: RPCResponse\ntry {\n  response = (blocksToRequest.length\n    ? await handler.transport.handle(config.url, { id: handler.counter++ || 1, jsonrpc: '2.0', method: 'in3\\_sign', params: blocksToRequest })\n    : { result: [] }) as RPCResponse\n  if (response.error) {\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been addressed with the following commits:",
        "It is a design decision to base the Node registry on URLs (DNS resolvable names). This has the implications outlined in this issue and they cannot easily be mitigated. Adding a delay until nodes can be used after registration only delays the problem. Assuming that an entity curates the registry or a whitelist is in place centralizes the system. Adding DNS record verification still allows an owner of a DNS entry to point its name to any IP address they would like it to point to. It certainly makes it harder to add RPC URLs with DNS names that are not in control of the attacker but it also adds a whole lot more complexity to the system (including manual steps performed by the node operator). In the end, the system allows IP based URLs in the registry which cannot be used for DNS validation.",
        "Note that the server code changes, and the new smart contract IN3WhiteList.sol are outside the scope of the original audit. We strongly recommend to reduce complexity and audit the final codebase before mainnet deployment."
    ],
    "Description": [
        "As outlined in issue 6.9 the NodeRegistry allows anyone to register nodes with arbitrary URLs. The url is then used by in3-server or clients to connect to other nodes in the system. Signers can only be convicted if they sign wrong blockhashes. However, if they never provide any signatures they can stay in the registry for as long as they want and sabotage the network.\nThe Registry implements an admin functionality that is available for the first year to remove misbehaving nodes (or spam entries) from the Registry. However, this is insufficient as an attacker might just re-register nodes after the minimum timeout they specify or spend some more finneys on registering more nodes. Depending on the eth-price this will be more or less profitable.",
        "From an attackers perspective the NodeRegistry is a good source of information for reconnaissance, allows to de-anonymize and profile nodes based on dns entries or netblocks or responses to in3_stats (https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/49), makes a good list of target for DoS attacks on the system or makes it easy to exploit nodes for certain yet unknown security vulnerabilities.",
        "Since nodes and potentially clients (not in scope) do not validate the rpc URL received from the NodeRegistry they will try to connect to whatever is stored in a nodes url entry.",
        "code/in3-server/src/chains/signatures.ts:L58-L75",
        "This allows for a wide range of attacks not limited to:",
        "Since none of the rpc endpoints provide signatures they cannot be convicted or removed (unless the unregisterKey does it within the first year. However, that will not solve the problem that someone can re-register the same URLs over and over again)"
    ],
    "Recommendation": [
        "It is a fundamental design decision of the system architecture to allow rpc urls in the Node Registry, therefore this issue can only be partially mitigated unless the system design is reworked. It is therefore suggested to add checks to both the registry contract (coarse validation to avoid adding invalid urls) and node implementations (rigorous validation of URL\u2019s and resolved IP addresses) and filter out any potentially harmful destinations."
    ]
}
----End JSON----

https://solodit.xyz/issues/malicious-clients-can-use-forks-or-reorgs-to-convict-honest-nodes-wont-fix-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Default value for past signed blocks is changed to 10 blocks. Slockit plans to use their off-chain channels to notify clients for planned forks. They also looking into using fork oracles in the future releases to detect planned hardforks to mitigate risks."
    ],
    "Description": [
        "In case of reorgs it is possible to have more than 6 blocks in a node that gets replaced by a new longer chain. Also for forks, such as upcoming Istanbul fork, it\u2019s common to have some nodes taking some time to update and they will be in the wrong chain for the time being. In both cases, in3-nodes are prone to sign blocks that are considered invalid in the main chain.\nMalicious nodes can catch these instances and convict the honest users in the main chain to get 50% of their deposits."
    ],
    "Recommendation": [
        "No perfect solution comes to mind at this time. One possible mitigation method for forks could be to disable the network on the time of the fork but this is most certainly going to be a threat to the system itself."
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-should-protect-itself-from-abusive-clients-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "private checkPerformanceLimits(request: RPCRequest) {\n  if (request.method === 'eth\\_call') {\n    if (!request.params || request.params.length < 2) throw new Error('eth\\_call must have a transaction and a block as parameters')\n    const tx = request.params as TxRequest\n    if (!tx || (tx.gas && toNumber(tx.gas) > 10000000)) throw new Error('eth\\_call with a gaslimit > 10M are not allowed')\n  }\n  else if (request.method === 'eth\\_getLogs') {\n    if (!request.params || request.params.length < 1) throw new Error('eth\\_getLogs must have a filter as parameter')\n    const filter: LogFilter = request.params[0]\n    let toB = filter && filter.toBlock\n    if (toB === 'latest' || toB === 'pending' || !toB) toB = this.watcher && this.watcher.block && this.watcher.block.number\n    let fromB = toB && filter && filter.fromBlock\n    if (fromB === 'earliest') fromB = 1;\n    const range = fromB && (toNumber(toB) - toNumber(fromB))\n    if (range > (request.in3.verification.startsWith('proof') ? 1000 : 10000))\n      throw new Error('eth\\_getLogs for a range of ' + range + ' blocks is not allowed. limits: with proof: 1000, without 10000 ')\n  }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Slockit implemented their own DOS protection for incubed server in merge_requests/99. The variant of this implementation adds more complexity to the code base. The benchmark and testing of the new DOS protection is not in scope for this audit."
    ],
    "Description": [
        "The in3-node implementation should provide features for client request throttling to avoid that a client can consume most of the nodes resources by causing a lot of resource intensive requests.",
        "This is a general problem to the system which is designed to make sure that low resource clients can verify blockchain properties. What this means is that almost all of the client requests are very lightweight. Clients can request nodes to sign data for them. A sign request involves cryptographic operations and a http-rpc request to a back-end blockchain node. The imbalance is clearly visible in the case of blockProofs where a client may request another node to interact with a smart contract (NodeRegistry) and ask other nodes to sign blockhashes. All other nodes will have to get the requested block data from their local blockchain nodes and the incubed node requesting the signatures will have to wait for all responses. The client instead only has to send out that request once and may just leave that tcp connection open. It might even consume more resources from a specific node by requesting the same signatures again and again not even waiting for a response but causing a lot of work on the node that has to collect all the signatures. This combined with unbound requests for signatures or other properties can easily be exploited by a powerful client implementation with a mission to stall the whole incubed network."
    ],
    "Recommendation": [
        "According to the threat model outlines a general DDoS scenario specific to rpcUrls. It discusses that the nodes are themselves responsible for DDoS protection. However, DDoS protection is a multi-layer approach and it is highly unlikely that every node-operator will hide their nodes behind a DDoS CDN like cloudflare. We therefore suggest to also build in strict limitations for clients that can be checked in code. Similar to checkPerformanceLimits which is just checking for some specific it is suggested to implement a multi-layer throttling mechanism that prevents nodes from being abused by single clients. Methods must be designed with (D)DoS scenarios in mind to avoid that third parties are abusing the network for DDoS campaigns or trying to DoS the incubed network.",
        "code/in3-server/src/modules/eth/EthHandler.ts:L74-L91"
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-dos-on-in3sign-and-other-requests-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Similar to https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/50, Mitigated by adding maxBlocksSigned and maxSignatures for requests of any client. \u201cThe Numbers of signatures a client can ask to fetch is now limited to maxSignatures which defaults to 5\u201d in merge_requests/101. The full extent of this fix is outside the scope of this audit."
    ],
    "Description": [
        "It is free for the client to ask the nodes to sign block hashes (and also other requests).\nin3.sign([{\"blockNumber\": 123}]) Takes an array of objects that will result in multiple requests in the node. This sample request has (at least) two internal requests, one eth_getBlockByNumber and signing the block hash.",
        "These requests can be continuously sent out to clients and result in using computation power of the nodes without any expense from the client."
    ],
    "Examples": [
        "Request to get and sign the first 200 blocks:",
        "web3.manager.request_blocking(\"in3_sign\", [{'blockNumber':i} for i in range(200)])"
    ],
    "Recommendation": [
        "Limit the number of blocks (input), or do not accept arrays for input."
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-key-management-pending-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "{\n  \"privateKey\": \"0xc858a0f49ce12df65031ba0eb0b353abc74f93f8ccd43df9682fd2e2293a4db3\",\n  \"rpcUrl\": \"http://rpc-kovan.slock.it\"\n}\n\n",
        "\"docker-run\": \"docker run -p 8500:8500 docker.slock.it/slockit/in3-server:latest --privateKey=0x3858a0f49ce12df65031ba0eb0b353abc74f93f8ccd43df9682fd2e2293a4db3 --chain=0x2a --rpcUrl=https://kovan.infura.io/HVtVmCIHVgqHGUgihfhX --minBlockHeight=6 --registry=0x013b82355a066A31427df3140C5326cdE9c64e3A --persistentFile=false --logging-host=logs7.papertrailapp.com --logging-name=Papertrail --logging-port=30571 --logging-type=winston-papertrail\",\n\"docker-setup\": \"docker run -p 8500:8500 slockit/in3-server:latest --privateKey=0x3858a0f49ce12df65031ba0eb0b353abc74f93f8ccd43df9682fd2e2293a4db3 --chain=0x2a --rpcUrl=https://kovan.infura.io/HVtVmCIHVgqHGUgihfhX --minBlockHeight=6 --registry=0x013b82355a066A31427df3140C5326cdE9c64e3A --persistentFile=false --autoRegistry-url=https://in3.slock.it/kovan1 --autoRegistry-capabilities-proof=true --autoRegistry-capabilities-multiChain=true --autoRegistry-deposit=1\",\n\"local\": \"export NODE\\_ENV=0 && npm run build && node ./js/src/server/server.js --privateKey=0xD231FCF9349A296F555A060A619235F88650BBA795E5907CFD7F5442876250E4 --chain=0x2a --rpcUrl=https://rpc.slock.it/kovan --minBlockHeight=6 --registry=0x27a37a1210df14f7e058393d026e2fb53b7cf8c1 --persistentFile=false\",\n\"ipfs\": \"docker run -d -p 5001:5001 jbenet/go-ipfs daemon --offline\",\n\"linkIn3\": \"cd node\\_modules; rm -rf in3; ln -s ../../in3 in3; cd ..\",\n\"lint:solium\": \"node node\\_modules/ethlint/bin/solium.js -d contracts/\",\n\"lint:solium:fix\": \"node node\\_modules/ethlint/bin/solium.js -d contracts/ --fix\",\n\"lint:solhint\": \"node node\\_modules/solhint/solhint.js \\\"contracts/\\*\\*/\\*.sol\\\" -w 0\",\n\"local-env\": \"export NODE\\_ENV=0 && npm run build && node ./js/src/server/server.js --privateKey=0x9e53e6933d69a28a737943e227ad013c7489e366f33281d350c77f089d8411a6 --chain=0x111 --rpcUrl=http://localhost:8545 --minBlockHeight=6 --registry=0x31636f91297C14A8f1E7Ac271f17947D6A5cE098 --persistentFile=false --autoRegistry-url=http://127.0.0.1:8500 --autoRegistry-capabilities-proof=true --autoRegistry-capabilities-multiChain=true --autoRegistry-deposit=0\",\n\"local-env2\": \"export NODE\\_ENV=0 && npm run build && node ./js/src/server/server.js --privateKey=0xf7db260e6edcdfe396d75f8283aad5aed835815f7d1db4458896310553a8a1a9 --chain=0x111 --rpcUrl=http://localhost:8545 --minBlockHeight=6 --registry=0x31636f91297C14A8f1E7Ac271f17947D6A5cE098 --persistentFile=false --autoRegistry-url=http://127.0.0.1:8501 --autoRegistry-capabilities-proof=true --autoRegistry-capabilities-multiChain=true --autoRegistry-deposit=0\",\n\"local-env3\": \"export NODE\\_ENV=0 && npm run build && node ./js/src/server/server.js --privateKey=0xf7db260e6edcdfe396d75f8283aad5aed835815f7d1db4458896310553a8a1a9 --chain=0x5 --rpcUrl=https://rpc.slock.it/goerli --minBlockHeight=6 --registry=0x85613723dB1Bc29f332A37EeF10b61F8a4225c7e --persistentFile=false\",\n\"local-env4\": \"export NODE\\_ENV=0 && npm run build && node ./js/src/server/server.js --privateKey=0xf7db260e6edcdfe396d75f8283aad5aed835815f7d1db4458896310553a8a1a9 --chain=0x2a --rpcUrl=https://rpc.slock.it/kovan --minBlockHeight=6 --registry=0x27a37a1210df14f7e058393d026e2fb53b7cf8c1 --persistentFile=false\"\n\n",
        "const key = toBuffer(txargs.privateKey)\n\n",
        "const txHash = await transport.handle(url, {\n  jsonrpc: '2.0',\n  id: idCount++,\n  method: 'eth\\_sendRawTransaction',\n  params: [toHex(tx.serialize())]\n}).then((\\_: RPCResponse) => \\_.error ? Promise.reject(new SentryError('Error sending tx', 'tx\\_error', 'Error sending the tx ' + JSON.stringify(txargs) + ':' + JSON.stringify(\\_.error))) as any : \\_.result + '')\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The breakdown of the fixes addressed with git.slock.it/PR/13 are as follows:",
        "The private key in code/in3-server/config.json has been removed.\nThe repository still contains private keys at least in the following locations:",
        "Note that private keys indexed by a git repository can be restored from the repository history.",
        "The following statement has been provided to address this issue:",
        "The following statement has been provided to address this issue:",
        "Addressed by wrapping the private key in an object that stores the key in encrypted form and only decrypts it when signing. The key is cleared after usage. The IN3-server still allows raw private keys to be configured. A warning is printed if that is the case. The loaded raw private key is temporarily assigned to a local variable and not explicitly cleared by the method.",
        "see previous remediation note.",
        "The following statement has been provided to address this issue",
        "The following statement has been provided to address this issue",
        "Fixed by generating the address for a private key once and storing it in a private key wrapper object.",
        "txArgs still contains a field privateKey as outlined in the issue description. However, this privateKey now represents the wrapper object noted in a previous comment which only provides access to the ETH address generated from the raw private key.",
        "The following statement has been provided to address this issue:"
    ],
    "Description": [
        "Secure and efficient key management is a challenge for any cryptographic system. Incubed nodes for example require an account on the ethereum blockchain to actively participate in the incubed network. The account and therefore a private-key is used to sign transactions on the ethereum blockchain and to provide signed proofs to other in3-nodes.",
        "This means that an attacker that is able to discover the keys used by an in3-server by any mechanism may be able to impersonate that node, steal the nodes funds or sign wrong data on behalf of the node which might also lead to a loss of funds.",
        "The private key for the in3-server can be specified in a configuration file called config.json residing in the program working dir. Settings from the config.json can be overridden via command-line options. The application keeps configuration parameters available internally in an IN3RPCConfig object and passes this object as an initialization parameter to other objects.",
        "The key can either be provided in plaintext as a hex-string starting with 0x or within an ethereum keystore format compatible protected keystore file. Either way it is provided it will be held in plaintext in the object.",
        "The application accepts plaintext private keys and the keys are stored unprotected in the applications memory in JavaScript objects. The in3-server might even re-use the nodes private key which may weaken the security provided by the node. The repository leaks a series of presumably \u2018test private keys\u2019 and the default config file already comes with a private key set that might be shared across unvary users that fail to override it.",
        "code/in3-server/config.json:L1-L4",
        "code/in3-server/package.json:L20-L31",
        "The private key is also passed as arguments to other functions. In error cases these may leak the private key to log interfaces or remote log aggregation instances (sentry). See txargs.privateKey in the example below:",
        "code/in3-server/src/util/tx.ts:L100-L100",
        "code/in3-server/src/util/tx.ts:L134-L140"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/noderegistry-multiple-nodes-can-share-slightly-different-rpc-url-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes32 urlHash = keccak256(bytes(\\_url));\n\n// make sure this url and also this owner was not registered before.\n// solium-disable-next-line\nrequire(!urlIndex[urlHash].used && signerIndex[\\_signer].stage == Stages.NotInUse,\n    \"a node with the same url or signer is already registered\");\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Same mitigation as issue 6.4."
    ],
    "Description": [
        "One of the requirements for Node registration is to have a unique URL which is not already used by a different owner. The uniqueness check is done by hashing the provided _url and checking if someone already registered with that hash of _url.",
        "However, byte-equality checks (via hashing in this case) to enforce uniqueness will not work for URLs. For example, while the following URLs are not equal and will result in different urlHashes they can logically be the same end-point:",
        "code/in3-contracts/contracts/NodeRegistry.sol:L547-L553",
        "This leads to the following attack vectors:"
    ],
    "Recommendation": [
        "Canonicalize URLs, but that will not completely prevent someone from registering nodes for other end-points or websites. Nodes can be removed by an admin in the first year but not after that. Rogue owners cannot be prevented from registering random nodes with high weights and minimum deposit. They cannot be convicted as they do not serve proofs. Rogue owners can still unregister to receive their deposit after messing with the system."
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-should-enforce-safe-settings-for-minblockheight-wont-fix-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "minBlockHeight: 6,\n\n",
        "const blockHeight = handler.config.minBlockHeight === undefined ? 6 : handler.config.minBlockHeight\n\n",
        "const tooYoungBlock = blockData.find(block => toNumber(blockNumber) - toNumber(block.number) < blockHeight)\nif (tooYoungBlock)\n  throw new Error(' cannot sign for block ' + tooYoungBlock.number + ', because the blockHeight must be at least ' + blockHeight)\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "The default block is changed to 10 and minBlockHeight is added to the registry\n(as part of the properties) in 8c72633e, but allow the user to define a minBlockHeight lower than this number. The client is responsible to review the settings depending on how secure they want their nodes to be.",
        "Client response:"
    ],
    "Description": [
        "A node that is signing wrong blockhashes might get their deposit slashed from the registry. The entity that is convicting a node that signs a wrong blockhash is awarded half of the deposit.",
        "A threat to this kind of system is that blocks might constantly be reorganized in the chain, especially with the latest block. Allowing a node to sign the latest block will definitely put the node\u2019s deposit at stake with every signature they provide.",
        "A node can configure the minBlockHeight it is about to sign with a configurative option. The option defaults to a minBlockHeight of 6 in the default config:",
        "code/in3-server/src/server/config.ts:L32-L32",
        "And again in the signing function for blockheaders:",
        "code/in3-server/src/chains/signatures.ts:L189-L189",
        "handleSign will refuse to sign any block that is within the last 5 blocks. The 6th block will be signed.",
        "code/in3-server/src/chains/signatures.ts:L190-L193",
        "However, a user is not prevented from configuring an insecure minBlockHeight (e.g. 0) which will very likely lead to the loss of funds because the node will be signing the latest block.",
        "The current default of 6 blocks leads to an approximate lag of 14 (avg blocktime) *6 (blocks) = 84 seconds. While this is a favorable setting because it allows nodes to provide signatures for blocks that are at least older than 6 blocks it might still not be secure. For example, CryptoExchange Kraken requires at least 30 confirmation (abt. 6 minutes) until a transaction is confirmed. For Bitcoin it is said to be safe to wait more than 6 blocks (abt. 1 hr) for a transaction to be confirmed. ETC even underwent a deep chain reorg that could have caused many nodes to lose their deposits. The ethereum whitepaper defines an uncle that can be referenced in a block to have the following property: It must be a direct child of the k-th generation ancestor of B, where 2 <= k <= 7. This suggests that k=7\u2018th block can at least still be an uncle. Bitfinex requires a minimum of 10 confirmations. Some blockchain explorers and analytics tools also require a minimum of 10 confirmations. Scraped data from https://etherscan.io/blocks_forked?ps=100 shows 3 forks of depth 3 since they started keeping records 115 days ago, and no forks deeper than 3. So some applications might legitimately pick a number somewhere between 5 and 20, trading some security for better UX. However, it should be re-evaluated whether the current default provides enough security to protect the nodes funds with a trade-off of lag to the network.",
        "Given these values it is suggested to revalidate the default of a minBlockHeight of 6 in favor of a more secure depth to make sure that - with a default setting - nodes will not lose funds in case of re-orgs."
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/in3-server-rpc-proof-handler-specification-inconsistency-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (request.in3.verification.startsWith('proof'))\n  switch (request.method) {\n    case 'eth\\_getBlockByNumber':\n    case 'eth\\_getBlockByHash':\n    case 'eth\\_getBlockTransactionCountByHash':\n    case 'eth\\_getBlockTransactionCountByNumber':\n      return handleBlock(this, request)\n\n",
        "// create the proof\nresponse.in3 = {\n  proof: {\n    type: 'blockProof',\n    signatures: await collectSignatures(handler, request.in3.signatures, [{ blockNumber: toNumber(blockData.number), hash: blockData.hash }], request.in3.verifiedHashes)\n  }\n}\n\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Addressed with https://git.slock.it/in3/ts/in3-server/issues/100. Checks for proof and proofWithSignature are more strict now, never is not checked and assumed to be the default. Falling back to no security as a default is not considered best practice. signatures has been renamed to the more accurate name signers. The client now allows both signers and signatures and we suggest already to start planning to phase-out this ambiguity, strictly enforce the specified protocol and reduce special cases and complexity in future iterations."
    ],
    "Description": [
        "According to the specification incubed requests must specify whether they want to have a proof or not. There are three variants of proofs that can be requested:",
        "Note that the name signatures for the array of signers a blockhash signature is requested from is misleading. It is actually signer addresses as listed in the NodeRegistry and not signatures.",
        "Following the in3-server we found at least one inconsistency (and suspect more) with the proof requested by a client. The graceful check for the existence of something starting with proof will pass proof and proofWithSignature but also any other proofXYZ to the blockproof handler.",
        "code/in3-server/src/modules/eth/EthHandler.ts:L106-L112",
        "Following through handleBlock we cannot find any check for proofWithSignature. The string is not found in the whole codebase which also suggests it is not tested. However, the code assumes that because request.in3.signatures is not empty, signatures were requested. This is inconsistent with the specification and a protocol violation.",
        "code/in3-server/src/modules/eth/proof.ts:L237-L244",
        "The same is valid for all other types of proofs. proofWithSignature is never checked and it is assumed that proofWithSignature was requested just because request.in3.signatures is present non-empty.",
        "The same is true for \u2018never\u2019 which is actually never handled in code."
    ],
    "Recommendation": [
        "The protocol should be strictly enforced without allowing any ambiguities and unsharpness. Ambiguities and gracefulness in the protocol can lead to severe inconsistencies and encourage client authors to not strictly adhere to the protocol. This makes it hard to update and maintain the protocol in the future and may allow potential attackers enough freedom to exploit the protocol. Furthermore the specification must be kept up-to-date at all times. The specification is to lead development and code must always be verified against the specification."
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-hardcoded-gas-limit-could-result-in-failed-transactionsrequests-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "await callContract(handler.config.rpcUrl, nodes.contract, 'convict(uint,bytes32)', [s.block, convictSignature], {\n  privateKey: handler.config.privateKey,\n  gas: 500000,\n  value: 0,\n  confirm: true                       // we are not waiting for confirmation, since we want to deliver the answer to the client.\n})\n\n",
        "await callContract(handler.config.rpcUrl, blockHashRegistry, 'recreateBlockheaders(uint,bytes[])', [latestSS - diffBlock, txArray], {\n  privateKey: handler.config.privateKey,\n  gas: 8000000,\n  value: 0,\n  confirm: true                       // we are not waiting for confirmation, since we want to deliver the answer to the client.\n})\n\n",
        "  if (!tx || (tx.gas && toNumber(tx.gas) > 10000000)) throw new Error('eth\\_call with a gaslimit > 10M are not allowed')\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by using web3 eth_estimateGas in merge_requests/109 to dynamically price the gas according to the network state."
    ],
    "Description": [
        "There are many instances of hardcoded gas limit in in3-server that depending on the complexity of the transaction or gas cost changes in Ethereum could result in failed transactions."
    ],
    "Examples": [
        "convict():",
        "code/in3-server/src/chains/signatures.ts:L132-L137",
        "recreateBlockheaders():",
        "code/in3-server/src/chains/signatures.ts:L275-L280",
        "Other instances of hard coded gasLimit or gasPrice:",
        "code/in3-server/src/modules/eth/EthHandler.ts:L78-L79"
    ],
    "Recommendation": [
        "Use web3 gas estimate instead. To be sure, there can be an additional gas added to the estimated value or max(HARDCODED_GAS, estimated_amount)"
    ]
}
----End JSON----

https://solodit.xyz/issues/in3-server-handlerecreation-tries-to-recreate-blockchain-if-no-block-is-available-to-recreate-it-from-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "const [, deposit, , , , , , ,] = await callContract(handler.config.rpcUrl, nodes.contract, 'nodes(uint):(string,uint,uint64,uint64,uint128,uint64,address,bytes32)', [toNumber(singingNode.index)])\nconst latestSS = toNumber((await callContract(handler.config.rpcUrl, blockHashRegistry, 'searchForAvailableBlock(uint,uint):(uint)', [s.block, diffBlocks]))[0])\nconst costPerBlock = 86412400000000\nconst blocksMissing = latestSS - s.block\nconst costs = blocksMissing \\* costPerBlock \\* 1.25\n\nif (costs > (deposit / 2)) {\n\n  console.log(\"not worth it\")\n  //it's not worth it\n  return\n}\nelse {\n\n  // it's worth convicting the server\n  const blockrequest = []\n  for (let i = 0; i < blocksMissing; i++) {\n    blockrequest.push({\n      jsonrpc: '2.0',\n      id: i + 1,\n      method: 'eth\\_getBlockByNumber', params: [\n        toHex(latestSS - i), false\n      ]\n    })\n  }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by 502b5528 by falling back to using the current block in case searchForAvailableBlock returns 0. Costs can be zero, but cannot be negative anymore.",
        "The behaviour of the IN3-server code is outside the scope of this audit. However, while verifying the fixes for this specific issue it was observed that the watch.ts:handleConvict() relies on a static hardcoded cost calculation. We further note that the cost calculation formula has an error and is missing parentheses to avoid that costs can be zero. We did not see a reason for the costs not to be allowed to be zero. Furthermore, costs are calculated based on the difference of the conviction block to the latest block. Actual recreation costs can be less if there is an available block in blockhashRegistry to recreate it from that is other than the latest block."
    ],
    "Description": [
        "A node that wants to convict another node for false proof must update the BlockhashRegistry for signatures provided in blocks older than the most recent 256 blocks. Only when the smart contract is able to verify that the signed blockhash is wrong the convicting node will be able to receive half of its deposit.",
        "The in3-server implements an automated mechanism to recreate blockhashes. It first searches for an existing blockhash within a range of blocks. If one is found and it is profitable (gas spend vs. amount awarded) the node will try to recreate the blockchain updating the registry.",
        "code/in3-server/src/chains/signatures.ts:L207-L231",
        "Please note that certain parts of the code rely on hardcoded gas values. Gas economics might change with future versions of the evm and have to be re-validated with every version. It is also good practice to provide inline comments about how and on what base certain values were selected."
    ],
    "Recommendation": [
        "Verify that the call succeeds and returns valid values. Check if the block already exists in the BlockhashRegistry and avoid recreation. Also note that searchForAvailableBlock can wrap with values close to uint_max even though that is unlikely to happen. In general, return values for external calls should be validated more rigorously."
    ]
}
----End JSON----

https://solodit.xyz/issues/impossible-to-remove-malicious-nodes-after-the-initial-period-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @dev only callable in the 1st year after deployment\nfunction removeNodeFromRegistry(address \\_signer)\n    external\n    onlyActiveState(\\_signer)\n{\n\n    // solium-disable-next-line security/no-block-members\n    require(block.timestamp < (blockTimeStampDeployment + YEAR\\_DEFINITION), \"only in 1st year\");// solhint-disable-line not-rely-on-time\n    require(msg.sender == unregisterKey, \"only unregisterKey is allowed to remove nodes\");\n\n    SignerInformation storage si = signerIndex[\\_signer];\n    In3Node memory n = nodes[si.index];\n\n    unregisterNodeInternal(si, n);\n\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue has been addressed with a large change-set that splits the NodeRegistry into two contracts, which results in a code flow that mitigates this issue by making the logic contract upgradable (after 47 days of notice).\nThe resolution adds more complexity to the system, and this complexity is not covered by the original audit. Splitting up the contracts has the side-effect of events being emitted by two different contracts, requiring nodes to subscribe to both contracts' events.",
        "The need for removing malicious nodes from the registry, arises from the design decision to allow anyone to register any URL. These URLs might not actually belong to the registrar of the URL and might not be IN3 nodes. This is partially mitigated by a centralization feature introduced in the mitigation phase that implements whitelist functionality for adding nodes.",
        "We generally advocate against adding complexity, centralization and upgrading mechanisms that can allow one party to misuse functionalities of the contract system for their benefit (e.g. adminSetNodeDeposit is only used to reset the deposit but allows the Logic contract to set any deposit; the logic contract is set by the owner and there is a 47 day timelock).",
        "We believe the solution to this issue, should have not been this complex. The trust model of the system is changed with this solution, now the logic contract can allow the admin a wide range of control over the system state and data.",
        "The following statement has been provided with the change-set:"
    ],
    "Description": [
        "The system has centralized power structure for the first year after deployment. An unregisterKey (creator of the contract) is allowed to remove Nodes that are in state Stages.Active from the registry, only in 1st year.",
        "However, there is no possibility to remove malicious nodes from the registry after that.",
        "code/in3-contracts/contracts/NodeRegistry.sol:L249-L264"
    ],
    "Recommendation": [
        "Provide a solution for the network to remove fraudulent node entries. This could be done by voting mechanism (with staking, etc)."
    ]
}
----End JSON----

https://solodit.xyz/issues/noderegistryregisternodefor-no-replay-protection-and-expiration-wont-fix-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "bytes32 tempHash = keccak256(\n    abi.encodePacked(\n        \\_url,\n        \\_props,\n        \\_timeout,\n        \\_weight,\n        msg.sender\n    )\n);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue was addressed with the following statement:"
    ],
    "Description": [
        "An owner can register a node with the signer not being the owner by calling registerNodeFor. The owner submits a message signed for the owner including the properties of the node including the url.",
        "code/in3-contracts/contracts/NodeRegistry.sol:L215-L223"
    ],
    "Recommendation": [
        "Include registryID and an expiration timestamp that is checked in the contract with the signed data. Validate function arguments."
    ]
}
----End JSON----

https://solodit.xyz/issues/blockhashregistry-structure-of-provided-blockheaders-should-be-validated-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function getParentAndBlockhash(bytes memory \\_blockheader) public pure returns (bytes32 parentHash, bytes32 bhash) {\n\n    /// we need the 1st byte of the blockheader to calculate the position of the parentHash\n    uint8 first = uint8(\\_blockheader[0]);\n\n    /// calculates the offset\n    /// by using the 1st byte (usually f9) and substracting f7 to get the start point of the parentHash information\n    /// we also have to add \"2\" = 1 byte to it to skip the length-information\n    require(first > 0xf7, \"invalid offset\");\n    uint8 offset = first - 0xf7 + 2;\n\n    /// we are using assembly because it's the most efficent way to access the parent blockhash within the rlp-encoded blockheader\n    // solium-disable-next-line security/no-inline-assembly\n    assembly { // solhint-disable-line no-inline-assembly\n        // mstore to get the memory pointer of the blockheader to 0x20\n        mstore(0x20, \\_blockheader)\n\n        // we load the pointer we just stored\n        // then we add 0x20 (32 bytes) to get to the start of the blockheader\n        // then we add the offset we calculated\n        // and load it to the parentHash variable\n        parentHash :=mload(\n            add(\n                add(\n                    mload(0x20), 0x20\n                ), offset)\n        )\n    }\n    bhash = keccak256(\\_blockheader);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Mitigated by:",
        "Additionally we would like to note the following:",
        "We would also like to note that the commit referenced as mitigation does not appear to be based on the audit code."
    ],
    "Description": [
        "getParentAndBlockhash takes an rlp-encoded blockheader blob, extracts the parent parent hash and returns both the parent hash and the calculated blockhash of the provided data. The method is used to add blockhashes to the registry that are older than 256 blocks as they are not available to the evm directly. This is done by establishing a trust-chain from a blockhash that is already in the registry up to an older block",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L98-L126"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/registries-incomplete-input-validation-and-inconsistent-order-of-validations-pending-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "assert(\\_blockNumber > \\_blockheaders.length);\n\n",
        "function removeNode(uint \\_nodeIndex) internal {\n    // trigger event\n    emit LogNodeRemoved(nodes[\\_nodeIndex].url, nodes[\\_nodeIndex].signer);\n    // deleting the old entry\n    delete urlIndex[keccak256(bytes(nodes[\\_nodeIndex].url))];\n    uint length = nodes.length;\n\n    assert(length > 0);\n\n",
        "function registerNodeFor(\n    string calldata \\_url,\n    uint64 \\_props,\n    uint64 \\_timeout,\n    address \\_signer,\n    uint64 \\_weight,\n    uint8 \\_v,\n    bytes32 \\_r,\n    bytes32 \\_s\n)\n    external\n    payable\n{\n\n",
        "SignerInformation storage si = signerIndex[\\_signer];\n\n",
        "require(si.stage != Stages.Convicted, \"node already convicted\");\n\n",
        "require(!urlIndex[newURl].used, \"url is already in use\");\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue describes general inconsistencies of the smart contract code base. The inconsistencies have been addressed with multiple change-sets:",
        "Issues that have been addressed by the development team:",
        "Fixed in 8d2bfa40 by adding the missing checks.",
        "Fixed in 8d2bfa40 by adding the missing checks.",
        "Fixed in 47255587 by adding the missing checks.",
        "The fix in 47255587 introduced a serious typo (v != _v) that has been fixed with 4a0377c5.",
        "Addressed with the comment that signer gets checked by ecrecover (slock.it/issue/10).",
        "Fixed in 4786a966.",
        "This issue has been reviewed as part of issue 6.16 (99f35fce).",
        "Issues that have not been addressed by the development team and still persist:",
        "This issue has not been addressed.",
        "General Notes:"
    ],
    "Description": [
        "Methods and Functions usually live in one of two worlds:",
        "While it is good practice to visually distinguish internal from public API by following commonly accepted naming convention e.g. by prefixing internal functions with an underscore (_doSomething vs. doSomething) or adding the keyword unsafe to unsafe functions that are not performing checks and may have a dramatic effect to the system (_unsafePayout vs. RequestPayout), it is important to properly verify that inputs to methods are within expected ranges for the implementation.",
        "Input validation checks should be explicit and well documented as part of the code\u2019s documentation. This is to make sure that smart-contracts are robust against erroneous inputs and reduce the potential attack surface for exploitation.",
        "It is good practice to verify the methods input as early as possible and only perform further actions if the validation succeeds. Methods can be split into an external or public API that performs initial checks and subsequently calls an internal method that performs the action.",
        "The following lists some public API methods that are not properly checking the provided data:",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L70-L70",
        "code/in3-contracts/contracts/NodeRegistry.sol:L602-L609",
        "code/in3-contracts/contracts/NodeRegistry.sol:L200-L212",
        "code/in3-contracts/contracts/NodeRegistry.sol:L321-L321",
        "code/in3-contracts/contracts/NodeRegistry.sol:L344-L344",
        "code/in3-contracts/contracts/NodeRegistry.sol:L444-L444"
    ],
    "Recommendation": [
        "Use Checks-Effects-Interactions pattern for all functions."
    ]
}
----End JSON----

https://solodit.xyz/issues/blockhashregistry-recreateblockheaders-allows-invalid-parent-hashes-for-intermediary-blocks-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "for (uint i = 0; i < \\_blockheaders.length; i++) {\n    (calcParent, calcBlockhash) = getParentAndBlockhash(\\_blockheaders[i]);\n    if (calcBlockhash != currentBlockhash) {\n        return 0x0;\n    }\n    currentBlockhash = calcParent;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed by requiring valid parent hashes for blockheaders."
    ],
    "Description": [
        "It is assumed that a blockhash of 0x00 is invalid, but the method accepts intermediary parent hashes extracted from blockheaders that are zero when establishing the trust chain.",
        "recreateBlockheaders relies on reCalculateBlockheaders to correctly establish a chain of trust from the provided list of _blockheaders to a valid blockhash stored in the contract. However, reCalculateBlockheaders fails to raise an exception in case getParentAndBlockhash returns a blockhash of 0x00. Subsequently it will skip over invalid blockhashes and continue to establish the trust chain without raising an error.",
        "This may allow an attacker with enough hashing power to store a blockheader hash that is actually invalid on the real chain but accepted within this smart contract. This may even only be done temporarily to overwrite an existing hash for a short period of time (see https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/24).",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L141-L147"
    ],
    "Recommendation": [
        "Stop processing the array of _blockheaders immediately if a blockheader is invalid."
    ]
}
----End JSON----

https://solodit.xyz/issues/blockhashregistry-recreateblockheaders-succeeds-and-emits-an-event-even-though-no-blockheaders-have-been-provided-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function recreateBlockheaders(uint \\_blockNumber, bytes[] memory \\_blockheaders) public {\n\n    bytes32 currentBlockhash = blockhashMapping[\\_blockNumber];\n    require(currentBlockhash != 0x0, \"parentBlock is not available\");\n\n    bytes32 calculatedHash = reCalculateBlockheaders(\\_blockheaders, currentBlockhash);\n    require(calculatedHash != 0x0, \"invalid headers\");\n\n",
        "bytes32 calculatedHash = reCalculateBlockheaders(\\_blockheaders, currentBlockhash);\n\n",
        "function reCalculateBlockheaders(bytes[] memory \\_blockheaders, bytes32 \\_bHash) public pure returns (bytes32 bhash) {\n\n    bytes32 currentBlockhash = \\_bHash;\n    bytes32 calcParent = 0x0;\n    bytes32 calcBlockhash = 0x0;\n\n    /// save to use for up to 200 blocks, exponential increase of gas-usage afterwards\n    for (uint i = 0; i < \\_blockheaders.length; i++) {\n        (calcParent, calcBlockhash) = getParentAndBlockhash(\\_blockheaders[i]);\n        if (calcBlockhash != currentBlockhash) {\n            return 0x0;\n        }\n        currentBlockhash = calcParent;\n    }\n\n    return currentBlockhash;\n\n",
        "    /// we should never fail this assert, as this would mean that we were able to recreate a invalid blockchain\n    assert(\\_blockNumber > \\_blockheaders.length);\n    uint bnr = \\_blockNumber - \\_blockheaders.length;\n    blockhashMapping[bnr] = calculatedHash;\n    emit LogBlockhashAdded(bnr, calculatedHash);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Fixed the vulnerable scenarios by adding proper checks to:"
    ],
    "Description": [
        "The method is used to re-create blockhashes from a list of rlp-encoded _blockheaders. However, the method never checks if _blockheaders actually contains items. The result is, that the method will unnecessarily store the same value that is already in the blockhashMapping at the same location and wrongly log LogBlockhashAdded even though nothing has been added nor changed.",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L61-L67",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L66-L66",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L134-L149",
        "code/in3-contracts/contracts/BlockhashRegistry.sol:L69-L74"
    ],
    "Recommendation": [
        "The method is crucial for the system to work correctly and must be tightly controlled by input validation. It should not be allowed to overwrite an existing value in the contract (issue 6.29) or emit an event even though nothing has happened. Therefore validate that user provided input is within safe bounds. In this case, that at least one _blockheader has been provided. Validate that _blockNumber is less than block.number and do not expect that parts of the code will throw and safe the contract from exploitation."
    ]
}
----End JSON----

https://solodit.xyz/issues/noderegistryupdatenode-replaces-signer-with-owner-and-emits-inconsistent-events-fixed-consensys-slockit-incubed3-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (newURl != keccak256(bytes(node.url))) {\n\n    // deleting the old entry\n    delete urlIndex[keccak256(bytes(node.url))];\n\n    // make sure the new url is not already in use\n    require(!urlIndex[newURl].used, \"url is already in use\");\n\n    UrlInformation memory ui;\n    ui.used = true;\n    ui.signer = msg.sender;\n    urlIndex[newURl] = ui;\n    node.url = \\_url;\n}\n\n\n",
        "emit LogNodeRegistered(\n    node.url,\n    \\_props,\n    msg.sender,\n    node.deposit\n);\n\n",
        "event LogNodeRegistered(string url, uint props, address signer, uint deposit);\n\n",
        "function updateNode(\n        address \\_signer,\n        string calldata \\_url,\n        uint64 \\_props,\n        uint64 \\_timeout,\n        uint64 \\_weight\n    )\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Reviewed merged changes at in3-contracts/5cb54165.",
        "However, there is a discrepancy between the process of registering a node and updating node\u2019s properties. When registering a node the owner has to provide a signed message containing the registration properties from the signer. Once the node is registered it can be unilaterally updated by the owner without requiring the signers permission to do so. According to slock.it it is assumed that the node owner and the signer are in control of the same entity and therefore this is not a concern."
    ],
    "Description": [
        "When the owner calls updateNode() function providing a new url for the node, the signer of the url is replaced by msg.sender which in this case is the owner of the node. Note that new URL can resolve to the same URL as before (See https://github.com/ConsenSys/slockit-in3-audit-2019-09/issues/36).",
        "code/in3-contracts/contracts/NodeRegistry.sol:L438-L452",
        "Furthermore, the method emits a LogNodeRegistered event when the node structure is updated. However, the event will always emit msg.sender as the signer even though that might not be true. For example, if the url does not change, the signer can still be another account that was previously registered with registerNodeFor and is not necessarily the owner.",
        "code/in3-contracts/contracts/NodeRegistry.sol:L473-L478",
        "code/in3-contracts/contracts/NodeRegistry.sol:L30-L30"
    ],
    "Recommendation": []
}
----End JSON----

https://solodit.xyz/issues/an-account-that-confirms-a-transaction-via-assetproxyowner-can-indefinitely-block-that-transaction-fixed-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/// @dev Allows an owner to confirm a transaction.\n/// @param transactionId Transaction ID.\nfunction confirmTransaction(uint256 transactionId)\n    public\n    ownerExists(msg.sender)\n    transactionExists(transactionId)\n    notConfirmed(transactionId, msg.sender)\n    notFullyConfirmed(transactionId)\n{\n    confirmations[transactionId][msg.sender] = true;\n    emit Confirmation(msg.sender, transactionId);\n    if (isConfirmed(transactionId)) {\n        \\_setConfirmationTime(transactionId, block.timestamp);\n    }\n}\n\n",
        "/// @dev Allows an owner to revoke a confirmation for a transaction.\n/// @param transactionId Transaction ID.\nfunction revokeConfirmation(uint256 transactionId)\n    public\n    ownerExists(msg.sender)\n    confirmed(transactionId, msg.sender)\n    notExecuted(transactionId)\n{\n    confirmations[transactionId][msg.sender] = false;\n    emit Revocation(msg.sender, transactionId);\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2297 by allowing transactions to be \u201cover confirmed\u201d without resetting the confirmation time. As long as there are enough honest signers, this prevents a malicious signer from blocking transactions."
    ],
    "Description": [
        "When a transaction reaches the required number of confirmations in confirmTransaction(), its confirmation time is recorded:",
        "code/contracts/multisig/contracts/src/MultiSigWalletWithTimeLock.sol:L86-L100",
        "Before the time lock has elapsed and the transaction is executed, any of the owners that originally confirmed the transaction can revoke their confirmation via revokeConfirmation():",
        "code/contracts/multisig/contracts/src/MultiSigWallet.sol:L249-L259",
        "Immediately after, that owner can call confirmTransaction() again, which will reset the confirmation time and thus the time lock.",
        "This is especially troubling in the case of a single compromised key, but it\u2019s also an issue for disagreement among owners, where any m of the n owners should be able to execute transactions but could be blocked."
    ],
    "Mitigations": [
        "Only an owner can do this, and that owner has to be part of the group that originally confirmed the transaction. This means the malicious owner may have to front run the others to make sure they\u2019re in that initial confirmation set.",
        "Even once a malicious owner is in position to execute this perpetual delay, they need to call revokeConfirmation() and confirmTransaction() again each time. Another owner can attempt to front the attacker and execute their own confirmTransaction() immediately after the revokeConfirmation() to regain control."
    ],
    "Recommendation": [
        "There are several ways to address this, but to best preserve the original MultiSigWallet semantics, once a transaction has reached the required number of confirmations, it should be impossible to revoke confirmations. In the original implementation, this is enforced by immediately executing the transaction when the final confirmation is received."
    ]
}
----End JSON----

https://solodit.xyz/issues/orders-with-signatures-that-require-regular-validation-can-have-their-validation-bypassed-if-the-order-is-partially-filled-fixed-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Validate either on the first fill or if the signature type requires\n// regular validation.\naddress makerAddress = order.makerAddress;\nif (orderInfo.orderTakerAssetFilledAmount == 0 ||\n    \\_doesSignatureRequireRegularValidation(\n        orderInfo.orderHash,\n        makerAddress,\n        signature\n    )\n) {\n\n",
        "function \\_doesSignatureRequireRegularValidation(\n    bytes32 hash,\n    address signerAddress,\n    bytes memory signature\n)\n    internal\n    pure\n    returns (bool needsRegularValidation)\n{\n    // Read the signatureType from the signature\n    SignatureType signatureType = \\_readSignatureType(\n        hash,\n        signerAddress,\n        signature\n    );\n\n    // Any signature type that makes an external call needs to be revalidated\n    // with every partial fill\n    needsRegularValidation =\n        signatureType == SignatureType.Wallet ||\n        signatureType == SignatureType.Validator ||\n        signatureType == SignatureType.EIP1271Wallet;\n    return needsRegularValidation;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in 0xProject/0x-monorepo#2246. Signatures are now always validated each time, regardless of type."
    ],
    "Description": [
        "The signature types Wallet, Validator, and EIP1271Wallet require explicit validation to authorize each action performed on a given order. This means that if an order was signed using one of these methods, the Exchange must perform a validation step on the signature each time the order is submitted for a partial fill. In contrast, the other canonical signature types (EIP712, EthSign, and PreSigned) are only required to be validated by the Exchange on the order\u2019s first fill; subsequent fills take the order\u2019s existing fill amount as implicit validation that the order has a valid, published signature.",
        "This re-validation step for Wallet, Validator, and EIP1271Wallet signatures is intended to facilitate their use with contracts whose validation depends on some state that may change over time. For example, a validating contract may call into a price feed and determine that some order is invalid if its price deviates from some expected range. In this case, the repeated validation allows 0x users to make orders with custom fill conditions which are evaluated at run-time.",
        "We found that if the sender provides the contract with an invalid signature after the order in question has already been partially filled, the regular validation check required for Wallet, Validator, and EIP1271Wallet signatures can be bypassed entirely."
    ],
    "Examples": [
        "Signature validation takes place in MixinExchangeCore._assertFillableOrder. A signature is only validated if it passes the following criteria:",
        "code/contracts/exchange/contracts/src/MixinExchangeCore.sol:L372-L381",
        "In effect, signature validation only occurs if:",
        "If an order is partially filled, the first condition will evaluate to false. Then, that order\u2019s signature will only be validated if _doesSignatureRequireRegularValidation evaluates to true:",
        "code/contracts/exchange/contracts/src/MixinSignatureValidator.sol:L183-L206",
        "The SignatureType returned from _readSignatureType is directly cast from the final byte of the passed-in signature. Any value that does not cast to Wallet, Validator, and EIP1271Wallet will cause _doesSignatureRequireRegularValidation to return false, skipping validation.",
        "The result is that an order whose signature requires regular validation can be forced to skip validation if it has been partially filled, by passing in an invalid signature."
    ],
    "Recommendation": [
        "There are a few options for remediation:",
        "The first option requires the fewest changes, and does not require storing additional state. While this does mean some additional cost validating subsequent signatures, we feel the increase in flexibility is well worth it, as a maker could choose to create multiple valid signatures for use across different order books."
    ]
}
----End JSON----

https://solodit.xyz/issues/changing-the-owners-or-required-confirmations-in-the-assetproxyowner-can-unconfirm-a-previously-confirmed-transaction-fixed-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function executeTransaction(uint256 transactionId)\n    public\n    notExecuted(transactionId)\n    fullyConfirmed(transactionId)\n\n",
        "/// @dev Returns the confirmation status of a transaction.\n/// @param transactionId Transaction ID.\n/// @return Confirmation status.\nfunction isConfirmed(uint256 transactionId)\n    public\n    view\n    returns (bool)\n{\n    uint256 count = 0;\n    for (uint256 i = 0; i < owners.length; i++) {\n        if (confirmations[transactionId][owners[i]]) {\n            count += 1;\n        }\n        if (count == required) {\n            return true;\n        }\n    }\n}\n\n",
        "/// @dev Allows an owner to confirm a transaction.\n/// @param transactionId Transaction ID.\nfunction confirmTransaction(uint256 transactionId)\n    public\n    ownerExists(msg.sender)\n    transactionExists(transactionId)\n    notConfirmed(transactionId, msg.sender)\n    notFullyConfirmed(transactionId)\n{\n    confirmations[transactionId][msg.sender] = true;\n    emit Confirmation(msg.sender, transactionId);\n    if (isConfirmed(transactionId)) {\n        \\_setConfirmationTime(transactionId, block.timestamp);\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This issue is somewhat inaccurate: isConfirmed() breaks out of the loop once it\u2019s found the correct number of confirmations. That means that lowering the number of required confirmations is not a problem.",
        "Further, 0xProject/0x-monorepo#2297 allows signers to confirm transactions that have already been confirmed.",
        "Increasing signing requirements or changing signers can still unconfirm previously confirmed transactions, but the development team is happy with that behavior."
    ],
    "Description": [
        "Once a transaction has been confirmed in the AssetProxyOwner, it cannot be executed until a lock period has passed. During that time, any change to the number of required confirmations will cause this transaction to no longer be executable.",
        "If the number of required confirmations was decreased, then one or more owners will have to revoke their confirmation before the transaction can be executed.",
        "If the number of required confirmations was increased, then additional owners will have to confirm the transaction, and when the new required number of confirmations is reached, a new confirmation time will be recorded, and thus the time lock will restart.",
        "Similarly, if an owner that had previously confirmed the transaction is replaced, the number of confirmations will drop for existing transactions, and they will need to be confirmed again.",
        "This is not disastrous, but it\u2019s almost certainly unintended behavior and may make it difficult to make changes to the multisig owners and parameters."
    ],
    "Examples": [
        "executeTransaction() requires that at the time of execution, the transaction is confirmed:",
        "code/contracts/multisig/contracts/src/AssetProxyOwner.sol:L115-L118",
        "isConfirmed() checks for exact equality with the number of required confirmations. Having too many confirmations is just as bad as too few:",
        "code/contracts/multisig/contracts/src/MultiSigWallet.sol:L318-L335",
        "If additional confirmations are required to reconfirm a transaction, that resets the time lock:",
        "code/contracts/multisig/contracts/src/MultiSigWalletWithTimeLock.sol:L86-L100"
    ],
    "Recommendation": [
        "As in https://github.com/ConsenSys/0x-v3-audit-2019-09/issues/39, the semantics of the original MultiSigWallet were that once a transaction is fully confirmed, it\u2019s immediately executed. The time lock means this is no longer possible, but it is possible to record that the transaction is confirmed and never allow this to change. In fact, the confirmation time already records this. Once the confirmation time is non-zero, a transaction should always be considered confirmed."
    ]
}
----End JSON----

https://solodit.xyz/issues/reentrancy-in-executetransaction-wont-fix-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Prevent `executeTransaction` from being called when context is already set\naddress currentContextAddress\\_ = currentContextAddress;\nif (currentContextAddress\\_ != address(0)) {\n    LibRichErrors.rrevert(LibExchangeRichErrors.TransactionInvalidContextError(\n        transactionHash,\n        currentContextAddress\\_\n    ));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "From the development team:"
    ],
    "Description": [
        "In MixinTransactions, executeTransaction() and batchExecuteTransactions() do not have the nonReentrant modifier. Because of that, it is possible to execute nested transactions or call these functions during other reentrancy attacks on the exchange. The reason behind that decision is to be able to call functions with nonReentrant modifier as delegated transactions.",
        "Nested transactions are partially prevented with a separate check that does not allow transaction execution if the exchange is currently in somebody else\u2019s context:",
        "code/contracts/exchange/contracts/src/MixinTransactions.sol:L155-L162",
        "This check still leaves some possibility of reentrancy. Allowing that behavior is dangerous and may create possible attack vectors in the future."
    ],
    "Recommendation": [
        "Add a new modifier to executeTransaction() and batchExecuteTransactions() which is similar to nonReentrant but uses different storage slot."
    ]
}
----End JSON----

https://solodit.xyz/issues/poison-order-that-consumes-gas-can-block-market-trades-wont-fix-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// ABI encode calldata for `fillOrder`\nbytes memory fillOrderCalldata = abi.encodeWithSelector(\n    IExchangeCore(address(0)).fillOrder.selector,\n    order,\n    takerAssetFillAmount,\n    signature\n);\n\n(bool didSucceed, bytes memory returnData) = address(this).delegatecall(fillOrderCalldata);\n\n",
        "(bool didSucceed, bytes memory returnData) = verifyingContractAddress.staticcall(callData);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "From the development team:",
        "(Note from the audit team: Hardcoding is not necessary. A parameter would do.)"
    ],
    "Description": [
        "The market buy/sell functions gather a list of orders together for the same asset and try to fill them in order until a target amount has been traded.",
        "These functions use MixinWrapperFunctions._fillOrderNoThrow() to attempt to fill each order but ignore failures. This way, if one order is unfillable for some reason, the overall market order can still succeed by filling other orders.",
        "Orders can still force _fillOrderNoThrow() to revert by using an external contract for signature validation and having that contract consume all available gas.",
        "This makes it possible to advertise a \u201cpoison\u201d order for a low price that will block all market orders from succeeding. It\u2019s reasonable to assume that off-chain order books will automatically include the best prices when constructing market orders, so this attack would likely be quite effective. Note that such an attack costs the attacker nothing because all they need is an on-chain contract that consumers all available gas (maybe via an assert). This makes it a very appealing attack vector for, e.g., an order book that wants to temporarily disable a competitor."
    ],
    "Details": [
        "_fillOrderNoThrow() forwards all available gas when filling the order:",
        "code/contracts/exchange/contracts/src/MixinWrapperFunctions.sol:L340-L348",
        "Similarly, when the Exchange attempts to fill an order that requires external signature validation (Wallet, Validator, or EIP1271Wallet signature types), it forwards all available gas:",
        "code/contracts/exchange/contracts/src/MixinSignatureValidator.sol:L642",
        "If the verifying contract consumes all available gas, it can force the overall transaction to revert."
    ],
    "Pedantic Note": [
        "Technically, it\u2019s impossible to consume all remaining gas when called by another contract because the EVM holds back a small amount, but even at the block gas limit, the amount held back would be insufficient to complete the transaction."
    ],
    "Recommendation": [
        "Constrain the gas that is forwarded during signature validation. This can be constrained either as a part of the signature or as a parameter provided by the taker."
    ]
}
----End JSON----

https://solodit.xyz/issues/front-running-in-matchorders-wont-fix-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function matchOrders(\n    LibOrder.Order memory leftOrder,\n    LibOrder.Order memory rightOrder,\n    bytes memory leftSignature,\n    bytes memory rightSignature\n)\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "From the development team:"
    ],
    "Description": [
        "Calls to matchOrders() are made to extract profit from the price difference between two opposite orders: left and right.",
        "code/contracts/exchange/contracts/src/MixinMatchOrders.sol:L106-L111",
        "The caller only pays protocol and transaction fees, so it\u2019s almost always profitable to front run every call to matchOrders(). That would lead to gas auctions and would make matchOrders() difficult to use."
    ],
    "Recommendation": [
        "Consider adding a commit-reveal scheme to matchOrders() to stop front running altogether."
    ]
}
----End JSON----

https://solodit.xyz/issues/the-exchange-owner-should-not-be-able-to-call-executetransaction-or-batchexecutetransaction-wont-fix-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "// Set the current transaction signer\naddress signerAddress = transaction.signerAddress;\n\\_setCurrentContextAddressIfRequired(signerAddress, signerAddress);\n\n",
        "/// @dev Registers an asset proxy to its asset proxy id.\n/// Once an asset proxy is registered, it cannot be unregistered.\n/// @param assetProxy Address of new asset proxy to register.\nfunction registerAssetProxy(address assetProxy)\n    external\n    onlyOwner\n{\n    // Ensure that no asset proxy exists with current id.\n    bytes4 assetProxyId = IAssetProxy(assetProxy).getProxyId();\n    address currentAssetProxy = \\_assetProxies[assetProxyId];\n    if (currentAssetProxy != address(0)) {\n        LibRichErrors.rrevert(LibExchangeRichErrors.AssetProxyExistsError(\n            assetProxyId,\n            currentAssetProxy\n        ));\n    }\n  \n    // Add asset proxy and log registration.\n    \\_assetProxies[assetProxyId] = assetProxy;\n    emit AssetProxyRegistered(\n        assetProxyId,\n        assetProxy\n    );\n}\n\n",
        "function \\_assertSenderIsOwner()\n    internal\n    view\n{\n    if (msg.sender != owner) {\n        LibRichErrors.rrevert(LibOwnableRichErrors.OnlyOwnerError(\n            msg.sender,\n            owner\n        ));\n    }\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "From the development team:"
    ],
    "Description": [
        "If the owner calls either of these functions, the resulting delegatecall can pass onlyOwner modifiers even if the transaction signer is not the owner. This is because, regardless of the contextAddress set through _executeTransaction, the onlyOwner modifier checks msg.sender."
    ],
    "Examples": [
        "code/contracts/exchange/contracts/src/MixinTransactions.sol:L102-L104",
        "code/contracts/exchange/contracts/src/MixinAssetProxyDispatcher.sol:L38-L61",
        "code/contracts/utils/contracts/src/Ownable.sol:L35-L45"
    ],
    "Recommendation": [
        "Add a check to _executeTransaction that prevents the owner from calling this function."
    ]
}
----End JSON----

https://solodit.xyz/issues/anyone-can-front-run-mixinexchangecorecancelorder-wont-fix-consensys-0x-v3-exchange-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "From the development team:"
    ],
    "Description": [
        "In order to cancel an order, an authorized address (maker or sender) calls cancelOrder(LibOrder.Order memory order). When calling that function, all data for the order becomes visible to everyone on the network, and anyone can fill that order before it\u2019s canceled.",
        "Usually, a maker is canceling an order because it\u2019s no longer profitable for them, so an attacker is likely to profit from front running the cancelOrder() transaction."
    ],
    "Recommendation": [
        "Make it impossible to front run order cancelation by providing less data to the cancelOrder() function such that this data is insufficient to execute the order."
    ]
}
----End JSON----

https://solodit.xyz/issues/intentional-secret-reuse-can-block-borrower-and-lender-from-accepting-liquidation-payment-fixed-consensys-atomic-loans-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "\tfunction provideSecret(bytes32 sale, bytes32 secret\\_) external {\n\t\trequire(sales[sale].set);\n\t\tif      (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashA) { secretHashes[sale].secretA = secret\\_; }\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashB) { secretHashes[sale].secretB = secret\\_; }\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashC) { secretHashes[sale].secretC = secret\\_; }\n        else if (sha256(abi.encodePacked(secret\\_)) == secretHashes[sale].secretHashD) { secretHashes[sale].secretD = secret\\_; }\n        else                                                                          { revert(); }\n\t}\n\n",
        "\tfunction accept(bytes32 sale) external {\n        require(!accepted(sale));\n        require(!off(sale));\n\t\trequire(hasSecrets(sale));\n\t\trequire(sha256(abi.encodePacked(secretHashes[sale].secretD)) == secretHashes[sale].secretHashD);\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in AtomicLoans/atomicloans-eth-contracts#65."
    ],
    "Description": [
        "For Dave (the liquidator) to claim the collateral he\u2019s purchasing, he must reveal secret D. Once that secret is revealed, Alice and Bob (the borrower and lender) can claim the payment.",
        "Secrets must be provided via the Sales.provideSecret() function:",
        "code/ethereum/contracts/Sales.sol:L193-L200",
        "Note that if Dave chooses the same secret hash as either Alice, Bob, or Charlie (arbiter), there is no way to set secretHashes[sale].secretD because one of the earlier conditionals will execute.",
        "For Alice and Bob to later receive payment, they must be able to provide Dave\u2019s secret:",
        "code/ethereum/contracts/Sales.sol:L218-L222",
        "Dave can exploit this to obtain the collateral for free:"
    ],
    "Mitigating factors": [
        "Alice and Bob could notice that Dave chose a duplicate secret hash and refuse to proceed with the sale. This is not something they are likely to do."
    ],
    "Recommendation": [
        "Either change the way provideSecret() works to allow for duplicate secret hashes or reject duplicate hashes in create()."
    ]
}
----End JSON----

https://solodit.xyz/issues/there-is-no-way-to-convert-between-custom-and-non-custom-funds-wont-fix-consensys-atomic-loans-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function create(\n    uint256  maxLoanDur\\_,\n    uint256  maxFundDur\\_,\n    address  arbiter\\_,\n    bool     compoundEnabled\\_,\n    uint256  amount\\_\n) external returns (bytes32 fund) {\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\n\n",
        "function createCustom(\n    uint256  minLoanAmt\\_,\n    uint256  maxLoanAmt\\_,\n    uint256  minLoanDur\\_,\n    uint256  maxLoanDur\\_,\n    uint256  maxFundDur\\_,\n    uint256  liquidationRatio\\_,\n    uint256  interest\\_,\n    uint256  penalty\\_,\n    uint256  fee\\_,\n    address  arbiter\\_,\n    bool     compoundEnabled\\_,\n    uint256  amount\\_\n) external returns (bytes32 fund) {\n    require(fundOwner[msg.sender].lender != msg.sender || msg.sender == deployer); // Only allow one loan fund per address\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Users who want to switch between custom and non-custom funds can create a new address to do so. This is not actually a big burden because lenders need to use agent software to manage their funds anyway. That workflow typically involves generating a new address because the private key needs to be given to the agent software."
    ],
    "Description": [
        "Each fund is created using either Funds.create() or Funds.createCustom(). Both enforce a limitation that there can only be one fund per account:",
        "code/ethereum/contracts/Funds.sol:L348-L355",
        "code/ethereum/contracts/Funds.sol:L383-L397",
        "These functions are the only place where bools[fund].custom is set, and there\u2019s no way to delete a fund once it exists. This means there\u2019s no way for a given account to switch between a custom and non-custom fund.",
        "This could be a problem if, for example, the default parameters change in a way that a user finds unappealing. They may want to switch to using a custom fund but find themselves unable to do so without moving to a new Ethereum account."
    ],
    "Recommendation": [
        "Either allow funds to be deleted or allow funds to be switched between custom and non-custom."
    ]
}
----End JSON----

https://solodit.xyz/issues/fundsmaxfunddur-has-no-effect-if-maxloandur-is-set-fixed-consensys-atomic-loans-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "if (maxLoanDur(fund) > 0) {\n    require(loanDur\\_       <= maxLoanDur(fund));\n} else {\n    require(now + loanDur\\_ <= maxFundDur(fund));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in AtomicLoans/atomicloans-eth-contracts#68."
    ],
    "Description": [
        "Funds.maxFundDur specifies the maximum amount of time a fund should be active. It\u2019s checked in request() to ensure the duration of the loan won\u2019t exceed that time, but the check is skipped if maxLoanDur is set:",
        "code/ethereum/contracts/Funds.sol:L510-L514"
    ],
    "Examples": [
        "If a user sets maxLoanDur (the maximum loan duration) to 1 week and sets the maxFundDur (timestamp when all loans should be complete) to December 1st, then there can actually be a loan that ends on December 7th."
    ],
    "Recommendation": [
        "Check against maxFundDur even when maxLoanDur is set."
    ]
}
----End JSON----

https://solodit.xyz/issues/readonlymode-is-ineffective-and-may-result-in-a-false-sense-of-security-addressed-consensys-pegasys-permissioning-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "This was addressed in PegaSysEng/[email\u00a0protected]ed2d4a2 by adding comments to clarify that readOnlyMode is meant simply to prevent accidental changes during upgrades."
    ],
    "Description": [
        "AccountRules and NodeRules can both enter and exit a mode of operation called readOnlyMode.",
        "The only effect of readOnlyMode is to prevent admins (who are the only users able to change rules) from changing rules.",
        "Those same admins can disable readOnlyMode, so this mode will not prevent a determined actor from doing something they want to do."
    ],
    "Recommendation": [
        "Either readOnlyMode should be removed to prevent it from providing a false sense of security, or the authorization required to toggle readOnlyMode should be separated from the authorization required to change rules."
    ]
}
----End JSON----

https://solodit.xyz/issues/ingresssetcontractaddress-can-cause-duplicate-entries-in-contractkeys-fixed-consensys-pegasys-permissioning-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function setContractAddress(bytes32 name, address addr) public returns (bool) {\n    require(name > 0x0000000000000000000000000000000000000000000000000000000000000000, \"Contract name must not be empty.\");\n    require(isAuthorized(msg.sender), \"Not authorized to update contract registry.\");\n\n    ContractDetails memory info = registry[name];\n    // create info if it doesn't exist in the registry\n    if (info.contractAddress == address(0)) {\n        info = ContractDetails({\n            owner: msg.sender,\n            contractAddress: addr\n        });\n\n        // Update registry indexing\n        contractKeys.push(name);\n   } else {\n        info.contractAddress = addr;\n   }\n    // update record in the registry\n    registry[name] = info;\n\n    emit RegistryUpdated(addr,name);\n\n    return true;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "This is fixed in PegaSysEng/[email\u00a0protected]faff726."
    ],
    "Description": [
        "setContractAddress() checks ContractDetails existence by inspecting contractAddress. A contractAddress of 0 means that the contract does not already exist, and its name must be added to contractKeys:",
        "code/contracts/Ingress.sol:L39-L62",
        "If, however, a contract is actually added with the address 0, which is currently allowed in the code, then the contract does already exists, and adding the name to contractKeys again will result in a duplicate."
    ],
    "Mitigation": [
        "An admin can call removeContract repeatedly with the same name to remove multiple duplicate entries."
    ],
    "Recommendation": [
        "Either disallow a contract address of 0 or check for existence via the owner field instead (which can never be 0)."
    ]
}
----End JSON----

https://solodit.xyz/issues/memory-corruption-in-buffer-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "/\\*\\*\n\\* @dev Initializes a buffer with an initial capacity.\n\\* @param buf The buffer to initialize.\n\\* @param capacity The number of bytes of space to allocate the buffer.\n\\* @return The buffer, for chaining.\n\\*/\nfunction init(buffer memory buf, uint capacity) internal pure returns(buffer memory) {\n    if (capacity % 32 != 0) {\n        capacity += 32 - (capacity % 32);\n    }\n    // Allocate space for the buffer data\n    buf.capacity = capacity;\n    assembly {\n        let ptr := mload(0x40)\n        mstore(buf, ptr)\n        mstore(ptr, 0)\n        mstore(0x40, add(32, add(ptr, capacity)))\n    }\n    return buf;\n}\n\n",
        "contract Test {\n    using Buffer for Buffer.buffer;\n\n    function test() external pure {\n        Buffer.buffer memory buffer;\n        buffer.init(1);\n\n        // foo immediately follows buffer.buf in memory\n        bytes memory foo = new bytes(0);\n       \n        assert(foo.length == 0);\n\n        buffer.append(\"A\");\n\n        // \"A\" == 65, gets written to the high order byte of foo.length\n        assert(foo.length == 65 \\* 256\\*\\*31);\n    }\n}\n\n",
        "mstore(0x40, add(ptr, add(capacity, 32)))\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue has been closed in ensdomains/buffer#3"
    ],
    "Description": [
        "Although out of scope for this audit, the audit team noticed a memory corruption issue in the Buffer library. The init function is as follows:",
        "contracts/Buffer.sol:L22-L41",
        "Note that memory is reserved only for capacity bytes, but the bytes actually requires capacity + 32 bytes to account for the prefixed array length. Other functions in Buffer assume correct allocation and therefore corrupt nearby memory.",
        "Although we didn\u2019t immediately spot an ENS exploit for this vulnerability, we consider any memory corruption issue to be important to address."
    ],
    "Example": [
        "A simple test shows the memory corruption issue:"
    ],
    "Remediation": [
        "Allocate an additional 32 bytes as follows, to account for storing the uint256 size of the bytes array:"
    ]
}
----End JSON----

https://solodit.xyz/issues/simplepriceoracleprice-is-susceptible-to-integer-overflow-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function price(string calldata /\\*name\\*/, uint /\\*expires\\*/, uint duration) external view returns(uint) {\n    return duration \\* rentPrice;\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue has been closed in ensdomains/ethregistrar#17 by using SafeMath."
    ],
    "Description": [
        "SimplePriceOracle.price is as follows:",
        "ethregistrar/contracts/SimplePriceOracle.sol:L26-L28",
        "This is susceptible to a simple overflow attack, e.g. setting the duration to 2**256/rentPrice to give yourself a price of 0.",
        "Severity note: It\u2019s unclear whether the SimplePriceOracle is expected to be used in practice, but the severity is set here under the assumption that the code may be used somewhere."
    ],
    "Remediation": [
        "Use SafeMath or explicitly check for the overflow."
    ]
}
----End JSON----

https://solodit.xyz/issues/ethregistrarcontrollerregister-is-vulnerable-to-front-running-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function makeCommitment(\n    string memory name,\n    address owner, /\\* or perhaps committer/sender \\*/\n    bytes32 secret\n)\n    pure\n    public\n    returns(bytes32)\n{\n    bytes32 label = keccak256(bytes(name));\n    return keccak256(abi.encodePacked(label, owner, secret));\n}\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue has been closed in ensdomains/ethregistrar#18"
    ],
    "Description": [
        "commit() and then register() appears to serve the purpose of preventing front running. However, because the commitment is not tied to a specific owner, it serves equally well as a commitment for a front-running attacker."
    ],
    "Example": [],
    "Remediation": [
        "Commitments should commit to owners in addition to names. This way an attacker can\u2019t repurpose a previous commitment. (They would have to buy on behalf of the original committer.)",
        "As an alternative, if it\u2019s undesirable to pin down owner, the commitment could include msg.sender instead (only allowing the original committer to call register).",
        "E.g. the following (and corresponding changes to callers):"
    ]
}
----End JSON----

https://solodit.xyz/issues/soa-record-check-on-the-wrong-domain-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "During the audit, this issue was discovered by the client development team and already fixed in ensdomains/root#25."
    ],
    "Description": [
        "The SOA record check in Root.getAddress is meant to happen on the root TLD, but in the version of the code audited, it is performed instead on _ens.nic.<tld>."
    ]
}
----End JSON----

https://solodit.xyz/issues/work-towards-a-trustless-model-for-ens-acknowledged-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Acknowledged by client team. As stated, this is a long-term issue for which there is no immediate fix, but work is already in progress."
    ],
    "Description": [
        "The ENS registry itself is owned by a multisig wallet owned by a number of reputable Ethereum community members. That multisig wallet can do just about anything, up to and including directly taking over any existing or future registered names.",
        "It\u2019s important to note that even if we as a community trust the current owners of the multisig wallet, we also need to consider the possibility of their Ethereum private keys being compromised by malicious actors."
    ],
    "Remediation": [
        "This centralized control is by design, and the multisig owners have been chosen carefully. However, we do recommend\u2014as is already the plan\u2014that the multisig wallet\u2019s power be reduced in future updates to the system. Changes made by that wallet are already quite transparent to the community, but future enhancements might include requiring a waiting period for any changes or disallowing certain types of changes altogether.",
        "In the meantime, wherever possible, the trust model should be made clear so that users understand what guarantees they do and do not have when interacting with ENS."
    ]
}
----End JSON----

https://solodit.xyz/issues/consider-replacing-the-buffer-implementation-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "There will be no immediate fix for this, but the client team is working on collaborating to get a better audited Buffer library in place."
    ],
    "Description": [
        "The audit team uncovered two bugs in the Buffer library, one each in the only two functions that were looked at. (The library was in general not in scope for this audit.) One bug was a critical memory corruption bug. This calls into question how safe this library is to use in general."
    ],
    "Remediation": [
        "Consider using a different library, ideally one that has been fully tested and audited and that minimizes the use of inline assembly, particularly around memory allocation."
    ]
}
----End JSON----

https://solodit.xyz/issues/overzealous-resizing-in-buffer-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [
        "function write(buffer memory buf, uint off, bytes memory data, uint len) internal pure returns(buffer memory) {\n    require(len <= data.length);\n\n    if (off + len > buf.capacity) {\n        resize(buf, max(buf.capacity, len + off) \\* 2);\n\n",
        "function write(buffer memory buf, uint off, bytes32 data, uint len) private pure returns(buffer memory) {\n    if (len + off > buf.capacity) {\n        resize(buf, (len + off) \\* 2);\n    }\n\n"
    ],
    "preamble": [],
    "Resolution": [
        "Issue has been closed in ensdomains/buffer#4"
    ],
    "Description": [
        "In the following code, the buffer is resized even when sufficient capacity is available to perform the write. The buf.buf.length term is unnecessary and leads to unnecessary resizing:",
        "contracts/Buffer.sol:L91-L95",
        "Contrast with the calculation in a similar function:",
        "contracts/Buffer.sol:L206-L209"
    ],
    "Remediation": [
        "Check just the condition if (off + len > buf.capacity) when deciding whether to resize the buffer. This will be a significant gas savings in the common case of reserving exactly the right capacity and then performing two append operations."
    ]
}
----End JSON----

https://solodit.xyz/issues/pending-auctions-in-the-legacy-registrar-dont-result-in-proper-ownership-in-ens-fixed-consensys-ens-permanent-registrar-markdown
--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Addressed in ensdomains/ethregistrar#23 by reducing the waiting period to 28 days."
    ],
    "Description": [
        "If an auction has yet to be finalized in the legacy HashRegistrar at the time that the new, permanent .eth registrar is put in place, the auction winner doesn\u2019t get actual ownership of the ENS entry.",
        "The sequence of events would look like:",
        "At this point, there\u2019s an owner of the deed for the name something.eth in the HashRegistrar, but the ENS subnode is unowned. It can\u2019t be transferred to the new registrar for 183 days, and the name can\u2019t be registered in the new registrar.",
        "The owner can get themselves out of this situation by calling releaseDeed in the HashRegistrar. If they want to avoid potentially losing their domain in the process, they can transfer the deed to a smart contract which can then release the deed and rent the same name in the new registrar atomically."
    ],
    "Remediation": [
        "Here are a few ideas of improvements to help in this situation:"
    ]
}
----End JSON----

https://solodit.xyz/issues/baseregistrarimplementationacceptregistrartransfer-should-probably-use-the-live-modifier-fixed-consensys-ens-permanent-registrar-markdown--------------------------------------------------
----Start JSON----
{
    "code": [],
    "preamble": [],
    "Resolution": [
        "Issue has been closed in ensdomains/ethregistrar#19."
    ],
    "Description": [
        "Most external functions in BaseRegistrarImplementation have the live modifier, which ensures that they can only be called on the current ENS owner of the registrar\u2019s base address. The acceptRegistrarTransfer function does not have this modifier, which means names can be transferred to the new registrar even if it\u2019s not the proper registry owner.",
        "It\u2019s hard to think of a real-world example of why this is problematic, especially because the interim registrar appears to protect against this by only transferring to the ens.owner, but it seems safer to include the live modifier unless there\u2019s a specific reason not to."
    ],
    "Remediation": [
        "Add the live modifier to acceptRegistrarTransfer."
    ]
}
----End JSON----
